{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-17T12:20:22.648592Z",
     "start_time": "2023-11-17T12:20:22.637548Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h1 align=\"center\">SWMAL</h1>\n",
       "<h3 align=\"center\">Assignment O3</h3>\n",
       "<h3 align=\"center\">Group 24</h3>\n",
       "<h5 align=\"center\">November 17 2023</h5>\n",
       "\n",
       "\n",
       "|Name|Student Number |\n",
       "|:---|:---|\n",
       "|Sean Harboe Bateman|200203025|\n",
       "|Martin Stokholm Lauridsen|201908195|\n",
       "|Christain Duwe Konnerup|202010016|"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown,display\n",
    "\n",
    "display(Markdown(\"header.md\"))"
   ]
  },
  {
   "attachments": {
    "model_plot.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Networks (CNNs)\n",
    "A CNN is a neural network model that is specialized in working with images or videos in a 2D dimension. A CNN is used for processing the images or videos in a grid. So in general CNN is used for series data and pattern recognition.\n",
    "\n",
    "To make a CNN there has to be different layers, these layers is the foundation for creating a functional CNN model. The layers also called convolutional layers, these layers is what gives the entire networks it's name. One of the important terms when talking about CNN's is filters. Filters is what gives a CNN the functionality for pattern recognition.\n",
    "\n",
    "`Convolutional layers` these layers are what applies the different filters to the different neurons data. These layers are linear operations that can apply 1 or more filters to a neuron at once, so the different neurons have different biases. Applying a convolutional layer to neuron will multiply the pixels from the neuron data with the bias from all the filters. After applying the filters the sum of region that the filter is applied to is made. When this has happened to all the regions, there will automatically generate a new matrix where every region is made of a sum. This new matrix is used by the network to learn the different features that are in the dataset. These layers can help determine a pattern in the dataset.\n",
    "\n",
    "`Fully Connected layers` is a combination multiple convolutional and pooling layers. A fully connected layer is a true copy of a real neural network, where every neuron from a previous layer is connected to every neuron in a new layer.\n",
    "\n",
    "`Pooling layers` is used to reduce the image into smaller regions. This is done by segmenting the image into groups of pixels. There is different ways of doing pooling. There is max pooling which takes the max value from a group of the neighbouring regions pixels and inputs it into the feature map instead of its own value. The other pooling method is called average pooling. When using average pooling it takes the average value of all the regions in the local region it is in. The reason for using pooling is to find the most active regions of pixels and shrink down the dimensions.\n",
    "\n",
    "`Multiple channels` is often used when working with processing of images or videos. Multiple channels allow the CNN to have different channels for the different color spectrum's. The multiple channels can also be used to create outlines on the different images. Each convolutional filter is applied to every multiple channel independently.\n",
    "\n",
    "`Activation Functions` is used to teach the model the complex relations between all the features in the data used. Activation functions is non-linear. Some examples on activation functions would be `Relu` or `softmax`.\n",
    "\n",
    "`Generlization` is used to ensure a models performance with unseen data, so that it does not matter how big the dataset is the model should still be able to perform somewhat decent. We used a stratified k-fold to make sure we had cross-validation on the dataset.\n",
    "\n",
    "`Learning Curve` can be seen in the plots we have made that illustrates the training loss and accuracy from the different iterations. Training loss measures the performance of the model while doing training. It is possible to see that over time that the training loss gets smaller and the prediction value gets closer to the actual value the longer it trains. The same happens to the accuracy, from start to finish its possible to see it grow closer to a score of 1.\n",
    "\n",
    "`Code Setup`\n",
    "- Import libraries needed\n",
    "- Get data from mnist\n",
    "- Setup train and test data with reshaping\n",
    "- Create CNN model\n",
    "- Initial setup for stratified k-fold\n",
    "- Setup array to store test accuracy\n",
    "- For loop that creates the model fits the model\n",
    "- Plotting the training loss and accuracy\n",
    "- Printing average score\n",
    "\n",
    "<img src=\"model_plot.png\" style=\"height:500px\">\n",
    "`Testing different epochs` we tried a lot of different combinations of epochs, folds and some different layers. however the best score was while using 6 folds and 20 epochs, and the final average score we ended up getting is `0.9927`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-17T11:37:23.644886Z",
     "start_time": "2023-11-17T11:22:19.808987Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0340 - accuracy: 0.9915\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0383 - accuracy: 0.9928\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0472 - accuracy: 0.9900\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0371 - accuracy: 0.9924\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0549 - accuracy: 0.9893\n",
      "Test average accuracy: 0.989300012588501\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import keras\n",
    "from keras.utils import plot_model\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "(x_train, y_train ), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape((-1,28,28,1)).astype('float32') / 255.0\n",
    "x_test = x_test.reshape((-1,28,28,1)).astype('float32') / 255.0\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes=10)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes=10)\n",
    "\n",
    "def create():\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Conv2D(32,(3,3), activation='relu', input_shape=(28,28,1)))\n",
    "    model.add(keras.layers.MaxPooling2D((2, 2)))\n",
    "    model.add(keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(keras.layers.MaxPooling2D((2, 2)))\n",
    "    model.add(keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(64, activation='relu'))\n",
    "    model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "    plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)\n",
    "\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "folds = 6\n",
    "kfold = StratifiedKFold(n_splits=folds, shuffle=True, random_state=50)\n",
    "test_accuracy = []\n",
    "\n",
    "training_loss = []\n",
    "training_accuracy = []\n",
    "\n",
    "for train, val in kfold.split(x_train,y_train.argmax(1)):\n",
    "\n",
    "    model = create()\n",
    "\n",
    "    x_train_kfold, x_val_kfold = x_train[train], x_train[val]\n",
    "    y_train_kfold, y_val_kfold = y_train[train], y_train[val]\n",
    "\n",
    "    epoch_loss = []\n",
    "    epoch_accuracy = []\n",
    "\n",
    "    for epochs in range(20):\n",
    "        modelhis = model.fit(x_train_kfold, y_train_kfold, epochs=1, batch_size=64, verbose=0)\n",
    "\n",
    "        epoch_loss.append(modelhis.history['loss'][0])\n",
    "        epoch_accuracy.append(modelhis.history['accuracy'][0])\n",
    "\n",
    "    training_loss.append(epoch_loss)\n",
    "    training_accuracy.append(epoch_accuracy)\n",
    "\n",
    "    test_loss, test_accuracy = model.evaluate(x_test,y_test)\n",
    "\n",
    "avg_accuracy = np.mean(test_accuracy)\n",
    "print(f'Test average accuracy: {avg_accuracy}')\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(np.mean(training_loss, axis=0), label='Training Loss')\n",
    "plt.title('Training Losss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(np.mean(training_accuracy, axis=0), label='Training Accuracy')\n",
    "plt.title('Training Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Conlusion`\n",
    "We have worked with CNN's and trained a model in processing images. Throughout the exercise we have tried a lot of different methods of doing processing on images using CNN's. We ended on the final version of our CNN which can maintain a high accuracy when using the MNIST dataset. We have tried different setup of layers, epochs and folds. The final result gave an accuracy of `0.9927`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SWMAL Exercise\n",
    "\n",
    "## Generalization Error\n",
    "\n",
    "In this exercise we are going to explain important overall concepts in training. \n",
    "\n",
    "First we look Figure 5.3 from Deep Learning (Ian Goodfellow, et. al. [DL]).\n",
    "\n",
    "<img src=\"https://itundervisning.ase.au.dk/SWMAL/L08/Figs/dl_generalization_error.png\" alt=\"WARNING: could not get image from server.\" style=\"height:500px\">\n",
    "\n",
    "The figure shows the typical relationship between the error and the capacity, where the test error and generelization error behave differently.The left side of the plot shows the underfitting regime where both errors are very high. Following an increase in capacity the training error gets lower. Meanwhile the gap between the training error and the generalization error gets increased. and then we are in the overfitting regime. Then the capacity is too large.  \n",
    "\n",
    "### Qa) On Generalization Error\n",
    "\n",
    "Explanation of concepts in the figure above:\n",
    "\n",
    "#### Training error\n",
    "The training error is the blue line in graph and describes the error in relation to the capacity of the training model as a percentage. The training error indicates how well the model understands patterns in the training data, where a low training error indicates that the model has a good understanding of the training data.\n",
    "\n",
    "#### Generalization error\n",
    "The green line on the graph is the generalization error and describes the error in the training model when it is tested on new data. The generalization error indicates how well the model can predict new data, where a low generalization error indicates that the model can predict new data well.\n",
    "\n",
    "#### Underfitting\n",
    "When the capacity of the model is too low, the model will not be able to understand the patterns in the training data. This will result in a high training error and a high generalization error. This is called underfitting and can be corrected by increasing the capacity of the model.\n",
    "\n",
    "#### Overfitting\n",
    "When the capacity of the model is too high, the model will be able to understand the patterns in the training data very well. This will result in a low training error and a high generalization error. This is called overfitting and can be corrected by decreasing the capacity of the model.\n",
    "\n",
    "#### Generalization gap\n",
    "The generalization gap is the vertical difference between the training error and the generalization error. The generalization gap is high when the model is overfitting and low when the model is underfitting.\n",
    "\n",
    "#### Optimal capacity \n",
    "When fitting the model we want to find the optimal capacity where the model can recoqnize patterns in the training set that can be used on new data but without being too specific and picking up noise in the training data. This is the point where the generalization error is lowest.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qb A MSE-Epoch/Error Plot\n",
    "\n",
    "Now we are taking a look at the SGD model for fitting polynomial, that is _polynomial regression_ which is similar to the Géron one, described in [HOML] (\"Polynomial Regression\" + \"Learning Curves\"). \n",
    "\n",
    "#### Part 1\n",
    "So as we've seen before there is a function for GenerateData that seed random data points for and also adds some noise. Then the data is split into the training and validation sets.\n",
    "\n",
    "In the pipeline we again use the polynominial feature but with a 90 degree, and no bias in order to get a model with very high capacity. The second preprocessor is the standard scaler which standardizes the features in our data set. By removing the mean and centerring the feautre distribution around 0 and scaling the variance to 1.\n",
    "\n",
    "lastly the poly_scaler is transformed into the training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-17T10:28:27.534070200Z",
     "start_time": "2023-11-17T10:28:27.263874Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape= (25, 1)\n",
      "X_val  .shape= (25, 1)\n",
      "y_train.shape= (25,)\n",
      "y_val  .shape= (25,)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjIAAAHACAYAAAC4foLWAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA2iUlEQVR4nO3deXhU9b3H8c8kkhCWBCGELSGgpG7gBmhZxKCWVKkF760b9wpKkGABRa4V6SJo1WhV3EXQCFiKYqsILm1BbwAVqaCIio8IaIQRLZtMFHWQ5Nw/5iaQfSaznPM75/16nnlCTmYyX06SOZ/5rT7LsiwBAAAYKMnuAgAAAJqLIAMAAIxFkAEAAMYiyAAAAGMRZAAAgLEIMgAAwFgEGQAAYCyCDAAAMBZBBgAAGIsgAwAAjJWwILN69WpdeOGF6tq1q3w+n1544YUaX7csSzNnzlTXrl2Vlpam/Px8bdq0KVHlAQAAAyUsyBw4cECnnHKKHn744Xq//qc//UmzZs3Sww8/rHXr1qlz58762c9+pm+++SZRJQIAAMP47Ng00ufzacmSJRo5cqSkUGtM165dNWXKFE2bNk2SFAwG1alTJ911110qKipKdIkAAMAAR9ldgCR99tln+uqrrzRs2LDqY6mpqTr77LO1Zs2aBoNMMBhUMBis/ryyslL79u1Thw4d5PP54l43AACInmVZ+uabb9S1a1clJUXWWeSIIPPVV19Jkjp16lTjeKdOnfT55583+Lji4mLdcsstca0NAAAkxo4dO5SdnR3RYxwRZKrUbkWxLKvRlpXp06dr6tSp1Z8HAgF1795dO3bsUHp6etzqBAAA4Vm9WrrwwrrHX3pJOuus0L/Ly8uVk5Ojtm3bRvz9HRFkOnfuLCnUMtOlS5fq47t27arTSnOk1NRUpaam1jmenp5OkAEAwAFOPVVKSpIqKw8fS06WTjlFqn2pbs6wEEesI9OzZ0917txZK1asqD528OBBrVq1SgMHDrSxMgAAEI3sbGnu3FB4kUIf58wJHY+FhLXIfPvtt9q6dWv155999pnee+89tW/fXt27d9eUKVN0xx13KC8vT3l5ebrjjjvUqlUrjRo1KlElAgCAOCgslAoKpK1bpV69YhdipAQGmfXr12vo0KHVn1eNbRkzZozmz5+vG2+8Ud9//71+/etf6+uvv9aZZ56p5cuXN6u/DAAAOEt2dmwDTBVb1pGJl/LycmVkZCgQCDBGBgAAQ0Rz/XbEGBkAAIDmIMgAAABjOWL6tZ0qKir0448/2l0GEJXk5GS1aNHC7jIAIOE8G2Qsy9JXX32lQCAgFw0TgoelpqYqMzOT8WEAPMWzQSYQCGj//v3q2LGjWrduzd5MMJZlWfrxxx8VCAT0xRdfSBJhBoBneDLIWJalXbt2KT09XZmZmXaXA0QtLS1Nbdu2ld/v1549ewgyADzDk4N9KyoqVFFRwYs9XMXn8ykjI0PBYJBxXwA8w5NB5tChQ5Kko47yZIMUXKxqwG9FRYXNlQBAYngyyFRhXAzcht9pAF7j6SADAADMRpABAADGIsggbD169FCPHj1qHJs/f758Pp/mz59vS00AAG8jyECjR4+Wz+dT586dqwdCx8Pnn3+u9PR0derUSXv27Kn3PldddZV8Pp/uv//+uNVRm8/nq3FLS0tT586dNXjwYN1www3auHFjTJ6H0AcAsUeQ8bjy8nI999xz8vl8+ve//62XX345bs+Vm5urWbNmadeuXZowYUKdr7/00kuaP3++hgwZomuvvTZuddSnQ4cOmjFjhmbMmKGpU6dqxIgRCgaDuvfee3XqqaeqsLBQwWAwoTUBAJrG/GOPe/rpp/Xdd9/phhtu0L333quSkhKNGDEibs83btw4Pf/883ruuee0aNEijRo1SpK0d+9eXX311WrdurXmzZunpKTEZuzMzEzNnDmzzvEPPvhAo0eP1pNPPqmDBw/qz3/+c0LrAgA0jhYZjyspKVFKSoqmT5+uQYMG6ZVXXtGXX34Z1+d84okndPTRR2vy5MnVzzVx4kR99dVXuvvuu3XMMcc0+T3OPvtstWjRosFaL7nkEvl8Pm3YsCGqWvv06aPly5crKytLCxcu1Ntvv139tYMHD+qhhx5SQUGBcnJylJqaqqysLP3Hf/xHnee98sorddVVV0k63H1WdavyzjvvaNKkSerdu7cyMjKUlpamPn366M4772SBOwBoAEEmzvx+qbQ09NFpPvjgA61bt07Dhw9X+/btNXr0aFVUVGjBggVxfd6uXbvqwQcf1L59+3T11Vfr2Wef1eLFi3XeeefV2+VUn6KiIh06dEjz5s2r87U9e/Zo6dKl6tu3r0477bSo6+3YsWN1XYsXL64+vm/fPk2ZMkXBYFAXXHCBrr/+euXn5+uVV17RwIEDtW7duur7jhw5srqla8SIEdXdWDNmzKi+z+OPP64lS5aoT58+KioqUmFhoSzL0vTp03XZZZdF/f8AAFeyXCQQCFiSrEAg0Oj9vv/+e+ujjz6yvv/++7jW88QTlpWUZFlS6OMTT8T16SJ23XXXWZKs559/3rIsy9q/f7/VsmVLKy8vr9775+bmWrm5uTWOzZs3z5JkzZs3L+LnHzlypCXJSk1NtdLT063t27eH/dgffvjB6tChg3XsscdalZWVNb42a9YsS5I1e/bssL6XJOu4445r9D6vvfaaJck666yzatTg9/vr3PfDDz+02rRpY5133nk1jjd1rsrKyqxDhw7VOFZZWWmNHTvWkmS98cYbTf5fEvW7DQCxFO71uz60yMSJ3y+NHy9VVoY+r6yUioqc0zJz8OBBLVy4UEcffbSGDx8uScrIyNCIESO0ZcsWrV69Ou41FBcXS5KCwaBuvfVW5eTkhP3Y1NRUjRkzRtu2bVNpaWmNr5WUlKhVq1bV429ioWvXrpJUY7ZVamqqunXrVue+J510koYOHarVq1dH1CWUm5ur5OTkGsd8Pp8mTpwoSXr11VebUzoAuBpBJk62bDkcYqpUVEhbt9pTT20vvPCC9u7dq0svvVQpKSnVx0ePHi1JevLJJ+New2233VajHsuyany9rKxMM2fOrHE7clr2+PHjJYXG3FRZu3atNm3apEsuuSSmm4LWrq3Ke++9p1GjRql79+5KSUmpHvfy4osv6uDBgw1OM6/PwYMHNWvWLJ1xxhlKT09XUlKSfD6f+vbtK0nauXNnTP4vAOAmzFqKk7w8KSmpZphJTpZ69bKvpiNVBZUrrriixvGCggJ17txZf/3rX/Xggw/GbYfwJUuW6C9/+YvOPfdcdezYUc8884weffTR6tYHKRRkbrnllhqPy83N1ZQpUyRJxx13nM4++2w9//zz2rdvn9q3b18daq6++uqY1ls1qLhjx47Vx9asWaNzzjlHkjRs2DDl5eWpTZs28vl8euGFF7Rx48aIpmz/6le/0osvvqif/OQnuvTSS5WVlaUWLVpo//79euCBB5j+DQD1IMjESXa2NHduqDupoiIUYubMCR23244dO7RixQpJ0qBBgxq83zPPPFPd6hFLu3fv1oQJE9S2bVs9+eSTat26tUpLSzVt2jSdf/751bOW8vPzG2wJqVJUVKRVq1Zp4cKFGjt2rBYvXqwTTzxRAwcOjGnNK1eulCT179+/+tjtt9+uYDCoN954o855XLt2bUQL6a1bt04vvviiCgoK9PLLL9foYlq7dq0eeOCB6P4DAOBSBJk4KiyUCgpC3Um9ejkjxEjSvHnzVFlZqcGDB+u4446r8/Wq9VJKSkriEmSuueYa7dq1S48//ri6d+8uSXrsscd00UUXaezYsSotLQ17F+f//M//VGZmpp544gm1bt1a3377rcaNGxfTenfv3q05c+ZIUo3ZQ9u2bVP79u3rhJjvvvtO7777bp3vUxVOKioq6nxt27ZtkqThw4fXGSfz+uuvR/cfAAAXI8jEWXa2cwKMFBrrMW/ePPl8Pj311FPq2bNnvff78MMP9fbbb+vDDz9U7969Y/b8ixYt0nPPPaef//znNQLHyJEjNWrUKC1atEiPPPKIJk2aFNb3S0lJ0ZgxY3Tvvffq5ptvVkpKSvU4n1j48MMPdcUVV2jXrl268sor1a9fv+qv5ebm6pNPPtGmTZt00kknSQqFlBtuuEG7d++u873at28vSfLXM+I7NzdXkvTGG29o8uTJ1cc3bdpUPSgaAJzM7w+ND83LS+x1jyDjMa+99prKyso0dOjQBkOMFFq0bcOGDSopKdF9990Xk+f+8ssvNXnyZLVr167GAN0qDz30kP73f/9XN910ky644IKwFsaTQoN+7733Xu3cuVOXXnqpOnToEHFte/bsqV7Z99ChQ9q7d6/eeeed6rVgxo0bp0ceeaTGYyZPnqzly5dr8ODBuuSSS9SyZUutXLlSX3zxhfLz86u7o6oMGDBAaWlpuv/++1VeXl493uamm27SGWecoTPOOEPPPvusvvzyS/30pz/V9u3btWzZMg0fPlx/+9vfIv4/AUCilJQcnqmblBQaWlFYmKAnj/FUcFs5bR0ZJ7rsssssSdaf//znRu+3Z88eKyUlxcrMzLSCwaBlWdGvIzN8+HBLkrVgwYIG77N06VJLknX22WfXWR+mMQMGDLAkWa+++mrYj6kiqcYtNTXVysrKsgYNGmTdcMMN1saNGxt87N/+9jfr9NNPt1q1amVlZmZal1xyibVt2zZrzJgxliTrs88+q3H/l19+2erfv7+VlpZW/XxVdu3aZY0dO9bq2rWr1bJlS6tPnz7WI488Yn366aeWJGvMmDFN/l+8/LsNwB47dhxeM63qlpwcOh6uaNaR8VlWE6MpDVJeXq6MjAwFAoFGZ9v88MMP+uyzz9SzZ0+1bNkygRUiHn744Qd169ZN7dq109atW8MeX+NG/G4DSLTSUun/J3DWOZ6fH973CPf6XR/WkYHxnnzySe3bt09FRUWeDjEAYIeq5UaOlMjlRhgjA2Pdeeed1TOKsrKywt6nCQAQO3YvN0KQgbGmT5+ulJQUnXLKKXFdvA8A0Dg7lxshyMBYLhreBQDGs2u5EcbIAAAAYxFkAACAsQgyAADAWJ4OMoyxgNvwOw3AazwZZFq0aCEptLkf4CYHDhyQz+er/h0HALfz5Kyl5ORktWvXTrt27ZIktWrVioXUYCzLsnTo0CGVl5ervLxc7dq1q7ODNgC4lSeDjCR17txZkqrDDGC65ORkdenSRRkZGXaXAgAJ49kg4/P51KVLF2VlZenHH3+0uxwgKkcddZSSk5NpWQTgOZ4NMlWSk5NphgcAwFCeHOwLAADcgSADAACMRZABAADGIsgAAABjEWQAAICxCDIAAMBYBBkAAGAsggwAADAWQQYAABiLIAMAQIL5/VJpaegjokOQAQAggUpKpNxc6ZxzQh9LSuyuyGwEGQAAEsTvl8aPlyorQ59XVkpFRbTMRIMgAwBAgmzZcjjEVKmokLZutaceNyDIAACQIHl5UlKtK29ystSrlz31uAFBBgCABMnOlubODYUXKfRxzpzQcTTPUXYXAACAlxQWSgUFoe6kXr2cH2L8/lCXWF6eM2ulRQYAgATLzpby8+MTDKKZ2l37sSbMsCLIAADgEtEEj9qPveceM2ZY+SzLsuwuIlbKy8uVkZGhQCCg9PR0u8sBACBh/P5QADlyVlRyslRW1nTLT32PTUqqO8NKCrXY5OfHouLDorl+0yIDAIALRDO1u77HVlZKPl/NY06cYUWQAQDABaKZ2t3QY++6y/kzrAgyAAC4QDRTuxt67G9+E+qaKi0NfSwsjFf1zcf0awAAXCKaqd2NPdbJo2kd0yJz6NAh/f73v1fPnj2VlpamY445Rrfeeqsq6xtpBAAA6hXN1O7ajzVh+rVjWmTuuusuPfbYY1qwYIFOOukkrV+/XldddZUyMjJ03XXX2V0eAACe0tAGlwUFzhon45gg89Zbb2nEiBEaPny4JKlHjx56+umntX79epsrAwDAXnasrtvYLCgnBRnHdC0NHjxYr732mj755BNJ0saNG/XGG2/oggsuaPAxwWBQ5eXlNW4AALiJXd07pmxw6ZggM23aNF1++eU6/vjj1aJFC5122mmaMmWKLr/88gYfU1xcrIyMjOpbTk5OAisGACC+GureScTquqZscOmYILN48WItXLhQixYt0rvvvqsFCxbonnvu0YIFCxp8zPTp0xUIBKpvO3bsSGDFAADEVzSL3MVCYaHzp187ZouCnJwc3XTTTZo4cWL1sdtuu00LFy7Uxx9/HNb3YIsCAICbRLPtgElcsUXBd999p6RanXHJyclMvwYAeJYp3Tt2csyspQsvvFC33367unfvrpNOOkkbNmzQrFmzNHbsWLtLAwDANtEscnckO2Y+JYJjupa++eYb/eEPf9CSJUu0a9cude3aVZdffrluvvlmpaSkhPU96FoCAKCukpLDg4aTkkKtPLEe7xJNUIrm+u2YIBMLBBkAAGpKxDibaIOSK8bIAACA2Iv3zCc7p4hLBBkAAFwt3gvb2T1FnCADAICLxXvmk90rABNkAABwuXgubGf3FHEG+wIAgKj5/c2fIh7N9dsx68gAAABzZWfbsz4NXUsAAMBYBBkAAGAsggwAADAWQQYAABiLIAMAAIxFkAEAAMYiyAAAAGMRZAAAgLEIMgAAwFgEGQAAYCyCDAAAMBZBBgAAGIsgAwAAjEWQAQAAxiLIAAAAYxFkAACAsQgyAADAWAQZAABgLIIMAAAwFkEGAAAYiyADAACMRZABAADGIsgAAABjEWQAAICxCDIAAMBYBBkAAGAsggwAADAWQQYAABiLIAMAAIxFkAEAAM3m90ulpaGPdiDIAACAZikpkXJzpXPOCX0sKUl8DQQZAAAiYHcLhFP4/dL48VJlZejzykqpqCjx54UgAwBAmJzQAuEUW7YcDjFVKiqkrVsTWwdBBgCAMDilBaKqFrtbhfLypKRaKSI5WerVK7F1EGQAAAiDU1ognNIqlJ0tzZ0bCi9S6OOcOaHjieSzLMtK7FPGT3l5uTIyMhQIBJSenm53OQAAF/H7Q8HhyDCTnCyVlSXu4u2EGuqraevWUEtMc2uI5vpNiwwAAGFwQguEU1qFjpSdLeXn2xekjrLnaQEAME9hoVRQEH0LRHNVjUup3SKT6HEpTkKLDAAAEbCzBcIJrUJOQ4sMAAAGsbtVyGkIMgAAGCY7mwBTha4lAABgLIIMAAAwFkEGAAAYiyADAACMRZABAADGIsgAAABjEWQAAICxCDIAAMBYBBkAAGAsggwAADAWQQYAABiLIAMAAIxFkAEAAMYiyAAAAGMRZAAAsInfL5WWhj6ieQgyAADYoKREys2Vzjkn9LGkxO6KzOSoIPPFF1/ov//7v9WhQwe1atVKp556qt555x27ywIAIKb8fmn8eKmyMvR5ZaVUVETLTHMcZXcBVb7++msNGjRIQ4cO1d///ndlZWVp27Ztateund2lAQDC5PdLW7ZIeXlSdrbd1TjXli2HQ0yVigpp61bOW6QcE2Tuuusu5eTkaN68edXHevToYV9BAICIlJQcbmVISpLmzpUKC+2uqnniHcjy8kLn6Mgwk5ws9eoV++dyO8d0LS1btkz9+vXTxRdfrKysLJ122ml6/PHHG31MMBhUeXl5jRsAIPHc1FWSiLEr2dmhoJecHPo8OVmaM4fWmOZwTJD59NNPNXv2bOXl5emf//ynJkyYoGuvvVZPPfVUg48pLi5WRkZG9S0nJyeBFQMAqjTWVWKSRAaywkKprCw0a6mszNzWK7v5LMuy7C5CklJSUtSvXz+tWbOm+ti1116rdevW6a233qr3McFgUMFgsPrz8vJy5eTkKBAIKD09Pe41AwBC/P5Q60XtrpKyMrNaGUpLQy0x9R3Pz094OZ5RXl6ujIyMZl2/HdMi06VLF5144ok1jp1wwgnavn17g49JTU1Venp6jRsAIPHc0lVSNXblSIxdcTbHBJlBgwZp8+bNNY598sknys3NtakiAEAk3NBV4pZA5iWOmbV0/fXXa+DAgbrjjjt0ySWX6O2339bcuXM1d+5cu0sDAIQpO9v8i35hoVRQEBrf06uX+f8ft3PMGBlJeumllzR9+nRt2bJFPXv21NSpU3X11VeH/fho+tgAAIA9orl+OyrIRIsgAwCAeVwx2BcAACBSBBkAAGAsggwAADAWQQYA4Fl+f2i6uIlbKSCEIAMA8KRE7KmE+CPIAAA8x02bXHodQQYA4Dlu2eQSBBkAgAc1tKfSrl20ypiGIAMA8JzaeyolJYVaaC69lPEypok4yPz73/+Wz+eTz+fTP//5z0bvO2nSJPl8Pg0cOFAuWkAYANBMTpolVLXJ5bPPSpYVukmMlzFNxEGmU6dOOuaYYyRJ//rXvxq838aNG/XYY48pKSlJDz30kHw+X/OrBAAYz4mzhLKzpczMwyGmSjjjZZwUyrysWV1LgwYNktR4kJk8ebIqKio0btw49e3bt3nVAQBcwcmzhBoaL9OrV8OPcWIo86pmBZmBAwdKajjILFy4UK+//rqOPvpo3X777c2vDgDgCk6eJVR7vExysjRnTuh4fZwcyrwoqhaZvXv3amut38JvvvlGN954oyTpj3/8ozIzM6MsEQBguua0eiRS1XiZ0tLQx8LChu/r5FDmRc0KMieddJIyMjIk1W2VueWWW/Tll1/q5JNP1oQJE6KvEABgvEhbPeyQnS3l5zddk9NDmdc0K8gkJSXpzDPPlCStXbu2+vjHH3+sBx98UJL00EMPKbnqNxYA4HmRtHo4mQmhzEuOau4DBw0apOXLl9dokZk8ebJ+/PFHjRo1SkOGDIlJgQAA98jOdscFv7BQKigIdSf16uWO/5Opmh1kqgb8bty4UcFgUC+99JJeffVVtWnTRn/6059iViAAAE7kllBmumav7PvTn/5UycnJOnjwoN588039z//8jyTp97//vbp16xazAgEAABrS7CDTpk0b9enTR5JUWFiozz//XHl5ebr++utjVhwAAEBjotprqWoadllZmSTpgQceUEpKStRFAQAAhCOqIFM1TkaSLrzwQp1//vlRFwQAABCuqIJMWlqaJCk1NVX33XdfTAoCAAAIV7ODTEVFhWbOnClJ+s1vfqNjjz02VjUBAACEpdlB5sEHH9T777+vHj16aPr06bGsCQAAICzNCjJPP/20pk2bJp/Pp7lz56pVq1axrgsAAKBJYS+I9/LLL2vixIn6+uuvVV5eLkn6wx/+oJ/97GdxKw4AAKAxYQeZN998U59//rlatWql0047TRMnTlShqRtlAAAAV/BZlmXZXUSslJeXKyMjQ4FAQOnp6XaXEzG/P7Q9fF4ey14DALwjmut3VNOvETslJVJurnTOOaGPJSV2VwQAgPMRZBzA75fGj5cqK0OfV1ZKRUWh4wAAoGEEGQfYsuVwiKlSURHaHh4AADSMIOMAeXlSUq2fRHKy1KuXPfUAAGAKgowDZGdLc+eGwosU+jhnDgN+AQBoStjTrxFfhYVSQUGoO6lXL0IMAADhIMg4SHY2AQYAgEjQtQQAcCW/XyotZQao2xFkAMAmXGjjh7W5vIMgAwA24EIbP6zN5S0EGQBIMK9eaBPVAsXaXN5CkAGABPPihTaRLVCszeUtBBkASDCvXWgT3QLF2lzeQpABgATz2oXWjhaowkKprCzUlVVWFvoc7sQ6MgBgAy8tglnVAnVkmElECxRrc3kDLTIAYJPsbCk/3/0X21i1QDFdHfUhyAAA4i7arh6mq6MhPsuyLLuLiJXy8nJlZGQoEAgoPT3d7nIAADHg94fCS+2uqbIy97dmeUU0129aZAAACRVpF1E4g4XpdvIuggwAIGGa00XU1HR1up28jSADAEiI5q4n09hgYa+ukozDmH4NAEiIxrqImhrr0tB09Wi+J9yBIBMlvz/0h5SXxx8NADQm2vVk6lsXxq41auAcdC1FgX5ZAAhfPFY09toqyaiL6dfNxHRAAGgevz/2KxrH43sicaK5ftO11Ez0ywJA87rXY7l1wJHPn58fm+8Js9C1VEu4axF4bfdaAKjN7u51u58fzkCQOUIkfxT0ywLwMrunPdv9/HAOTwaZ+lpdmvNHwTbxALwqnNV23fz8cA7PBZmGWl2a+0fhld1rAeBIdnev2/38cA5PBZnGWl34owCA8NndvW7388M5PBVkmpppxB8FAITP7u51u58fzuCpdWTCWfuFtQjCx6rGAIBYiGYdGU+1yITT6sKYl/Aw7RGAE4S7ZAbcy7FBpri4WD6fT1OmTInp96UpMnpMewTgBLyhguTQILNu3TrNnTtXJ598cly+P60u0WHaIwC78YYKVRwXZL799lv913/9lx5//HEdffTRdpeDejDDC4DdeEOFKo4LMhMnTtTw4cN13nnnNXnfYDCo8vLyGrcq9JvGDzO8ANiNN1So4qgg88wzz+jdd99VcXFxWPcvLi5WRkZG9S0nJ0eS9NRT9JvGG2ONANiJN1So4pjp1zt27FC/fv20fPlynXLKKZKk/Px8nXrqqbr//vvrfUwwGFQwGKz+vLy8XDk5OfL5ArKsw9O3ak+xBgC4A0tmuEM0068dE2ReeOEFXXTRRUquiteSKioq5PP5lJSUpGAwWONr9ak6EVJAUs0TUVrKFu8AADhRNEHmqDjVFLFzzz1XH3zwQY1jV111lY4//nhNmzatyRBzJJ9POjKe0W8KAIA7OSbItG3bVr17965xrHXr1urQoUOd40158EFpypTQCHb6TQEAcC/HBJlYGj1aGjmSflMAANzO0UFm5cqVzX5sdjYBBgAAt3PU9GsAACLFumHeRpABABiL/ZZAkAEAGIn9liARZAAAhmK/JUgEGQCAodhvCRJBBoCHMUjUbOy3BIkgA8CjGCTqDmxgC8fstRQL0ezVAMA7/P5QeDlyfAWbyx7m94fGn+TlhXc+Ir0/UFs0129aZAB4DoNEGxZpSxUtW7Cbp1tkeBcBeJMpLTKJfo2K9LyYch7hfLTINEOs30UwaBAwhwmDRO1o6Yi0pYqWLTiBJ1tkYv0uoqTk8KJMSUmhF0gGnAHO5/c7c3NZu1o6aJGBXWiRiVAs30WwsiRgruxsKT/feRddu1o6Im2pMqFlC+7n6N2v46VqEaXa7yIaW0Spob7qxl5w+GMG0BzNeY2KlcJCqaAg/JaqSO8PxJonW2QifRfRWF81K0sCiDW7WzoibalyassWvMGTY2SqhNM/Hk4fcElJqDupouLwCw5jZABEy6ljeIBYi2aMjCe7lqpkZzf94hBO1xFNqwDiIZzXKMDrPB1kwhFuXzUvOAAAJJ4nx8hEwu6+atanAQCgYQSZMNi1KRlLfwMA0DhPD/Z1MhaaAryD7VLgdSyI50Is/Q14Ay2vQHQIMg7V1Po0jJ0BzMfK4ED0CDIO1dggY97BAe5AyysQPcbIOFztBbEYOwO4B3/PQAhjZBwiHt09tZf+5h2cs9Hlh0jYvbwD4AYEmRhJVHcPezs5F11+aA67lncA3IKupRhIdPMwezs5D10EANB87LVks6a6e2K9PgR7OzlPOHtyAQBijyATAw3tx7R+faibwbIkn096/PHYtZywt5OzhLsnFwAgthgjEwP1DdgrLpZuvDEUYqTQx6uvZhCoG9Q3oJdBm2ZjkDZgLoJMjNQesJebezjEVLEs6a237KgOsdLYgF4GbZqJQdqA2QgyMVR7qrSbefEdbDirsHrpd8ANWFkXMB9BJk4GDgyNizlSUpI0YIA99cSSV9/BsoaP+/AzBcxHkImT7OzQ4N4jx0zMnWv+O3Uvv4NlDR/34WcKmI8gE0duHDPh5XewDOh1H36mgPlYEA8RYeG3uvtfwXz8TAF7sSAeEqbqHWztlYW99OLPGj7uw88UMBdBBhFjZWEAgFMQZNAsvIMFADgBg30BAICxCDIAAMBYBBkAAGAsggwAADAWQQYA4sgp+5I5pQ4g1ggyABAnTtmXzCl1APHAyr4AEAdOWQXbKXUAjYnm+k2LDADEgVP2JXNKHUC8EGRcrql+cfrNgfhwys7aTqkDiBeCjIs11S/utn5zQhmcxCk7azulDiBeGCPjUk31i7ut37ykRBo/PvT/SUoKvXAXFtpdFeCcnbWdUgdQH8bIoI6m+sXd1G/u9x8OMVLoY1ERLTNwhuxsKT8/9uEh0hbIeNUB2I0g41JN9YvHq9/cju4dN4UyIBxu6xYGokGQcamm+sXj0W9u14urkwYzMk4H8UYLJFATQcZgTV00CwtDY15KS0Mfa48ZaerrkdYSzotrPC70ThnMyLvk8BD2okMLJFATQcZQ4V40m+oXj1W/eTgvrvG80McylDUH75LDQ9iLnpNaIAEnIMgYyIkXzaZeXBNRs52DGXmX3DQn/t6ayCktkIBTEGQM5MSLZlMvrk6sOZZ4l9w0t/8OJJLdLZCAkxxldwGIXNVFs/YaMLG+aPr9oYtPXl547/YKC6WCgvrXqkhUzXapCnJFRaGLM++S63L770CiZWfz+wVItMgYKRFNy80dy9BQ944XmsN5l9w4L/wOAEg8VvY1WLxW6oznqr+sLgp+BwDUFs31m66lMETaxZIo8WpabmwsQ7TPR3M4EvE74NS/WQCxR9dSE7w4XZSBqzCZF/9mAS9zTJApLi5W//791bZtW2VlZWnkyJHavHmzrTV5dbpoU2MZWNAMTuXVv1nAyxwTZFatWqWJEydq7dq1WrFihQ4dOqRhw4bpwIEDttXk5emiDQ1c5d2udzQUWJ0cZE34m3Xy+QNM5NjBvrt371ZWVpZWrVqlIUOGhPWYWA/2jeegVxNxPryjpORwy0ZSUqiFrrCw4eNO4fTfUaefP8Au0Vy/HdMiU1sgEJAktW/fvsH7BINBlZeX17jFEtNFazLh3S6i11D3zLp1zu+2cfLfLN1eQHw4MshYlqWpU6dq8ODB6t27d4P3Ky4uVkZGRvUtJycn5rWwNshhDAL2hoYC6xtvmBFknfo3yxsBID4cGWQmTZqk999/X08//XSj95s+fboCgUD1bceOHXGpx849fJzEye92ETsNBdbBg80Jsk78m+WNABAfjgsykydP1rJly1RaWqrsJl6FUlNTlZ6eXuOGyEQ68NCp73YROw0F1v79CbLR4I0AEB+OGexrWZYmT56sJUuWaOXKlcrLy4v4e3htZd9oMfAQjWloBV5TVuZ16qJ4ppw/IJGiuX47Jsj8+te/1qJFi7R06VIdd9xx1cczMjKUlpYW1vcgyITP6bM7vMypF2CTENIBs7hi1tLs2bMVCASUn5+vLl26VN8WL15sd2mu5PWBh05dy4N1eqLH7CDAWxwTZCzLqvd25ZVX2l2aK3l54KFTwwIX4NjwekgHvMYxQQaJ5dWBh04OC1yAY8PLIR3wIoKMh3lxBpKTwwIX4NjwakgHvOoouwuAvbKzvfUCXxUWag9ydkJYqLoAFxWFwhUX4OYrLJQKCmIzO4jB14Cz0SJjGKcOUjWF09+te7GVLF5isSieU8dTATjMMdOvY8Ht06+ZUho7Jq/lQQtBYrBEAZA4rph+jcY5eZCqiZy4hH04aCFIHCePpwJwGEHGELyo2ssJXXqE2cRi8DVgBoKMIXhRTYz6AotTWkEIs4nl9PFUAEIIMjaK5F0+L6rxV19gcVIrCGE28Rh8DTgfQcYmzXmXb9KLqhO6YiLRUGBZs8Y5rSCEWXuYOp4K8AqCjA2ieZdvwouqU7piItFQt43P56xWEJPCLAAkAkHGBm4e6+CkrphINNRtM2CA81pBTAizAJAoBBkbuHmsg6khrbFuG1pBAMC52KLABm5eit7JWwA0pbFl7b22lQMAmIIgY5NY7gXjJKaHNAILAJiFLQoQFyZvAQAASKxort+0yCAuaNmIHbv3VrL7+cNhQo0A4oPBvoCD2T2V3e7nD4cJNQKIH7qW4Hqmvlu3e/dlu58/HCbUCKBp7H4NNMDkd+t2T2W3+/nDYUKNVUxb7RowBUEGrmXq4nxV7F5vyO7nD4cJNUpmB2rA6QgycC2T3q3Xx+69lex+fqnpVgwn1NgU0wM14HSMkYFruWX8hN1T2e16/pKSwwEgKSkUWBpaVdnuc9SY0tJQS0x9x/PzE14O4EjRXL8JMnC1kpK6i/OxxYDzuSWESu76vwDxwmBfoAHsk2Qm07sFj2RC9xdgMhbEg+uxOJ95TN6zqz5u3ZIEcAJaZAA4jhtbMbKzQ2NiTP4/AE5EiwwAR6IVA0A4CDIAHItuQQBNoWsJAAAYiyADAACMRZABAADGIsgAAABjEWQAAICxCDJAGJravBDxwXkH0BSCDNCEkpLQXjnnnBP6WFJid0UNc9OF36TzHi43/XwApyDIAI3w+w/vwCyFPhYVOfNC5KYLv0nnPVxu+vkATkKQARphyuaFbrvwR3Pendjq4bafD+AkBBmgEVWbFx7JiZsXmhK4wtXc8+7UVg+3/XwAJyHIAI0wZfNCUwJXuJpz3p3c6uG2nw/gJAQZoAmFhVJZWai7oqws9LnTmBK4IhHpeXdyq4cbfz6AU/gsy7LsLiJWysvLlZGRoUAgoPT0dLvLARLO7/fubtF+f6g76cgwk5wcCkFOORde/vkAjYnm+s3u14CLeHm36KpWj6KiUEuME1s9vPzzAeKFIOMBfn+o2T0vjxdRuFthoVRQQKsH4CWMkXE5p87iMJkTp/fisOxsKT+fEAN4BUHGxeyaxeHmCz3BEACchSDjYnbM4nDzhd7J03sBwKsIMi6W6LUr3H6hd/L0XgDwKoKMiyV67Qq3X+hZ1AwAnIcg43KJXMzN7Rd6FjUDAOdh+rUHJGrtChPW8YgW03sBwFlY2Rcxx+ql3sa6RQAiFc31m64lxBzreIS4eRp6Q9w8aw2AMxFkgDho7gXd5PDj9llrAJyJIAPEWHMv6Ka3Zrh91hoAZyLIADHWnAu6G1oz3D5rDYAzEWSAGGvOBd0NrRlMTwdgB4IMEGPNuaC7pTUjkesWAYDEOjJAXES63oyb1uBJ1LpFACCxjgzgKKzBA8CLorl+0yIDOAitGQAQGcbIAP/P5DVcAMCrCDKAzF/DBQC8ynFB5tFHH1XPnj3VsmVL9e3bV6+//rrdJcHl3LCGCwB4laOCzOLFizVlyhT97ne/04YNG3TWWWfp/PPP1/bt2+0uDS7mhjVcAMCrHBVkZs2apcLCQo0bN04nnHCC7r//fuXk5Gj27Nl2lwYXc8saLgDgRY6ZtXTw4EG98847uummm2ocHzZsmNasWVPvY4LBoILBYPXngUBAUmgaFxCu9HTpgQek664LtcwkJUn33x86zq8SAMRf1XW7OSvCOCbI7NmzRxUVFerUqVON4506ddJXX31V72OKi4t1yy231Dmek5MTlxrhDZWV0uTJoRsAIHH27t2rjIyMiB7jmCBTxefz1fjcsqw6x6pMnz5dU6dOrf58//79ys3N1fbt2yM+EaipvLxcOTk52rFjB4sLRoHzGDucy9jhXMYG5zF2AoGAunfvrvbt20f8WMcEmczMTCUnJ9dpfdm1a1edVpoqqampSk1NrXM8IyODX6oYSU9P51zGAOcxdjiXscO5jA3OY+wk1R6wGM5j4lBHs6SkpKhv375asWJFjeMrVqzQwIEDbaoKAAA4mWNaZCRp6tSpuuKKK9SvXz8NGDBAc+fO1fbt2zVhwgS7SwMAAA7kqCBz6aWXau/evbr11lv15Zdfqnfv3nrllVeUm5sb1uNTU1M1Y8aMerubEBnOZWxwHmOHcxk7nMvY4DzGTjTn0lW7XwMAAG9xzBgZAACASBFkAACAsQgyAADAWAQZAABgLNcGmV/+8pfq3r27WrZsqS5duuiKK67Qzp077S7LOGVlZSosLFTPnj2VlpamY489VjNmzNDBgwftLs04t99+uwYOHKhWrVqpXbt2dpdjlEcffVQ9e/ZUy5Yt1bdvX73++ut2l2Sk1atX68ILL1TXrl3l8/n0wgsv2F2SkYqLi9W/f3+1bdtWWVlZGjlypDZv3mx3WUaaPXu2Tj755OpFBQcMGKC///3vEX0P1waZoUOH6tlnn9XmzZv13HPPadu2bfrVr35ld1nG+fjjj1VZWak5c+Zo06ZNuu+++/TYY4/pt7/9rd2lGefgwYO6+OKLdc0119hdilEWL16sKVOm6He/+502bNigs846S+eff762b99ud2nGOXDggE455RQ9/PDDdpditFWrVmnixIlau3atVqxYoUOHDmnYsGE6cOCA3aUZJzs7W3feeafWr1+v9evX65xzztGIESO0adOmsL+HZ6ZfL1u2TCNHjlQwGFSLFi3sLsdod999t2bPnq1PP/3U7lKMNH/+fE2ZMkX79++3uxQjnHnmmTr99NM1e/bs6mMnnHCCRo4cqeLiYhsrM5vP59OSJUs0cuRIu0sx3u7du5WVlaVVq1ZpyJAhdpdjvPbt2+vuu+9WYWFhWPd3bYvMkfbt26e//OUvGjhwICEmBgKBQLM29gIidfDgQb3zzjsaNmxYjePDhg3TmjVrbKoKqCkQCEgSr4tRqqio0DPPPKMDBw5owIABYT/O1UFm2rRpat26tTp06KDt27dr6dKldpdkvG3btumhhx5i2wgkxJ49e1RRUVFn49hOnTrV2WAWsINlWZo6daoGDx6s3r17212OkT744AO1adNGqampmjBhgpYsWaITTzwx7McbFWRmzpwpn8/X6G39+vXV9//Nb36jDRs2aPny5UpOTtbo0aPlkZ60JkV6LiVp586d+vnPf66LL75Y48aNs6lyZ2nOeUTkfD5fjc8ty6pzDLDDpEmT9P777+vpp5+2uxRjHXfccXrvvfe0du1aXXPNNRozZow++uijsB/vqL2WmjJp0iRddtlljd6nR48e1f/OzMxUZmamfvKTn+iEE05QTk6O1q5dG1GTlVtFei537typoUOHVm/miZBIzyMik5mZqeTk5DqtL7t27arTSgMk2uTJk7Vs2TKtXr1a2dnZdpdjrJSUFPXq1UuS1K9fP61bt04PPPCA5syZE9bjjQoyVcGkOapaYoLBYCxLMlYk5/KLL77Q0KFD1bdvX82bN09JSUY15MVVNL+TaFpKSor69u2rFStW6KKLLqo+vmLFCo0YMcLGyuBllmVp8uTJWrJkiVauXKmePXvaXZKrWJYV0bXaqCATrrfffltvv/22Bg8erKOPPlqffvqpbr75Zh177LG0xkRo586dys/PV/fu3XXPPfdo9+7d1V/r3LmzjZWZZ/v27dq3b5+2b9+uiooKvffee5KkXr16qU2bNvYW52BTp07VFVdcoX79+lW3CG7fvp1xWs3w7bffauvWrdWff/bZZ3rvvffUvn17de/e3cbKzDJx4kQtWrRIS5cuVdu2batbDDMyMpSWlmZzdWb57W9/q/PPP185OTn65ptv9Mwzz2jlypX6xz/+Ef43sVzo/ffft4YOHWq1b9/eSk1NtXr06GFNmDDB8vv9dpdmnHnz5lmS6r0hMmPGjKn3PJaWltpdmuM98sgjVm5urpWSkmKdfvrp1qpVq+wuyUilpaX1/g6OGTPG7tKM0tBr4rx58+wuzThjx46t/tvu2LGjde6551rLly+P6Ht4Zh0ZAADgPgx2AAAAxiLIAAAAYxFkAACAsQgyAADAWAQZAABgLIIMAAAwFkEGAAAYiyADAACMRZABAADGIsgAAABjEWQA2OrNN9+Uz+eTz+fTX//613rv869//Utt2rSRz+fTjTfemOAKATgZey0BsN2IESO0bNkyHX/88frwww+VnJxc/bXNmzdr8ODB2rNnj8aMGaN58+bJ5/PZWC0AJ6FFBoDt7rzzTiUnJ+vjjz/WwoULq4/v3LlTBQUF2rNnj37xi1/oiSeeIMQAqIEWGQCOMG7cOJWUlKhnz57avHmzDhw4oCFDhuiDDz7Q4MGDtXz5cqWlpdldJgCHIcgAcIQvvvhCeXl5+v7773XfffdpyZIlWr16tfr06aPVq1erXbt2dpcIwIHoWgLgCN26ddO1114rSbr++uu1evVq9ejRQ//4xz/qDTHffvutZs6cqV/84hfq3LmzfD6frrzyysQWDcB2BBkAjnHdddcpKSn0stS+fXstX75cXbt2rfe+e/bs0S233KJ3331X/fr1S2SZABzkKLsLAABJOnTokMaPH6/KykpJ0nfffdfomJguXbrI7/erW7du+uGHHxg/A3gULTIAbGdZlsaNG6eXXnpJHTt2VM+ePfXDDz9oxowZDT4mNTVV3bp1S2CVAJyIIAPAdjfeeKMWLFigNm3a6OWXX9btt98uSVqwYIE++ugjm6sD4GQEGQC2uueee3TPPfeoRYsWeu6559S/f39ddtllOvnkk1VRUaHp06fbXSIAByPIALDNU089pRtvvFE+n0/z58/XsGHDJEk+n09//OMfJUnLli3Tm2++aWeZAByMIAPAFq+88ooKCwtlWZZmzZqlUaNG1fj6L3/5S5155pmSpGnTptlRIgADEGQAJNxbb72liy++WIcOHdK0adM0ZcqUeu9XNVbmzTff1NKlSxNYIQBTMP0aQMINGDBABw4caPJ+5557rlh8HEBjaJEBAADGokUGgLEefvhh7d+/X4cOHZIkvf/++7rtttskSUOGDNGQIUPsLA9AArBpJABj9ejRQ59//nm9X5sxY4ZmzpyZ2IIAJBxBBgAAGIsxMgAAwFgEGQAAYCyCDAAAMBZBBgAAGIsgAwAAjEWQAQAAxiLIAAAAYxFkAACAsQgyAADAWAQZAABgLIIMAAAwFkEGAAAY6/8AVgayAz6LZv4AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "# Run code: Qb(part I)\n",
    "# NOTE: modified code from [GITHOML], 04_training_linear_models.ipynb\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "def GenerateData():\n",
    "    m = 100\n",
    "    X = 6 * np.random.rand(m, 1) - 3\n",
    "    y = 2 + X + 0.5 * X**2 + np.random.randn(m, 1)\n",
    "    return X, y\n",
    "\n",
    "X, y = GenerateData()\n",
    "X_train, X_val, y_train, y_val = \\\n",
    "    train_test_split( \\\n",
    "        X[:50], y[:50].ravel(), \\\n",
    "        test_size=0.5, \\\n",
    "        random_state=10)\n",
    "\n",
    "print(\"X_train.shape=\",X_train.shape)\n",
    "print(\"X_val  .shape=\",X_val.shape)\n",
    "print(\"y_train.shape=\",y_train.shape)\n",
    "print(\"y_val  .shape=\",y_val.shape)\n",
    "\n",
    "poly_scaler = Pipeline([\n",
    "        (\"poly_features\", PolynomialFeatures(degree=90, include_bias=False)),\n",
    "        (\"std_scaler\", StandardScaler()),\n",
    "    ])\n",
    "\n",
    "X_train_poly_scaled = poly_scaler.fit_transform(X_train)\n",
    "X_val_poly_scaled   = poly_scaler.transform(X_val)\n",
    "\n",
    "X_new=np.linspace(-3, 3, 100).reshape(100, 1)\n",
    "plt.plot(X, y, \"b.\", label=\"All X-y Data\")\n",
    "plt.xlabel(\"$x_1$\", fontsize=18, )\n",
    "plt.ylabel(\"$y$\", rotation=0, fontsize=18)\n",
    "plt.legend(loc=\"upper left\", fontsize=14)\n",
    "plt.axis([-3, 3, 0, 10])\n",
    "plt.show()\n",
    "\n",
    "print('OK')      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Part 2\n",
    "\n",
    "First thing is a function Train with the parameters X_train, y_train, X_val, y_val, n_epochs and verbose. The function is used to train the model and return the training and validation errors. The errors are saved in arrays. \n",
    "The Train function then uses the SGDRegressor to fit the model to the training data. It runs for 1 iteration with constant as the learning rate.\n",
    " \n",
    "The model is then used to predict the training and validation sets.\n",
    "The mean squared error is then calculated for both the training and validation sets. \n",
    "The errors are then saved in the arrays train_errors and val_errors. \n",
    "The function then returns the errors arrays.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-17T10:28:28.285588600Z",
     "start_time": "2023-11-17T10:28:27.434053700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...n_epochs= 500\n",
      "  epoch=   0, mse_train=11.85, mse_val=14.58\n",
      "  epoch=   1, mse_train=11.51, mse_val=14.10\n",
      "  epoch=   2, mse_train=11.15, mse_val=13.60\n",
      "  epoch=   3, mse_train=10.81, mse_val=13.13\n",
      "  epoch=   4, mse_train=10.49, mse_val=12.70\n",
      "  epoch=   5, mse_train=10.18, mse_val=12.30\n",
      "  epoch=   6, mse_train=9.88, mse_val=11.92\n",
      "  epoch=   7, mse_train=9.60, mse_val=11.56\n",
      "  epoch=   8, mse_train=9.33, mse_val=11.23\n",
      "  epoch=   9, mse_train=9.07, mse_val=10.91\n",
      "  epoch=  10, mse_train=8.82, mse_val=10.62\n",
      "  epoch=  11, mse_train=8.59, mse_val=10.34\n",
      "  epoch=  12, mse_train=8.36, mse_val=10.07\n",
      "  epoch=  13, mse_train=8.14, mse_val=9.82\n",
      "  epoch=  14, mse_train=7.93, mse_val=9.57\n",
      "  epoch=  15, mse_train=7.72, mse_val=9.34\n",
      "  epoch=  16, mse_train=7.53, mse_val=9.12\n",
      "  epoch=  17, mse_train=7.34, mse_val=8.91\n",
      "  epoch=  18, mse_train=7.16, mse_val=8.71\n",
      "  epoch=  19, mse_train=6.98, mse_val=8.52\n",
      "  epoch=  20, mse_train=6.81, mse_val=8.33\n",
      "  epoch=  21, mse_train=6.65, mse_val=8.15\n",
      "  epoch=  22, mse_train=6.49, mse_val=7.98\n",
      "  epoch=  23, mse_train=6.34, mse_val=7.81\n",
      "  epoch=  24, mse_train=6.19, mse_val=7.65\n",
      "  epoch=  25, mse_train=6.05, mse_val=7.49\n",
      "  epoch=  26, mse_train=5.91, mse_val=7.34\n",
      "  epoch=  27, mse_train=5.77, mse_val=7.20\n",
      "  epoch=  28, mse_train=5.64, mse_val=7.06\n",
      "  epoch=  29, mse_train=5.52, mse_val=6.92\n",
      "  epoch=  30, mse_train=5.40, mse_val=6.79\n",
      "  epoch=  31, mse_train=5.28, mse_val=6.66\n",
      "  epoch=  32, mse_train=5.16, mse_val=6.54\n",
      "  epoch=  33, mse_train=5.05, mse_val=6.42\n",
      "  epoch=  34, mse_train=4.94, mse_val=6.30\n",
      "  epoch=  35, mse_train=4.84, mse_val=6.18\n",
      "  epoch=  36, mse_train=4.73, mse_val=6.07\n",
      "  epoch=  37, mse_train=4.63, mse_val=5.97\n",
      "  epoch=  38, mse_train=4.54, mse_val=5.86\n",
      "  epoch=  39, mse_train=4.44, mse_val=5.76\n",
      "  epoch=  40, mse_train=4.35, mse_val=5.66\n",
      "  epoch=  41, mse_train=4.26, mse_val=5.56\n",
      "  epoch=  42, mse_train=4.17, mse_val=5.47\n",
      "  epoch=  43, mse_train=4.09, mse_val=5.37\n",
      "  epoch=  44, mse_train=4.01, mse_val=5.28\n",
      "  epoch=  45, mse_train=3.93, mse_val=5.20\n",
      "  epoch=  46, mse_train=3.85, mse_val=5.11\n",
      "  epoch=  47, mse_train=3.77, mse_val=5.03\n",
      "  epoch=  48, mse_train=3.70, mse_val=4.95\n",
      "  epoch=  49, mse_train=3.63, mse_val=4.87\n",
      "  epoch=  50, mse_train=3.56, mse_val=4.79\n",
      "  epoch=  51, mse_train=3.49, mse_val=4.71\n",
      "  epoch=  52, mse_train=3.42, mse_val=4.64\n",
      "  epoch=  53, mse_train=3.36, mse_val=4.57\n",
      "  epoch=  54, mse_train=3.29, mse_val=4.49\n",
      "  epoch=  55, mse_train=3.23, mse_val=4.43\n",
      "  epoch=  56, mse_train=3.17, mse_val=4.36\n",
      "  epoch=  57, mse_train=3.11, mse_val=4.29\n",
      "  epoch=  58, mse_train=3.06, mse_val=4.23\n",
      "  epoch=  59, mse_train=3.00, mse_val=4.16\n",
      "  epoch=  60, mse_train=2.95, mse_val=4.10\n",
      "  epoch=  61, mse_train=2.89, mse_val=4.04\n",
      "  epoch=  62, mse_train=2.84, mse_val=3.98\n",
      "  epoch=  63, mse_train=2.79, mse_val=3.93\n",
      "  epoch=  64, mse_train=2.74, mse_val=3.87\n",
      "  epoch=  65, mse_train=2.70, mse_val=3.81\n",
      "  epoch=  66, mse_train=2.65, mse_val=3.76\n",
      "  epoch=  67, mse_train=2.60, mse_val=3.71\n",
      "  epoch=  68, mse_train=2.56, mse_val=3.66\n",
      "  epoch=  69, mse_train=2.52, mse_val=3.60\n",
      "  epoch=  70, mse_train=2.47, mse_val=3.56\n",
      "  epoch=  71, mse_train=2.43, mse_val=3.51\n",
      "  epoch=  72, mse_train=2.39, mse_val=3.46\n",
      "  epoch=  73, mse_train=2.35, mse_val=3.41\n",
      "  epoch=  74, mse_train=2.31, mse_val=3.37\n",
      "  epoch=  75, mse_train=2.28, mse_val=3.32\n",
      "  epoch=  76, mse_train=2.24, mse_val=3.28\n",
      "  epoch=  77, mse_train=2.20, mse_val=3.24\n",
      "  epoch=  78, mse_train=2.17, mse_val=3.20\n",
      "  epoch=  79, mse_train=2.14, mse_val=3.15\n",
      "  epoch=  80, mse_train=2.10, mse_val=3.12\n",
      "  epoch=  81, mse_train=2.07, mse_val=3.08\n",
      "  epoch=  82, mse_train=2.04, mse_val=3.04\n",
      "  epoch=  83, mse_train=2.01, mse_val=3.00\n",
      "  epoch=  84, mse_train=1.98, mse_val=2.96\n",
      "  epoch=  85, mse_train=1.95, mse_val=2.93\n",
      "  epoch=  86, mse_train=1.92, mse_val=2.89\n",
      "  epoch=  87, mse_train=1.89, mse_val=2.86\n",
      "  epoch=  88, mse_train=1.86, mse_val=2.82\n",
      "  epoch=  89, mse_train=1.84, mse_val=2.79\n",
      "  epoch=  90, mse_train=1.81, mse_val=2.76\n",
      "  epoch=  91, mse_train=1.79, mse_val=2.73\n",
      "  epoch=  92, mse_train=1.76, mse_val=2.70\n",
      "  epoch=  93, mse_train=1.74, mse_val=2.67\n",
      "  epoch=  94, mse_train=1.71, mse_val=2.64\n",
      "  epoch=  95, mse_train=1.69, mse_val=2.61\n",
      "  epoch=  96, mse_train=1.67, mse_val=2.58\n",
      "  epoch=  97, mse_train=1.65, mse_val=2.55\n",
      "  epoch=  98, mse_train=1.62, mse_val=2.52\n",
      "  epoch=  99, mse_train=1.60, mse_val=2.50\n",
      "  epoch= 100, mse_train=1.58, mse_val=2.47\n",
      "  epoch= 101, mse_train=1.56, mse_val=2.45\n",
      "  epoch= 102, mse_train=1.54, mse_val=2.42\n",
      "  epoch= 103, mse_train=1.52, mse_val=2.40\n",
      "  epoch= 104, mse_train=1.50, mse_val=2.37\n",
      "  epoch= 105, mse_train=1.49, mse_val=2.35\n",
      "  epoch= 106, mse_train=1.47, mse_val=2.33\n",
      "  epoch= 107, mse_train=1.45, mse_val=2.30\n",
      "  epoch= 108, mse_train=1.43, mse_val=2.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch= 109, mse_train=1.42, mse_val=2.26\n",
      "  epoch= 110, mse_train=1.40, mse_val=2.24\n",
      "  epoch= 111, mse_train=1.38, mse_val=2.22\n",
      "  epoch= 112, mse_train=1.37, mse_val=2.20\n",
      "  epoch= 113, mse_train=1.35, mse_val=2.18\n",
      "  epoch= 114, mse_train=1.34, mse_val=2.16\n",
      "  epoch= 115, mse_train=1.32, mse_val=2.14\n",
      "  epoch= 116, mse_train=1.31, mse_val=2.12\n",
      "  epoch= 117, mse_train=1.30, mse_val=2.10\n",
      "  epoch= 118, mse_train=1.28, mse_val=2.08\n",
      "  epoch= 119, mse_train=1.27, mse_val=2.06\n",
      "  epoch= 120, mse_train=1.26, mse_val=2.05\n",
      "  epoch= 121, mse_train=1.24, mse_val=2.03\n",
      "  epoch= 122, mse_train=1.23, mse_val=2.01\n",
      "  epoch= 123, mse_train=1.22, mse_val=2.00\n",
      "  epoch= 124, mse_train=1.21, mse_val=1.98\n",
      "  epoch= 125, mse_train=1.19, mse_val=1.97\n",
      "  epoch= 126, mse_train=1.18, mse_val=1.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch= 127, mse_train=1.17, mse_val=1.94\n",
      "  epoch= 128, mse_train=1.16, mse_val=1.92\n",
      "  epoch= 129, mse_train=1.15, mse_val=1.91\n",
      "  epoch= 130, mse_train=1.14, mse_val=1.89\n",
      "  epoch= 131, mse_train=1.13, mse_val=1.88\n",
      "  epoch= 132, mse_train=1.12, mse_val=1.87\n",
      "  epoch= 133, mse_train=1.11, mse_val=1.85\n",
      "  epoch= 134, mse_train=1.10, mse_val=1.84\n",
      "  epoch= 135, mse_train=1.09, mse_val=1.83\n",
      "  epoch= 136, mse_train=1.08, mse_val=1.81\n",
      "  epoch= 137, mse_train=1.07, mse_val=1.80\n",
      "  epoch= 138, mse_train=1.06, mse_val=1.79\n",
      "  epoch= 139, mse_train=1.06, mse_val=1.78\n",
      "  epoch= 140, mse_train=1.05, mse_val=1.77\n",
      "  epoch= 141, mse_train=1.04, mse_val=1.76\n",
      "  epoch= 142, mse_train=1.03, mse_val=1.74\n",
      "  epoch= 143, mse_train=1.02, mse_val=1.73\n",
      "  epoch= 144, mse_train=1.02, mse_val=1.72\n",
      "  epoch= 145, mse_train=1.01, mse_val=1.71\n",
      "  epoch= 146, mse_train=1.00, mse_val=1.70\n",
      "  epoch= 147, mse_train=0.99, mse_val=1.69\n",
      "  epoch= 148, mse_train=0.99, mse_val=1.68\n",
      "  epoch= 149, mse_train=0.98, mse_val=1.67\n",
      "  epoch= 150, mse_train=0.97, mse_val=1.67\n",
      "  epoch= 151, mse_train=0.97, mse_val=1.66\n",
      "  epoch= 152, mse_train=0.96, mse_val=1.65\n",
      "  epoch= 153, mse_train=0.95, mse_val=1.64\n",
      "  epoch= 154, mse_train=0.95, mse_val=1.63\n",
      "  epoch= 155, mse_train=0.94, mse_val=1.62\n",
      "  epoch= 156, mse_train=0.93, mse_val=1.61\n",
      "  epoch= 157, mse_train=0.93, mse_val=1.61\n",
      "  epoch= 158, mse_train=0.92, mse_val=1.60\n",
      "  epoch= 159, mse_train=0.92, mse_val=1.59\n",
      "  epoch= 160, mse_train=0.91, mse_val=1.58\n",
      "  epoch= 161, mse_train=0.91, mse_val=1.58\n",
      "  epoch= 162, mse_train=0.90, mse_val=1.57\n",
      "  epoch= 163, mse_train=0.90, mse_val=1.56\n",
      "  epoch= 164, mse_train=0.89, mse_val=1.56\n",
      "  epoch= 165, mse_train=0.89, mse_val=1.55\n",
      "  epoch= 166, mse_train=0.88, mse_val=1.54\n",
      "  epoch= 167, mse_train=0.88, mse_val=1.54\n",
      "  epoch= 168, mse_train=0.87, mse_val=1.53\n",
      "  epoch= 169, mse_train=0.87, mse_val=1.52\n",
      "  epoch= 170, mse_train=0.86, mse_val=1.52\n",
      "  epoch= 171, mse_train=0.86, mse_val=1.51\n",
      "  epoch= 172, mse_train=0.85, mse_val=1.51\n",
      "  epoch= 173, mse_train=0.85, mse_val=1.50\n",
      "  epoch= 174, mse_train=0.84, mse_val=1.50\n",
      "  epoch= 175, mse_train=0.84, mse_val=1.49\n",
      "  epoch= 176, mse_train=0.84, mse_val=1.49\n",
      "  epoch= 177, mse_train=0.83, mse_val=1.48\n",
      "  epoch= 178, mse_train=0.83, mse_val=1.48\n",
      "  epoch= 179, mse_train=0.82, mse_val=1.47\n",
      "  epoch= 180, mse_train=0.82, mse_val=1.47\n",
      "  epoch= 181, mse_train=0.82, mse_val=1.46\n",
      "  epoch= 182, mse_train=0.81, mse_val=1.46\n",
      "  epoch= 183, mse_train=0.81, mse_val=1.45\n",
      "  epoch= 184, mse_train=0.81, mse_val=1.45\n",
      "  epoch= 185, mse_train=0.80, mse_val=1.45\n",
      "  epoch= 186, mse_train=0.80, mse_val=1.44\n",
      "  epoch= 187, mse_train=0.80, mse_val=1.44\n",
      "  epoch= 188, mse_train=0.79, mse_val=1.43\n",
      "  epoch= 189, mse_train=0.79, mse_val=1.43\n",
      "  epoch= 190, mse_train=0.79, mse_val=1.43\n",
      "  epoch= 191, mse_train=0.78, mse_val=1.42\n",
      "  epoch= 192, mse_train=0.78, mse_val=1.42\n",
      "  epoch= 193, mse_train=0.78, mse_val=1.42\n",
      "  epoch= 194, mse_train=0.77, mse_val=1.41\n",
      "  epoch= 195, mse_train=0.77, mse_val=1.41\n",
      "  epoch= 196, mse_train=0.77, mse_val=1.41\n",
      "  epoch= 197, mse_train=0.77, mse_val=1.40\n",
      "  epoch= 198, mse_train=0.76, mse_val=1.40\n",
      "  epoch= 199, mse_train=0.76, mse_val=1.40\n",
      "  epoch= 200, mse_train=0.76, mse_val=1.40\n",
      "  epoch= 201, mse_train=0.75, mse_val=1.39\n",
      "  epoch= 202, mse_train=0.75, mse_val=1.39\n",
      "  epoch= 203, mse_train=0.75, mse_val=1.39\n",
      "  epoch= 204, mse_train=0.75, mse_val=1.39\n",
      "  epoch= 205, mse_train=0.74, mse_val=1.39\n",
      "  epoch= 206, mse_train=0.74, mse_val=1.38\n",
      "  epoch= 207, mse_train=0.74, mse_val=1.38\n",
      "  epoch= 208, mse_train=0.74, mse_val=1.38\n",
      "  epoch= 209, mse_train=0.73, mse_val=1.38\n",
      "  epoch= 210, mse_train=0.73, mse_val=1.38\n",
      "  epoch= 211, mse_train=0.73, mse_val=1.37\n",
      "  epoch= 212, mse_train=0.73, mse_val=1.37\n",
      "  epoch= 213, mse_train=0.73, mse_val=1.37\n",
      "  epoch= 214, mse_train=0.72, mse_val=1.37\n",
      "  epoch= 215, mse_train=0.72, mse_val=1.37\n",
      "  epoch= 216, mse_train=0.72, mse_val=1.37\n",
      "  epoch= 217, mse_train=0.72, mse_val=1.36\n",
      "  epoch= 218, mse_train=0.72, mse_val=1.36\n",
      "  epoch= 219, mse_train=0.71, mse_val=1.36\n",
      "  epoch= 220, mse_train=0.71, mse_val=1.36\n",
      "  epoch= 221, mse_train=0.71, mse_val=1.36\n",
      "  epoch= 222, mse_train=0.71, mse_val=1.36\n",
      "  epoch= 223, mse_train=0.71, mse_val=1.36\n",
      "  epoch= 224, mse_train=0.70, mse_val=1.36\n",
      "  epoch= 225, mse_train=0.70, mse_val=1.36\n",
      "  epoch= 226, mse_train=0.70, mse_val=1.36\n",
      "  epoch= 227, mse_train=0.70, mse_val=1.36\n",
      "  epoch= 228, mse_train=0.70, mse_val=1.35\n",
      "  epoch= 229, mse_train=0.70, mse_val=1.35\n",
      "  epoch= 230, mse_train=0.69, mse_val=1.35\n",
      "  epoch= 231, mse_train=0.69, mse_val=1.35\n",
      "  epoch= 232, mse_train=0.69, mse_val=1.35\n",
      "  epoch= 233, mse_train=0.69, mse_val=1.35\n",
      "  epoch= 234, mse_train=0.69, mse_val=1.35\n",
      "  epoch= 235, mse_train=0.69, mse_val=1.35\n",
      "  epoch= 236, mse_train=0.68, mse_val=1.35\n",
      "  epoch= 237, mse_train=0.68, mse_val=1.35\n",
      "  epoch= 238, mse_train=0.68, mse_val=1.35\n",
      "  epoch= 239, mse_train=0.68, mse_val=1.35\n",
      "  epoch= 240, mse_train=0.68, mse_val=1.35\n",
      "  epoch= 241, mse_train=0.68, mse_val=1.35\n",
      "  epoch= 242, mse_train=0.67, mse_val=1.35\n",
      "  epoch= 243, mse_train=0.67, mse_val=1.35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch= 244, mse_train=0.67, mse_val=1.35\n",
      "  epoch= 245, mse_train=0.67, mse_val=1.35\n",
      "  epoch= 246, mse_train=0.67, mse_val=1.35\n",
      "  epoch= 247, mse_train=0.67, mse_val=1.35\n",
      "  epoch= 248, mse_train=0.67, mse_val=1.35\n",
      "  epoch= 249, mse_train=0.67, mse_val=1.35\n",
      "  epoch= 250, mse_train=0.66, mse_val=1.35\n",
      "  epoch= 251, mse_train=0.66, mse_val=1.35\n",
      "  epoch= 252, mse_train=0.66, mse_val=1.35\n",
      "  epoch= 253, mse_train=0.66, mse_val=1.36\n",
      "  epoch= 254, mse_train=0.66, mse_val=1.36\n",
      "  epoch= 255, mse_train=0.66, mse_val=1.36\n",
      "  epoch= 256, mse_train=0.66, mse_val=1.36\n",
      "  epoch= 257, mse_train=0.66, mse_val=1.36\n",
      "  epoch= 258, mse_train=0.65, mse_val=1.36\n",
      "  epoch= 259, mse_train=0.65, mse_val=1.36\n",
      "  epoch= 260, mse_train=0.65, mse_val=1.36\n",
      "  epoch= 261, mse_train=0.65, mse_val=1.36\n",
      "  epoch= 262, mse_train=0.65, mse_val=1.36\n",
      "  epoch= 263, mse_train=0.65, mse_val=1.36\n",
      "  epoch= 264, mse_train=0.65, mse_val=1.36\n",
      "  epoch= 265, mse_train=0.65, mse_val=1.37\n",
      "  epoch= 266, mse_train=0.65, mse_val=1.37\n",
      "  epoch= 267, mse_train=0.64, mse_val=1.37\n",
      "  epoch= 268, mse_train=0.64, mse_val=1.37\n",
      "  epoch= 269, mse_train=0.64, mse_val=1.37\n",
      "  epoch= 270, mse_train=0.64, mse_val=1.37\n",
      "  epoch= 271, mse_train=0.64, mse_val=1.37\n",
      "  epoch= 272, mse_train=0.64, mse_val=1.37\n",
      "  epoch= 273, mse_train=0.64, mse_val=1.37\n",
      "  epoch= 274, mse_train=0.64, mse_val=1.38\n",
      "  epoch= 275, mse_train=0.64, mse_val=1.38\n",
      "  epoch= 276, mse_train=0.64, mse_val=1.38\n",
      "  epoch= 277, mse_train=0.63, mse_val=1.38\n",
      "  epoch= 278, mse_train=0.63, mse_val=1.38\n",
      "  epoch= 279, mse_train=0.63, mse_val=1.38\n",
      "  epoch= 280, mse_train=0.63, mse_val=1.38\n",
      "  epoch= 281, mse_train=0.63, mse_val=1.39\n",
      "  epoch= 282, mse_train=0.63, mse_val=1.39\n",
      "  epoch= 283, mse_train=0.63, mse_val=1.39\n",
      "  epoch= 284, mse_train=0.63, mse_val=1.39\n",
      "  epoch= 285, mse_train=0.63, mse_val=1.39\n",
      "  epoch= 286, mse_train=0.63, mse_val=1.39\n",
      "  epoch= 287, mse_train=0.63, mse_val=1.40\n",
      "  epoch= 288, mse_train=0.62, mse_val=1.40\n",
      "  epoch= 289, mse_train=0.62, mse_val=1.40\n",
      "  epoch= 290, mse_train=0.62, mse_val=1.40\n",
      "  epoch= 291, mse_train=0.62, mse_val=1.40\n",
      "  epoch= 292, mse_train=0.62, mse_val=1.40\n",
      "  epoch= 293, mse_train=0.62, mse_val=1.41\n",
      "  epoch= 294, mse_train=0.62, mse_val=1.41\n",
      "  epoch= 295, mse_train=0.62, mse_val=1.41\n",
      "  epoch= 296, mse_train=0.62, mse_val=1.41\n",
      "  epoch= 297, mse_train=0.62, mse_val=1.41\n",
      "  epoch= 298, mse_train=0.62, mse_val=1.42\n",
      "  epoch= 299, mse_train=0.62, mse_val=1.42\n",
      "  epoch= 300, mse_train=0.61, mse_val=1.42\n",
      "  epoch= 301, mse_train=0.61, mse_val=1.42\n",
      "  epoch= 302, mse_train=0.61, mse_val=1.42\n",
      "  epoch= 303, mse_train=0.61, mse_val=1.43\n",
      "  epoch= 304, mse_train=0.61, mse_val=1.43\n",
      "  epoch= 305, mse_train=0.61, mse_val=1.43\n",
      "  epoch= 306, mse_train=0.61, mse_val=1.43\n",
      "  epoch= 307, mse_train=0.61, mse_val=1.43\n",
      "  epoch= 308, mse_train=0.61, mse_val=1.44\n",
      "  epoch= 309, mse_train=0.61, mse_val=1.44\n",
      "  epoch= 310, mse_train=0.61, mse_val=1.44\n",
      "  epoch= 311, mse_train=0.61, mse_val=1.44\n",
      "  epoch= 312, mse_train=0.61, mse_val=1.44\n",
      "  epoch= 313, mse_train=0.61, mse_val=1.45\n",
      "  epoch= 314, mse_train=0.60, mse_val=1.45\n",
      "  epoch= 315, mse_train=0.60, mse_val=1.45\n",
      "  epoch= 316, mse_train=0.60, mse_val=1.45\n",
      "  epoch= 317, mse_train=0.60, mse_val=1.46\n",
      "  epoch= 318, mse_train=0.60, mse_val=1.46\n",
      "  epoch= 319, mse_train=0.60, mse_val=1.46\n",
      "  epoch= 320, mse_train=0.60, mse_val=1.46\n",
      "  epoch= 321, mse_train=0.60, mse_val=1.47\n",
      "  epoch= 322, mse_train=0.60, mse_val=1.47\n",
      "  epoch= 323, mse_train=0.60, mse_val=1.47\n",
      "  epoch= 324, mse_train=0.60, mse_val=1.47\n",
      "  epoch= 325, mse_train=0.60, mse_val=1.48\n",
      "  epoch= 326, mse_train=0.60, mse_val=1.48\n",
      "  epoch= 327, mse_train=0.60, mse_val=1.48\n",
      "  epoch= 328, mse_train=0.60, mse_val=1.48\n",
      "  epoch= 329, mse_train=0.60, mse_val=1.49\n",
      "  epoch= 330, mse_train=0.59, mse_val=1.49\n",
      "  epoch= 331, mse_train=0.59, mse_val=1.49\n",
      "  epoch= 332, mse_train=0.59, mse_val=1.49\n",
      "  epoch= 333, mse_train=0.59, mse_val=1.50\n",
      "  epoch= 334, mse_train=0.59, mse_val=1.50\n",
      "  epoch= 335, mse_train=0.59, mse_val=1.50\n",
      "  epoch= 336, mse_train=0.59, mse_val=1.50\n",
      "  epoch= 337, mse_train=0.59, mse_val=1.51\n",
      "  epoch= 338, mse_train=0.59, mse_val=1.51\n",
      "  epoch= 339, mse_train=0.59, mse_val=1.51\n",
      "  epoch= 340, mse_train=0.59, mse_val=1.51\n",
      "  epoch= 341, mse_train=0.59, mse_val=1.52\n",
      "  epoch= 342, mse_train=0.59, mse_val=1.52\n",
      "  epoch= 343, mse_train=0.59, mse_val=1.52\n",
      "  epoch= 344, mse_train=0.59, mse_val=1.52\n",
      "  epoch= 345, mse_train=0.59, mse_val=1.53\n",
      "  epoch= 346, mse_train=0.59, mse_val=1.53\n",
      "  epoch= 347, mse_train=0.59, mse_val=1.53\n",
      "  epoch= 348, mse_train=0.58, mse_val=1.53\n",
      "  epoch= 349, mse_train=0.58, mse_val=1.54\n",
      "  epoch= 350, mse_train=0.58, mse_val=1.54\n",
      "  epoch= 351, mse_train=0.58, mse_val=1.54\n",
      "  epoch= 352, mse_train=0.58, mse_val=1.55\n",
      "  epoch= 353, mse_train=0.58, mse_val=1.55\n",
      "  epoch= 354, mse_train=0.58, mse_val=1.55\n",
      "  epoch= 355, mse_train=0.58, mse_val=1.55\n",
      "  epoch= 356, mse_train=0.58, mse_val=1.56\n",
      "  epoch= 357, mse_train=0.58, mse_val=1.56\n",
      "  epoch= 358, mse_train=0.58, mse_val=1.56\n",
      "  epoch= 359, mse_train=0.58, mse_val=1.57\n",
      "  epoch= 360, mse_train=0.58, mse_val=1.57\n",
      "  epoch= 361, mse_train=0.58, mse_val=1.57\n",
      "  epoch= 362, mse_train=0.58, mse_val=1.57\n",
      "  epoch= 363, mse_train=0.58, mse_val=1.58\n",
      "  epoch= 364, mse_train=0.58, mse_val=1.58\n",
      "  epoch= 365, mse_train=0.58, mse_val=1.58\n",
      "  epoch= 366, mse_train=0.58, mse_val=1.59\n",
      "  epoch= 367, mse_train=0.58, mse_val=1.59\n",
      "  epoch= 368, mse_train=0.58, mse_val=1.59\n",
      "  epoch= 369, mse_train=0.58, mse_val=1.59\n",
      "  epoch= 370, mse_train=0.57, mse_val=1.60\n",
      "  epoch= 371, mse_train=0.57, mse_val=1.60\n",
      "  epoch= 372, mse_train=0.57, mse_val=1.60\n",
      "  epoch= 373, mse_train=0.57, mse_val=1.61"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  epoch= 374, mse_train=0.57, mse_val=1.61\n",
      "  epoch= 375, mse_train=0.57, mse_val=1.61\n",
      "  epoch= 376, mse_train=0.57, mse_val=1.61\n",
      "  epoch= 377, mse_train=0.57, mse_val=1.62\n",
      "  epoch= 378, mse_train=0.57, mse_val=1.62\n",
      "  epoch= 379, mse_train=0.57, mse_val=1.62\n",
      "  epoch= 380, mse_train=0.57, mse_val=1.63\n",
      "  epoch= 381, mse_train=0.57, mse_val=1.63\n",
      "  epoch= 382, mse_train=0.57, mse_val=1.63\n",
      "  epoch= 383, mse_train=0.57, mse_val=1.64\n",
      "  epoch= 384, mse_train=0.57, mse_val=1.64\n",
      "  epoch= 385, mse_train=0.57, mse_val=1.64\n",
      "  epoch= 386, mse_train=0.57, mse_val=1.64\n",
      "  epoch= 387, mse_train=0.57, mse_val=1.65\n",
      "  epoch= 388, mse_train=0.57, mse_val=1.65\n",
      "  epoch= 389, mse_train=0.57, mse_val=1.65\n",
      "  epoch= 390, mse_train=0.57, mse_val=1.66\n",
      "  epoch= 391, mse_train=0.57, mse_val=1.66\n",
      "  epoch= 392, mse_train=0.57, mse_val=1.66\n",
      "  epoch= 393, mse_train=0.57, mse_val=1.67\n",
      "  epoch= 394, mse_train=0.57, mse_val=1.67\n",
      "  epoch= 395, mse_train=0.56, mse_val=1.67\n",
      "  epoch= 396, mse_train=0.56, mse_val=1.67\n",
      "  epoch= 397, mse_train=0.56, mse_val=1.68\n",
      "  epoch= 398, mse_train=0.56, mse_val=1.68\n",
      "  epoch= 399, mse_train=0.56, mse_val=1.68\n",
      "  epoch= 400, mse_train=0.56, mse_val=1.69\n",
      "  epoch= 401, mse_train=0.56, mse_val=1.69\n",
      "  epoch= 402, mse_train=0.56, mse_val=1.69\n",
      "  epoch= 403, mse_train=0.56, mse_val=1.70\n",
      "  epoch= 404, mse_train=0.56, mse_val=1.70\n",
      "  epoch= 405, mse_train=0.56, mse_val=1.70\n",
      "  epoch= 406, mse_train=0.56, mse_val=1.70\n",
      "  epoch= 407, mse_train=0.56, mse_val=1.71\n",
      "  epoch= 408, mse_train=0.56, mse_val=1.71\n",
      "  epoch= 409, mse_train=0.56, mse_val=1.71\n",
      "  epoch= 410, mse_train=0.56, mse_val=1.72\n",
      "  epoch= 411, mse_train=0.56, mse_val=1.72\n",
      "  epoch= 412, mse_train=0.56, mse_val=1.72\n",
      "  epoch= 413, mse_train=0.56, mse_val=1.73\n",
      "  epoch= 414, mse_train=0.56, mse_val=1.73\n",
      "  epoch= 415, mse_train=0.56, mse_val=1.73\n",
      "  epoch= 416, mse_train=0.56, mse_val=1.74\n",
      "  epoch= 417, mse_train=0.56, mse_val=1.74\n",
      "  epoch= 418, mse_train=0.56, mse_val=1.74\n",
      "  epoch= 419, mse_train=0.56, mse_val=1.74\n",
      "  epoch= 420, mse_train=0.56, mse_val=1.75\n",
      "  epoch= 421, mse_train=0.56, mse_val=1.75\n",
      "  epoch= 422, mse_train=0.56, mse_val=1.75\n",
      "  epoch= 423, mse_train=0.56, mse_val=1.76\n",
      "  epoch= 424, mse_train=0.56, mse_val=1.76\n",
      "  epoch= 425, mse_train=0.55, mse_val=1.76\n",
      "  epoch= 426, mse_train=0.55, mse_val=1.77\n",
      "  epoch= 427, mse_train=0.55, mse_val=1.77\n",
      "  epoch= 428, mse_train=0.55, mse_val=1.77\n",
      "  epoch= 429, mse_train=0.55, mse_val=1.78\n",
      "  epoch= 430, mse_train=0.55, mse_val=1.78\n",
      "  epoch= 431, mse_train=0.55, mse_val=1.78\n",
      "  epoch= 432, mse_train=0.55, mse_val=1.78\n",
      "  epoch= 433, mse_train=0.55, mse_val=1.79\n",
      "  epoch= 434, mse_train=0.55, mse_val=1.79\n",
      "  epoch= 435, mse_train=0.55, mse_val=1.79\n",
      "  epoch= 436, mse_train=0.55, mse_val=1.80\n",
      "  epoch= 437, mse_train=0.55, mse_val=1.80\n",
      "  epoch= 438, mse_train=0.55, mse_val=1.80\n",
      "  epoch= 439, mse_train=0.55, mse_val=1.81\n",
      "  epoch= 440, mse_train=0.55, mse_val=1.81\n",
      "  epoch= 441, mse_train=0.55, mse_val=1.81\n",
      "  epoch= 442, mse_train=0.55, mse_val=1.82\n",
      "  epoch= 443, mse_train=0.55, mse_val=1.82\n",
      "  epoch= 444, mse_train=0.55, mse_val=1.82\n",
      "  epoch= 445, mse_train=0.55, mse_val=1.82\n",
      "  epoch= 446, mse_train=0.55, mse_val=1.83\n",
      "  epoch= 447, mse_train=0.55, mse_val=1.83\n",
      "  epoch= 448, mse_train=0.55, mse_val=1.83\n",
      "  epoch= 449, mse_train=0.55, mse_val=1.84\n",
      "  epoch= 450, mse_train=0.55, mse_val=1.84\n",
      "  epoch= 451, mse_train=0.55, mse_val=1.84\n",
      "  epoch= 452, mse_train=0.55, mse_val=1.85\n",
      "  epoch= 453, mse_train=0.55, mse_val=1.85\n",
      "  epoch= 454, mse_train=0.55, mse_val=1.85\n",
      "  epoch= 455, mse_train=0.55, mse_val=1.86\n",
      "  epoch= 456, mse_train=0.55, mse_val=1.86\n",
      "  epoch= 457, mse_train=0.55, mse_val=1.86\n",
      "  epoch= 458, mse_train=0.55, mse_val=1.86\n",
      "  epoch= 459, mse_train=0.55, mse_val=1.87\n",
      "  epoch= 460, mse_train=0.55, mse_val=1.87\n",
      "  epoch= 461, mse_train=0.55, mse_val=1.87\n",
      "  epoch= 462, mse_train=0.55, mse_val=1.88\n",
      "  epoch= 463, mse_train=0.54, mse_val=1.88\n",
      "  epoch= 464, mse_train=0.54, mse_val=1.88\n",
      "  epoch= 465, mse_train=0.54, mse_val=1.89\n",
      "  epoch= 466, mse_train=0.54, mse_val=1.89\n",
      "  epoch= 467, mse_train=0.54, mse_val=1.89\n",
      "  epoch= 468, mse_train=0.54, mse_val=1.89\n",
      "  epoch= 469, mse_train=0.54, mse_val=1.90\n",
      "  epoch= 470, mse_train=0.54, mse_val=1.90\n",
      "  epoch= 471, mse_train=0.54, mse_val=1.90\n",
      "  epoch= 472, mse_train=0.54, mse_val=1.91\n",
      "  epoch= 473, mse_train=0.54, mse_val=1.91\n",
      "  epoch= 474, mse_train=0.54, mse_val=1.91\n",
      "  epoch= 475, mse_train=0.54, mse_val=1.92\n",
      "  epoch= 476, mse_train=0.54, mse_val=1.92\n",
      "  epoch= 477, mse_train=0.54, mse_val=1.92\n",
      "  epoch= 478, mse_train=0.54, mse_val=1.92\n",
      "  epoch= 479, mse_train=0.54, mse_val=1.93\n",
      "  epoch= 480, mse_train=0.54, mse_val=1.93\n",
      "  epoch= 481, mse_train=0.54, mse_val=1.93\n",
      "  epoch= 482, mse_train=0.54, mse_val=1.94\n",
      "  epoch= 483, mse_train=0.54, mse_val=1.94\n",
      "  epoch= 484, mse_train=0.54, mse_val=1.94\n",
      "  epoch= 485, mse_train=0.54, mse_val=1.95\n",
      "  epoch= 486, mse_train=0.54, mse_val=1.95\n",
      "  epoch= 487, mse_train=0.54, mse_val=1.95\n",
      "  epoch= 488, mse_train=0.54, mse_val=1.95\n",
      "  epoch= 489, mse_train=0.54, mse_val=1.96\n",
      "  epoch= 490, mse_train=0.54, mse_val=1.96\n",
      "  epoch= 491, mse_train=0.54, mse_val=1.96\n",
      "  epoch= 492, mse_train=0.54, mse_val=1.97\n",
      "  epoch= 493, mse_train=0.54, mse_val=1.97\n",
      "  epoch= 494, mse_train=0.54, mse_val=1.97\n",
      "  epoch= 495, mse_train=0.54, mse_val=1.97\n",
      "  epoch= 496, mse_train=0.54, mse_val=1.98\n",
      "  epoch= 497, mse_train=0.54, mse_val=1.98\n",
      "  epoch= 498, mse_train=0.54, mse_val=1.98\n",
      "  epoch= 499, mse_train=0.54, mse_val=1.99\n",
      "OK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\msldk\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Run code: Qb(part II)\n",
    "\n",
    "def Train(X_train, y_train, X_val, y_val, n_epochs, verbose=False):\n",
    "    print(\"Training...n_epochs=\",n_epochs)\n",
    "    \n",
    "    train_errors, val_errors = [], []\n",
    "    \n",
    "    sgd_reg = SGDRegressor(max_iter=1,\n",
    "                           penalty=None,\n",
    "                           eta0=0.0005,\n",
    "                           warm_start=True,\n",
    "                           early_stopping=False,\n",
    "                           learning_rate=\"constant\",\n",
    "                           # Had to change this to 0 instead of \"inf\" to fix the error \n",
    "                           tol=-float(0), \n",
    "                           random_state=42)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        \n",
    "        sgd_reg.fit(X_train, y_train)\n",
    "        \n",
    "        y_train_predict = sgd_reg.predict(X_train)\n",
    "        y_val_predict   = sgd_reg.predict(X_val)\n",
    "\n",
    "        mse_train=mean_squared_error(y_train, y_train_predict)\n",
    "        mse_val  =mean_squared_error(y_val  , y_val_predict)\n",
    "\n",
    "        train_errors.append(mse_train)\n",
    "        val_errors  .append(mse_val)\n",
    "        if verbose:\n",
    "            print(f\"  epoch={epoch:4d}, mse_train={mse_train:4.2f}, mse_val={mse_val:4.2f}\")\n",
    "\n",
    "    return train_errors, val_errors\n",
    "\n",
    "n_epochs = 500\n",
    "train_errors, val_errors = Train(X_train_poly_scaled, y_train, X_val_poly_scaled, y_val, n_epochs, True)\n",
    "\n",
    "print('OK')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Part 3\n",
    "\n",
    "The code below is used to plot the training and validation errors. Here we can see which model is the best and this is also indicated with an annotation on the graph. This is when the RMSE is the lowest near the dotted horizontal line going parralel to the x-axis. this model will be the best model for new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-17T10:28:28.499391600Z",
     "start_time": "2023-11-17T10:28:28.310603800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "# Run code: Qb(part III)\n",
    "\n",
    "best_epoch = np.argmin(val_errors)\n",
    "best_val_rmse = np.sqrt(val_errors[best_epoch])\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.annotate('Best model',\n",
    "             xy=(best_epoch, best_val_rmse),\n",
    "             xytext=(best_epoch, best_val_rmse + 1),\n",
    "             ha=\"center\",\n",
    "             arrowprops=dict(facecolor='black', shrink=0.05),\n",
    "             fontsize=16,\n",
    "            )\n",
    "\n",
    "best_val_rmse -= 0.03  # just to make the graph look better\n",
    "plt.plot([0, n_epochs], [best_val_rmse, best_val_rmse], \"k:\", linewidth=2)\n",
    "plt.plot(np.sqrt(train_errors), \"b--\", linewidth=2, label=\"Training set\")\n",
    "plt.plot(np.sqrt(val_errors), \"g-\", linewidth=3, label=\"Validation set\")\n",
    "plt.legend(loc=\"upper right\", fontsize=14)\n",
    "plt.xlabel(\"Epoch\", fontsize=14)\n",
    "plt.ylabel(\"RMSE\", fontsize=14)\n",
    "plt.show()\n",
    "\n",
    "print('OK')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qc)  Early Stopping\n",
    "\n",
    "Now we are going to implement early stopping in the code above.\n",
    "The early stopping could be implemented as a pseudo code like this:\n",
    "\n",
    "```python\n",
    "best_val_error = float(\"inf\")\n",
    "best_epoch = None\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    ...\n",
    "   \n",
    "    if val_error < best_val_error:\n",
    "        best_val_error = val_error\n",
    "        best_epoch = epoch\n",
    "    \n",
    "    if val_error > best_val_error:\n",
    "        printf(\"early stopping\")\n",
    "        break\n",
    "``` \n",
    "\n",
    "Where we stop the training when the validation error ( val_error ) is higher than the best validation error ( best_val_error )."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qd) Explain the Polynomial RMSE-Capacity plot\n",
    "\n",
    "#### Why does the _training error_ keep dropping, while the _CV-error_ drops until around capacity 3, and then begin to rise again?\n",
    "\n",
    "As the model complexity increases the model becoumes more better at fitting the training data. It continues to decrease as the model adjusts to noice in the training data.\n",
    "\n",
    "For the validation RMSE it is initially decresing as the model is learning the patterns in the training data. When the model complexity increases the model starts to overfit the training data and the validation RMSE starts to increase. This leads to the model being worse for new unseen data becuase it becomes to specific to the training data.\n",
    "\n",
    "#### What does the x-axis _Capacity_ and y-axis _RMSE_ represent?\n",
    "The x-axis with capacity represents the complexity of the model, specifilly the degree of polynominal features of the regression model. The y-axis with RMSE represents the error of the model.\n",
    "\n",
    "#### Increasing the model capacity. What happens when you do plots for `degrees` larger than around 10? Relate this with what you found via Qa+b in `capacity_under_overfitting.ipynb`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-17T10:28:28.882497600Z",
     "start_time": "2023-11-17T10:28:28.505907Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterating...degrees= range(1, 8)\n",
      "  degree=   1, rmse_training=0.48, rmse_cv=0.64\n",
      "  degree=   2, rmse_training=0.17, rmse_cv=0.24\n",
      "  degree=   3, rmse_training=0.11, rmse_cv=0.14\n",
      "  degree=   4, rmse_training=0.11, rmse_cv=0.21\n",
      "  degree=   5, rmse_training=0.10, rmse_cv=0.31\n",
      "  degree=   6, rmse_training=0.10, rmse_cv=0.34\n",
      "  degree=   7, rmse_training=0.10, rmse_cv=0.44\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "# Run and review this code\n",
    "# NOTE: modified code from [GITHOML], 04_training_linear_models.ipynb\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from math import sqrt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def true_fun(X):\n",
    "    return np.cos(1.5 * np.pi * X)\n",
    "\n",
    "def GenerateData():\n",
    "    n_samples = 30\n",
    "    #degrees = [1, 4, 15]\n",
    "    degrees = range(1,8)\n",
    "\n",
    "    X = np.sort(np.random.rand(n_samples))\n",
    "    y = true_fun(X) + np.random.randn(n_samples) * 0.1\n",
    "    return X, y, degrees\n",
    "\n",
    "np.random.seed(0)\n",
    "X, y, degrees  = GenerateData()\n",
    "\n",
    "print(\"Iterating...degrees=\",degrees)\n",
    "capacities, rmses_training, rmses_validation= [], [], []\n",
    "for i in range(len(degrees)):\n",
    "    d=degrees[i]\n",
    "    \n",
    "    polynomial_features = PolynomialFeatures(degree=d, include_bias=False)\n",
    "    \n",
    "    linear_regression = LinearRegression()\n",
    "    pipeline = Pipeline([\n",
    "            (\"polynomial_features\", polynomial_features),\n",
    "            (\"linear_regression\", linear_regression)\n",
    "        ])\n",
    "    \n",
    "    Z = X[:, np.newaxis]\n",
    "    pipeline.fit(Z, y)\n",
    "    \n",
    "    p = pipeline.predict(Z)\n",
    "    train_rms = mean_squared_error(y,p)\n",
    "\n",
    "    # Evaluate the models using crossvalidation\n",
    "    scores = cross_val_score(pipeline, Z, y, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "    score_mean = -scores.mean()\n",
    "    \n",
    "    rmse_training=sqrt(train_rms)\n",
    "    rmse_validation=sqrt(score_mean)\n",
    "    \n",
    "    print(f\"  degree={d:4d}, rmse_training={rmse_training:4.2f}, rmse_cv={rmse_validation:4.2f}\")\n",
    "    \n",
    "    capacities      .append(d)\n",
    "    rmses_training  .append(rmse_training)\n",
    "    rmses_validation.append(rmse_validation)\n",
    "    \n",
    "plt.figure(figsize=(7,4))\n",
    "plt.plot(capacities, rmses_training,  \"b--\", linewidth=2, label=\"training RMSE\")\n",
    "plt.plot(capacities, rmses_validation,\"g-\",  linewidth=2, label=\"validation RMSE\")\n",
    "plt.legend(loc=\"upper right\", fontsize=14)\n",
    "plt.xlabel(\"Capacity\", fontsize=14)\n",
    "plt.ylabel(\"RMSE\", fontsize=14)\n",
    "plt.show()\n",
    "\n",
    "print('OK')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Increasing the model capacity. What happens when you do plots for `degrees` larger than around 10? Relate this with what you found via Qa+b in `capacity_under_overfitting.ipynb`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-17T10:28:29.572212700Z",
     "start_time": "2023-11-17T10:28:28.877376800Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterating...degrees= range(1, 12)\n",
      "  degree=   1, rmse_training=0.48, rmse_cv=0.64\n",
      "  degree=   2, rmse_training=0.17, rmse_cv=0.24\n",
      "  degree=   3, rmse_training=0.11, rmse_cv=0.14\n",
      "  degree=   4, rmse_training=0.11, rmse_cv=0.21\n",
      "  degree=   5, rmse_training=0.10, rmse_cv=0.31\n",
      "  degree=   6, rmse_training=0.10, rmse_cv=0.34\n",
      "  degree=   7, rmse_training=0.10, rmse_cv=0.44\n",
      "  degree=   8, rmse_training=0.10, rmse_cv=0.60\n",
      "  degree=   9, rmse_training=0.10, rmse_cv=4.61\n",
      "  degree=  10, rmse_training=0.10, rmse_cv=38.94\n",
      "  degree=  11, rmse_training=0.10, rmse_cv=154.97\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "# Run and review this code\n",
    "# NOTE: modified code from [GITHOML], 04_training_linear_models.ipynb\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from math import sqrt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def true_fun(X):\n",
    "    return np.cos(1.5 * np.pi * X)\n",
    "\n",
    "def GenerateData():\n",
    "    n_samples = 30\n",
    "    #degrees = [1, 4, 15]\n",
    "    degrees = range(1,12)\n",
    "\n",
    "    X = np.sort(np.random.rand(n_samples))\n",
    "    y = true_fun(X) + np.random.randn(n_samples) * 0.1\n",
    "    return X, y, degrees\n",
    "\n",
    "np.random.seed(0)\n",
    "X, y, degrees  = GenerateData()\n",
    "\n",
    "print(\"Iterating...degrees=\",degrees)\n",
    "capacities, rmses_training, rmses_validation= [], [], []\n",
    "for i in range(len(degrees)):\n",
    "    d=degrees[i]\n",
    "    \n",
    "    polynomial_features = PolynomialFeatures(degree=d, include_bias=False)\n",
    "    \n",
    "    linear_regression = LinearRegression()\n",
    "    pipeline = Pipeline([\n",
    "            (\"polynomial_features\", polynomial_features),\n",
    "            (\"linear_regression\", linear_regression)\n",
    "        ])\n",
    "    \n",
    "    Z = X[:, np.newaxis]\n",
    "    pipeline.fit(Z, y)\n",
    "    \n",
    "    p = pipeline.predict(Z)\n",
    "    train_rms = mean_squared_error(y,p)\n",
    "\n",
    "    # Evaluate the models using crossvalidation\n",
    "    scores = cross_val_score(pipeline, Z, y, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "    score_mean = -scores.mean()\n",
    "    \n",
    "    rmse_training=sqrt(train_rms)\n",
    "    rmse_validation=sqrt(score_mean)\n",
    "    \n",
    "    print(f\"  degree={d:4d}, rmse_training={rmse_training:4.2f}, rmse_cv={rmse_validation:4.2f}\")\n",
    "    \n",
    "    capacities      .append(d)\n",
    "    rmses_training  .append(rmse_training)\n",
    "    rmses_validation.append(rmse_validation)\n",
    "    \n",
    "plt.figure(figsize=(7,4))\n",
    "plt.plot(capacities, rmses_training,  \"b--\", linewidth=2, label=\"training RMSE\")\n",
    "plt.plot(capacities, rmses_validation,\"g-\",  linewidth=2, label=\"validation RMSE\")\n",
    "plt.legend(loc=\"upper right\", fontsize=14)\n",
    "plt.xlabel(\"Capacity\", fontsize=14)\n",
    "plt.ylabel(\"RMSE\", fontsize=14)\n",
    "plt.show()\n",
    "\n",
    "print('OK')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "After increacing the capacity we now see that the RMSE of the validation goes exponetial and at 10 capacity it is grown very much. This is because the model is overfitting the training data and is not able to predict new data. This is also what we found in Qa+b in `capacity_under_overfitting.ipynb` where we saw that the model was overfitting the training data and was not able to predict new data when degress was too high."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SWMAL Exercise\n",
    "\n",
    "## Model capacity and under/overfitting\n",
    "\n",
    "### Qa) Explain the polynomial fitting via code review\n",
    "\n",
    "In the code below the underfitting and overfitting concepts are demonstrated in polynomial regression.\n",
    "\n",
    "The first function definition `true_fun` is the true function we want to fit, and the second function `GenerateData` generates the data samples from the true function, with some added noise. \n",
    "\n",
    "Next part that is defined is the degress which are used to fit the polynomial regression model.  \n",
    "\n",
    "The next part is the for loop, where we fit the polynomial regression models of different degrees (1, 4, 15) to the data, and evaluates their performance using cross-validation. \n",
    "\n",
    "The true function is a cosine curve with added random noise. The code uses scikit-learn's Pipeline to create a polynomial regression model and calculates mean squared error scores for each degree. The results show how model complexity (degree) affects performance, highlighting the trade-off between underfitting and overfitting. \n",
    "\n",
    "Finally the loop ends with prints of the cross-validation sub-scores for each fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-17T10:26:36.664103800Z",
     "start_time": "2023-11-17T10:26:35.810712Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterating...degrees= [1, 4, 15]\n",
      "  degree=   1, score_mean=-0.41,  PolynomialFeatures(degree=1, include_bias=False)\n",
      "    CV sub-scores:  mean = -0.41,  std = 0.43\n",
      "      CV fold 0  =>  score = -1.2\n",
      "      CV fold 1  =>  score = -0.2\n",
      "      CV fold 2  =>  score = -0.044\n",
      "      CV fold 3  =>  score = -0.36\n",
      "      CV fold 4  =>  score = -0.28\n",
      "      CV fold 5  =>  score = -0.3\n",
      "      CV fold 6  =>  score = -0.18\n",
      "      CV fold 7  =>  score = -0.0086\n",
      "      CV fold 8  =>  score = -0.25\n",
      "      CV fold 9  =>  score = -1.3\n",
      "  degree=   4, score_mean=-0.04,  PolynomialFeatures(degree=4, include_bias=False)\n",
      "    CV sub-scores:  mean = -0.043,  std = 0.071\n",
      "      CV fold 0  =>  score = -0.25\n",
      "      CV fold 1  =>  score = -0.042\n",
      "      CV fold 2  =>  score = -0.027\n",
      "      CV fold 3  =>  score = -0.029\n",
      "      CV fold 4  =>  score = -0.0049\n",
      "      CV fold 5  =>  score = -0.0049\n",
      "      CV fold 6  =>  score = -0.019\n",
      "      CV fold 7  =>  score = -0.038\n",
      "      CV fold 8  =>  score = -0.012\n",
      "      CV fold 9  =>  score = -0.0029\n",
      "  degree=  15, score_mean=-182815433.48,  PolynomialFeatures(degree=15, include_bias=False)\n",
      "    CV sub-scores:  mean = -1.8e+08,  std = 5.5e+08\n",
      "      CV fold 0  =>  score = -1.8e+09\n",
      "      CV fold 1  =>  score = -3.4e+04\n",
      "      CV fold 2  =>  score = -0.0051\n",
      "      CV fold 3  =>  score = -0.007\n",
      "      CV fold 4  =>  score = -0.0092\n",
      "      CV fold 5  =>  score = -0.069\n",
      "      CV fold 6  =>  score = -0.051\n",
      "      CV fold 7  =>  score = -0.079\n",
      "      CV fold 8  =>  score = -0.074\n",
      "      CV fold 9  =>  score = -3.5e+03\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "# NOTE: code from https://scikit-learn.org/stable/auto_examples/model_selection/plot_underfitting_overfitting.html\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def true_fun(X):\n",
    "    return np.cos(1.5 * np.pi * X)\n",
    "\n",
    "def GenerateData(n_samples = 30):\n",
    "    X = np.sort(np.random.rand(n_samples))\n",
    "    y = true_fun(X) + np.random.randn(n_samples) * 0.1\n",
    "    return X, y\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "X, y = GenerateData()\n",
    "degrees = [1, 4, 15]\n",
    "    \n",
    "print(\"Iterating...degrees=\",degrees)\n",
    "plt.figure(figsize=(14, 5))\n",
    "for i in range(len(degrees)):\n",
    "    ax = plt.subplot(1, len(degrees), i + 1)\n",
    "    plt.setp(ax, xticks=(), yticks=())\n",
    "\n",
    "    polynomial_features = PolynomialFeatures(degree=degrees[i], include_bias=False)\n",
    "    \n",
    "    linear_regression = LinearRegression()\n",
    "    pipeline = Pipeline([\n",
    "            (\"polynomial_features\", polynomial_features),\n",
    "            (\"linear_regression\", linear_regression)\n",
    "        ])\n",
    "    pipeline.fit(X[:, np.newaxis], y)\n",
    "\n",
    "    # Evaluate the models using crossvalidation\n",
    "    scores = cross_val_score(pipeline, X[:, np.newaxis], y, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "    \n",
    "    score_mean = scores.mean()\n",
    "    print(f\"  degree={degrees[i]:4d}, score_mean={score_mean:4.2f},  {polynomial_features}\")   \n",
    "\n",
    "    X_test = np.linspace(0, 1, 100)\n",
    "    y_pred = pipeline.predict(X_test[:, np.newaxis])\n",
    "    \n",
    "    # Plotting details\n",
    "    plt.plot(X_test, y_pred          , label=\"Model\")\n",
    "    plt.plot(X_test, true_fun(X_test), label=\"True function\")\n",
    "    plt.scatter(X, y, edgecolor='b', s=20, label=\"Samples\")\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(\"y\")\n",
    "    plt.xlim((0, 1))\n",
    "    plt.ylim((-2, 2))\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.title(\"Degree {}\\nScore(-MSE) = {:.2e}(+/- {:.2e})\".format(degrees[i], scores.mean(), scores.std()))\n",
    "    \n",
    "    # CEF: loop added, prints each score per CV-fold. \n",
    "    #      NOTICE the sub-means when degree=15!\n",
    "    print(f\"    CV sub-scores:  mean = {scores.mean():.2},  std = {scores.std():.2}\")\n",
    "    for i in range(len(scores)):\n",
    "        print(f\"      CV fold {i}  =>  score = {scores[i]:.2}\")\n",
    "        \n",
    "plt.show()\n",
    "print('OK')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qb) Explain the capacity and under/overfitting concept\n",
    "\n",
    "A low degres polynomial regression model will underfit the data, because it will not be able to recoqnize the patternz in the data. This gives a result with a high bias and low variance. We notice this in the plot also where the model is not able to fit the data well and is way off. \n",
    "\n",
    "With the medium degress we get a more balanced fit of the data, and the model is able to recoqnize the patternz in the data. This gives a result with a low bias and low variance. We notice this in the plot also where the model is able to fit the data well and almost follows the true function.\n",
    "\n",
    "Lastly we have a high degree where overfitting is happening. The model is able to fit the data very well, but it is not able to recoqnize the patternz in the data. This gives a result with a low bias and high variance. We notice this in the plot also where the model is able to fit the data very well, but is not able to follow the true function. The model is overfitting the data and is not able to generalize well, this is noticable with how the model correlates very closely with the samples and tries to hit/touch all of them. "
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qc) Score method\n",
    "\n",
    "The scoring method `neg_mean_squared_error` is the MSE but negated so instead of a high score being good, a low score is good.  \n",
    "\n",
    "In the `MSE` the `J-function` is going from bein a cost function to be more of a score function, because we want to maximize some measure of model performance.\n",
    "\n",
    "If we set it to `mean_squared_error` then it raises an exception.  \n",
    "![exception.png](exeception.png) \n",
    "<img src=\"exception.png\" style=\"height:500px\">\n",
    "\n",
    "This happens because the MSE has minimum theoretical score of 0. \n",
    "The highest score is without any upper bound so can grow very large when the actual values are far from the predictions.\n",
    "\n",
    "The high degree model (15) has a big negative value, because the samples are very far form the predictions. Given that it is a negative value, it is a very good score that indicate the model is overfitting the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SWMAL Exercise\n",
    "\n",
    "\n",
    "## Hyperparameters and Gridsearch \n",
    "\n",
    "\n",
    "### Qa Explain GridSearchCV\n",
    "\n",
    "There are two code cells below: 1) function setup, 2) the actual grid-search.\n",
    "\n",
    "Review the code cells and write a __short__ summary. Mainly focus on __cell 2__, but dig into cell 1 if you find it interesting (notice the use of local-function, a nifty feature in python).\n",
    "  \n",
    "In detail, examine the lines:  \n",
    "  \n",
    "```python\n",
    "grid_tuned = GridSearchCV(model, tuning_parameters, ..\n",
    "grid_tuned.fit(X_train, y_train)\n",
    "..\n",
    "FullReport(grid_tuned , X_test, y_test, time_gridsearch)\n",
    "```\n",
    "and write a short description of how the `GridSeachCV` works: explain how the search parameter set is created and the overall search mechanism is functioning (without going into too much detail).\n",
    "\n",
    "What role does the parameter `scoring='f1_micro'` play in the `GridSearchCV`, and what does `n_jobs=-1` mean? \n",
    "\n",
    "\n",
    "\"Cell 1: function setup\n",
    "This cell contains functions and setup related to training and evaluating machine learning models. Key points include:\n",
    "\n",
    "The SearchReport function generates a report based on the results of grid or randomized search. It includes a GetBestModelCTOR function that constructs a string representation of the best model and its parameters.\n",
    "\n",
    "The ClassificationReport function generates a detailed classification report based on the trained model and test data.\n",
    "\n",
    "The FullReport function combines the results of SearchReport and ClassificationReport and prints them.\n",
    "\n",
    "The LoadAndSetupData function loads and sets up the dataset based on the specified mode.\n",
    "\n",
    "There is a TryKerasImport function that checks if the import of Keras or TensorFlow.keras is successful.\n",
    "\n",
    "Cell 2: the actual grid-search\n",
    "This cell performs the actual grid search:\n",
    "\n",
    "Data is loaded using the LoadAndSetupData function for the 'iris' mode.\n",
    "\n",
    "An SVM model (svm.SVC) is defined with a fixed gamma and a set of tuning parameters (tuning_parameters) to be searched through. It also specifies the number of cross-validation folds (CV), verbose level (VERBOSE), and n_jobs=-1 to utilize all available processors.\n",
    "\n",
    "A GridSearchCV object (grid_tuned) is created with the model, tuning parameters, cross-validation strategy, scoring metric ('f1_micro'), verbose level, and the number of parallel jobs.\n",
    "\n",
    "The grid search is executed by calling the fit method on grid_tuned with the training data (X_train and y_train).\n",
    "\n",
    "Results are reported using the FullReport function, which prints the best parameters, best score, and generates a classification report for the test dataset.\n",
    "\n",
    "In summary, the GridSearchCV is used to systematically search through a specified parameter grid for the best hyperparameters of a given model. The parameter set is created based on the provided tuning parameters. The scoring='f1_micro' parameter indicates that the model's performance is evaluated using the F1 micro score. The n_jobs=-1 parameter means that the search is performed in parallel using all available processors, which can significantly speed up the process.\"\n",
    "Answered by chatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-17T13:13:31.964531Z",
     "start_time": "2023-11-17T13:13:31.923824Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK(function setup)\n"
     ]
    }
   ],
   "source": [
    "# TODO: Qa, code review..cell 1) function setup\n",
    "\n",
    "from time import time\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, train_test_split\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn import datasets\n",
    "\n",
    "import sys,os\n",
    "sys.path.append(os.path.expanduser('../'))\n",
    "from libitmal import dataloaders as itmaldataloaders # Needed for load of iris, moon and mnist\n",
    "\n",
    "currmode=\"N/A\" # GLOBAL var!\n",
    "\n",
    "def SearchReport(model): \n",
    "    \n",
    "    def GetBestModelCTOR(model, best_params):\n",
    "        def GetParams(best_params):\n",
    "            ret_str=\"\"          \n",
    "            for key in sorted(best_params):\n",
    "                value = best_params[key]\n",
    "                temp_str = \"'\" if str(type(value))==\"<class 'str'>\" else \"\"\n",
    "                if len(ret_str)>0:\n",
    "                    ret_str += ','\n",
    "                ret_str += f'{key}={temp_str}{value}{temp_str}'  \n",
    "            return ret_str          \n",
    "        try:\n",
    "            param_str = GetParams(best_params)\n",
    "            return type(model).__name__ + '(' + param_str + ')' \n",
    "        except:\n",
    "            return \"N/A(1)\"\n",
    "        \n",
    "    print(\"\\nBest model set found on train set:\")\n",
    "    print()\n",
    "    print(f\"\\tbest parameters={model.best_params_}\")\n",
    "    print(f\"\\tbest '{model.scoring}' score={model.best_score_}\")\n",
    "    print(f\"\\tbest index={model.best_index_}\")\n",
    "    print()\n",
    "    print(f\"Best estimator CTOR:\")\n",
    "    print(f\"\\t{model.best_estimator_}\")\n",
    "    print()\n",
    "    try:\n",
    "        print(f\"Grid scores ('{model.scoring}') on development set:\")\n",
    "        means = model.cv_results_['mean_test_score']\n",
    "        stds  = model.cv_results_['std_test_score']\n",
    "        i=0\n",
    "        for mean, std, params in zip(means, stds, model.cv_results_['params']):\n",
    "            print(\"\\t[%2d]: %0.3f (+/-%0.03f) for %r\" % (i, mean, std * 2, params))\n",
    "            i += 1\n",
    "    except:\n",
    "        print(\"WARNING: the random search do not provide means/stds\")\n",
    "    \n",
    "    global currmode                \n",
    "    assert \"f1_micro\"==str(model.scoring), f\"come on, we need to fix the scoring to be able to compare model-fits! Your scoreing={str(model.scoring)}...remember to add scoring='f1_micro' to the search\"   \n",
    "    return f\"best: dat={currmode}, score={model.best_score_:0.5f}, model={GetBestModelCTOR(model.estimator,model.best_params_)}\", model.best_estimator_ \n",
    "\n",
    "def ClassificationReport(model, X_test, y_test, target_names=None):\n",
    "    assert X_test.shape[0]==y_test.shape[0]\n",
    "    print(\"\\nDetailed classification report:\")\n",
    "    print(\"\\tThe model is trained on the full development set.\")\n",
    "    print(\"\\tThe scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test, model.predict(X_test)                 \n",
    "    print(classification_report(y_true, y_pred, target_names=target_names))\n",
    "    print()\n",
    "    \n",
    "def FullReport(model, X_test, y_test, t):\n",
    "    print(f\"SEARCH TIME: {t:0.2f} sec\")\n",
    "    beststr, bestmodel = SearchReport(model)\n",
    "    ClassificationReport(model, X_test, y_test)    \n",
    "    print(f\"CTOR for best model: {bestmodel}\\n\")\n",
    "    print(f\"{beststr}\\n\")\n",
    "    return beststr, bestmodel\n",
    "    \n",
    "def LoadAndSetupData(mode, test_size=0.3):\n",
    "    assert test_size>=0.0 and test_size<=1.0\n",
    "    \n",
    "    def ShapeToString(Z):\n",
    "        n = Z.ndim\n",
    "        s = \"(\"\n",
    "        for i in range(n):\n",
    "            s += f\"{Z.shape[i]:5d}\"\n",
    "            if i+1!=n:\n",
    "                s += \";\"\n",
    "        return s+\")\"\n",
    "\n",
    "    global currmode\n",
    "    currmode=mode\n",
    "    print(f\"DATA: {currmode}..\")\n",
    "    \n",
    "    if mode=='moon':\n",
    "        X, y = itmaldataloaders.MOON_GetDataSet(n_samples=5000, noise=0.2)\n",
    "        itmaldataloaders.MOON_Plot(X, y)\n",
    "    elif mode=='mnist':\n",
    "        X, y = itmaldataloaders.MNIST_GetDataSet(load_mode=0)\n",
    "        if X.ndim==3:\n",
    "            X=np.reshape(X, (X.shape[0], -1))\n",
    "    elif mode=='iris':\n",
    "        X, y = itmaldataloaders.IRIS_GetDataSet()\n",
    "    else:\n",
    "        raise ValueError(f\"could not load data for that particular mode='{mode}', only 'moon'/'mnist'/'iris' supported\")\n",
    "        \n",
    "    print(f'  org. data:  X.shape      ={ShapeToString(X)}, y.shape      ={ShapeToString(y)}')\n",
    "\n",
    "    assert X.ndim==2\n",
    "    assert X.shape[0]==y.shape[0]\n",
    "    assert y.ndim==1 or (y.ndim==2 and y.shape[1]==0)    \n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=0, shuffle=True\n",
    "    )\n",
    "    \n",
    "    print(f'  train data: X_train.shape={ShapeToString(X_train)}, y_train.shape={ShapeToString(y_train)}')\n",
    "    print(f'  test data:  X_test.shape ={ShapeToString(X_test)}, y_test.shape ={ShapeToString(y_test)}')\n",
    "    print()\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def TryKerasImport(verbose=True):\n",
    "    \n",
    "    kerasok = True\n",
    "    try:\n",
    "        import keras as keras_try\n",
    "    except:\n",
    "        kerasok = False\n",
    "\n",
    "    tensorflowkerasok = True\n",
    "    try:\n",
    "        import tensorflow.keras as tensorflowkeras_try\n",
    "    except:\n",
    "        tensorflowkerasok = False\n",
    "        \n",
    "    ok = kerasok or tensorflowkerasok\n",
    "    \n",
    "    if not ok and verbose:\n",
    "        if not kerasok:\n",
    "            print(\"WARNING: importing 'keras' failed\", file=sys.stderr)\n",
    "        if not tensorflowkerasok:\n",
    "            print(\"WARNING: importing 'tensorflow.keras' failed\", file=sys.stderr)\n",
    "\n",
    "    return ok\n",
    "    \n",
    "print(f\"OK(function setup\" + (\"\" if TryKerasImport() else \", hope MNIST loads works because it seems you miss the installation of Keras or Tensorflow!\") + \")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-17T13:13:32.853078Z",
     "start_time": "2023-11-17T13:13:31.928083Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA: iris..\n",
      "  org. data:  X.shape      =(  150;    4), y.shape      =(  150)\n",
      "  train data: X_train.shape=(  105;    4), y_train.shape=(  105)\n",
      "  test data:  X_test.shape =(   45;    4), y_test.shape =(   45)\n",
      "SEARCH TIME: 0.91 sec\n",
      "\n",
      "Best model set found on train set:\n",
      "\n",
      "\tbest parameters={'C': 1, 'kernel': 'linear'}\n",
      "\tbest 'f1_micro' score=0.9714285714285715\n",
      "\tbest index=2\n",
      "\n",
      "Best estimator CTOR:\n",
      "\tSVC(C=1, gamma=0.001, kernel='linear')\n",
      "\n",
      "Grid scores ('f1_micro') on development set:\n",
      "\t[ 0]: 0.962 (+/-0.093) for {'C': 0.1, 'kernel': 'linear'}\n",
      "\t[ 1]: 0.371 (+/-0.038) for {'C': 0.1, 'kernel': 'rbf'}\n",
      "\t[ 2]: 0.971 (+/-0.047) for {'C': 1, 'kernel': 'linear'}\n",
      "\t[ 3]: 0.695 (+/-0.047) for {'C': 1, 'kernel': 'rbf'}\n",
      "\t[ 4]: 0.952 (+/-0.085) for {'C': 10, 'kernel': 'linear'}\n",
      "\t[ 5]: 0.924 (+/-0.097) for {'C': 10, 'kernel': 'rbf'}\n",
      "\n",
      "Detailed classification report:\n",
      "\tThe model is trained on the full development set.\n",
      "\tThe scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        16\n",
      "           1       1.00      0.94      0.97        18\n",
      "           2       0.92      1.00      0.96        11\n",
      "\n",
      "    accuracy                           0.98        45\n",
      "   macro avg       0.97      0.98      0.98        45\n",
      "weighted avg       0.98      0.98      0.98        45\n",
      "\n",
      "\n",
      "CTOR for best model: SVC(C=1, gamma=0.001, kernel='linear')\n",
      "\n",
      "best: dat=iris, score=0.97143, model=SVC(C=1,kernel='linear')\n",
      "\n",
      "OK(grid-search)\n"
     ]
    }
   ],
   "source": [
    "# TODO: Qa, code review..cell 2) the actual grid-search\n",
    "\n",
    "# Setup data\n",
    "X_train, X_test, y_train, y_test = LoadAndSetupData(\n",
    "    'iris')  # 'iris', 'moon', or 'mnist'\n",
    "\n",
    "# Setup search parameters\n",
    "model = svm.SVC(\n",
    "    gamma=0.001\n",
    ")  # NOTE: gamma=\"scale\" does not work in older Scikit-learn frameworks,\n",
    "# FIX:  replace with model = svm.SVC(gamma=0.001)\n",
    "\n",
    "tuning_parameters = {\n",
    "    'kernel': ('linear', 'rbf'), \n",
    "    'C': [0.1, 1, 10]\n",
    "}\n",
    "\n",
    "CV = 5\n",
    "VERBOSE = 0\n",
    "\n",
    "# Run GridSearchCV for the model\n",
    "grid_tuned = GridSearchCV(model,\n",
    "                          tuning_parameters,\n",
    "                          cv=CV,\n",
    "                          scoring='f1_micro',\n",
    "                          verbose=VERBOSE,\n",
    "                          n_jobs=-1)\n",
    "\n",
    "start = time()\n",
    "grid_tuned.fit(X_train, y_train)\n",
    "t = time() - start\n",
    "\n",
    "# Report result\n",
    "b0, m0 = FullReport(grid_tuned, X_test, y_test, t)\n",
    "print('OK(grid-search)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qb Hyperparameter Grid Search using an SDG classifier\n",
    "\n",
    "The svm.SVC model has been substituted with an SGDClassifier, and the model's hyperparameters have been adjusted. A  different loss function is now employed. Additionally, there has been set a maximum number of iterations and regularization to mitigate overfitting, though it results in a less flexible model. The parameter eta0 represents the initial learning rate, and penalty determines the type of regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-17T13:13:37.077636Z",
     "start_time": "2023-11-17T13:13:32.851828Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA: iris..\n",
      "  org. data:  X.shape      =(  150;    4), y.shape      =(  150)\n",
      "  train data: X_train.shape=(  105;    4), y_train.shape=(  105)\n",
      "  test data:  X_test.shape =(   45;    4), y_test.shape =(   45)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEARCH TIME: 4.19 sec\n",
      "\n",
      "Best model set found on train set:\n",
      "\n",
      "\tbest parameters={'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\tbest 'f1_micro' score=0.9904761904761905\n",
      "\tbest index=1672\n",
      "\n",
      "Best estimator CTOR:\n",
      "\tSGDClassifier(alpha=0.001, eta0=0.01, loss='perceptron', max_iter=300,\n",
      "              n_iter_no_change=20, penalty='l1', power_t=0.1, random_state=42)\n",
      "\n",
      "Grid scores ('f1_micro') on development set:\n",
      "\t[ 0]: 0.905 (+/-0.085) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[ 1]: 0.905 (+/-0.085) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[ 2]: 0.905 (+/-0.085) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[ 3]: 0.905 (+/-0.085) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[ 4]: 0.886 (+/-0.238) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[ 5]: 0.886 (+/-0.238) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[ 6]: 0.886 (+/-0.238) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[ 7]: 0.886 (+/-0.238) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[ 8]: 0.914 (+/-0.111) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[ 9]: 0.914 (+/-0.111) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[10]: 0.914 (+/-0.111) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[11]: 0.914 (+/-0.111) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[12]: 0.924 (+/-0.076) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[13]: 0.924 (+/-0.076) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[14]: 0.924 (+/-0.076) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[15]: 0.924 (+/-0.076) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[16]: 0.876 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[17]: 0.876 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[18]: 0.876 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[19]: 0.876 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[20]: 0.905 (+/-0.060) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[21]: 0.905 (+/-0.060) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[22]: 0.905 (+/-0.060) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[23]: 0.905 (+/-0.060) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[24]: 0.905 (+/-0.085) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[25]: 0.905 (+/-0.085) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[26]: 0.905 (+/-0.085) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[27]: 0.905 (+/-0.085) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[28]: 0.886 (+/-0.238) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[29]: 0.886 (+/-0.238) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[30]: 0.886 (+/-0.238) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[31]: 0.886 (+/-0.238) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[32]: 0.914 (+/-0.111) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[33]: 0.914 (+/-0.111) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[34]: 0.914 (+/-0.111) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[35]: 0.914 (+/-0.111) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[36]: 0.924 (+/-0.076) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[37]: 0.924 (+/-0.076) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[38]: 0.924 (+/-0.076) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[39]: 0.924 (+/-0.076) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[40]: 0.876 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[41]: 0.876 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[42]: 0.876 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[43]: 0.876 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[44]: 0.905 (+/-0.060) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[45]: 0.905 (+/-0.060) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[46]: 0.905 (+/-0.060) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[47]: 0.905 (+/-0.060) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[48]: 0.905 (+/-0.085) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[49]: 0.905 (+/-0.085) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[50]: 0.905 (+/-0.085) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[51]: 0.905 (+/-0.085) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[52]: 0.886 (+/-0.238) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[53]: 0.886 (+/-0.238) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[54]: 0.886 (+/-0.238) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[55]: 0.886 (+/-0.238) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[56]: 0.914 (+/-0.111) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[57]: 0.914 (+/-0.111) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[58]: 0.914 (+/-0.111) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[59]: 0.914 (+/-0.111) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[60]: 0.924 (+/-0.076) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[61]: 0.924 (+/-0.076) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[62]: 0.924 (+/-0.076) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[63]: 0.924 (+/-0.076) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[64]: 0.876 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[65]: 0.876 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[66]: 0.876 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[67]: 0.876 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[68]: 0.905 (+/-0.060) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[69]: 0.905 (+/-0.060) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[70]: 0.905 (+/-0.060) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[71]: 0.905 (+/-0.060) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[72]: 0.714 (+/-0.313) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[73]: 0.714 (+/-0.313) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[74]: 0.714 (+/-0.313) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[75]: 0.714 (+/-0.313) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[76]: 0.705 (+/-0.327) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[77]: 0.705 (+/-0.327) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[78]: 0.705 (+/-0.327) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[79]: 0.705 (+/-0.327) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[80]: 0.848 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[81]: 0.848 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[82]: 0.848 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[83]: 0.848 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[84]: 0.848 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[85]: 0.848 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[86]: 0.848 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[87]: 0.848 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[88]: 0.829 (+/-0.273) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[89]: 0.829 (+/-0.273) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[90]: 0.829 (+/-0.273) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[91]: 0.829 (+/-0.273) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[92]: 0.829 (+/-0.273) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[93]: 0.829 (+/-0.273) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[94]: 0.829 (+/-0.273) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[95]: 0.829 (+/-0.273) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[96]: 0.714 (+/-0.313) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[97]: 0.714 (+/-0.313) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[98]: 0.714 (+/-0.313) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[99]: 0.714 (+/-0.313) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[100]: 0.705 (+/-0.327) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[101]: 0.705 (+/-0.327) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[102]: 0.705 (+/-0.327) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[103]: 0.705 (+/-0.327) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[104]: 0.848 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[105]: 0.848 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[106]: 0.848 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[107]: 0.848 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[108]: 0.848 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[109]: 0.848 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[110]: 0.848 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[111]: 0.848 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[112]: 0.829 (+/-0.273) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[113]: 0.829 (+/-0.273) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[114]: 0.829 (+/-0.273) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[115]: 0.829 (+/-0.273) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[116]: 0.829 (+/-0.273) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[117]: 0.829 (+/-0.273) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[118]: 0.829 (+/-0.273) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[119]: 0.829 (+/-0.273) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[120]: 0.714 (+/-0.313) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[121]: 0.714 (+/-0.313) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[122]: 0.714 (+/-0.313) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[123]: 0.714 (+/-0.313) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[124]: 0.705 (+/-0.327) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[125]: 0.705 (+/-0.327) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[126]: 0.705 (+/-0.327) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[127]: 0.705 (+/-0.327) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[128]: 0.848 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[129]: 0.848 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[130]: 0.848 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[131]: 0.848 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[132]: 0.848 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[133]: 0.848 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[134]: 0.848 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[135]: 0.848 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[136]: 0.829 (+/-0.273) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[137]: 0.829 (+/-0.273) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[138]: 0.829 (+/-0.273) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[139]: 0.829 (+/-0.273) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[140]: 0.829 (+/-0.273) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[141]: 0.829 (+/-0.273) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[142]: 0.829 (+/-0.273) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[143]: 0.829 (+/-0.273) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[144]: 0.781 (+/-0.364) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[145]: 0.781 (+/-0.364) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[146]: 0.781 (+/-0.364) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[147]: 0.781 (+/-0.364) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[148]: 0.933 (+/-0.076) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[149]: 0.933 (+/-0.076) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[150]: 0.933 (+/-0.076) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[151]: 0.933 (+/-0.076) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[152]: 0.781 (+/-0.214) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[153]: 0.781 (+/-0.214) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[154]: 0.781 (+/-0.214) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[155]: 0.781 (+/-0.214) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[156]: 0.743 (+/-0.461) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[157]: 0.743 (+/-0.461) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[158]: 0.743 (+/-0.461) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[159]: 0.743 (+/-0.461) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[160]: 0.686 (+/-0.245) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[161]: 0.686 (+/-0.245) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[162]: 0.686 (+/-0.245) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[163]: 0.686 (+/-0.245) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[164]: 0.829 (+/-0.286) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[165]: 0.829 (+/-0.286) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[166]: 0.829 (+/-0.286) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[167]: 0.829 (+/-0.286) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[168]: 0.781 (+/-0.364) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[169]: 0.781 (+/-0.364) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[170]: 0.781 (+/-0.364) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[171]: 0.781 (+/-0.364) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[172]: 0.933 (+/-0.076) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[173]: 0.933 (+/-0.076) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[174]: 0.933 (+/-0.076) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[175]: 0.933 (+/-0.076) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[176]: 0.781 (+/-0.214) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[177]: 0.781 (+/-0.214) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[178]: 0.781 (+/-0.214) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[179]: 0.781 (+/-0.214) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[180]: 0.743 (+/-0.461) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[181]: 0.743 (+/-0.461) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[182]: 0.743 (+/-0.461) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[183]: 0.743 (+/-0.461) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[184]: 0.686 (+/-0.245) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[185]: 0.686 (+/-0.245) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[186]: 0.686 (+/-0.245) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[187]: 0.686 (+/-0.245) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[188]: 0.829 (+/-0.286) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[189]: 0.829 (+/-0.286) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[190]: 0.829 (+/-0.286) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[191]: 0.829 (+/-0.286) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[192]: 0.781 (+/-0.364) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[193]: 0.781 (+/-0.364) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[194]: 0.781 (+/-0.364) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[195]: 0.781 (+/-0.364) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[196]: 0.933 (+/-0.076) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[197]: 0.933 (+/-0.076) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[198]: 0.933 (+/-0.076) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[199]: 0.933 (+/-0.076) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[200]: 0.781 (+/-0.214) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[201]: 0.781 (+/-0.214) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[202]: 0.781 (+/-0.214) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[203]: 0.781 (+/-0.214) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[204]: 0.743 (+/-0.461) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[205]: 0.743 (+/-0.461) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[206]: 0.743 (+/-0.461) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[207]: 0.743 (+/-0.461) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[208]: 0.686 (+/-0.245) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[209]: 0.686 (+/-0.245) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[210]: 0.686 (+/-0.245) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[211]: 0.686 (+/-0.245) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[212]: 0.829 (+/-0.286) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[213]: 0.829 (+/-0.286) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[214]: 0.829 (+/-0.286) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[215]: 0.829 (+/-0.286) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[216]: 0.819 (+/-0.304) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[217]: 0.819 (+/-0.304) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[218]: 0.819 (+/-0.304) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[219]: 0.819 (+/-0.304) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[220]: 0.895 (+/-0.111) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[221]: 0.895 (+/-0.111) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[222]: 0.895 (+/-0.111) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[223]: 0.895 (+/-0.111) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[224]: 0.895 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[225]: 0.895 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[226]: 0.895 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[227]: 0.895 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[228]: 0.790 (+/-0.230) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[229]: 0.790 (+/-0.230) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[230]: 0.790 (+/-0.230) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[231]: 0.790 (+/-0.230) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[232]: 0.962 (+/-0.038) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[233]: 0.962 (+/-0.038) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[234]: 0.962 (+/-0.038) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[235]: 0.962 (+/-0.038) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[236]: 0.886 (+/-0.177) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[237]: 0.886 (+/-0.177) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[238]: 0.886 (+/-0.177) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[239]: 0.886 (+/-0.177) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[240]: 0.819 (+/-0.304) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[241]: 0.819 (+/-0.304) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[242]: 0.819 (+/-0.304) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[243]: 0.819 (+/-0.304) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[244]: 0.895 (+/-0.111) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[245]: 0.895 (+/-0.111) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[246]: 0.895 (+/-0.111) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[247]: 0.895 (+/-0.111) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[248]: 0.895 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[249]: 0.895 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[250]: 0.895 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[251]: 0.895 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[252]: 0.790 (+/-0.230) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[253]: 0.790 (+/-0.230) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[254]: 0.790 (+/-0.230) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[255]: 0.790 (+/-0.230) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[256]: 0.962 (+/-0.038) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[257]: 0.962 (+/-0.038) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[258]: 0.962 (+/-0.038) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[259]: 0.962 (+/-0.038) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[260]: 0.886 (+/-0.177) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[261]: 0.886 (+/-0.177) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[262]: 0.886 (+/-0.177) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[263]: 0.886 (+/-0.177) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[264]: 0.819 (+/-0.304) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[265]: 0.819 (+/-0.304) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[266]: 0.819 (+/-0.304) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[267]: 0.819 (+/-0.304) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[268]: 0.895 (+/-0.111) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[269]: 0.895 (+/-0.111) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[270]: 0.895 (+/-0.111) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[271]: 0.895 (+/-0.111) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[272]: 0.895 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[273]: 0.895 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[274]: 0.895 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[275]: 0.895 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[276]: 0.790 (+/-0.230) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[277]: 0.790 (+/-0.230) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[278]: 0.790 (+/-0.230) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[279]: 0.790 (+/-0.230) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[280]: 0.962 (+/-0.038) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[281]: 0.962 (+/-0.038) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[282]: 0.962 (+/-0.038) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[283]: 0.962 (+/-0.038) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[284]: 0.886 (+/-0.177) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[285]: 0.886 (+/-0.177) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[286]: 0.886 (+/-0.177) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[287]: 0.886 (+/-0.177) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[288]: 0.886 (+/-0.143) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[289]: 0.886 (+/-0.143) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[290]: 0.886 (+/-0.143) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[291]: 0.886 (+/-0.143) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[292]: 0.857 (+/-0.295) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[293]: 0.857 (+/-0.295) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[294]: 0.857 (+/-0.295) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[295]: 0.857 (+/-0.295) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[296]: 0.943 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[297]: 0.943 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[298]: 0.943 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[299]: 0.943 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[300]: 0.838 (+/-0.238) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[301]: 0.838 (+/-0.238) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[302]: 0.838 (+/-0.238) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[303]: 0.838 (+/-0.238) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[304]: 0.962 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[305]: 0.962 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[306]: 0.962 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[307]: 0.962 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[308]: 0.886 (+/-0.114) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[309]: 0.886 (+/-0.114) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[310]: 0.886 (+/-0.114) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[311]: 0.886 (+/-0.114) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[312]: 0.886 (+/-0.143) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[313]: 0.886 (+/-0.143) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[314]: 0.886 (+/-0.143) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[315]: 0.886 (+/-0.143) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[316]: 0.857 (+/-0.295) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[317]: 0.857 (+/-0.295) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[318]: 0.857 (+/-0.295) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[319]: 0.857 (+/-0.295) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[320]: 0.943 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[321]: 0.943 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[322]: 0.943 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[323]: 0.943 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[324]: 0.838 (+/-0.238) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[325]: 0.838 (+/-0.238) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[326]: 0.838 (+/-0.238) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[327]: 0.838 (+/-0.238) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[328]: 0.962 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[329]: 0.962 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[330]: 0.962 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[331]: 0.962 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[332]: 0.886 (+/-0.114) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[333]: 0.886 (+/-0.114) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[334]: 0.886 (+/-0.114) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[335]: 0.886 (+/-0.114) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[336]: 0.886 (+/-0.143) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[337]: 0.886 (+/-0.143) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[338]: 0.886 (+/-0.143) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[339]: 0.886 (+/-0.143) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[340]: 0.857 (+/-0.295) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[341]: 0.857 (+/-0.295) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[342]: 0.857 (+/-0.295) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[343]: 0.857 (+/-0.295) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[344]: 0.943 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[345]: 0.943 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[346]: 0.943 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[347]: 0.943 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[348]: 0.838 (+/-0.238) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[349]: 0.838 (+/-0.238) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[350]: 0.838 (+/-0.238) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[351]: 0.838 (+/-0.238) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[352]: 0.962 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[353]: 0.962 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[354]: 0.962 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[355]: 0.962 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[356]: 0.886 (+/-0.114) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[357]: 0.886 (+/-0.114) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[358]: 0.886 (+/-0.114) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[359]: 0.886 (+/-0.114) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[360]: 0.886 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[361]: 0.886 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[362]: 0.886 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[363]: 0.886 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[364]: 0.762 (+/-0.508) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[365]: 0.762 (+/-0.508) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[366]: 0.762 (+/-0.508) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[367]: 0.762 (+/-0.508) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[368]: 0.895 (+/-0.152) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[369]: 0.895 (+/-0.152) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[370]: 0.895 (+/-0.152) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[371]: 0.895 (+/-0.152) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[372]: 0.800 (+/-0.212) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[373]: 0.800 (+/-0.212) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[374]: 0.800 (+/-0.212) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[375]: 0.800 (+/-0.212) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[376]: 0.952 (+/-0.060) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[377]: 0.952 (+/-0.060) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[378]: 0.952 (+/-0.060) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[379]: 0.952 (+/-0.060) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[380]: 0.876 (+/-0.205) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[381]: 0.876 (+/-0.205) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[382]: 0.876 (+/-0.205) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[383]: 0.876 (+/-0.205) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[384]: 0.886 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[385]: 0.886 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[386]: 0.886 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[387]: 0.886 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[388]: 0.762 (+/-0.508) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[389]: 0.762 (+/-0.508) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[390]: 0.762 (+/-0.508) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[391]: 0.762 (+/-0.508) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[392]: 0.895 (+/-0.152) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[393]: 0.895 (+/-0.152) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[394]: 0.895 (+/-0.152) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[395]: 0.895 (+/-0.152) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[396]: 0.800 (+/-0.212) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[397]: 0.800 (+/-0.212) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[398]: 0.800 (+/-0.212) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[399]: 0.800 (+/-0.212) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[400]: 0.952 (+/-0.060) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[401]: 0.952 (+/-0.060) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[402]: 0.952 (+/-0.060) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[403]: 0.952 (+/-0.060) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[404]: 0.876 (+/-0.205) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[405]: 0.876 (+/-0.205) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[406]: 0.876 (+/-0.205) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[407]: 0.876 (+/-0.205) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[408]: 0.886 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[409]: 0.886 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[410]: 0.886 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[411]: 0.886 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[412]: 0.762 (+/-0.508) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[413]: 0.762 (+/-0.508) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[414]: 0.762 (+/-0.508) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[415]: 0.762 (+/-0.508) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[416]: 0.895 (+/-0.152) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[417]: 0.895 (+/-0.152) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[418]: 0.895 (+/-0.152) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[419]: 0.895 (+/-0.152) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[420]: 0.800 (+/-0.212) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[421]: 0.800 (+/-0.212) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[422]: 0.800 (+/-0.212) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[423]: 0.800 (+/-0.212) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[424]: 0.952 (+/-0.060) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[425]: 0.952 (+/-0.060) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[426]: 0.952 (+/-0.060) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[427]: 0.952 (+/-0.060) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[428]: 0.876 (+/-0.205) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[429]: 0.876 (+/-0.205) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[430]: 0.876 (+/-0.205) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[431]: 0.876 (+/-0.205) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[432]: 0.933 (+/-0.114) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[433]: 0.933 (+/-0.114) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[434]: 0.695 (+/-0.047) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[435]: 0.695 (+/-0.047) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[436]: 0.914 (+/-0.126) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[437]: 0.914 (+/-0.126) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[438]: 0.695 (+/-0.047) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[439]: 0.695 (+/-0.047) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[440]: 0.886 (+/-0.222) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[441]: 0.886 (+/-0.222) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[442]: 0.695 (+/-0.047) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[443]: 0.695 (+/-0.047) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[444]: 0.924 (+/-0.047) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[445]: 0.924 (+/-0.047) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[446]: 0.695 (+/-0.047) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[447]: 0.695 (+/-0.047) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[448]: 0.905 (+/-0.104) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[449]: 0.905 (+/-0.104) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[450]: 0.695 (+/-0.047) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[451]: 0.695 (+/-0.047) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[452]: 0.895 (+/-0.111) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[453]: 0.895 (+/-0.111) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[454]: 0.695 (+/-0.047) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[455]: 0.695 (+/-0.047) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[456]: 0.933 (+/-0.114) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[457]: 0.933 (+/-0.114) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[458]: 0.695 (+/-0.047) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[459]: 0.695 (+/-0.047) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[460]: 0.914 (+/-0.126) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[461]: 0.914 (+/-0.126) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[462]: 0.695 (+/-0.047) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[463]: 0.695 (+/-0.047) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[464]: 0.886 (+/-0.222) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[465]: 0.886 (+/-0.222) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[466]: 0.695 (+/-0.047) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[467]: 0.695 (+/-0.047) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[468]: 0.924 (+/-0.047) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[469]: 0.924 (+/-0.047) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[470]: 0.695 (+/-0.047) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[471]: 0.695 (+/-0.047) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[472]: 0.905 (+/-0.104) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[473]: 0.905 (+/-0.104) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[474]: 0.695 (+/-0.047) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[475]: 0.695 (+/-0.047) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[476]: 0.895 (+/-0.111) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[477]: 0.895 (+/-0.111) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[478]: 0.695 (+/-0.047) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[479]: 0.695 (+/-0.047) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[480]: 0.933 (+/-0.114) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[481]: 0.933 (+/-0.114) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[482]: 0.695 (+/-0.047) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[483]: 0.695 (+/-0.047) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[484]: 0.914 (+/-0.126) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[485]: 0.914 (+/-0.126) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[486]: 0.695 (+/-0.047) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[487]: 0.695 (+/-0.047) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[488]: 0.886 (+/-0.222) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[489]: 0.886 (+/-0.222) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[490]: 0.695 (+/-0.047) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[491]: 0.695 (+/-0.047) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[492]: 0.924 (+/-0.047) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[493]: 0.924 (+/-0.047) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[494]: 0.695 (+/-0.047) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[495]: 0.695 (+/-0.047) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[496]: 0.905 (+/-0.104) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[497]: 0.905 (+/-0.104) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[498]: 0.695 (+/-0.047) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[499]: 0.695 (+/-0.047) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[500]: 0.895 (+/-0.111) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[501]: 0.895 (+/-0.111) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[502]: 0.695 (+/-0.047) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[503]: 0.695 (+/-0.047) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[504]: 0.952 (+/-0.104) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[505]: 0.952 (+/-0.104) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[506]: 0.848 (+/-0.152) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[507]: 0.848 (+/-0.152) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[508]: 0.952 (+/-0.104) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[509]: 0.952 (+/-0.104) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[510]: 0.848 (+/-0.152) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[511]: 0.848 (+/-0.152) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[512]: 0.914 (+/-0.093) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[513]: 0.914 (+/-0.093) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[514]: 0.867 (+/-0.126) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[515]: 0.867 (+/-0.126) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[516]: 0.914 (+/-0.093) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[517]: 0.914 (+/-0.093) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[518]: 0.867 (+/-0.126) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[519]: 0.867 (+/-0.126) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[520]: 0.867 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[521]: 0.867 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[522]: 0.857 (+/-0.104) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[523]: 0.857 (+/-0.104) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[524]: 0.867 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[525]: 0.867 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[526]: 0.857 (+/-0.104) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[527]: 0.857 (+/-0.104) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[528]: 0.952 (+/-0.104) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[529]: 0.952 (+/-0.104) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[530]: 0.848 (+/-0.152) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[531]: 0.848 (+/-0.152) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[532]: 0.952 (+/-0.104) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[533]: 0.952 (+/-0.104) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[534]: 0.848 (+/-0.152) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[535]: 0.848 (+/-0.152) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[536]: 0.914 (+/-0.093) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[537]: 0.914 (+/-0.093) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[538]: 0.867 (+/-0.126) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[539]: 0.867 (+/-0.126) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[540]: 0.914 (+/-0.093) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[541]: 0.914 (+/-0.093) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[542]: 0.867 (+/-0.126) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[543]: 0.867 (+/-0.126) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[544]: 0.867 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[545]: 0.867 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[546]: 0.857 (+/-0.104) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[547]: 0.857 (+/-0.104) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[548]: 0.867 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[549]: 0.867 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[550]: 0.857 (+/-0.104) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[551]: 0.857 (+/-0.104) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[552]: 0.952 (+/-0.104) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[553]: 0.952 (+/-0.104) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[554]: 0.848 (+/-0.152) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[555]: 0.848 (+/-0.152) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[556]: 0.952 (+/-0.104) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[557]: 0.952 (+/-0.104) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[558]: 0.848 (+/-0.152) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[559]: 0.848 (+/-0.152) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[560]: 0.914 (+/-0.093) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[561]: 0.914 (+/-0.093) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[562]: 0.867 (+/-0.126) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[563]: 0.867 (+/-0.126) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[564]: 0.914 (+/-0.093) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[565]: 0.914 (+/-0.093) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[566]: 0.867 (+/-0.126) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[567]: 0.867 (+/-0.126) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[568]: 0.867 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[569]: 0.867 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[570]: 0.857 (+/-0.104) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[571]: 0.857 (+/-0.104) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[572]: 0.867 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[573]: 0.867 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[574]: 0.857 (+/-0.104) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[575]: 0.857 (+/-0.104) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[576]: 0.848 (+/-0.279) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[577]: 0.848 (+/-0.279) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[578]: 0.914 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[579]: 0.914 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[580]: 0.867 (+/-0.220) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[581]: 0.867 (+/-0.220) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[582]: 0.876 (+/-0.076) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[583]: 0.876 (+/-0.076) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[584]: 0.771 (+/-0.440) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[585]: 0.771 (+/-0.440) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[586]: 0.924 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[587]: 0.924 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[588]: 0.667 (+/-0.200) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[589]: 0.667 (+/-0.200) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[590]: 0.895 (+/-0.111) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[591]: 0.895 (+/-0.111) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[592]: 0.695 (+/-0.506) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[593]: 0.695 (+/-0.506) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[594]: 0.924 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[595]: 0.924 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[596]: 0.743 (+/-0.374) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[597]: 0.743 (+/-0.374) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[598]: 0.895 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[599]: 0.895 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[600]: 0.848 (+/-0.279) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[601]: 0.848 (+/-0.279) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[602]: 0.914 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[603]: 0.914 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[604]: 0.867 (+/-0.220) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[605]: 0.867 (+/-0.220) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[606]: 0.876 (+/-0.076) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[607]: 0.876 (+/-0.076) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[608]: 0.771 (+/-0.440) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[609]: 0.771 (+/-0.440) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[610]: 0.924 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[611]: 0.924 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[612]: 0.667 (+/-0.200) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[613]: 0.667 (+/-0.200) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[614]: 0.895 (+/-0.111) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[615]: 0.895 (+/-0.111) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[616]: 0.695 (+/-0.506) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[617]: 0.695 (+/-0.506) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[618]: 0.924 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[619]: 0.924 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[620]: 0.743 (+/-0.374) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[621]: 0.743 (+/-0.374) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[622]: 0.895 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[623]: 0.895 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[624]: 0.848 (+/-0.279) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[625]: 0.848 (+/-0.279) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[626]: 0.914 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[627]: 0.914 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[628]: 0.867 (+/-0.220) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[629]: 0.867 (+/-0.220) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[630]: 0.876 (+/-0.076) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[631]: 0.876 (+/-0.076) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[632]: 0.771 (+/-0.440) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[633]: 0.771 (+/-0.440) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[634]: 0.924 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[635]: 0.924 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[636]: 0.667 (+/-0.200) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[637]: 0.667 (+/-0.200) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[638]: 0.895 (+/-0.111) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[639]: 0.895 (+/-0.111) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[640]: 0.695 (+/-0.506) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[641]: 0.695 (+/-0.506) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[642]: 0.924 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[643]: 0.924 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[644]: 0.743 (+/-0.374) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[645]: 0.743 (+/-0.374) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[646]: 0.895 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[647]: 0.895 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[648]: 0.781 (+/-0.333) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[649]: 0.781 (+/-0.333) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[650]: 0.781 (+/-0.333) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[651]: 0.781 (+/-0.333) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[652]: 0.857 (+/-0.248) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[653]: 0.857 (+/-0.248) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[654]: 0.857 (+/-0.248) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[655]: 0.857 (+/-0.248) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[656]: 0.819 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[657]: 0.819 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[658]: 0.819 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[659]: 0.819 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[660]: 0.867 (+/-0.220) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[661]: 0.867 (+/-0.220) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[662]: 0.867 (+/-0.220) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[663]: 0.867 (+/-0.220) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[664]: 0.752 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[665]: 0.752 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[666]: 0.752 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[667]: 0.752 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[668]: 0.781 (+/-0.245) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[669]: 0.781 (+/-0.245) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[670]: 0.781 (+/-0.245) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[671]: 0.781 (+/-0.245) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[672]: 0.781 (+/-0.333) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[673]: 0.781 (+/-0.333) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[674]: 0.781 (+/-0.333) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[675]: 0.781 (+/-0.333) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[676]: 0.857 (+/-0.248) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[677]: 0.857 (+/-0.248) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[678]: 0.857 (+/-0.248) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[679]: 0.857 (+/-0.248) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[680]: 0.819 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[681]: 0.819 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[682]: 0.819 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[683]: 0.819 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[684]: 0.867 (+/-0.220) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[685]: 0.867 (+/-0.220) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[686]: 0.867 (+/-0.220) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[687]: 0.867 (+/-0.220) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[688]: 0.752 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[689]: 0.752 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[690]: 0.752 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[691]: 0.752 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[692]: 0.781 (+/-0.245) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[693]: 0.781 (+/-0.245) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[694]: 0.781 (+/-0.245) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[695]: 0.781 (+/-0.245) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[696]: 0.781 (+/-0.333) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[697]: 0.781 (+/-0.333) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[698]: 0.781 (+/-0.333) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[699]: 0.781 (+/-0.333) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[700]: 0.857 (+/-0.248) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[701]: 0.857 (+/-0.248) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[702]: 0.857 (+/-0.248) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[703]: 0.857 (+/-0.248) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[704]: 0.819 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[705]: 0.819 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[706]: 0.819 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[707]: 0.819 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[708]: 0.867 (+/-0.220) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[709]: 0.867 (+/-0.220) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[710]: 0.867 (+/-0.220) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[711]: 0.867 (+/-0.220) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[712]: 0.752 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[713]: 0.752 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[714]: 0.752 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[715]: 0.752 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[716]: 0.781 (+/-0.245) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[717]: 0.781 (+/-0.245) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[718]: 0.781 (+/-0.245) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[719]: 0.781 (+/-0.245) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[720]: 0.733 (+/-0.230) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[721]: 0.733 (+/-0.230) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[722]: 0.733 (+/-0.230) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[723]: 0.733 (+/-0.230) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[724]: 0.638 (+/-0.619) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[725]: 0.638 (+/-0.619) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[726]: 0.638 (+/-0.619) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[727]: 0.638 (+/-0.619) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[728]: 0.838 (+/-0.214) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[729]: 0.838 (+/-0.214) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[730]: 0.838 (+/-0.214) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[731]: 0.838 (+/-0.214) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[732]: 0.762 (+/-0.104) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[733]: 0.762 (+/-0.104) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[734]: 0.762 (+/-0.104) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[735]: 0.762 (+/-0.104) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[736]: 0.743 (+/-0.465) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[737]: 0.743 (+/-0.465) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[738]: 0.743 (+/-0.465) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[739]: 0.743 (+/-0.465) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[740]: 0.724 (+/-0.321) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[741]: 0.724 (+/-0.321) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[742]: 0.724 (+/-0.321) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[743]: 0.724 (+/-0.321) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[744]: 0.733 (+/-0.230) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[745]: 0.733 (+/-0.230) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[746]: 0.733 (+/-0.230) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[747]: 0.733 (+/-0.230) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[748]: 0.638 (+/-0.619) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[749]: 0.638 (+/-0.619) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[750]: 0.638 (+/-0.619) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[751]: 0.638 (+/-0.619) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[752]: 0.838 (+/-0.214) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[753]: 0.838 (+/-0.214) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[754]: 0.838 (+/-0.214) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[755]: 0.838 (+/-0.214) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[756]: 0.762 (+/-0.104) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[757]: 0.762 (+/-0.104) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[758]: 0.762 (+/-0.104) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[759]: 0.762 (+/-0.104) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[760]: 0.743 (+/-0.465) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[761]: 0.743 (+/-0.465) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[762]: 0.743 (+/-0.465) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[763]: 0.743 (+/-0.465) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[764]: 0.724 (+/-0.321) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[765]: 0.724 (+/-0.321) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[766]: 0.724 (+/-0.321) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[767]: 0.724 (+/-0.321) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[768]: 0.733 (+/-0.230) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[769]: 0.733 (+/-0.230) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[770]: 0.733 (+/-0.230) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[771]: 0.733 (+/-0.230) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[772]: 0.638 (+/-0.619) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[773]: 0.638 (+/-0.619) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[774]: 0.638 (+/-0.619) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[775]: 0.638 (+/-0.619) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[776]: 0.838 (+/-0.214) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[777]: 0.838 (+/-0.214) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[778]: 0.838 (+/-0.214) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[779]: 0.838 (+/-0.214) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[780]: 0.762 (+/-0.104) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[781]: 0.762 (+/-0.104) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[782]: 0.762 (+/-0.104) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[783]: 0.762 (+/-0.104) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[784]: 0.743 (+/-0.465) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[785]: 0.743 (+/-0.465) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[786]: 0.743 (+/-0.465) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[787]: 0.743 (+/-0.465) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[788]: 0.724 (+/-0.321) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[789]: 0.724 (+/-0.321) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[790]: 0.724 (+/-0.321) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[791]: 0.724 (+/-0.321) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[792]: 0.781 (+/-0.364) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[793]: 0.781 (+/-0.364) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[794]: 0.781 (+/-0.364) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[795]: 0.781 (+/-0.364) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[796]: 0.933 (+/-0.076) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[797]: 0.933 (+/-0.076) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[798]: 0.933 (+/-0.076) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[799]: 0.933 (+/-0.076) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[800]: 0.790 (+/-0.205) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[801]: 0.790 (+/-0.205) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[802]: 0.790 (+/-0.205) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[803]: 0.790 (+/-0.205) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[804]: 0.667 (+/-0.395) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[805]: 0.667 (+/-0.395) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[806]: 0.667 (+/-0.395) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[807]: 0.667 (+/-0.395) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[808]: 0.686 (+/-0.322) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[809]: 0.686 (+/-0.322) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[810]: 0.686 (+/-0.322) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[811]: 0.686 (+/-0.322) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[812]: 0.733 (+/-0.322) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[813]: 0.733 (+/-0.322) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[814]: 0.733 (+/-0.322) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[815]: 0.733 (+/-0.322) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[816]: 0.781 (+/-0.364) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[817]: 0.781 (+/-0.364) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[818]: 0.781 (+/-0.364) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[819]: 0.781 (+/-0.364) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[820]: 0.933 (+/-0.076) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[821]: 0.933 (+/-0.076) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[822]: 0.933 (+/-0.076) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[823]: 0.933 (+/-0.076) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[824]: 0.790 (+/-0.205) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[825]: 0.790 (+/-0.205) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[826]: 0.790 (+/-0.205) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[827]: 0.790 (+/-0.205) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[828]: 0.667 (+/-0.395) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[829]: 0.667 (+/-0.395) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[830]: 0.667 (+/-0.395) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[831]: 0.667 (+/-0.395) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[832]: 0.686 (+/-0.322) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[833]: 0.686 (+/-0.322) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[834]: 0.686 (+/-0.322) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[835]: 0.686 (+/-0.322) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[836]: 0.733 (+/-0.322) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[837]: 0.733 (+/-0.322) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[838]: 0.733 (+/-0.322) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[839]: 0.733 (+/-0.322) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[840]: 0.781 (+/-0.364) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[841]: 0.781 (+/-0.364) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[842]: 0.781 (+/-0.364) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[843]: 0.781 (+/-0.364) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[844]: 0.933 (+/-0.076) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[845]: 0.933 (+/-0.076) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[846]: 0.933 (+/-0.076) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[847]: 0.933 (+/-0.076) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[848]: 0.790 (+/-0.205) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[849]: 0.790 (+/-0.205) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[850]: 0.790 (+/-0.205) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[851]: 0.790 (+/-0.205) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[852]: 0.667 (+/-0.395) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[853]: 0.667 (+/-0.395) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[854]: 0.667 (+/-0.395) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[855]: 0.667 (+/-0.395) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[856]: 0.686 (+/-0.322) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[857]: 0.686 (+/-0.322) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[858]: 0.686 (+/-0.322) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[859]: 0.686 (+/-0.322) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[860]: 0.733 (+/-0.322) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[861]: 0.733 (+/-0.322) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[862]: 0.733 (+/-0.322) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[863]: 0.733 (+/-0.322) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[864]: 0.819 (+/-0.304) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[865]: 0.819 (+/-0.304) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[866]: 0.819 (+/-0.304) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[867]: 0.819 (+/-0.304) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[868]: 0.895 (+/-0.111) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[869]: 0.895 (+/-0.111) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[870]: 0.895 (+/-0.111) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[871]: 0.895 (+/-0.111) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[872]: 0.895 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[873]: 0.895 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[874]: 0.895 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[875]: 0.895 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[876]: 0.790 (+/-0.230) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[877]: 0.790 (+/-0.230) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[878]: 0.790 (+/-0.230) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[879]: 0.790 (+/-0.230) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[880]: 0.962 (+/-0.038) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[881]: 0.962 (+/-0.038) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[882]: 0.962 (+/-0.038) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[883]: 0.962 (+/-0.038) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[884]: 0.886 (+/-0.177) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[885]: 0.886 (+/-0.177) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[886]: 0.886 (+/-0.177) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[887]: 0.886 (+/-0.177) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[888]: 0.819 (+/-0.304) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[889]: 0.819 (+/-0.304) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[890]: 0.819 (+/-0.304) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[891]: 0.819 (+/-0.304) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[892]: 0.895 (+/-0.111) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[893]: 0.895 (+/-0.111) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[894]: 0.895 (+/-0.111) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[895]: 0.895 (+/-0.111) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[896]: 0.895 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[897]: 0.895 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[898]: 0.895 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[899]: 0.895 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[900]: 0.790 (+/-0.230) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[901]: 0.790 (+/-0.230) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[902]: 0.790 (+/-0.230) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[903]: 0.790 (+/-0.230) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[904]: 0.962 (+/-0.038) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[905]: 0.962 (+/-0.038) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[906]: 0.962 (+/-0.038) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[907]: 0.962 (+/-0.038) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[908]: 0.886 (+/-0.177) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[909]: 0.886 (+/-0.177) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[910]: 0.886 (+/-0.177) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[911]: 0.886 (+/-0.177) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[912]: 0.819 (+/-0.304) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[913]: 0.819 (+/-0.304) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[914]: 0.819 (+/-0.304) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[915]: 0.819 (+/-0.304) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[916]: 0.895 (+/-0.111) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[917]: 0.895 (+/-0.111) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[918]: 0.895 (+/-0.111) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[919]: 0.895 (+/-0.111) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[920]: 0.895 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[921]: 0.895 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[922]: 0.895 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[923]: 0.895 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[924]: 0.790 (+/-0.230) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[925]: 0.790 (+/-0.230) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[926]: 0.790 (+/-0.230) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[927]: 0.790 (+/-0.230) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[928]: 0.962 (+/-0.038) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[929]: 0.962 (+/-0.038) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[930]: 0.962 (+/-0.038) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[931]: 0.962 (+/-0.038) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[932]: 0.886 (+/-0.177) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[933]: 0.886 (+/-0.177) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[934]: 0.886 (+/-0.177) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[935]: 0.886 (+/-0.177) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[936]: 0.886 (+/-0.143) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[937]: 0.886 (+/-0.143) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[938]: 0.886 (+/-0.143) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[939]: 0.886 (+/-0.143) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[940]: 0.857 (+/-0.295) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[941]: 0.857 (+/-0.295) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[942]: 0.857 (+/-0.295) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[943]: 0.857 (+/-0.295) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[944]: 0.943 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[945]: 0.943 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[946]: 0.943 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[947]: 0.943 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[948]: 0.838 (+/-0.238) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[949]: 0.838 (+/-0.238) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[950]: 0.838 (+/-0.238) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[951]: 0.838 (+/-0.238) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[952]: 0.962 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[953]: 0.962 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[954]: 0.962 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[955]: 0.962 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[956]: 0.886 (+/-0.114) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[957]: 0.886 (+/-0.114) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[958]: 0.886 (+/-0.114) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[959]: 0.886 (+/-0.114) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[960]: 0.886 (+/-0.143) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[961]: 0.886 (+/-0.143) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[962]: 0.886 (+/-0.143) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[963]: 0.886 (+/-0.143) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[964]: 0.857 (+/-0.295) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[965]: 0.857 (+/-0.295) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[966]: 0.857 (+/-0.295) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[967]: 0.857 (+/-0.295) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[968]: 0.943 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[969]: 0.943 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[970]: 0.943 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[971]: 0.943 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[972]: 0.838 (+/-0.238) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[973]: 0.838 (+/-0.238) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[974]: 0.838 (+/-0.238) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[975]: 0.838 (+/-0.238) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[976]: 0.962 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[977]: 0.962 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[978]: 0.962 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[979]: 0.962 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[980]: 0.886 (+/-0.114) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[981]: 0.886 (+/-0.114) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[982]: 0.886 (+/-0.114) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[983]: 0.886 (+/-0.114) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[984]: 0.886 (+/-0.143) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[985]: 0.886 (+/-0.143) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[986]: 0.886 (+/-0.143) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[987]: 0.886 (+/-0.143) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[988]: 0.857 (+/-0.295) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[989]: 0.857 (+/-0.295) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[990]: 0.857 (+/-0.295) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[991]: 0.857 (+/-0.295) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[992]: 0.943 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[993]: 0.943 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[994]: 0.943 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[995]: 0.943 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[996]: 0.838 (+/-0.238) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[997]: 0.838 (+/-0.238) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[998]: 0.838 (+/-0.238) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[999]: 0.838 (+/-0.238) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1000]: 0.962 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1001]: 0.962 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1002]: 0.962 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1003]: 0.962 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1004]: 0.886 (+/-0.114) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1005]: 0.886 (+/-0.114) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1006]: 0.886 (+/-0.114) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1007]: 0.886 (+/-0.114) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1008]: 0.886 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1009]: 0.886 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1010]: 0.886 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1011]: 0.886 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1012]: 0.762 (+/-0.508) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1013]: 0.762 (+/-0.508) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1014]: 0.762 (+/-0.508) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1015]: 0.762 (+/-0.508) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1016]: 0.895 (+/-0.152) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1017]: 0.895 (+/-0.152) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1018]: 0.895 (+/-0.152) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1019]: 0.895 (+/-0.152) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1020]: 0.800 (+/-0.212) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1021]: 0.800 (+/-0.212) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1022]: 0.800 (+/-0.212) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1023]: 0.800 (+/-0.212) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1024]: 0.952 (+/-0.060) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1025]: 0.952 (+/-0.060) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1026]: 0.952 (+/-0.060) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1027]: 0.952 (+/-0.060) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1028]: 0.876 (+/-0.205) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1029]: 0.876 (+/-0.205) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1030]: 0.876 (+/-0.205) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1031]: 0.876 (+/-0.205) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1032]: 0.886 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1033]: 0.886 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1034]: 0.886 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1035]: 0.886 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1036]: 0.762 (+/-0.508) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1037]: 0.762 (+/-0.508) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1038]: 0.762 (+/-0.508) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1039]: 0.762 (+/-0.508) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1040]: 0.895 (+/-0.152) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1041]: 0.895 (+/-0.152) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1042]: 0.895 (+/-0.152) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1043]: 0.895 (+/-0.152) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1044]: 0.800 (+/-0.212) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1045]: 0.800 (+/-0.212) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1046]: 0.800 (+/-0.212) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1047]: 0.800 (+/-0.212) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1048]: 0.952 (+/-0.060) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1049]: 0.952 (+/-0.060) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1050]: 0.952 (+/-0.060) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1051]: 0.952 (+/-0.060) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1052]: 0.876 (+/-0.205) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1053]: 0.876 (+/-0.205) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1054]: 0.876 (+/-0.205) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1055]: 0.876 (+/-0.205) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1056]: 0.886 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1057]: 0.886 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1058]: 0.886 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1059]: 0.886 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1060]: 0.762 (+/-0.508) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1061]: 0.762 (+/-0.508) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1062]: 0.762 (+/-0.508) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1063]: 0.762 (+/-0.508) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1064]: 0.895 (+/-0.152) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1065]: 0.895 (+/-0.152) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1066]: 0.895 (+/-0.152) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1067]: 0.895 (+/-0.152) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1068]: 0.800 (+/-0.212) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1069]: 0.800 (+/-0.212) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1070]: 0.800 (+/-0.212) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1071]: 0.800 (+/-0.212) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1072]: 0.952 (+/-0.060) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1073]: 0.952 (+/-0.060) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1074]: 0.952 (+/-0.060) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1075]: 0.952 (+/-0.060) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1076]: 0.876 (+/-0.205) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1077]: 0.876 (+/-0.205) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1078]: 0.876 (+/-0.205) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1079]: 0.876 (+/-0.205) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1080]: 0.933 (+/-0.143) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1081]: 0.933 (+/-0.143) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1082]: 0.810 (+/-0.120) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1083]: 0.810 (+/-0.120) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1084]: 0.819 (+/-0.251) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1085]: 0.819 (+/-0.251) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1086]: 0.829 (+/-0.155) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1087]: 0.829 (+/-0.155) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1088]: 0.876 (+/-0.129) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1089]: 0.876 (+/-0.129) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1090]: 0.886 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1091]: 0.886 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1092]: 0.781 (+/-0.143) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1093]: 0.781 (+/-0.143) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1094]: 0.895 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1095]: 0.895 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1096]: 0.905 (+/-0.190) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1097]: 0.905 (+/-0.190) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1098]: 0.886 (+/-0.143) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1099]: 0.886 (+/-0.143) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1100]: 0.781 (+/-0.143) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1101]: 0.781 (+/-0.143) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1102]: 0.876 (+/-0.177) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1103]: 0.876 (+/-0.177) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1104]: 0.933 (+/-0.143) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1105]: 0.933 (+/-0.143) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1106]: 0.810 (+/-0.120) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1107]: 0.810 (+/-0.120) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1108]: 0.819 (+/-0.251) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1109]: 0.819 (+/-0.251) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1110]: 0.829 (+/-0.155) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1111]: 0.829 (+/-0.155) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1112]: 0.876 (+/-0.129) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1113]: 0.876 (+/-0.129) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1114]: 0.886 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1115]: 0.886 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1116]: 0.781 (+/-0.143) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1117]: 0.781 (+/-0.143) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1118]: 0.895 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1119]: 0.895 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1120]: 0.905 (+/-0.190) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1121]: 0.905 (+/-0.190) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1122]: 0.886 (+/-0.143) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1123]: 0.886 (+/-0.143) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1124]: 0.781 (+/-0.143) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1125]: 0.781 (+/-0.143) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1126]: 0.876 (+/-0.177) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1127]: 0.876 (+/-0.177) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1128]: 0.933 (+/-0.143) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1129]: 0.933 (+/-0.143) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1130]: 0.810 (+/-0.120) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1131]: 0.810 (+/-0.120) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1132]: 0.819 (+/-0.251) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1133]: 0.819 (+/-0.251) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1134]: 0.829 (+/-0.155) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1135]: 0.829 (+/-0.155) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1136]: 0.876 (+/-0.129) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1137]: 0.876 (+/-0.129) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1138]: 0.886 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1139]: 0.886 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1140]: 0.781 (+/-0.143) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1141]: 0.781 (+/-0.143) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1142]: 0.895 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1143]: 0.895 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1144]: 0.905 (+/-0.190) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1145]: 0.905 (+/-0.190) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1146]: 0.886 (+/-0.143) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1147]: 0.886 (+/-0.143) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1148]: 0.781 (+/-0.143) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1149]: 0.781 (+/-0.143) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1150]: 0.876 (+/-0.177) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1151]: 0.876 (+/-0.177) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1152]: 0.695 (+/-0.567) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1153]: 0.695 (+/-0.567) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1154]: 0.867 (+/-0.152) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1155]: 0.867 (+/-0.152) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1156]: 0.848 (+/-0.152) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1157]: 0.848 (+/-0.152) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1158]: 0.867 (+/-0.152) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1159]: 0.867 (+/-0.152) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1160]: 0.829 (+/-0.187) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1161]: 0.829 (+/-0.187) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1162]: 0.857 (+/-0.170) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1163]: 0.857 (+/-0.170) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1164]: 0.743 (+/-0.129) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1165]: 0.743 (+/-0.129) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1166]: 0.857 (+/-0.170) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1167]: 0.857 (+/-0.170) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1168]: 0.657 (+/-0.444) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1169]: 0.657 (+/-0.444) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1170]: 0.838 (+/-0.196) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1171]: 0.838 (+/-0.196) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1172]: 0.752 (+/-0.203) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1173]: 0.752 (+/-0.203) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1174]: 0.838 (+/-0.196) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1175]: 0.838 (+/-0.196) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1176]: 0.695 (+/-0.567) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1177]: 0.695 (+/-0.567) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1178]: 0.867 (+/-0.152) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1179]: 0.867 (+/-0.152) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1180]: 0.848 (+/-0.152) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1181]: 0.848 (+/-0.152) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1182]: 0.867 (+/-0.152) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1183]: 0.867 (+/-0.152) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1184]: 0.829 (+/-0.187) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1185]: 0.829 (+/-0.187) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1186]: 0.857 (+/-0.170) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1187]: 0.857 (+/-0.170) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1188]: 0.743 (+/-0.129) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1189]: 0.743 (+/-0.129) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1190]: 0.857 (+/-0.170) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1191]: 0.857 (+/-0.170) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1192]: 0.657 (+/-0.444) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1193]: 0.657 (+/-0.444) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1194]: 0.838 (+/-0.196) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1195]: 0.838 (+/-0.196) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1196]: 0.752 (+/-0.203) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1197]: 0.752 (+/-0.203) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1198]: 0.838 (+/-0.196) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1199]: 0.838 (+/-0.196) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1200]: 0.695 (+/-0.567) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1201]: 0.695 (+/-0.567) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1202]: 0.867 (+/-0.152) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1203]: 0.867 (+/-0.152) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1204]: 0.848 (+/-0.152) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1205]: 0.848 (+/-0.152) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1206]: 0.867 (+/-0.152) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1207]: 0.867 (+/-0.152) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1208]: 0.829 (+/-0.187) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1209]: 0.829 (+/-0.187) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1210]: 0.857 (+/-0.170) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1211]: 0.857 (+/-0.170) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1212]: 0.743 (+/-0.129) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1213]: 0.743 (+/-0.129) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1214]: 0.857 (+/-0.170) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1215]: 0.857 (+/-0.170) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1216]: 0.657 (+/-0.444) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1217]: 0.657 (+/-0.444) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1218]: 0.838 (+/-0.196) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1219]: 0.838 (+/-0.196) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1220]: 0.752 (+/-0.203) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1221]: 0.752 (+/-0.203) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1222]: 0.838 (+/-0.196) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1223]: 0.838 (+/-0.196) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1224]: 0.857 (+/-0.289) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1225]: 0.857 (+/-0.289) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1226]: 0.933 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1227]: 0.933 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1228]: 0.800 (+/-0.265) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1229]: 0.800 (+/-0.265) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1230]: 0.914 (+/-0.111) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1231]: 0.914 (+/-0.111) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1232]: 0.752 (+/-0.472) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1233]: 0.752 (+/-0.472) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1234]: 0.924 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1235]: 0.924 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1236]: 0.857 (+/-0.190) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1237]: 0.857 (+/-0.190) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1238]: 0.943 (+/-0.093) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1239]: 0.943 (+/-0.093) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1240]: 0.800 (+/-0.332) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1241]: 0.800 (+/-0.332) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1242]: 0.962 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1243]: 0.962 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1244]: 0.810 (+/-0.200) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1245]: 0.810 (+/-0.200) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1246]: 0.962 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1247]: 0.962 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1248]: 0.857 (+/-0.289) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1249]: 0.857 (+/-0.289) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1250]: 0.933 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1251]: 0.933 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1252]: 0.800 (+/-0.265) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1253]: 0.800 (+/-0.265) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1254]: 0.914 (+/-0.111) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1255]: 0.914 (+/-0.111) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1256]: 0.752 (+/-0.472) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1257]: 0.752 (+/-0.472) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1258]: 0.924 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1259]: 0.924 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1260]: 0.857 (+/-0.190) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1261]: 0.857 (+/-0.190) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1262]: 0.943 (+/-0.093) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1263]: 0.943 (+/-0.093) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1264]: 0.800 (+/-0.332) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1265]: 0.800 (+/-0.332) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1266]: 0.962 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1267]: 0.962 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1268]: 0.810 (+/-0.200) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1269]: 0.810 (+/-0.200) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1270]: 0.962 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1271]: 0.962 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1272]: 0.857 (+/-0.289) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1273]: 0.857 (+/-0.289) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1274]: 0.933 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1275]: 0.933 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1276]: 0.800 (+/-0.265) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1277]: 0.800 (+/-0.265) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1278]: 0.914 (+/-0.111) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1279]: 0.914 (+/-0.111) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1280]: 0.752 (+/-0.472) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1281]: 0.752 (+/-0.472) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1282]: 0.924 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1283]: 0.924 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1284]: 0.857 (+/-0.190) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1285]: 0.857 (+/-0.190) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1286]: 0.943 (+/-0.093) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1287]: 0.943 (+/-0.093) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1288]: 0.800 (+/-0.332) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1289]: 0.800 (+/-0.332) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1290]: 0.962 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1291]: 0.962 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1292]: 0.810 (+/-0.200) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1293]: 0.810 (+/-0.200) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1294]: 0.962 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1295]: 0.962 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1296]: 0.876 (+/-0.222) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1297]: 0.876 (+/-0.222) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1298]: 0.876 (+/-0.222) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1299]: 0.876 (+/-0.222) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1300]: 0.886 (+/-0.143) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1301]: 0.886 (+/-0.143) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1302]: 0.886 (+/-0.143) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1303]: 0.886 (+/-0.143) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1304]: 0.943 (+/-0.093) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1305]: 0.943 (+/-0.093) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1306]: 0.943 (+/-0.093) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1307]: 0.943 (+/-0.093) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1308]: 0.905 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1309]: 0.905 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1310]: 0.905 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1311]: 0.905 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1312]: 0.886 (+/-0.129) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1313]: 0.886 (+/-0.129) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1314]: 0.886 (+/-0.129) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1315]: 0.886 (+/-0.129) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1316]: 0.867 (+/-0.212) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1317]: 0.867 (+/-0.212) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1318]: 0.867 (+/-0.212) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1319]: 0.867 (+/-0.212) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1320]: 0.876 (+/-0.222) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1321]: 0.876 (+/-0.222) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1322]: 0.876 (+/-0.222) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1323]: 0.876 (+/-0.222) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1324]: 0.886 (+/-0.143) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1325]: 0.886 (+/-0.143) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1326]: 0.886 (+/-0.143) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1327]: 0.886 (+/-0.143) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1328]: 0.943 (+/-0.093) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1329]: 0.943 (+/-0.093) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1330]: 0.943 (+/-0.093) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1331]: 0.943 (+/-0.093) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1332]: 0.905 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1333]: 0.905 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1334]: 0.905 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1335]: 0.905 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1336]: 0.886 (+/-0.129) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1337]: 0.886 (+/-0.129) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1338]: 0.886 (+/-0.129) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1339]: 0.886 (+/-0.129) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1340]: 0.867 (+/-0.212) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1341]: 0.867 (+/-0.212) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1342]: 0.867 (+/-0.212) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1343]: 0.867 (+/-0.212) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1344]: 0.876 (+/-0.222) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1345]: 0.876 (+/-0.222) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1346]: 0.876 (+/-0.222) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1347]: 0.876 (+/-0.222) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1348]: 0.886 (+/-0.143) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1349]: 0.886 (+/-0.143) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1350]: 0.886 (+/-0.143) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1351]: 0.886 (+/-0.143) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1352]: 0.943 (+/-0.093) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1353]: 0.943 (+/-0.093) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1354]: 0.943 (+/-0.093) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1355]: 0.943 (+/-0.093) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1356]: 0.905 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1357]: 0.905 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1358]: 0.905 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1359]: 0.905 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1360]: 0.886 (+/-0.129) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1361]: 0.886 (+/-0.129) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1362]: 0.886 (+/-0.129) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1363]: 0.886 (+/-0.129) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1364]: 0.867 (+/-0.212) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1365]: 0.867 (+/-0.212) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1366]: 0.867 (+/-0.212) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1367]: 0.867 (+/-0.212) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1368]: 0.724 (+/-0.304) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1369]: 0.724 (+/-0.304) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1370]: 0.724 (+/-0.304) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1371]: 0.724 (+/-0.304) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1372]: 0.705 (+/-0.327) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1373]: 0.705 (+/-0.327) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1374]: 0.705 (+/-0.327) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1375]: 0.705 (+/-0.327) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1376]: 0.848 (+/-0.185) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1377]: 0.848 (+/-0.185) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1378]: 0.848 (+/-0.185) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1379]: 0.848 (+/-0.185) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1380]: 0.848 (+/-0.185) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1381]: 0.848 (+/-0.185) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1382]: 0.848 (+/-0.185) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1383]: 0.848 (+/-0.185) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1384]: 0.829 (+/-0.273) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1385]: 0.829 (+/-0.273) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1386]: 0.829 (+/-0.273) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1387]: 0.829 (+/-0.273) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1388]: 0.819 (+/-0.304) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1389]: 0.819 (+/-0.304) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1390]: 0.819 (+/-0.304) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1391]: 0.819 (+/-0.304) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1392]: 0.724 (+/-0.304) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1393]: 0.724 (+/-0.304) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1394]: 0.724 (+/-0.304) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1395]: 0.724 (+/-0.304) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1396]: 0.705 (+/-0.327) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1397]: 0.705 (+/-0.327) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1398]: 0.705 (+/-0.327) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1399]: 0.705 (+/-0.327) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1400]: 0.848 (+/-0.185) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1401]: 0.848 (+/-0.185) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1402]: 0.848 (+/-0.185) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1403]: 0.848 (+/-0.185) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1404]: 0.848 (+/-0.185) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1405]: 0.848 (+/-0.185) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1406]: 0.848 (+/-0.185) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1407]: 0.848 (+/-0.185) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1408]: 0.829 (+/-0.273) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1409]: 0.829 (+/-0.273) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1410]: 0.829 (+/-0.273) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1411]: 0.829 (+/-0.273) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1412]: 0.819 (+/-0.304) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1413]: 0.819 (+/-0.304) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1414]: 0.819 (+/-0.304) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1415]: 0.819 (+/-0.304) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1416]: 0.724 (+/-0.304) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1417]: 0.724 (+/-0.304) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1418]: 0.724 (+/-0.304) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1419]: 0.724 (+/-0.304) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1420]: 0.705 (+/-0.327) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1421]: 0.705 (+/-0.327) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1422]: 0.705 (+/-0.327) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1423]: 0.705 (+/-0.327) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1424]: 0.848 (+/-0.185) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1425]: 0.848 (+/-0.185) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1426]: 0.848 (+/-0.185) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1427]: 0.848 (+/-0.185) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1428]: 0.848 (+/-0.185) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1429]: 0.848 (+/-0.185) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1430]: 0.848 (+/-0.185) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1431]: 0.848 (+/-0.185) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1432]: 0.829 (+/-0.273) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1433]: 0.829 (+/-0.273) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1434]: 0.829 (+/-0.273) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1435]: 0.829 (+/-0.273) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1436]: 0.819 (+/-0.304) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1437]: 0.819 (+/-0.304) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1438]: 0.819 (+/-0.304) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1439]: 0.819 (+/-0.304) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1440]: 0.838 (+/-0.230) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1441]: 0.838 (+/-0.230) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1442]: 0.838 (+/-0.230) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1443]: 0.838 (+/-0.230) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1444]: 0.933 (+/-0.076) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1445]: 0.933 (+/-0.076) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1446]: 0.933 (+/-0.076) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1447]: 0.933 (+/-0.076) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1448]: 0.629 (+/-0.251) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1449]: 0.629 (+/-0.251) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1450]: 0.629 (+/-0.251) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1451]: 0.629 (+/-0.251) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1452]: 0.667 (+/-0.395) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1453]: 0.667 (+/-0.395) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1454]: 0.667 (+/-0.395) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1455]: 0.667 (+/-0.395) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1456]: 0.848 (+/-0.236) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1457]: 0.848 (+/-0.236) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1458]: 0.848 (+/-0.236) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1459]: 0.848 (+/-0.236) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1460]: 0.695 (+/-0.155) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1461]: 0.695 (+/-0.155) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1462]: 0.695 (+/-0.155) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1463]: 0.695 (+/-0.155) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1464]: 0.838 (+/-0.230) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1465]: 0.838 (+/-0.230) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1466]: 0.838 (+/-0.230) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1467]: 0.838 (+/-0.230) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1468]: 0.933 (+/-0.076) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1469]: 0.933 (+/-0.076) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1470]: 0.933 (+/-0.076) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1471]: 0.933 (+/-0.076) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1472]: 0.629 (+/-0.251) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1473]: 0.629 (+/-0.251) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1474]: 0.629 (+/-0.251) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1475]: 0.629 (+/-0.251) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1476]: 0.667 (+/-0.395) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1477]: 0.667 (+/-0.395) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1478]: 0.667 (+/-0.395) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1479]: 0.667 (+/-0.395) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1480]: 0.848 (+/-0.236) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1481]: 0.848 (+/-0.236) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1482]: 0.848 (+/-0.236) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1483]: 0.848 (+/-0.236) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1484]: 0.695 (+/-0.155) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1485]: 0.695 (+/-0.155) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1486]: 0.695 (+/-0.155) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1487]: 0.695 (+/-0.155) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1488]: 0.838 (+/-0.230) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1489]: 0.838 (+/-0.230) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1490]: 0.838 (+/-0.230) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1491]: 0.838 (+/-0.230) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1492]: 0.933 (+/-0.076) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1493]: 0.933 (+/-0.076) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1494]: 0.933 (+/-0.076) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1495]: 0.933 (+/-0.076) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1496]: 0.629 (+/-0.251) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1497]: 0.629 (+/-0.251) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1498]: 0.629 (+/-0.251) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1499]: 0.629 (+/-0.251) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1500]: 0.667 (+/-0.395) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1501]: 0.667 (+/-0.395) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1502]: 0.667 (+/-0.395) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1503]: 0.667 (+/-0.395) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1504]: 0.848 (+/-0.236) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1505]: 0.848 (+/-0.236) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1506]: 0.848 (+/-0.236) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1507]: 0.848 (+/-0.236) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1508]: 0.695 (+/-0.155) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1509]: 0.695 (+/-0.155) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1510]: 0.695 (+/-0.155) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1511]: 0.695 (+/-0.155) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1512]: 0.943 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1513]: 0.943 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1514]: 0.943 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1515]: 0.943 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1516]: 0.924 (+/-0.076) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1517]: 0.924 (+/-0.076) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1518]: 0.924 (+/-0.076) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1519]: 0.924 (+/-0.076) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1520]: 0.962 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1521]: 0.962 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1522]: 0.962 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1523]: 0.962 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1524]: 0.857 (+/-0.148) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1525]: 0.857 (+/-0.148) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1526]: 0.857 (+/-0.148) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1527]: 0.857 (+/-0.148) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1528]: 0.981 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1529]: 0.981 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1530]: 0.981 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1531]: 0.981 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1532]: 0.914 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1533]: 0.914 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1534]: 0.914 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1535]: 0.914 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1536]: 0.943 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1537]: 0.943 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1538]: 0.943 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1539]: 0.943 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1540]: 0.924 (+/-0.076) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1541]: 0.924 (+/-0.076) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1542]: 0.924 (+/-0.076) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1543]: 0.924 (+/-0.076) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1544]: 0.962 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1545]: 0.962 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1546]: 0.962 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1547]: 0.962 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1548]: 0.857 (+/-0.148) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1549]: 0.857 (+/-0.148) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1550]: 0.857 (+/-0.148) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1551]: 0.857 (+/-0.148) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1552]: 0.981 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1553]: 0.981 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1554]: 0.981 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1555]: 0.981 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1556]: 0.914 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1557]: 0.914 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1558]: 0.914 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1559]: 0.914 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1560]: 0.943 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1561]: 0.943 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1562]: 0.943 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1563]: 0.943 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1564]: 0.924 (+/-0.076) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1565]: 0.924 (+/-0.076) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1566]: 0.924 (+/-0.076) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1567]: 0.924 (+/-0.076) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1568]: 0.962 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1569]: 0.962 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1570]: 0.962 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1571]: 0.962 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1572]: 0.857 (+/-0.148) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1573]: 0.857 (+/-0.148) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1574]: 0.857 (+/-0.148) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1575]: 0.857 (+/-0.148) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1576]: 0.981 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1577]: 0.981 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1578]: 0.981 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1579]: 0.981 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1580]: 0.914 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1581]: 0.914 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1582]: 0.914 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1583]: 0.914 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1584]: 0.952 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1585]: 0.952 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1586]: 0.952 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1587]: 0.952 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1588]: 0.943 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1589]: 0.943 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1590]: 0.943 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1591]: 0.943 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1592]: 0.952 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1593]: 0.952 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1594]: 0.952 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1595]: 0.952 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1596]: 0.876 (+/-0.205) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1597]: 0.876 (+/-0.205) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1598]: 0.876 (+/-0.205) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1599]: 0.876 (+/-0.205) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1600]: 0.952 (+/-0.000) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1601]: 0.952 (+/-0.000) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1602]: 0.952 (+/-0.000) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1603]: 0.952 (+/-0.000) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1604]: 0.924 (+/-0.114) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1605]: 0.924 (+/-0.114) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1606]: 0.924 (+/-0.114) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1607]: 0.924 (+/-0.114) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1608]: 0.952 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1609]: 0.952 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1610]: 0.952 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1611]: 0.952 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1612]: 0.943 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1613]: 0.943 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1614]: 0.943 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1615]: 0.943 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1616]: 0.952 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1617]: 0.952 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1618]: 0.952 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1619]: 0.952 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1620]: 0.876 (+/-0.205) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1621]: 0.876 (+/-0.205) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1622]: 0.876 (+/-0.205) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1623]: 0.876 (+/-0.205) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1624]: 0.952 (+/-0.000) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1625]: 0.952 (+/-0.000) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1626]: 0.952 (+/-0.000) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1627]: 0.952 (+/-0.000) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1628]: 0.924 (+/-0.114) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1629]: 0.924 (+/-0.114) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1630]: 0.924 (+/-0.114) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1631]: 0.924 (+/-0.114) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1632]: 0.952 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1633]: 0.952 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1634]: 0.952 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1635]: 0.952 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1636]: 0.943 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1637]: 0.943 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1638]: 0.943 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1639]: 0.943 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1640]: 0.952 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1641]: 0.952 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1642]: 0.952 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1643]: 0.952 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1644]: 0.876 (+/-0.205) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1645]: 0.876 (+/-0.205) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1646]: 0.876 (+/-0.205) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1647]: 0.876 (+/-0.205) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1648]: 0.952 (+/-0.000) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1649]: 0.952 (+/-0.000) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1650]: 0.952 (+/-0.000) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1651]: 0.952 (+/-0.000) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1652]: 0.924 (+/-0.114) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1653]: 0.924 (+/-0.114) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1654]: 0.924 (+/-0.114) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1655]: 0.924 (+/-0.114) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1656]: 0.962 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1657]: 0.962 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1658]: 0.962 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1659]: 0.962 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1660]: 0.933 (+/-0.097) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1661]: 0.933 (+/-0.097) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1662]: 0.933 (+/-0.097) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1663]: 0.933 (+/-0.097) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1664]: 0.914 (+/-0.111) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1665]: 0.914 (+/-0.111) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1666]: 0.914 (+/-0.111) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1667]: 0.914 (+/-0.111) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1668]: 0.886 (+/-0.166) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1669]: 0.886 (+/-0.166) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1670]: 0.886 (+/-0.166) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1671]: 0.886 (+/-0.166) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1672]: 0.990 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1673]: 0.990 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1674]: 0.990 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1675]: 0.990 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1676]: 0.905 (+/-0.135) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1677]: 0.905 (+/-0.135) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1678]: 0.905 (+/-0.135) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1679]: 0.905 (+/-0.135) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1680]: 0.962 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1681]: 0.962 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1682]: 0.962 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1683]: 0.962 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1684]: 0.933 (+/-0.097) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1685]: 0.933 (+/-0.097) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1686]: 0.933 (+/-0.097) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1687]: 0.933 (+/-0.097) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1688]: 0.914 (+/-0.111) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1689]: 0.914 (+/-0.111) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1690]: 0.914 (+/-0.111) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1691]: 0.914 (+/-0.111) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1692]: 0.886 (+/-0.166) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1693]: 0.886 (+/-0.166) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1694]: 0.886 (+/-0.166) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1695]: 0.886 (+/-0.166) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1696]: 0.990 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1697]: 0.990 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1698]: 0.990 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1699]: 0.990 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1700]: 0.905 (+/-0.135) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1701]: 0.905 (+/-0.135) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1702]: 0.905 (+/-0.135) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1703]: 0.905 (+/-0.135) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1704]: 0.962 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1705]: 0.962 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1706]: 0.962 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1707]: 0.962 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1708]: 0.933 (+/-0.097) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1709]: 0.933 (+/-0.097) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1710]: 0.933 (+/-0.097) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1711]: 0.933 (+/-0.097) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1712]: 0.914 (+/-0.111) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1713]: 0.914 (+/-0.111) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1714]: 0.914 (+/-0.111) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1715]: 0.914 (+/-0.111) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1716]: 0.886 (+/-0.166) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1717]: 0.886 (+/-0.166) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1718]: 0.886 (+/-0.166) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1719]: 0.886 (+/-0.166) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1720]: 0.990 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1721]: 0.990 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1722]: 0.990 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1723]: 0.990 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1724]: 0.905 (+/-0.135) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1725]: 0.905 (+/-0.135) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1726]: 0.905 (+/-0.135) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1727]: 0.905 (+/-0.135) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1728]: 0.876 (+/-0.143) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1729]: 0.876 (+/-0.143) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1730]: 0.695 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1731]: 0.695 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1732]: 0.886 (+/-0.245) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1733]: 0.886 (+/-0.245) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1734]: 0.695 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1735]: 0.695 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1736]: 0.905 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1737]: 0.905 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1738]: 0.695 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1739]: 0.695 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1740]: 0.838 (+/-0.177) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1741]: 0.838 (+/-0.177) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1742]: 0.695 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1743]: 0.695 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1744]: 0.914 (+/-0.111) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1745]: 0.914 (+/-0.111) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1746]: 0.695 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1747]: 0.695 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1748]: 0.905 (+/-0.104) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1749]: 0.905 (+/-0.104) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1750]: 0.695 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1751]: 0.695 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1752]: 0.876 (+/-0.143) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1753]: 0.876 (+/-0.143) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1754]: 0.695 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1755]: 0.695 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1756]: 0.886 (+/-0.245) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1757]: 0.886 (+/-0.245) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1758]: 0.695 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1759]: 0.695 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1760]: 0.905 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1761]: 0.905 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1762]: 0.695 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1763]: 0.695 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1764]: 0.838 (+/-0.177) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1765]: 0.838 (+/-0.177) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1766]: 0.695 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1767]: 0.695 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1768]: 0.914 (+/-0.111) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1769]: 0.914 (+/-0.111) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1770]: 0.695 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1771]: 0.695 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1772]: 0.905 (+/-0.104) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1773]: 0.905 (+/-0.104) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1774]: 0.695 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1775]: 0.695 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1776]: 0.876 (+/-0.143) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1777]: 0.876 (+/-0.143) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1778]: 0.695 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1779]: 0.695 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1780]: 0.886 (+/-0.245) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1781]: 0.886 (+/-0.245) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1782]: 0.695 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1783]: 0.695 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1784]: 0.905 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1785]: 0.905 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1786]: 0.695 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1787]: 0.695 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1788]: 0.838 (+/-0.177) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1789]: 0.838 (+/-0.177) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1790]: 0.695 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1791]: 0.695 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1792]: 0.914 (+/-0.111) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1793]: 0.914 (+/-0.111) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1794]: 0.695 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1795]: 0.695 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1796]: 0.905 (+/-0.104) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1797]: 0.905 (+/-0.104) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1798]: 0.695 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1799]: 0.695 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1800]: 0.952 (+/-0.104) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1801]: 0.952 (+/-0.104) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1802]: 0.848 (+/-0.152) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1803]: 0.848 (+/-0.152) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1804]: 0.952 (+/-0.104) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1805]: 0.952 (+/-0.104) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1806]: 0.848 (+/-0.152) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1807]: 0.848 (+/-0.152) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1808]: 0.914 (+/-0.093) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1809]: 0.914 (+/-0.093) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1810]: 0.867 (+/-0.126) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1811]: 0.867 (+/-0.126) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1812]: 0.914 (+/-0.093) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1813]: 0.914 (+/-0.093) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1814]: 0.867 (+/-0.126) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1815]: 0.867 (+/-0.126) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1816]: 0.867 (+/-0.185) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1817]: 0.867 (+/-0.185) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1818]: 0.857 (+/-0.104) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1819]: 0.857 (+/-0.104) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1820]: 0.867 (+/-0.185) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1821]: 0.867 (+/-0.185) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1822]: 0.857 (+/-0.104) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1823]: 0.857 (+/-0.104) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1824]: 0.952 (+/-0.104) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1825]: 0.952 (+/-0.104) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1826]: 0.848 (+/-0.152) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1827]: 0.848 (+/-0.152) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1828]: 0.952 (+/-0.104) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1829]: 0.952 (+/-0.104) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1830]: 0.848 (+/-0.152) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1831]: 0.848 (+/-0.152) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1832]: 0.914 (+/-0.093) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1833]: 0.914 (+/-0.093) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1834]: 0.867 (+/-0.126) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1835]: 0.867 (+/-0.126) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1836]: 0.914 (+/-0.093) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1837]: 0.914 (+/-0.093) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1838]: 0.867 (+/-0.126) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1839]: 0.867 (+/-0.126) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1840]: 0.867 (+/-0.185) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1841]: 0.867 (+/-0.185) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1842]: 0.857 (+/-0.104) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1843]: 0.857 (+/-0.104) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1844]: 0.867 (+/-0.185) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1845]: 0.867 (+/-0.185) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1846]: 0.857 (+/-0.104) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1847]: 0.857 (+/-0.104) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1848]: 0.952 (+/-0.104) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1849]: 0.952 (+/-0.104) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1850]: 0.848 (+/-0.152) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1851]: 0.848 (+/-0.152) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1852]: 0.952 (+/-0.104) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1853]: 0.952 (+/-0.104) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1854]: 0.848 (+/-0.152) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1855]: 0.848 (+/-0.152) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1856]: 0.914 (+/-0.093) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1857]: 0.914 (+/-0.093) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1858]: 0.867 (+/-0.126) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1859]: 0.867 (+/-0.126) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1860]: 0.914 (+/-0.093) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1861]: 0.914 (+/-0.093) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1862]: 0.867 (+/-0.126) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1863]: 0.867 (+/-0.126) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1864]: 0.867 (+/-0.185) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1865]: 0.867 (+/-0.185) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1866]: 0.857 (+/-0.104) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1867]: 0.857 (+/-0.104) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1868]: 0.867 (+/-0.185) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1869]: 0.867 (+/-0.185) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1870]: 0.857 (+/-0.104) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1871]: 0.857 (+/-0.104) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1872]: 0.638 (+/-0.524) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1873]: 0.638 (+/-0.524) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1874]: 0.914 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1875]: 0.914 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1876]: 0.829 (+/-0.205) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1877]: 0.829 (+/-0.205) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1878]: 0.895 (+/-0.093) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1879]: 0.895 (+/-0.093) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1880]: 0.914 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1881]: 0.914 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1882]: 0.924 (+/-0.076) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1883]: 0.924 (+/-0.076) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1884]: 0.876 (+/-0.205) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1885]: 0.876 (+/-0.205) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1886]: 0.886 (+/-0.097) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1887]: 0.886 (+/-0.097) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1888]: 0.867 (+/-0.185) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1889]: 0.867 (+/-0.185) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1890]: 0.914 (+/-0.203) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1891]: 0.914 (+/-0.203) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1892]: 0.800 (+/-0.194) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1893]: 0.800 (+/-0.194) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1894]: 0.886 (+/-0.187) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1895]: 0.886 (+/-0.187) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1896]: 0.638 (+/-0.524) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1897]: 0.638 (+/-0.524) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1898]: 0.914 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1899]: 0.914 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1900]: 0.829 (+/-0.205) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1901]: 0.829 (+/-0.205) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1902]: 0.895 (+/-0.093) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1903]: 0.895 (+/-0.093) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1904]: 0.914 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1905]: 0.914 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1906]: 0.924 (+/-0.076) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1907]: 0.924 (+/-0.076) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1908]: 0.876 (+/-0.205) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1909]: 0.876 (+/-0.205) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1910]: 0.886 (+/-0.097) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1911]: 0.886 (+/-0.097) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1912]: 0.867 (+/-0.185) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1913]: 0.867 (+/-0.185) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1914]: 0.914 (+/-0.203) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1915]: 0.914 (+/-0.203) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1916]: 0.800 (+/-0.194) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1917]: 0.800 (+/-0.194) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1918]: 0.886 (+/-0.187) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1919]: 0.886 (+/-0.187) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1920]: 0.638 (+/-0.524) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1921]: 0.638 (+/-0.524) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1922]: 0.914 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1923]: 0.914 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1924]: 0.829 (+/-0.205) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1925]: 0.829 (+/-0.205) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1926]: 0.895 (+/-0.093) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1927]: 0.895 (+/-0.093) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1928]: 0.914 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1929]: 0.914 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1930]: 0.924 (+/-0.076) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1931]: 0.924 (+/-0.076) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1932]: 0.876 (+/-0.205) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1933]: 0.876 (+/-0.205) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1934]: 0.886 (+/-0.097) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1935]: 0.886 (+/-0.097) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1936]: 0.867 (+/-0.185) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1937]: 0.867 (+/-0.185) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1938]: 0.914 (+/-0.203) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1939]: 0.914 (+/-0.203) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1940]: 0.800 (+/-0.194) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1941]: 0.800 (+/-0.194) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1942]: 0.886 (+/-0.187) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1943]: 0.886 (+/-0.187) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1944]: 0.848 (+/-0.373) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1945]: 0.848 (+/-0.373) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1946]: 0.848 (+/-0.373) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1947]: 0.848 (+/-0.373) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1948]: 0.848 (+/-0.383) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1949]: 0.848 (+/-0.383) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1950]: 0.848 (+/-0.383) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1951]: 0.848 (+/-0.383) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1952]: 0.838 (+/-0.214) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1953]: 0.838 (+/-0.214) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1954]: 0.838 (+/-0.214) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1955]: 0.838 (+/-0.214) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1956]: 0.705 (+/-0.164) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1957]: 0.705 (+/-0.164) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1958]: 0.705 (+/-0.164) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1959]: 0.705 (+/-0.164) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1960]: 0.838 (+/-0.322) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1961]: 0.838 (+/-0.322) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1962]: 0.838 (+/-0.322) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1963]: 0.838 (+/-0.322) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1964]: 0.686 (+/-0.129) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1965]: 0.686 (+/-0.129) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1966]: 0.686 (+/-0.129) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1967]: 0.686 (+/-0.129) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1968]: 0.848 (+/-0.373) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1969]: 0.848 (+/-0.373) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1970]: 0.848 (+/-0.373) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1971]: 0.848 (+/-0.373) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1972]: 0.848 (+/-0.383) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1973]: 0.848 (+/-0.383) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1974]: 0.848 (+/-0.383) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1975]: 0.848 (+/-0.383) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1976]: 0.838 (+/-0.214) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1977]: 0.838 (+/-0.214) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1978]: 0.838 (+/-0.214) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1979]: 0.838 (+/-0.214) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1980]: 0.705 (+/-0.164) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1981]: 0.705 (+/-0.164) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1982]: 0.705 (+/-0.164) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1983]: 0.705 (+/-0.164) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1984]: 0.838 (+/-0.322) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1985]: 0.838 (+/-0.322) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1986]: 0.838 (+/-0.322) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1987]: 0.838 (+/-0.322) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1988]: 0.686 (+/-0.129) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1989]: 0.686 (+/-0.129) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1990]: 0.686 (+/-0.129) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1991]: 0.686 (+/-0.129) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1992]: 0.848 (+/-0.373) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1993]: 0.848 (+/-0.373) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1994]: 0.848 (+/-0.373) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1995]: 0.848 (+/-0.373) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1996]: 0.848 (+/-0.383) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1997]: 0.848 (+/-0.383) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1998]: 0.848 (+/-0.383) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1999]: 0.848 (+/-0.383) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2000]: 0.838 (+/-0.214) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2001]: 0.838 (+/-0.214) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2002]: 0.838 (+/-0.214) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2003]: 0.838 (+/-0.214) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2004]: 0.705 (+/-0.164) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2005]: 0.705 (+/-0.164) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2006]: 0.705 (+/-0.164) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2007]: 0.705 (+/-0.164) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2008]: 0.838 (+/-0.322) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2009]: 0.838 (+/-0.322) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2010]: 0.838 (+/-0.322) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2011]: 0.838 (+/-0.322) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2012]: 0.686 (+/-0.129) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2013]: 0.686 (+/-0.129) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2014]: 0.686 (+/-0.129) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2015]: 0.686 (+/-0.129) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2016]: 0.724 (+/-0.428) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2017]: 0.724 (+/-0.428) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2018]: 0.724 (+/-0.428) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2019]: 0.724 (+/-0.428) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2020]: 0.667 (+/-0.455) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2021]: 0.667 (+/-0.455) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2022]: 0.667 (+/-0.455) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2023]: 0.667 (+/-0.455) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2024]: 0.790 (+/-0.230) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2025]: 0.790 (+/-0.230) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2026]: 0.790 (+/-0.230) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2027]: 0.790 (+/-0.230) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2028]: 0.838 (+/-0.273) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2029]: 0.838 (+/-0.273) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2030]: 0.838 (+/-0.273) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2031]: 0.838 (+/-0.273) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2032]: 0.733 (+/-0.305) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2033]: 0.733 (+/-0.305) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2034]: 0.733 (+/-0.305) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2035]: 0.733 (+/-0.305) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2036]: 0.686 (+/-0.398) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2037]: 0.686 (+/-0.398) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2038]: 0.686 (+/-0.398) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2039]: 0.686 (+/-0.398) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2040]: 0.724 (+/-0.428) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2041]: 0.724 (+/-0.428) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2042]: 0.724 (+/-0.428) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2043]: 0.724 (+/-0.428) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2044]: 0.667 (+/-0.455) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2045]: 0.667 (+/-0.455) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2046]: 0.667 (+/-0.455) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2047]: 0.667 (+/-0.455) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2048]: 0.790 (+/-0.230) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2049]: 0.790 (+/-0.230) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2050]: 0.790 (+/-0.230) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2051]: 0.790 (+/-0.230) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2052]: 0.838 (+/-0.273) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2053]: 0.838 (+/-0.273) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2054]: 0.838 (+/-0.273) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2055]: 0.838 (+/-0.273) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2056]: 0.733 (+/-0.305) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2057]: 0.733 (+/-0.305) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2058]: 0.733 (+/-0.305) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2059]: 0.733 (+/-0.305) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2060]: 0.686 (+/-0.398) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2061]: 0.686 (+/-0.398) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2062]: 0.686 (+/-0.398) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2063]: 0.686 (+/-0.398) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2064]: 0.724 (+/-0.428) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2065]: 0.724 (+/-0.428) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2066]: 0.724 (+/-0.428) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2067]: 0.724 (+/-0.428) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2068]: 0.667 (+/-0.455) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2069]: 0.667 (+/-0.455) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2070]: 0.667 (+/-0.455) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2071]: 0.667 (+/-0.455) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2072]: 0.790 (+/-0.230) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2073]: 0.790 (+/-0.230) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2074]: 0.790 (+/-0.230) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2075]: 0.790 (+/-0.230) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2076]: 0.838 (+/-0.273) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2077]: 0.838 (+/-0.273) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2078]: 0.838 (+/-0.273) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2079]: 0.838 (+/-0.273) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2080]: 0.733 (+/-0.305) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2081]: 0.733 (+/-0.305) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2082]: 0.733 (+/-0.305) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2083]: 0.733 (+/-0.305) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2084]: 0.686 (+/-0.398) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2085]: 0.686 (+/-0.398) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2086]: 0.686 (+/-0.398) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2087]: 0.686 (+/-0.398) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2088]: 0.838 (+/-0.230) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2089]: 0.838 (+/-0.230) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2090]: 0.838 (+/-0.230) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2091]: 0.838 (+/-0.230) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2092]: 0.848 (+/-0.304) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2093]: 0.848 (+/-0.304) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2094]: 0.848 (+/-0.304) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2095]: 0.848 (+/-0.304) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2096]: 0.648 (+/-0.129) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2097]: 0.648 (+/-0.129) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2098]: 0.648 (+/-0.129) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2099]: 0.648 (+/-0.129) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2100]: 0.724 (+/-0.140) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2101]: 0.724 (+/-0.140) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2102]: 0.724 (+/-0.140) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2103]: 0.724 (+/-0.140) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2104]: 0.819 (+/-0.258) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2105]: 0.819 (+/-0.258) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2106]: 0.819 (+/-0.258) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2107]: 0.819 (+/-0.258) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2108]: 0.743 (+/-0.260) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2109]: 0.743 (+/-0.260) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2110]: 0.743 (+/-0.260) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2111]: 0.743 (+/-0.260) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2112]: 0.838 (+/-0.230) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2113]: 0.838 (+/-0.230) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2114]: 0.838 (+/-0.230) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2115]: 0.838 (+/-0.230) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2116]: 0.848 (+/-0.304) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2117]: 0.848 (+/-0.304) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2118]: 0.848 (+/-0.304) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2119]: 0.848 (+/-0.304) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2120]: 0.648 (+/-0.129) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2121]: 0.648 (+/-0.129) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2122]: 0.648 (+/-0.129) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2123]: 0.648 (+/-0.129) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2124]: 0.724 (+/-0.140) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2125]: 0.724 (+/-0.140) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2126]: 0.724 (+/-0.140) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2127]: 0.724 (+/-0.140) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2128]: 0.819 (+/-0.258) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2129]: 0.819 (+/-0.258) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2130]: 0.819 (+/-0.258) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2131]: 0.819 (+/-0.258) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2132]: 0.743 (+/-0.260) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2133]: 0.743 (+/-0.260) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2134]: 0.743 (+/-0.260) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2135]: 0.743 (+/-0.260) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2136]: 0.838 (+/-0.230) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2137]: 0.838 (+/-0.230) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2138]: 0.838 (+/-0.230) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2139]: 0.838 (+/-0.230) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2140]: 0.848 (+/-0.304) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2141]: 0.848 (+/-0.304) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2142]: 0.848 (+/-0.304) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2143]: 0.848 (+/-0.304) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2144]: 0.648 (+/-0.129) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2145]: 0.648 (+/-0.129) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2146]: 0.648 (+/-0.129) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2147]: 0.648 (+/-0.129) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2148]: 0.724 (+/-0.140) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2149]: 0.724 (+/-0.140) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2150]: 0.724 (+/-0.140) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2151]: 0.724 (+/-0.140) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2152]: 0.819 (+/-0.258) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2153]: 0.819 (+/-0.258) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2154]: 0.819 (+/-0.258) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2155]: 0.819 (+/-0.258) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2156]: 0.743 (+/-0.260) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2157]: 0.743 (+/-0.260) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2158]: 0.743 (+/-0.260) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2159]: 0.743 (+/-0.260) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2160]: 0.943 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2161]: 0.943 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2162]: 0.943 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2163]: 0.943 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2164]: 0.924 (+/-0.076) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2165]: 0.924 (+/-0.076) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2166]: 0.924 (+/-0.076) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2167]: 0.924 (+/-0.076) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2168]: 0.962 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2169]: 0.962 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2170]: 0.962 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2171]: 0.962 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2172]: 0.857 (+/-0.148) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2173]: 0.857 (+/-0.148) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2174]: 0.857 (+/-0.148) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2175]: 0.857 (+/-0.148) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2176]: 0.981 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2177]: 0.981 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2178]: 0.981 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2179]: 0.981 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2180]: 0.914 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2181]: 0.914 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2182]: 0.914 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2183]: 0.914 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2184]: 0.943 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2185]: 0.943 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2186]: 0.943 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2187]: 0.943 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2188]: 0.924 (+/-0.076) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2189]: 0.924 (+/-0.076) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2190]: 0.924 (+/-0.076) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2191]: 0.924 (+/-0.076) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2192]: 0.962 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2193]: 0.962 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2194]: 0.962 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2195]: 0.962 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2196]: 0.857 (+/-0.148) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2197]: 0.857 (+/-0.148) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2198]: 0.857 (+/-0.148) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2199]: 0.857 (+/-0.148) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2200]: 0.981 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2201]: 0.981 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2202]: 0.981 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2203]: 0.981 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2204]: 0.914 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2205]: 0.914 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2206]: 0.914 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2207]: 0.914 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2208]: 0.943 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2209]: 0.943 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2210]: 0.943 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2211]: 0.943 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2212]: 0.924 (+/-0.076) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2213]: 0.924 (+/-0.076) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2214]: 0.924 (+/-0.076) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2215]: 0.924 (+/-0.076) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2216]: 0.962 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2217]: 0.962 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2218]: 0.962 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2219]: 0.962 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2220]: 0.857 (+/-0.148) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2221]: 0.857 (+/-0.148) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2222]: 0.857 (+/-0.148) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2223]: 0.857 (+/-0.148) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2224]: 0.981 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2225]: 0.981 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2226]: 0.981 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2227]: 0.981 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2228]: 0.914 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2229]: 0.914 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2230]: 0.914 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2231]: 0.914 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2232]: 0.952 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2233]: 0.952 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2234]: 0.952 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2235]: 0.952 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2236]: 0.943 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2237]: 0.943 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2238]: 0.943 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2239]: 0.943 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2240]: 0.952 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2241]: 0.952 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2242]: 0.952 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2243]: 0.952 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2244]: 0.876 (+/-0.205) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2245]: 0.876 (+/-0.205) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2246]: 0.876 (+/-0.205) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2247]: 0.876 (+/-0.205) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2248]: 0.952 (+/-0.000) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2249]: 0.952 (+/-0.000) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2250]: 0.952 (+/-0.000) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2251]: 0.952 (+/-0.000) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2252]: 0.924 (+/-0.114) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2253]: 0.924 (+/-0.114) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2254]: 0.924 (+/-0.114) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2255]: 0.924 (+/-0.114) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2256]: 0.952 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2257]: 0.952 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2258]: 0.952 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2259]: 0.952 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2260]: 0.943 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2261]: 0.943 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2262]: 0.943 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2263]: 0.943 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2264]: 0.952 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2265]: 0.952 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2266]: 0.952 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2267]: 0.952 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2268]: 0.876 (+/-0.205) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2269]: 0.876 (+/-0.205) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2270]: 0.876 (+/-0.205) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2271]: 0.876 (+/-0.205) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2272]: 0.952 (+/-0.000) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2273]: 0.952 (+/-0.000) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2274]: 0.952 (+/-0.000) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2275]: 0.952 (+/-0.000) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2276]: 0.924 (+/-0.114) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2277]: 0.924 (+/-0.114) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2278]: 0.924 (+/-0.114) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2279]: 0.924 (+/-0.114) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2280]: 0.952 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2281]: 0.952 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2282]: 0.952 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2283]: 0.952 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2284]: 0.943 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2285]: 0.943 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2286]: 0.943 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2287]: 0.943 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2288]: 0.952 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2289]: 0.952 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2290]: 0.952 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2291]: 0.952 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2292]: 0.876 (+/-0.205) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2293]: 0.876 (+/-0.205) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2294]: 0.876 (+/-0.205) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2295]: 0.876 (+/-0.205) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2296]: 0.952 (+/-0.000) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2297]: 0.952 (+/-0.000) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2298]: 0.952 (+/-0.000) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2299]: 0.952 (+/-0.000) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2300]: 0.924 (+/-0.114) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2301]: 0.924 (+/-0.114) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2302]: 0.924 (+/-0.114) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2303]: 0.924 (+/-0.114) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2304]: 0.962 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2305]: 0.962 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2306]: 0.962 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2307]: 0.962 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2308]: 0.933 (+/-0.097) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2309]: 0.933 (+/-0.097) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2310]: 0.933 (+/-0.097) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2311]: 0.933 (+/-0.097) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2312]: 0.914 (+/-0.111) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2313]: 0.914 (+/-0.111) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2314]: 0.914 (+/-0.111) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2315]: 0.914 (+/-0.111) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2316]: 0.886 (+/-0.166) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2317]: 0.886 (+/-0.166) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2318]: 0.886 (+/-0.166) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2319]: 0.886 (+/-0.166) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2320]: 0.990 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2321]: 0.990 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2322]: 0.990 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2323]: 0.990 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2324]: 0.905 (+/-0.135) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2325]: 0.905 (+/-0.135) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2326]: 0.905 (+/-0.135) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2327]: 0.905 (+/-0.135) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2328]: 0.962 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2329]: 0.962 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2330]: 0.962 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2331]: 0.962 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2332]: 0.933 (+/-0.097) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2333]: 0.933 (+/-0.097) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2334]: 0.933 (+/-0.097) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2335]: 0.933 (+/-0.097) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2336]: 0.914 (+/-0.111) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2337]: 0.914 (+/-0.111) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2338]: 0.914 (+/-0.111) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2339]: 0.914 (+/-0.111) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2340]: 0.886 (+/-0.166) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2341]: 0.886 (+/-0.166) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2342]: 0.886 (+/-0.166) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2343]: 0.886 (+/-0.166) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2344]: 0.990 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2345]: 0.990 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2346]: 0.990 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2347]: 0.990 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2348]: 0.905 (+/-0.135) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2349]: 0.905 (+/-0.135) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2350]: 0.905 (+/-0.135) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2351]: 0.905 (+/-0.135) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2352]: 0.962 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2353]: 0.962 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2354]: 0.962 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2355]: 0.962 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2356]: 0.933 (+/-0.097) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2357]: 0.933 (+/-0.097) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2358]: 0.933 (+/-0.097) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2359]: 0.933 (+/-0.097) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2360]: 0.914 (+/-0.111) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2361]: 0.914 (+/-0.111) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2362]: 0.914 (+/-0.111) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2363]: 0.914 (+/-0.111) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2364]: 0.886 (+/-0.166) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2365]: 0.886 (+/-0.166) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2366]: 0.886 (+/-0.166) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2367]: 0.886 (+/-0.166) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2368]: 0.990 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2369]: 0.990 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2370]: 0.990 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2371]: 0.990 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2372]: 0.905 (+/-0.135) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2373]: 0.905 (+/-0.135) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2374]: 0.905 (+/-0.135) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2375]: 0.905 (+/-0.135) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2376]: 0.886 (+/-0.196) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2377]: 0.886 (+/-0.196) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2378]: 0.790 (+/-0.166) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2379]: 0.790 (+/-0.166) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2380]: 0.857 (+/-0.200) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2381]: 0.857 (+/-0.200) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2382]: 0.781 (+/-0.177) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2383]: 0.781 (+/-0.177) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2384]: 0.829 (+/-0.155) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2385]: 0.829 (+/-0.155) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2386]: 0.886 (+/-0.097) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2387]: 0.886 (+/-0.097) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2388]: 0.838 (+/-0.177) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2389]: 0.838 (+/-0.177) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2390]: 0.895 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2391]: 0.895 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2392]: 0.867 (+/-0.212) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2393]: 0.867 (+/-0.212) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2394]: 0.895 (+/-0.111) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2395]: 0.895 (+/-0.111) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2396]: 0.924 (+/-0.076) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2397]: 0.924 (+/-0.076) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2398]: 0.876 (+/-0.177) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2399]: 0.876 (+/-0.177) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2400]: 0.886 (+/-0.196) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2401]: 0.886 (+/-0.196) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2402]: 0.790 (+/-0.166) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2403]: 0.790 (+/-0.166) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2404]: 0.857 (+/-0.200) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2405]: 0.857 (+/-0.200) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2406]: 0.781 (+/-0.177) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2407]: 0.781 (+/-0.177) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2408]: 0.829 (+/-0.155) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2409]: 0.829 (+/-0.155) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2410]: 0.886 (+/-0.097) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2411]: 0.886 (+/-0.097) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2412]: 0.838 (+/-0.177) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2413]: 0.838 (+/-0.177) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2414]: 0.895 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2415]: 0.895 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2416]: 0.867 (+/-0.212) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2417]: 0.867 (+/-0.212) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2418]: 0.895 (+/-0.111) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2419]: 0.895 (+/-0.111) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2420]: 0.924 (+/-0.076) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2421]: 0.924 (+/-0.076) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2422]: 0.876 (+/-0.177) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2423]: 0.876 (+/-0.177) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2424]: 0.886 (+/-0.196) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2425]: 0.886 (+/-0.196) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2426]: 0.790 (+/-0.166) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2427]: 0.790 (+/-0.166) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2428]: 0.857 (+/-0.200) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2429]: 0.857 (+/-0.200) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2430]: 0.781 (+/-0.177) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2431]: 0.781 (+/-0.177) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2432]: 0.829 (+/-0.155) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2433]: 0.829 (+/-0.155) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2434]: 0.886 (+/-0.097) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2435]: 0.886 (+/-0.097) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2436]: 0.838 (+/-0.177) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2437]: 0.838 (+/-0.177) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2438]: 0.895 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2439]: 0.895 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2440]: 0.867 (+/-0.212) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2441]: 0.867 (+/-0.212) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2442]: 0.895 (+/-0.111) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2443]: 0.895 (+/-0.111) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2444]: 0.924 (+/-0.076) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2445]: 0.924 (+/-0.076) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2446]: 0.876 (+/-0.177) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2447]: 0.876 (+/-0.177) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2448]: 0.771 (+/-0.358) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2449]: 0.771 (+/-0.358) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2450]: 0.867 (+/-0.152) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2451]: 0.867 (+/-0.152) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2452]: 0.676 (+/-0.530) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2453]: 0.676 (+/-0.530) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2454]: 0.867 (+/-0.152) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2455]: 0.867 (+/-0.152) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2456]: 0.819 (+/-0.229) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2457]: 0.819 (+/-0.229) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2458]: 0.857 (+/-0.170) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2459]: 0.857 (+/-0.170) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2460]: 0.876 (+/-0.230) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2461]: 0.876 (+/-0.230) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2462]: 0.857 (+/-0.170) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2463]: 0.857 (+/-0.170) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2464]: 0.581 (+/-0.309) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2465]: 0.581 (+/-0.309) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2466]: 0.838 (+/-0.196) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2467]: 0.838 (+/-0.196) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2468]: 0.762 (+/-0.263) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2469]: 0.762 (+/-0.263) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2470]: 0.848 (+/-0.185) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2471]: 0.848 (+/-0.185) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2472]: 0.771 (+/-0.358) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2473]: 0.771 (+/-0.358) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2474]: 0.867 (+/-0.152) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2475]: 0.867 (+/-0.152) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2476]: 0.676 (+/-0.530) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2477]: 0.676 (+/-0.530) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2478]: 0.867 (+/-0.152) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2479]: 0.867 (+/-0.152) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2480]: 0.819 (+/-0.229) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2481]: 0.819 (+/-0.229) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2482]: 0.857 (+/-0.170) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2483]: 0.857 (+/-0.170) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2484]: 0.876 (+/-0.230) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2485]: 0.876 (+/-0.230) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2486]: 0.857 (+/-0.170) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2487]: 0.857 (+/-0.170) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2488]: 0.581 (+/-0.309) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2489]: 0.581 (+/-0.309) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2490]: 0.838 (+/-0.196) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2491]: 0.838 (+/-0.196) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2492]: 0.762 (+/-0.263) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2493]: 0.762 (+/-0.263) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2494]: 0.848 (+/-0.185) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2495]: 0.848 (+/-0.185) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2496]: 0.771 (+/-0.358) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2497]: 0.771 (+/-0.358) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2498]: 0.867 (+/-0.152) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2499]: 0.867 (+/-0.152) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2500]: 0.676 (+/-0.530) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2501]: 0.676 (+/-0.530) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2502]: 0.867 (+/-0.152) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2503]: 0.867 (+/-0.152) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2504]: 0.819 (+/-0.229) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2505]: 0.819 (+/-0.229) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2506]: 0.857 (+/-0.170) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2507]: 0.857 (+/-0.170) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2508]: 0.876 (+/-0.230) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2509]: 0.876 (+/-0.230) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2510]: 0.857 (+/-0.170) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2511]: 0.857 (+/-0.170) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2512]: 0.581 (+/-0.309) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2513]: 0.581 (+/-0.309) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2514]: 0.838 (+/-0.196) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2515]: 0.838 (+/-0.196) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2516]: 0.762 (+/-0.263) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2517]: 0.762 (+/-0.263) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2518]: 0.848 (+/-0.185) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2519]: 0.848 (+/-0.185) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2520]: 0.657 (+/-0.456) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2521]: 0.657 (+/-0.456) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2522]: 0.943 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2523]: 0.943 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2524]: 0.838 (+/-0.205) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2525]: 0.838 (+/-0.205) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2526]: 0.895 (+/-0.111) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2527]: 0.895 (+/-0.111) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2528]: 0.800 (+/-0.378) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2529]: 0.800 (+/-0.378) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2530]: 0.971 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2531]: 0.971 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2532]: 0.724 (+/-0.093) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2533]: 0.724 (+/-0.093) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2534]: 0.962 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2535]: 0.962 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2536]: 0.848 (+/-0.220) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2537]: 0.848 (+/-0.220) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2538]: 0.952 (+/-0.060) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2539]: 0.952 (+/-0.060) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2540]: 0.848 (+/-0.194) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2541]: 0.848 (+/-0.194) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2542]: 0.962 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2543]: 0.962 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2544]: 0.657 (+/-0.456) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2545]: 0.657 (+/-0.456) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2546]: 0.943 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2547]: 0.943 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2548]: 0.838 (+/-0.205) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2549]: 0.838 (+/-0.205) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2550]: 0.895 (+/-0.111) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2551]: 0.895 (+/-0.111) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2552]: 0.800 (+/-0.378) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2553]: 0.800 (+/-0.378) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2554]: 0.971 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2555]: 0.971 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2556]: 0.724 (+/-0.093) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2557]: 0.724 (+/-0.093) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2558]: 0.962 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2559]: 0.962 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2560]: 0.848 (+/-0.220) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2561]: 0.848 (+/-0.220) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2562]: 0.952 (+/-0.060) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2563]: 0.952 (+/-0.060) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2564]: 0.848 (+/-0.194) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2565]: 0.848 (+/-0.194) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2566]: 0.962 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2567]: 0.962 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2568]: 0.657 (+/-0.456) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2569]: 0.657 (+/-0.456) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2570]: 0.943 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2571]: 0.943 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2572]: 0.838 (+/-0.205) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2573]: 0.838 (+/-0.205) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2574]: 0.895 (+/-0.111) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2575]: 0.895 (+/-0.111) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2576]: 0.800 (+/-0.378) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2577]: 0.800 (+/-0.378) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2578]: 0.971 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2579]: 0.971 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2580]: 0.724 (+/-0.093) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2581]: 0.724 (+/-0.093) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2582]: 0.962 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2583]: 0.962 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2584]: 0.848 (+/-0.220) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2585]: 0.848 (+/-0.220) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2586]: 0.952 (+/-0.060) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2587]: 0.952 (+/-0.060) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2588]: 0.848 (+/-0.194) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2589]: 0.848 (+/-0.194) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2590]: 0.962 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2591]: 0.962 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2592]: 0.867 (+/-0.212) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2593]: 0.867 (+/-0.212) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2594]: 0.867 (+/-0.212) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2595]: 0.867 (+/-0.212) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2596]: 0.838 (+/-0.286) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2597]: 0.838 (+/-0.286) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2598]: 0.838 (+/-0.286) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2599]: 0.838 (+/-0.286) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2600]: 0.857 (+/-0.104) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2601]: 0.857 (+/-0.104) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2602]: 0.857 (+/-0.104) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2603]: 0.857 (+/-0.104) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2604]: 0.914 (+/-0.093) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2605]: 0.914 (+/-0.093) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2606]: 0.914 (+/-0.093) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2607]: 0.914 (+/-0.093) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2608]: 0.924 (+/-0.129) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2609]: 0.924 (+/-0.129) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2610]: 0.924 (+/-0.129) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2611]: 0.924 (+/-0.129) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2612]: 0.895 (+/-0.111) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2613]: 0.895 (+/-0.111) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2614]: 0.895 (+/-0.111) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2615]: 0.895 (+/-0.111) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2616]: 0.867 (+/-0.212) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2617]: 0.867 (+/-0.212) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2618]: 0.867 (+/-0.212) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2619]: 0.867 (+/-0.212) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2620]: 0.838 (+/-0.286) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2621]: 0.838 (+/-0.286) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2622]: 0.838 (+/-0.286) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2623]: 0.838 (+/-0.286) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2624]: 0.857 (+/-0.104) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2625]: 0.857 (+/-0.104) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2626]: 0.857 (+/-0.104) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2627]: 0.857 (+/-0.104) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2628]: 0.914 (+/-0.093) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2629]: 0.914 (+/-0.093) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2630]: 0.914 (+/-0.093) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2631]: 0.914 (+/-0.093) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2632]: 0.924 (+/-0.129) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2633]: 0.924 (+/-0.129) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2634]: 0.924 (+/-0.129) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2635]: 0.924 (+/-0.129) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2636]: 0.895 (+/-0.111) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2637]: 0.895 (+/-0.111) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2638]: 0.895 (+/-0.111) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2639]: 0.895 (+/-0.111) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2640]: 0.867 (+/-0.212) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2641]: 0.867 (+/-0.212) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2642]: 0.867 (+/-0.212) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2643]: 0.867 (+/-0.212) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2644]: 0.838 (+/-0.286) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2645]: 0.838 (+/-0.286) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2646]: 0.838 (+/-0.286) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2647]: 0.838 (+/-0.286) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2648]: 0.857 (+/-0.104) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2649]: 0.857 (+/-0.104) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2650]: 0.857 (+/-0.104) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2651]: 0.857 (+/-0.104) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2652]: 0.914 (+/-0.093) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2653]: 0.914 (+/-0.093) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2654]: 0.914 (+/-0.093) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2655]: 0.914 (+/-0.093) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2656]: 0.924 (+/-0.129) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2657]: 0.924 (+/-0.129) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2658]: 0.924 (+/-0.129) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2659]: 0.924 (+/-0.129) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2660]: 0.895 (+/-0.111) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2661]: 0.895 (+/-0.111) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2662]: 0.895 (+/-0.111) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2663]: 0.895 (+/-0.111) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2664]: 0.781 (+/-0.328) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2665]: 0.781 (+/-0.328) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2666]: 0.781 (+/-0.328) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2667]: 0.781 (+/-0.328) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2668]: 0.714 (+/-0.335) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2669]: 0.714 (+/-0.335) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2670]: 0.714 (+/-0.335) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2671]: 0.714 (+/-0.335) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2672]: 0.886 (+/-0.245) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2673]: 0.886 (+/-0.245) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2674]: 0.886 (+/-0.245) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2675]: 0.886 (+/-0.245) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2676]: 0.829 (+/-0.260) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2677]: 0.829 (+/-0.260) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2678]: 0.829 (+/-0.260) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2679]: 0.829 (+/-0.260) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2680]: 0.810 (+/-0.295) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2681]: 0.810 (+/-0.295) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2682]: 0.810 (+/-0.295) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2683]: 0.810 (+/-0.295) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2684]: 0.800 (+/-0.279) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2685]: 0.800 (+/-0.279) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2686]: 0.800 (+/-0.279) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2687]: 0.800 (+/-0.279) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2688]: 0.781 (+/-0.328) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2689]: 0.781 (+/-0.328) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2690]: 0.781 (+/-0.328) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2691]: 0.781 (+/-0.328) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2692]: 0.714 (+/-0.335) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2693]: 0.714 (+/-0.335) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2694]: 0.714 (+/-0.335) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2695]: 0.714 (+/-0.335) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2696]: 0.886 (+/-0.245) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2697]: 0.886 (+/-0.245) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2698]: 0.886 (+/-0.245) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2699]: 0.886 (+/-0.245) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2700]: 0.829 (+/-0.260) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2701]: 0.829 (+/-0.260) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2702]: 0.829 (+/-0.260) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2703]: 0.829 (+/-0.260) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2704]: 0.810 (+/-0.295) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2705]: 0.810 (+/-0.295) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2706]: 0.810 (+/-0.295) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2707]: 0.810 (+/-0.295) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2708]: 0.800 (+/-0.279) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2709]: 0.800 (+/-0.279) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2710]: 0.800 (+/-0.279) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2711]: 0.800 (+/-0.279) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2712]: 0.781 (+/-0.328) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2713]: 0.781 (+/-0.328) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2714]: 0.781 (+/-0.328) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2715]: 0.781 (+/-0.328) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2716]: 0.714 (+/-0.335) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2717]: 0.714 (+/-0.335) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2718]: 0.714 (+/-0.335) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2719]: 0.714 (+/-0.335) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2720]: 0.886 (+/-0.245) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2721]: 0.886 (+/-0.245) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2722]: 0.886 (+/-0.245) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2723]: 0.886 (+/-0.245) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2724]: 0.829 (+/-0.260) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2725]: 0.829 (+/-0.260) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2726]: 0.829 (+/-0.260) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2727]: 0.829 (+/-0.260) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2728]: 0.810 (+/-0.295) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2729]: 0.810 (+/-0.295) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2730]: 0.810 (+/-0.295) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2731]: 0.810 (+/-0.295) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2732]: 0.800 (+/-0.279) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2733]: 0.800 (+/-0.279) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2734]: 0.800 (+/-0.279) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2735]: 0.800 (+/-0.279) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2736]: 0.581 (+/-0.480) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2737]: 0.581 (+/-0.480) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2738]: 0.581 (+/-0.480) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2739]: 0.581 (+/-0.480) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2740]: 0.848 (+/-0.304) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2741]: 0.848 (+/-0.304) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2742]: 0.848 (+/-0.304) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2743]: 0.848 (+/-0.304) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2744]: 0.695 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2745]: 0.695 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2746]: 0.695 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2747]: 0.695 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2748]: 0.724 (+/-0.140) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2749]: 0.724 (+/-0.140) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2750]: 0.724 (+/-0.140) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2751]: 0.724 (+/-0.140) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2752]: 0.495 (+/-0.344) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2753]: 0.495 (+/-0.344) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2754]: 0.495 (+/-0.344) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2755]: 0.495 (+/-0.344) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2756]: 0.743 (+/-0.260) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2757]: 0.743 (+/-0.260) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2758]: 0.743 (+/-0.260) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2759]: 0.743 (+/-0.260) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2760]: 0.581 (+/-0.480) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2761]: 0.581 (+/-0.480) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2762]: 0.581 (+/-0.480) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2763]: 0.581 (+/-0.480) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2764]: 0.848 (+/-0.304) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2765]: 0.848 (+/-0.304) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2766]: 0.848 (+/-0.304) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2767]: 0.848 (+/-0.304) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2768]: 0.695 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2769]: 0.695 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2770]: 0.695 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2771]: 0.695 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2772]: 0.724 (+/-0.140) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2773]: 0.724 (+/-0.140) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2774]: 0.724 (+/-0.140) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2775]: 0.724 (+/-0.140) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2776]: 0.495 (+/-0.344) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2777]: 0.495 (+/-0.344) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2778]: 0.495 (+/-0.344) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2779]: 0.495 (+/-0.344) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2780]: 0.743 (+/-0.260) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2781]: 0.743 (+/-0.260) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2782]: 0.743 (+/-0.260) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2783]: 0.743 (+/-0.260) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2784]: 0.581 (+/-0.480) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2785]: 0.581 (+/-0.480) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2786]: 0.581 (+/-0.480) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2787]: 0.581 (+/-0.480) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2788]: 0.848 (+/-0.304) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2789]: 0.848 (+/-0.304) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2790]: 0.848 (+/-0.304) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2791]: 0.848 (+/-0.304) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2792]: 0.695 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2793]: 0.695 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2794]: 0.695 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2795]: 0.695 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2796]: 0.724 (+/-0.140) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2797]: 0.724 (+/-0.140) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2798]: 0.724 (+/-0.140) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2799]: 0.724 (+/-0.140) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2800]: 0.495 (+/-0.344) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2801]: 0.495 (+/-0.344) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2802]: 0.495 (+/-0.344) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2803]: 0.495 (+/-0.344) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2804]: 0.743 (+/-0.260) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2805]: 0.743 (+/-0.260) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2806]: 0.743 (+/-0.260) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2807]: 0.743 (+/-0.260) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2808]: 0.962 (+/-0.038) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2809]: 0.962 (+/-0.038) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2810]: 0.962 (+/-0.038) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2811]: 0.962 (+/-0.038) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2812]: 0.886 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2813]: 0.886 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2814]: 0.886 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2815]: 0.886 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2816]: 0.962 (+/-0.111) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2817]: 0.962 (+/-0.111) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2818]: 0.962 (+/-0.111) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2819]: 0.962 (+/-0.111) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2820]: 0.848 (+/-0.185) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2821]: 0.848 (+/-0.185) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2822]: 0.848 (+/-0.185) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2823]: 0.848 (+/-0.185) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2824]: 0.981 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2825]: 0.981 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2826]: 0.981 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2827]: 0.981 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2828]: 0.933 (+/-0.097) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2829]: 0.933 (+/-0.097) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2830]: 0.933 (+/-0.097) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2831]: 0.933 (+/-0.097) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2832]: 0.962 (+/-0.038) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2833]: 0.962 (+/-0.038) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2834]: 0.962 (+/-0.038) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2835]: 0.962 (+/-0.038) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2836]: 0.886 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2837]: 0.886 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2838]: 0.886 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2839]: 0.886 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2840]: 0.962 (+/-0.111) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2841]: 0.962 (+/-0.111) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2842]: 0.962 (+/-0.111) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2843]: 0.962 (+/-0.111) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2844]: 0.848 (+/-0.185) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2845]: 0.848 (+/-0.185) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2846]: 0.848 (+/-0.185) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2847]: 0.848 (+/-0.185) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2848]: 0.981 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2849]: 0.981 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2850]: 0.981 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2851]: 0.981 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2852]: 0.933 (+/-0.097) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2853]: 0.933 (+/-0.097) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2854]: 0.933 (+/-0.097) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2855]: 0.933 (+/-0.097) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2856]: 0.962 (+/-0.038) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2857]: 0.962 (+/-0.038) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2858]: 0.962 (+/-0.038) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2859]: 0.962 (+/-0.038) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2860]: 0.886 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2861]: 0.886 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2862]: 0.886 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2863]: 0.886 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2864]: 0.962 (+/-0.111) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2865]: 0.962 (+/-0.111) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2866]: 0.962 (+/-0.111) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2867]: 0.962 (+/-0.111) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2868]: 0.848 (+/-0.185) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2869]: 0.848 (+/-0.185) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2870]: 0.848 (+/-0.185) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2871]: 0.848 (+/-0.185) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2872]: 0.981 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2873]: 0.981 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2874]: 0.981 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2875]: 0.981 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2876]: 0.933 (+/-0.097) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2877]: 0.933 (+/-0.097) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2878]: 0.933 (+/-0.097) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2879]: 0.933 (+/-0.097) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2880]: 0.952 (+/-0.104) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2881]: 0.952 (+/-0.104) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2882]: 0.952 (+/-0.104) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2883]: 0.952 (+/-0.104) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2884]: 0.867 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2885]: 0.867 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2886]: 0.867 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2887]: 0.867 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2888]: 0.981 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2889]: 0.981 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2890]: 0.981 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2891]: 0.981 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2892]: 0.962 (+/-0.071) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2893]: 0.962 (+/-0.071) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2894]: 0.962 (+/-0.071) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2895]: 0.962 (+/-0.071) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2896]: 0.971 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2897]: 0.971 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2898]: 0.971 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2899]: 0.971 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2900]: 0.924 (+/-0.114) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2901]: 0.924 (+/-0.114) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2902]: 0.924 (+/-0.114) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2903]: 0.924 (+/-0.114) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2904]: 0.952 (+/-0.104) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2905]: 0.952 (+/-0.104) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2906]: 0.952 (+/-0.104) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2907]: 0.952 (+/-0.104) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2908]: 0.867 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2909]: 0.867 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2910]: 0.867 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2911]: 0.867 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2912]: 0.981 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2913]: 0.981 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2914]: 0.981 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2915]: 0.981 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2916]: 0.962 (+/-0.071) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2917]: 0.962 (+/-0.071) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2918]: 0.962 (+/-0.071) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2919]: 0.962 (+/-0.071) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2920]: 0.971 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2921]: 0.971 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2922]: 0.971 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2923]: 0.971 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2924]: 0.924 (+/-0.114) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2925]: 0.924 (+/-0.114) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2926]: 0.924 (+/-0.114) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2927]: 0.924 (+/-0.114) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2928]: 0.952 (+/-0.104) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2929]: 0.952 (+/-0.104) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2930]: 0.952 (+/-0.104) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2931]: 0.952 (+/-0.104) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2932]: 0.867 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2933]: 0.867 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2934]: 0.867 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2935]: 0.867 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2936]: 0.981 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2937]: 0.981 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2938]: 0.981 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2939]: 0.981 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2940]: 0.962 (+/-0.071) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2941]: 0.962 (+/-0.071) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2942]: 0.962 (+/-0.071) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2943]: 0.962 (+/-0.071) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2944]: 0.971 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2945]: 0.971 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2946]: 0.971 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2947]: 0.971 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2948]: 0.924 (+/-0.114) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2949]: 0.924 (+/-0.114) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2950]: 0.924 (+/-0.114) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2951]: 0.924 (+/-0.114) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2952]: 0.962 (+/-0.038) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2953]: 0.962 (+/-0.038) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2954]: 0.962 (+/-0.038) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2955]: 0.962 (+/-0.038) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2956]: 0.876 (+/-0.230) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2957]: 0.876 (+/-0.230) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2958]: 0.876 (+/-0.230) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2959]: 0.876 (+/-0.230) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2960]: 0.971 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2961]: 0.971 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2962]: 0.971 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2963]: 0.971 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2964]: 0.895 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2965]: 0.895 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2966]: 0.895 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2967]: 0.895 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2968]: 0.971 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2969]: 0.971 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2970]: 0.971 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2971]: 0.971 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2972]: 0.943 (+/-0.140) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2973]: 0.943 (+/-0.140) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2974]: 0.943 (+/-0.140) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2975]: 0.943 (+/-0.140) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2976]: 0.962 (+/-0.038) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2977]: 0.962 (+/-0.038) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2978]: 0.962 (+/-0.038) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2979]: 0.962 (+/-0.038) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2980]: 0.876 (+/-0.230) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2981]: 0.876 (+/-0.230) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2982]: 0.876 (+/-0.230) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2983]: 0.876 (+/-0.230) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2984]: 0.971 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2985]: 0.971 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2986]: 0.971 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2987]: 0.971 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2988]: 0.895 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2989]: 0.895 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2990]: 0.895 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2991]: 0.895 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2992]: 0.971 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2993]: 0.971 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2994]: 0.971 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2995]: 0.971 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2996]: 0.943 (+/-0.140) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2997]: 0.943 (+/-0.140) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2998]: 0.943 (+/-0.140) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2999]: 0.943 (+/-0.140) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3000]: 0.962 (+/-0.038) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3001]: 0.962 (+/-0.038) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3002]: 0.962 (+/-0.038) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3003]: 0.962 (+/-0.038) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3004]: 0.876 (+/-0.230) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3005]: 0.876 (+/-0.230) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3006]: 0.876 (+/-0.230) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3007]: 0.876 (+/-0.230) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3008]: 0.971 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3009]: 0.971 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3010]: 0.971 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3011]: 0.971 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3012]: 0.895 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3013]: 0.895 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3014]: 0.895 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3015]: 0.895 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3016]: 0.971 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3017]: 0.971 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3018]: 0.971 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3019]: 0.971 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3020]: 0.943 (+/-0.140) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3021]: 0.943 (+/-0.140) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3022]: 0.943 (+/-0.140) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3023]: 0.943 (+/-0.140) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3024]: 0.867 (+/-0.126) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3025]: 0.867 (+/-0.126) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3026]: 0.695 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3027]: 0.695 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3028]: 0.848 (+/-0.194) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3029]: 0.848 (+/-0.194) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3030]: 0.695 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3031]: 0.695 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3032]: 0.905 (+/-0.120) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3033]: 0.905 (+/-0.120) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3034]: 0.695 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3035]: 0.695 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3036]: 0.876 (+/-0.097) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3037]: 0.876 (+/-0.097) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3038]: 0.695 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3039]: 0.695 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3040]: 0.905 (+/-0.135) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3041]: 0.905 (+/-0.135) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3042]: 0.695 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3043]: 0.695 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3044]: 0.829 (+/-0.166) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3045]: 0.829 (+/-0.166) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3046]: 0.695 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3047]: 0.695 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3048]: 0.867 (+/-0.126) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3049]: 0.867 (+/-0.126) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3050]: 0.695 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3051]: 0.695 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3052]: 0.848 (+/-0.194) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3053]: 0.848 (+/-0.194) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3054]: 0.695 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3055]: 0.695 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3056]: 0.905 (+/-0.120) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3057]: 0.905 (+/-0.120) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3058]: 0.695 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3059]: 0.695 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3060]: 0.876 (+/-0.097) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3061]: 0.876 (+/-0.097) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3062]: 0.695 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3063]: 0.695 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3064]: 0.905 (+/-0.135) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3065]: 0.905 (+/-0.135) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3066]: 0.695 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3067]: 0.695 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3068]: 0.829 (+/-0.166) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3069]: 0.829 (+/-0.166) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3070]: 0.695 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3071]: 0.695 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3072]: 0.867 (+/-0.126) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3073]: 0.867 (+/-0.126) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3074]: 0.695 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3075]: 0.695 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3076]: 0.848 (+/-0.194) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3077]: 0.848 (+/-0.194) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3078]: 0.695 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3079]: 0.695 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3080]: 0.905 (+/-0.120) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3081]: 0.905 (+/-0.120) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3082]: 0.695 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3083]: 0.695 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3084]: 0.876 (+/-0.097) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3085]: 0.876 (+/-0.097) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3086]: 0.695 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3087]: 0.695 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3088]: 0.905 (+/-0.135) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3089]: 0.905 (+/-0.135) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3090]: 0.695 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3091]: 0.695 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3092]: 0.829 (+/-0.166) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3093]: 0.829 (+/-0.166) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3094]: 0.695 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3095]: 0.695 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3096]: 0.943 (+/-0.093) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3097]: 0.943 (+/-0.093) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3098]: 0.819 (+/-0.140) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3099]: 0.819 (+/-0.140) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3100]: 0.943 (+/-0.093) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3101]: 0.943 (+/-0.093) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3102]: 0.838 (+/-0.129) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3103]: 0.838 (+/-0.129) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3104]: 0.924 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3105]: 0.924 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3106]: 0.867 (+/-0.126) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3107]: 0.867 (+/-0.126) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3108]: 0.924 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3109]: 0.924 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3110]: 0.867 (+/-0.126) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3111]: 0.867 (+/-0.126) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3112]: 0.867 (+/-0.185) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3113]: 0.867 (+/-0.185) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3114]: 0.848 (+/-0.093) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3115]: 0.848 (+/-0.093) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3116]: 0.857 (+/-0.170) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3117]: 0.857 (+/-0.170) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3118]: 0.857 (+/-0.104) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3119]: 0.857 (+/-0.104) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3120]: 0.943 (+/-0.093) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3121]: 0.943 (+/-0.093) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3122]: 0.819 (+/-0.140) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3123]: 0.819 (+/-0.140) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3124]: 0.943 (+/-0.093) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3125]: 0.943 (+/-0.093) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3126]: 0.838 (+/-0.129) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3127]: 0.838 (+/-0.129) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3128]: 0.924 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3129]: 0.924 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3130]: 0.867 (+/-0.126) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3131]: 0.867 (+/-0.126) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3132]: 0.924 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3133]: 0.924 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3134]: 0.867 (+/-0.126) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3135]: 0.867 (+/-0.126) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3136]: 0.867 (+/-0.185) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3137]: 0.867 (+/-0.185) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3138]: 0.848 (+/-0.093) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3139]: 0.848 (+/-0.093) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3140]: 0.857 (+/-0.170) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3141]: 0.857 (+/-0.170) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3142]: 0.857 (+/-0.104) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3143]: 0.857 (+/-0.104) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3144]: 0.943 (+/-0.093) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3145]: 0.943 (+/-0.093) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3146]: 0.819 (+/-0.140) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3147]: 0.819 (+/-0.140) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3148]: 0.943 (+/-0.093) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3149]: 0.943 (+/-0.093) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3150]: 0.838 (+/-0.129) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3151]: 0.838 (+/-0.129) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3152]: 0.924 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3153]: 0.924 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3154]: 0.867 (+/-0.126) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3155]: 0.867 (+/-0.126) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3156]: 0.924 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3157]: 0.924 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3158]: 0.867 (+/-0.126) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3159]: 0.867 (+/-0.126) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3160]: 0.867 (+/-0.185) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3161]: 0.867 (+/-0.185) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3162]: 0.848 (+/-0.093) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3163]: 0.848 (+/-0.093) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3164]: 0.857 (+/-0.170) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3165]: 0.857 (+/-0.170) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3166]: 0.857 (+/-0.104) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3167]: 0.857 (+/-0.104) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3168]: 0.657 (+/-0.523) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3169]: 0.657 (+/-0.523) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3170]: 0.895 (+/-0.229) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3171]: 0.895 (+/-0.229) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3172]: 0.867 (+/-0.164) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3173]: 0.867 (+/-0.164) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3174]: 0.905 (+/-0.104) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3175]: 0.905 (+/-0.104) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3176]: 0.724 (+/-0.126) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3177]: 0.724 (+/-0.126) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3178]: 0.943 (+/-0.071) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3179]: 0.943 (+/-0.071) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3180]: 0.733 (+/-0.129) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3181]: 0.733 (+/-0.129) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3182]: 0.924 (+/-0.114) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3183]: 0.924 (+/-0.114) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3184]: 0.733 (+/-0.245) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3185]: 0.733 (+/-0.245) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3186]: 0.810 (+/-0.209) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3187]: 0.810 (+/-0.209) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3188]: 0.781 (+/-0.280) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3189]: 0.781 (+/-0.280) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3190]: 0.905 (+/-0.120) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3191]: 0.905 (+/-0.120) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3192]: 0.657 (+/-0.523) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3193]: 0.657 (+/-0.523) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3194]: 0.895 (+/-0.229) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3195]: 0.895 (+/-0.229) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3196]: 0.867 (+/-0.164) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3197]: 0.867 (+/-0.164) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3198]: 0.905 (+/-0.104) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3199]: 0.905 (+/-0.104) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3200]: 0.724 (+/-0.126) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3201]: 0.724 (+/-0.126) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3202]: 0.943 (+/-0.071) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3203]: 0.943 (+/-0.071) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3204]: 0.733 (+/-0.129) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3205]: 0.733 (+/-0.129) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3206]: 0.924 (+/-0.114) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3207]: 0.924 (+/-0.114) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3208]: 0.733 (+/-0.245) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3209]: 0.733 (+/-0.245) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3210]: 0.810 (+/-0.209) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3211]: 0.810 (+/-0.209) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3212]: 0.781 (+/-0.280) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3213]: 0.781 (+/-0.280) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3214]: 0.905 (+/-0.120) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3215]: 0.905 (+/-0.120) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3216]: 0.657 (+/-0.523) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3217]: 0.657 (+/-0.523) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3218]: 0.895 (+/-0.229) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3219]: 0.895 (+/-0.229) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3220]: 0.867 (+/-0.164) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3221]: 0.867 (+/-0.164) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3222]: 0.905 (+/-0.104) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3223]: 0.905 (+/-0.104) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3224]: 0.724 (+/-0.126) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3225]: 0.724 (+/-0.126) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3226]: 0.943 (+/-0.071) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3227]: 0.943 (+/-0.071) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3228]: 0.733 (+/-0.129) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3229]: 0.733 (+/-0.129) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3230]: 0.924 (+/-0.114) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3231]: 0.924 (+/-0.114) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3232]: 0.733 (+/-0.245) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3233]: 0.733 (+/-0.245) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3234]: 0.810 (+/-0.209) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3235]: 0.810 (+/-0.209) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3236]: 0.781 (+/-0.280) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3237]: 0.781 (+/-0.280) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3238]: 0.905 (+/-0.120) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3239]: 0.905 (+/-0.120) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3240]: 0.838 (+/-0.273) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3241]: 0.838 (+/-0.273) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3242]: 0.838 (+/-0.273) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3243]: 0.838 (+/-0.273) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3244]: 0.743 (+/-0.267) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3245]: 0.743 (+/-0.267) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3246]: 0.743 (+/-0.267) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3247]: 0.743 (+/-0.267) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3248]: 0.695 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3249]: 0.695 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3250]: 0.695 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3251]: 0.695 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3252]: 0.714 (+/-0.060) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3253]: 0.714 (+/-0.060) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3254]: 0.714 (+/-0.060) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3255]: 0.714 (+/-0.060) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3256]: 0.733 (+/-0.311) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3257]: 0.733 (+/-0.311) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3258]: 0.733 (+/-0.311) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3259]: 0.733 (+/-0.311) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3260]: 0.724 (+/-0.236) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3261]: 0.724 (+/-0.236) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3262]: 0.724 (+/-0.236) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3263]: 0.724 (+/-0.236) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3264]: 0.838 (+/-0.273) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3265]: 0.838 (+/-0.273) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3266]: 0.838 (+/-0.273) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3267]: 0.838 (+/-0.273) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3268]: 0.743 (+/-0.267) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3269]: 0.743 (+/-0.267) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3270]: 0.743 (+/-0.267) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3271]: 0.743 (+/-0.267) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3272]: 0.695 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3273]: 0.695 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3274]: 0.695 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3275]: 0.695 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3276]: 0.714 (+/-0.060) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3277]: 0.714 (+/-0.060) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3278]: 0.714 (+/-0.060) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3279]: 0.714 (+/-0.060) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3280]: 0.733 (+/-0.311) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3281]: 0.733 (+/-0.311) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3282]: 0.733 (+/-0.311) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3283]: 0.733 (+/-0.311) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3284]: 0.724 (+/-0.236) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3285]: 0.724 (+/-0.236) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3286]: 0.724 (+/-0.236) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3287]: 0.724 (+/-0.236) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3288]: 0.838 (+/-0.273) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3289]: 0.838 (+/-0.273) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3290]: 0.838 (+/-0.273) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3291]: 0.838 (+/-0.273) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3292]: 0.743 (+/-0.267) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3293]: 0.743 (+/-0.267) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3294]: 0.743 (+/-0.267) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3295]: 0.743 (+/-0.267) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3296]: 0.695 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3297]: 0.695 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3298]: 0.695 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3299]: 0.695 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3300]: 0.714 (+/-0.060) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3301]: 0.714 (+/-0.060) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3302]: 0.714 (+/-0.060) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3303]: 0.714 (+/-0.060) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3304]: 0.733 (+/-0.311) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3305]: 0.733 (+/-0.311) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3306]: 0.733 (+/-0.311) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3307]: 0.733 (+/-0.311) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3308]: 0.724 (+/-0.236) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3309]: 0.724 (+/-0.236) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3310]: 0.724 (+/-0.236) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3311]: 0.724 (+/-0.236) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3312]: 0.638 (+/-0.433) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3313]: 0.638 (+/-0.433) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3314]: 0.638 (+/-0.433) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3315]: 0.638 (+/-0.433) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3316]: 0.571 (+/-0.493) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3317]: 0.571 (+/-0.493) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3318]: 0.571 (+/-0.493) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3319]: 0.571 (+/-0.493) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3320]: 0.848 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3321]: 0.848 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3322]: 0.848 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3323]: 0.848 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3324]: 0.629 (+/-0.304) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3325]: 0.629 (+/-0.304) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3326]: 0.629 (+/-0.304) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3327]: 0.629 (+/-0.304) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3328]: 0.667 (+/-0.225) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3329]: 0.667 (+/-0.225) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3330]: 0.667 (+/-0.225) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3331]: 0.667 (+/-0.225) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3332]: 0.657 (+/-0.140) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3333]: 0.657 (+/-0.140) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3334]: 0.657 (+/-0.140) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3335]: 0.657 (+/-0.140) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3336]: 0.638 (+/-0.433) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3337]: 0.638 (+/-0.433) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3338]: 0.638 (+/-0.433) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3339]: 0.638 (+/-0.433) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3340]: 0.571 (+/-0.493) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3341]: 0.571 (+/-0.493) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3342]: 0.571 (+/-0.493) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3343]: 0.571 (+/-0.493) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3344]: 0.848 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3345]: 0.848 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3346]: 0.848 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3347]: 0.848 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3348]: 0.629 (+/-0.304) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3349]: 0.629 (+/-0.304) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3350]: 0.629 (+/-0.304) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3351]: 0.629 (+/-0.304) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3352]: 0.667 (+/-0.225) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3353]: 0.667 (+/-0.225) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3354]: 0.667 (+/-0.225) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3355]: 0.667 (+/-0.225) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3356]: 0.657 (+/-0.140) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3357]: 0.657 (+/-0.140) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3358]: 0.657 (+/-0.140) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3359]: 0.657 (+/-0.140) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3360]: 0.638 (+/-0.433) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3361]: 0.638 (+/-0.433) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3362]: 0.638 (+/-0.433) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3363]: 0.638 (+/-0.433) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3364]: 0.571 (+/-0.493) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3365]: 0.571 (+/-0.493) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3366]: 0.571 (+/-0.493) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3367]: 0.571 (+/-0.493) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3368]: 0.848 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3369]: 0.848 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3370]: 0.848 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3371]: 0.848 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3372]: 0.629 (+/-0.304) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3373]: 0.629 (+/-0.304) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3374]: 0.629 (+/-0.304) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3375]: 0.629 (+/-0.304) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3376]: 0.667 (+/-0.225) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3377]: 0.667 (+/-0.225) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3378]: 0.667 (+/-0.225) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3379]: 0.667 (+/-0.225) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3380]: 0.657 (+/-0.140) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3381]: 0.657 (+/-0.140) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3382]: 0.657 (+/-0.140) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3383]: 0.657 (+/-0.140) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3384]: 0.581 (+/-0.480) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3385]: 0.581 (+/-0.480) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3386]: 0.581 (+/-0.480) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3387]: 0.581 (+/-0.480) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3388]: 0.733 (+/-0.492) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3389]: 0.733 (+/-0.492) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3390]: 0.733 (+/-0.492) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3391]: 0.733 (+/-0.492) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3392]: 0.752 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3393]: 0.752 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3394]: 0.752 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3395]: 0.752 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3396]: 0.638 (+/-0.267) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3397]: 0.638 (+/-0.267) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3398]: 0.638 (+/-0.267) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3399]: 0.638 (+/-0.267) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3400]: 0.514 (+/-0.406) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3401]: 0.514 (+/-0.406) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3402]: 0.514 (+/-0.406) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3403]: 0.514 (+/-0.406) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3404]: 0.600 (+/-0.492) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3405]: 0.600 (+/-0.492) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3406]: 0.600 (+/-0.492) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3407]: 0.600 (+/-0.492) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3408]: 0.581 (+/-0.480) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3409]: 0.581 (+/-0.480) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3410]: 0.581 (+/-0.480) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3411]: 0.581 (+/-0.480) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3412]: 0.733 (+/-0.492) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3413]: 0.733 (+/-0.492) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3414]: 0.733 (+/-0.492) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3415]: 0.733 (+/-0.492) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3416]: 0.752 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3417]: 0.752 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3418]: 0.752 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3419]: 0.752 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3420]: 0.638 (+/-0.267) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3421]: 0.638 (+/-0.267) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3422]: 0.638 (+/-0.267) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3423]: 0.638 (+/-0.267) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3424]: 0.514 (+/-0.406) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3425]: 0.514 (+/-0.406) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3426]: 0.514 (+/-0.406) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3427]: 0.514 (+/-0.406) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3428]: 0.600 (+/-0.492) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3429]: 0.600 (+/-0.492) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3430]: 0.600 (+/-0.492) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3431]: 0.600 (+/-0.492) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3432]: 0.581 (+/-0.480) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3433]: 0.581 (+/-0.480) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3434]: 0.581 (+/-0.480) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3435]: 0.581 (+/-0.480) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3436]: 0.733 (+/-0.492) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3437]: 0.733 (+/-0.492) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3438]: 0.733 (+/-0.492) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3439]: 0.733 (+/-0.492) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3440]: 0.752 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3441]: 0.752 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3442]: 0.752 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3443]: 0.752 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3444]: 0.638 (+/-0.267) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3445]: 0.638 (+/-0.267) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3446]: 0.638 (+/-0.267) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3447]: 0.638 (+/-0.267) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3448]: 0.514 (+/-0.406) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3449]: 0.514 (+/-0.406) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3450]: 0.514 (+/-0.406) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3451]: 0.514 (+/-0.406) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3452]: 0.600 (+/-0.492) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3453]: 0.600 (+/-0.492) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3454]: 0.600 (+/-0.492) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3455]: 0.600 (+/-0.492) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3456]: 0.962 (+/-0.038) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3457]: 0.962 (+/-0.038) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3458]: 0.962 (+/-0.038) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3459]: 0.962 (+/-0.038) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3460]: 0.886 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3461]: 0.886 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3462]: 0.886 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3463]: 0.886 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3464]: 0.962 (+/-0.111) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3465]: 0.962 (+/-0.111) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3466]: 0.962 (+/-0.111) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3467]: 0.962 (+/-0.111) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3468]: 0.848 (+/-0.185) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3469]: 0.848 (+/-0.185) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3470]: 0.848 (+/-0.185) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3471]: 0.848 (+/-0.185) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3472]: 0.981 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3473]: 0.981 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3474]: 0.981 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3475]: 0.981 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3476]: 0.933 (+/-0.097) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3477]: 0.933 (+/-0.097) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3478]: 0.933 (+/-0.097) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3479]: 0.933 (+/-0.097) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3480]: 0.962 (+/-0.038) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3481]: 0.962 (+/-0.038) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3482]: 0.962 (+/-0.038) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3483]: 0.962 (+/-0.038) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3484]: 0.886 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3485]: 0.886 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3486]: 0.886 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3487]: 0.886 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3488]: 0.962 (+/-0.111) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3489]: 0.962 (+/-0.111) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3490]: 0.962 (+/-0.111) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3491]: 0.962 (+/-0.111) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3492]: 0.848 (+/-0.185) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3493]: 0.848 (+/-0.185) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3494]: 0.848 (+/-0.185) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3495]: 0.848 (+/-0.185) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3496]: 0.981 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3497]: 0.981 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3498]: 0.981 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3499]: 0.981 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3500]: 0.933 (+/-0.097) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3501]: 0.933 (+/-0.097) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3502]: 0.933 (+/-0.097) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3503]: 0.933 (+/-0.097) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3504]: 0.962 (+/-0.038) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3505]: 0.962 (+/-0.038) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3506]: 0.962 (+/-0.038) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3507]: 0.962 (+/-0.038) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3508]: 0.886 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3509]: 0.886 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3510]: 0.886 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3511]: 0.886 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3512]: 0.962 (+/-0.111) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3513]: 0.962 (+/-0.111) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3514]: 0.962 (+/-0.111) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3515]: 0.962 (+/-0.111) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3516]: 0.848 (+/-0.185) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3517]: 0.848 (+/-0.185) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3518]: 0.848 (+/-0.185) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3519]: 0.848 (+/-0.185) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3520]: 0.981 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3521]: 0.981 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3522]: 0.981 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3523]: 0.981 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3524]: 0.933 (+/-0.097) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3525]: 0.933 (+/-0.097) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3526]: 0.933 (+/-0.097) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3527]: 0.933 (+/-0.097) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3528]: 0.952 (+/-0.104) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3529]: 0.952 (+/-0.104) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3530]: 0.952 (+/-0.104) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3531]: 0.952 (+/-0.104) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3532]: 0.867 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3533]: 0.867 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3534]: 0.867 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3535]: 0.867 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3536]: 0.981 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3537]: 0.981 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3538]: 0.981 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3539]: 0.981 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3540]: 0.962 (+/-0.071) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3541]: 0.962 (+/-0.071) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3542]: 0.962 (+/-0.071) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3543]: 0.962 (+/-0.071) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3544]: 0.971 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3545]: 0.971 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3546]: 0.971 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3547]: 0.971 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3548]: 0.924 (+/-0.114) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3549]: 0.924 (+/-0.114) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3550]: 0.924 (+/-0.114) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3551]: 0.924 (+/-0.114) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3552]: 0.952 (+/-0.104) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3553]: 0.952 (+/-0.104) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3554]: 0.952 (+/-0.104) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3555]: 0.952 (+/-0.104) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3556]: 0.867 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3557]: 0.867 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3558]: 0.867 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3559]: 0.867 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3560]: 0.981 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3561]: 0.981 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3562]: 0.981 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3563]: 0.981 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3564]: 0.962 (+/-0.071) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3565]: 0.962 (+/-0.071) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3566]: 0.962 (+/-0.071) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3567]: 0.962 (+/-0.071) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3568]: 0.971 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3569]: 0.971 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3570]: 0.971 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3571]: 0.971 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3572]: 0.924 (+/-0.114) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3573]: 0.924 (+/-0.114) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3574]: 0.924 (+/-0.114) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3575]: 0.924 (+/-0.114) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3576]: 0.952 (+/-0.104) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3577]: 0.952 (+/-0.104) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3578]: 0.952 (+/-0.104) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3579]: 0.952 (+/-0.104) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3580]: 0.867 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3581]: 0.867 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3582]: 0.867 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3583]: 0.867 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3584]: 0.981 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3585]: 0.981 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3586]: 0.981 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3587]: 0.981 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3588]: 0.962 (+/-0.071) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3589]: 0.962 (+/-0.071) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3590]: 0.962 (+/-0.071) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3591]: 0.962 (+/-0.071) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3592]: 0.971 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3593]: 0.971 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3594]: 0.971 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3595]: 0.971 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3596]: 0.924 (+/-0.114) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3597]: 0.924 (+/-0.114) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3598]: 0.924 (+/-0.114) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3599]: 0.924 (+/-0.114) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3600]: 0.962 (+/-0.038) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3601]: 0.962 (+/-0.038) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3602]: 0.962 (+/-0.038) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3603]: 0.962 (+/-0.038) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3604]: 0.876 (+/-0.230) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3605]: 0.876 (+/-0.230) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3606]: 0.876 (+/-0.230) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3607]: 0.876 (+/-0.230) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3608]: 0.971 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3609]: 0.971 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3610]: 0.971 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3611]: 0.971 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3612]: 0.895 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3613]: 0.895 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3614]: 0.895 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3615]: 0.895 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3616]: 0.971 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3617]: 0.971 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3618]: 0.971 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3619]: 0.971 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3620]: 0.943 (+/-0.140) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3621]: 0.943 (+/-0.140) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3622]: 0.943 (+/-0.140) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3623]: 0.943 (+/-0.140) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3624]: 0.962 (+/-0.038) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3625]: 0.962 (+/-0.038) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3626]: 0.962 (+/-0.038) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3627]: 0.962 (+/-0.038) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3628]: 0.876 (+/-0.230) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3629]: 0.876 (+/-0.230) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3630]: 0.876 (+/-0.230) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3631]: 0.876 (+/-0.230) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3632]: 0.971 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3633]: 0.971 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3634]: 0.971 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3635]: 0.971 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3636]: 0.895 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3637]: 0.895 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3638]: 0.895 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3639]: 0.895 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3640]: 0.971 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3641]: 0.971 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3642]: 0.971 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3643]: 0.971 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3644]: 0.943 (+/-0.140) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3645]: 0.943 (+/-0.140) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3646]: 0.943 (+/-0.140) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3647]: 0.943 (+/-0.140) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3648]: 0.962 (+/-0.038) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3649]: 0.962 (+/-0.038) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3650]: 0.962 (+/-0.038) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3651]: 0.962 (+/-0.038) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3652]: 0.876 (+/-0.230) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3653]: 0.876 (+/-0.230) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3654]: 0.876 (+/-0.230) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3655]: 0.876 (+/-0.230) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3656]: 0.971 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3657]: 0.971 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3658]: 0.971 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3659]: 0.971 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3660]: 0.895 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3661]: 0.895 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3662]: 0.895 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3663]: 0.895 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3664]: 0.971 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3665]: 0.971 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3666]: 0.971 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3667]: 0.971 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3668]: 0.943 (+/-0.140) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3669]: 0.943 (+/-0.140) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3670]: 0.943 (+/-0.140) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3671]: 0.943 (+/-0.140) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3672]: 0.800 (+/-0.298) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3673]: 0.800 (+/-0.298) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3674]: 0.781 (+/-0.196) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3675]: 0.781 (+/-0.196) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3676]: 0.857 (+/-0.341) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3677]: 0.857 (+/-0.341) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3678]: 0.810 (+/-0.120) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3679]: 0.810 (+/-0.120) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3680]: 0.848 (+/-0.152) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3681]: 0.848 (+/-0.152) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3682]: 0.867 (+/-0.164) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3683]: 0.867 (+/-0.164) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3684]: 0.848 (+/-0.236) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3685]: 0.848 (+/-0.236) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3686]: 0.886 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3687]: 0.886 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3688]: 0.895 (+/-0.140) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3689]: 0.895 (+/-0.140) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3690]: 0.886 (+/-0.143) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3691]: 0.886 (+/-0.143) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3692]: 0.771 (+/-0.251) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3693]: 0.771 (+/-0.251) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3694]: 0.857 (+/-0.159) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3695]: 0.857 (+/-0.159) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3696]: 0.800 (+/-0.298) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3697]: 0.800 (+/-0.298) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3698]: 0.781 (+/-0.196) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3699]: 0.781 (+/-0.196) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3700]: 0.857 (+/-0.341) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3701]: 0.857 (+/-0.341) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3702]: 0.810 (+/-0.120) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3703]: 0.810 (+/-0.120) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3704]: 0.848 (+/-0.152) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3705]: 0.848 (+/-0.152) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3706]: 0.867 (+/-0.164) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3707]: 0.867 (+/-0.164) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3708]: 0.848 (+/-0.236) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3709]: 0.848 (+/-0.236) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3710]: 0.886 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3711]: 0.886 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3712]: 0.895 (+/-0.140) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3713]: 0.895 (+/-0.140) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3714]: 0.886 (+/-0.143) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3715]: 0.886 (+/-0.143) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3716]: 0.771 (+/-0.251) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3717]: 0.771 (+/-0.251) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3718]: 0.857 (+/-0.159) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3719]: 0.857 (+/-0.159) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3720]: 0.800 (+/-0.298) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3721]: 0.800 (+/-0.298) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3722]: 0.781 (+/-0.196) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3723]: 0.781 (+/-0.196) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3724]: 0.857 (+/-0.341) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3725]: 0.857 (+/-0.341) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3726]: 0.810 (+/-0.120) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3727]: 0.810 (+/-0.120) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3728]: 0.848 (+/-0.152) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3729]: 0.848 (+/-0.152) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3730]: 0.867 (+/-0.164) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3731]: 0.867 (+/-0.164) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3732]: 0.848 (+/-0.236) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3733]: 0.848 (+/-0.236) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3734]: 0.886 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3735]: 0.886 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3736]: 0.895 (+/-0.140) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3737]: 0.895 (+/-0.140) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3738]: 0.886 (+/-0.143) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3739]: 0.886 (+/-0.143) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3740]: 0.771 (+/-0.251) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3741]: 0.771 (+/-0.251) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3742]: 0.857 (+/-0.159) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3743]: 0.857 (+/-0.159) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3744]: 0.629 (+/-0.464) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3745]: 0.629 (+/-0.464) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3746]: 0.867 (+/-0.152) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3747]: 0.867 (+/-0.152) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3748]: 0.590 (+/-0.453) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3749]: 0.590 (+/-0.453) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3750]: 0.867 (+/-0.152) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3751]: 0.867 (+/-0.152) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3752]: 0.752 (+/-0.368) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3753]: 0.752 (+/-0.368) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3754]: 0.857 (+/-0.170) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3755]: 0.857 (+/-0.170) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3756]: 0.743 (+/-0.166) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3757]: 0.743 (+/-0.166) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3758]: 0.857 (+/-0.170) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3759]: 0.857 (+/-0.170) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3760]: 0.752 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3761]: 0.752 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3762]: 0.838 (+/-0.196) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3763]: 0.838 (+/-0.196) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3764]: 0.648 (+/-0.369) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3765]: 0.648 (+/-0.369) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3766]: 0.838 (+/-0.196) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3767]: 0.838 (+/-0.196) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3768]: 0.629 (+/-0.464) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3769]: 0.629 (+/-0.464) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3770]: 0.867 (+/-0.152) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3771]: 0.867 (+/-0.152) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3772]: 0.590 (+/-0.453) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3773]: 0.590 (+/-0.453) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3774]: 0.867 (+/-0.152) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3775]: 0.867 (+/-0.152) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3776]: 0.752 (+/-0.368) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3777]: 0.752 (+/-0.368) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3778]: 0.857 (+/-0.170) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3779]: 0.857 (+/-0.170) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3780]: 0.743 (+/-0.166) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3781]: 0.743 (+/-0.166) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3782]: 0.857 (+/-0.170) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3783]: 0.857 (+/-0.170) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3784]: 0.752 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3785]: 0.752 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3786]: 0.838 (+/-0.196) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3787]: 0.838 (+/-0.196) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3788]: 0.648 (+/-0.369) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3789]: 0.648 (+/-0.369) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3790]: 0.829 (+/-0.222) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3791]: 0.829 (+/-0.222) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3792]: 0.629 (+/-0.464) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3793]: 0.629 (+/-0.464) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3794]: 0.867 (+/-0.152) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3795]: 0.867 (+/-0.152) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3796]: 0.590 (+/-0.453) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3797]: 0.590 (+/-0.453) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3798]: 0.867 (+/-0.152) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3799]: 0.867 (+/-0.152) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3800]: 0.752 (+/-0.368) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3801]: 0.752 (+/-0.368) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3802]: 0.857 (+/-0.170) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3803]: 0.857 (+/-0.170) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3804]: 0.743 (+/-0.166) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3805]: 0.743 (+/-0.166) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3806]: 0.857 (+/-0.170) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3807]: 0.857 (+/-0.170) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3808]: 0.752 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3809]: 0.752 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3810]: 0.838 (+/-0.196) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3811]: 0.838 (+/-0.196) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3812]: 0.648 (+/-0.369) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3813]: 0.648 (+/-0.369) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3814]: 0.848 (+/-0.229) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3815]: 0.848 (+/-0.229) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3816]: 0.733 (+/-0.364) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3817]: 0.733 (+/-0.364) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3818]: 0.876 (+/-0.205) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3819]: 0.876 (+/-0.205) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3820]: 0.667 (+/-0.439) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3821]: 0.667 (+/-0.439) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3822]: 0.914 (+/-0.126) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3823]: 0.914 (+/-0.126) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3824]: 0.781 (+/-0.222) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3825]: 0.781 (+/-0.222) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3826]: 0.886 (+/-0.129) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3827]: 0.886 (+/-0.129) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3828]: 0.714 (+/-0.159) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3829]: 0.714 (+/-0.159) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3830]: 0.952 (+/-0.104) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3831]: 0.952 (+/-0.104) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3832]: 0.724 (+/-0.298) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3833]: 0.724 (+/-0.298) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3834]: 0.971 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3835]: 0.971 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3836]: 0.552 (+/-0.299) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3837]: 0.552 (+/-0.299) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3838]: 0.933 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3839]: 0.933 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3840]: 0.733 (+/-0.364) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3841]: 0.733 (+/-0.364) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3842]: 0.876 (+/-0.205) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3843]: 0.876 (+/-0.205) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3844]: 0.667 (+/-0.439) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3845]: 0.667 (+/-0.439) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3846]: 0.914 (+/-0.126) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3847]: 0.914 (+/-0.126) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3848]: 0.781 (+/-0.222) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3849]: 0.781 (+/-0.222) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3850]: 0.886 (+/-0.129) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3851]: 0.886 (+/-0.129) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3852]: 0.714 (+/-0.159) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3853]: 0.714 (+/-0.159) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3854]: 0.952 (+/-0.104) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3855]: 0.952 (+/-0.104) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3856]: 0.724 (+/-0.298) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3857]: 0.724 (+/-0.298) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3858]: 0.971 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3859]: 0.971 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3860]: 0.552 (+/-0.299) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3861]: 0.552 (+/-0.299) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3862]: 0.933 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3863]: 0.933 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3864]: 0.733 (+/-0.364) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3865]: 0.733 (+/-0.364) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3866]: 0.876 (+/-0.205) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3867]: 0.876 (+/-0.205) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3868]: 0.667 (+/-0.439) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3869]: 0.667 (+/-0.439) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3870]: 0.914 (+/-0.126) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3871]: 0.914 (+/-0.126) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3872]: 0.781 (+/-0.222) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3873]: 0.781 (+/-0.222) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3874]: 0.886 (+/-0.129) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3875]: 0.886 (+/-0.129) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3876]: 0.714 (+/-0.159) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3877]: 0.714 (+/-0.159) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3878]: 0.952 (+/-0.104) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3879]: 0.952 (+/-0.104) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3880]: 0.724 (+/-0.298) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3881]: 0.724 (+/-0.298) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3882]: 0.971 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3883]: 0.971 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3884]: 0.552 (+/-0.299) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3885]: 0.552 (+/-0.299) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3886]: 0.933 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3887]: 0.933 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\n",
      "Detailed classification report:\n",
      "\tThe model is trained on the full development set.\n",
      "\tThe scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        16\n",
      "           1       1.00      0.89      0.94        18\n",
      "           2       0.85      1.00      0.92        11\n",
      "\n",
      "    accuracy                           0.96        45\n",
      "   macro avg       0.95      0.96      0.95        45\n",
      "weighted avg       0.96      0.96      0.96        45\n",
      "\n",
      "\n",
      "CTOR for best model: SGDClassifier(alpha=0.001, eta0=0.01, loss='perceptron', max_iter=300,\n",
      "              n_iter_no_change=20, penalty='l1', power_t=0.1, random_state=42)\n",
      "\n",
      "best: dat=iris, score=0.99048, model=SGDClassifier(alpha=0.001,early_stopping=False,eta0=0.01,learning_rate='optimal',loss='perceptron',max_iter=300,n_iter_no_change=20,penalty='l1',power_t=0.1,validation_fraction=0.1)\n",
      "\n",
      "OK(grid-search)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html\n",
    "\n",
    "# Setup data\n",
    "X_train, X_test, y_train, y_test = LoadAndSetupData(\n",
    "    'iris')  # 'iris', 'moon', or 'mnist'\n",
    "\n",
    "# Setup search parameters\n",
    "model = SGDClassifier(\n",
    "    loss='hinge',\n",
    "    random_state=42\n",
    ")  \n",
    "\n",
    "tuning_parameters = {\n",
    "    'loss': ['hinge', 'squared_hinge', 'perceptron'],\n",
    "    'max_iter': [300, 900, 1400],\n",
    "    'alpha': [0.0001, 0.001, 0.01],\n",
    "    'eta0': [0.01, 0.1],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'learning_rate': ['constant', 'optimal', 'invscaling'],\n",
    "    'power_t': [0.1, 0.5],\n",
    "    'early_stopping': [False],\n",
    "    'validation_fraction': [0.1, 0.2],\n",
    "    'n_iter_no_change': [5, 10, 20],\n",
    "}\n",
    "\n",
    "\n",
    "CV = 5\n",
    "VERBOSE = 0\n",
    "\n",
    "# Run GridSearchCV for the model\n",
    "grid_tuned = GridSearchCV(model,\n",
    "                          tuning_parameters,\n",
    "                          cv=CV,\n",
    "                          scoring='f1_micro',\n",
    "                          verbose=VERBOSE,\n",
    "                          n_jobs=-1)\n",
    "\n",
    "start = time()\n",
    "grid_tuned.fit(X_train, y_train)\n",
    "t = time() - start\n",
    "\n",
    "# Report result\n",
    "b0, m0 = FullReport(grid_tuned, X_test, y_test, t)\n",
    "print('OK(grid-search)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qc Hyperparameter Random  Search using an SDG classifier\n",
    "\n",
    "\n",
    "The default parameters for the random search were given and put in to the code for the RandomizedSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-17T13:13:37.188276Z",
     "start_time": "2023-11-17T13:13:37.074980Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA: iris..\n",
      "  org. data:  X.shape      =(  150;    4), y.shape      =(  150)\n",
      "  train data: X_train.shape=(  105;    4), y_train.shape=(  105)\n",
      "  test data:  X_test.shape =(   45;    4), y_test.shape =(   45)\n",
      "\n",
      "SEARCH TIME: 0.05 sec\n",
      "\n",
      "Best model set found on train set:\n",
      "\n",
      "\tbest parameters={'validation_fraction': 0.3, 'power_t': 0.5, 'penalty': 'l1', 'n_iter_no_change': 5, 'max_iter': 2000, 'loss': 'hinge', 'learning_rate': 'optimal', 'eta0': 0.1, 'early_stopping': False, 'alpha': 0.01}\n",
      "\tbest 'f1_micro' score=0.9619047619047618\n",
      "\tbest index=11\n",
      "\n",
      "Best estimator CTOR:\n",
      "\tSGDClassifier(alpha=0.01, eta0=0.1, max_iter=2000, penalty='l1',\n",
      "              random_state=42, validation_fraction=0.3)\n",
      "\n",
      "Grid scores ('f1_micro') on development set:\n",
      "\t[ 0]: 0.619 (+/-0.301) for {'validation_fraction': 0.1, 'power_t': 0.1, 'penalty': 'l2', 'n_iter_no_change': 10, 'max_iter': 300, 'loss': 'squared_hinge', 'learning_rate': 'constant', 'eta0': 0.2, 'early_stopping': False, 'alpha': 0.01}\n",
      "\t[ 1]: 0.886 (+/-0.177) for {'validation_fraction': 0.3, 'power_t': 0.5, 'penalty': 'l2', 'n_iter_no_change': 20, 'max_iter': 2000, 'loss': 'hinge', 'learning_rate': 'optimal', 'eta0': 0.01, 'early_stopping': False, 'alpha': 0.0001}\n",
      "\t[ 2]: 0.705 (+/-0.071) for {'validation_fraction': 0.3, 'power_t': 0.8, 'penalty': 'l1', 'n_iter_no_change': 20, 'max_iter': 2000, 'loss': 'hinge', 'learning_rate': 'invscaling', 'eta0': 0.2, 'early_stopping': False, 'alpha': 0.0001}\n",
      "\t[ 3]: 0.581 (+/-0.304) for {'validation_fraction': 0.3, 'power_t': 0.1, 'penalty': 'l2', 'n_iter_no_change': 10, 'max_iter': 2000, 'loss': 'hinge', 'learning_rate': 'constant', 'eta0': 0.2, 'early_stopping': False, 'alpha': 0.1}\n",
      "\t[ 4]: 0.829 (+/-0.260) for {'validation_fraction': 0.1, 'power_t': 0.5, 'penalty': 'l2', 'n_iter_no_change': 10, 'max_iter': 900, 'loss': 'squared_hinge', 'learning_rate': 'constant', 'eta0': 0.01, 'early_stopping': False, 'alpha': 0.01}\n",
      "\t[ 5]: 0.914 (+/-0.164) for {'validation_fraction': 0.2, 'power_t': 0.8, 'penalty': 'l2', 'n_iter_no_change': 20, 'max_iter': 300, 'loss': 'squared_hinge', 'learning_rate': 'invscaling', 'eta0': 0.2, 'early_stopping': False, 'alpha': 0.001}\n",
      "\t[ 6]: 0.829 (+/-0.177) for {'validation_fraction': 0.3, 'power_t': 0.5, 'penalty': 'l2', 'n_iter_no_change': 10, 'max_iter': 900, 'loss': 'hinge', 'learning_rate': 'optimal', 'eta0': 0.2, 'early_stopping': False, 'alpha': 0.1}\n",
      "\t[ 7]: 0.838 (+/-0.230) for {'validation_fraction': 0.2, 'power_t': 0.1, 'penalty': 'l1', 'n_iter_no_change': 5, 'max_iter': 300, 'loss': 'perceptron', 'learning_rate': 'constant', 'eta0': 0.01, 'early_stopping': False, 'alpha': 0.001}\n",
      "\t[ 8]: 0.829 (+/-0.196) for {'validation_fraction': 0.3, 'power_t': 0.1, 'penalty': 'l1', 'n_iter_no_change': 5, 'max_iter': 300, 'loss': 'hinge', 'learning_rate': 'invscaling', 'eta0': 0.2, 'early_stopping': False, 'alpha': 0.01}\n",
      "\t[ 9]: 0.562 (+/-0.383) for {'validation_fraction': 0.2, 'power_t': 0.8, 'penalty': 'l2', 'n_iter_no_change': 20, 'max_iter': 900, 'loss': 'perceptron', 'learning_rate': 'constant', 'eta0': 0.2, 'early_stopping': False, 'alpha': 0.0001}\n",
      "\t[10]: 0.705 (+/-0.236) for {'validation_fraction': 0.3, 'power_t': 0.1, 'penalty': 'l1', 'n_iter_no_change': 20, 'max_iter': 1400, 'loss': 'perceptron', 'learning_rate': 'constant', 'eta0': 0.2, 'early_stopping': False, 'alpha': 0.1}\n",
      "\t[11]: 0.962 (+/-0.038) for {'validation_fraction': 0.3, 'power_t': 0.5, 'penalty': 'l1', 'n_iter_no_change': 5, 'max_iter': 2000, 'loss': 'hinge', 'learning_rate': 'optimal', 'eta0': 0.1, 'early_stopping': False, 'alpha': 0.01}\n",
      "\t[12]: 0.933 (+/-0.129) for {'validation_fraction': 0.3, 'power_t': 0.5, 'penalty': 'l1', 'n_iter_no_change': 10, 'max_iter': 1400, 'loss': 'squared_hinge', 'learning_rate': 'invscaling', 'eta0': 0.2, 'early_stopping': False, 'alpha': 0.001}\n",
      "\t[13]: 0.514 (+/-0.406) for {'validation_fraction': 0.1, 'power_t': 0.5, 'penalty': 'l1', 'n_iter_no_change': 20, 'max_iter': 300, 'loss': 'perceptron', 'learning_rate': 'constant', 'eta0': 0.2, 'early_stopping': False, 'alpha': 0.01}\n",
      "\t[14]: 0.838 (+/-0.230) for {'validation_fraction': 0.1, 'power_t': 0.8, 'penalty': 'l1', 'n_iter_no_change': 5, 'max_iter': 1400, 'loss': 'perceptron', 'learning_rate': 'constant', 'eta0': 0.1, 'early_stopping': False, 'alpha': 0.001}\n",
      "\t[15]: 0.952 (+/-0.104) for {'validation_fraction': 0.3, 'power_t': 0.1, 'penalty': 'l2', 'n_iter_no_change': 5, 'max_iter': 2000, 'loss': 'squared_hinge', 'learning_rate': 'invscaling', 'eta0': 0.01, 'early_stopping': False, 'alpha': 0.0001}\n",
      "\t[16]: 0.895 (+/-0.111) for {'validation_fraction': 0.2, 'power_t': 0.5, 'penalty': 'l2', 'n_iter_no_change': 5, 'max_iter': 1400, 'loss': 'hinge', 'learning_rate': 'optimal', 'eta0': 0.01, 'early_stopping': False, 'alpha': 0.0001}\n",
      "\t[17]: 0.781 (+/-0.364) for {'validation_fraction': 0.1, 'power_t': 0.5, 'penalty': 'l1', 'n_iter_no_change': 5, 'max_iter': 900, 'loss': 'perceptron', 'learning_rate': 'constant', 'eta0': 0.1, 'early_stopping': False, 'alpha': 0.0001}\n",
      "\t[18]: 0.867 (+/-0.194) for {'validation_fraction': 0.2, 'power_t': 0.1, 'penalty': 'l1', 'n_iter_no_change': 10, 'max_iter': 1400, 'loss': 'hinge', 'learning_rate': 'invscaling', 'eta0': 0.2, 'early_stopping': False, 'alpha': 0.0001}\n",
      "\t[19]: 0.800 (+/-0.212) for {'validation_fraction': 0.3, 'power_t': 0.1, 'penalty': 'l2', 'n_iter_no_change': 10, 'max_iter': 900, 'loss': 'perceptron', 'learning_rate': 'optimal', 'eta0': 0.2, 'early_stopping': False, 'alpha': 0.0001}\n",
      "\n",
      "Detailed classification report:\n",
      "\tThe model is trained on the full development set.\n",
      "\tThe scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        16\n",
      "           1       1.00      0.83      0.91        18\n",
      "           2       0.79      1.00      0.88        11\n",
      "\n",
      "    accuracy                           0.93        45\n",
      "   macro avg       0.93      0.94      0.93        45\n",
      "weighted avg       0.95      0.93      0.93        45\n",
      "\n",
      "\n",
      "CTOR for best model: SGDClassifier(alpha=0.01, eta0=0.1, max_iter=2000, penalty='l1',\n",
      "              random_state=42, validation_fraction=0.3)\n",
      "\n",
      "best: dat=iris, score=0.96190, model=SGDClassifier(alpha=0.01,early_stopping=False,eta0=0.1,learning_rate='optimal',loss='hinge',max_iter=2000,n_iter_no_change=5,penalty='l1',power_t=0.5,validation_fraction=0.3)\n",
      "\n",
      "OK(randomized-search)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Setup data\n",
    "X_train, X_test, y_train, y_test = LoadAndSetupData('iris')\n",
    "\n",
    "# Setup search parameters for RandomizedSearchCV\n",
    "model = SGDClassifier(loss='hinge', random_state=42)\n",
    "\n",
    "random_tuning_parameters = {\n",
    "    'loss': ['hinge', 'squared_hinge', 'perceptron'],\n",
    "    'max_iter': [300, 900, 1400, 2000],\n",
    "    'alpha': [0.0001, 0.001, 0.01, 0.1],\n",
    "    'eta0': [0.01, 0.1, 0.2],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'learning_rate': ['constant', 'optimal', 'invscaling'],\n",
    "    'power_t': [0.1, 0.5, 0.8],\n",
    "    'early_stopping': [False],\n",
    "    'validation_fraction': [0.1, 0.2, 0.3],\n",
    "    'n_iter_no_change': [5, 10, 20],\n",
    "}\n",
    "\n",
    "CV = 5\n",
    "VERBOSE = 0\n",
    "\n",
    "# Run RandomizedSearchCV for the model\n",
    "random_tuned = RandomizedSearchCV(\n",
    "    model,\n",
    "    random_tuning_parameters,\n",
    "    n_iter=20,\n",
    "    random_state=42,\n",
    "    cv=CV,\n",
    "    scoring='f1_micro',\n",
    "    verbose=VERBOSE,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "start_random = time()\n",
    "random_tuned.fit(X_train, y_train)\n",
    "t_random = time() - start_random\n",
    "\n",
    "# Report result for RandomizedSearchCV\n",
    "b_random, m_random = FullReport(random_tuned, X_test, y_test, t_random)\n",
    "print('OK(randomized-search)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid search is systematic and ensures to explore all combinations and making it exhaustive but potentially computationally expensive.\n",
    "Random search is more flexible, exploring a random subset of combinations, which can be advantageous when the hyperparameter space is vast.\n",
    "Grid search may be computationally expensive, especially with large hyperparameter spaces.\n",
    "Random search might be more time-efficient in such cases but may not guarantee finding the absolute best set of hyperparameters.\n",
    "\n",
    "Both grid search (GridSearchCV) and random search (RandomizedSearchCV) are used with the same set of initial hyperparameter values. This allows for a direct comparison of their results, demonstrating the trade-offs between an exhaustive search and a more flexible, randomized approach.\n",
    "\n",
    "__Result of GridSearchCV__\n",
    "best: dat=iris, score=0.99048, model=SGDClassifier(alpha=0.001,early_stopping=False,eta0=0.01,learning_rate='optimal',loss='perceptron',max_iter=300,n_iter_no_change=20,penalty='l1',power_t=0.1,validation_fraction=0.1)\n",
    "\n",
    "__Result of RandomizedSearchCV__\n",
    "best: dat=iris, score=0.96190, model=SGDClassifier(alpha=0.01,early_stopping=False,eta0=0.1,learning_rate='optimal',loss='hinge',max_iter=2000,n_iter_no_change=5,penalty='l1',power_t=0.5,validation_fraction=0.3)\n",
    "\n",
    "As the results show the GridSearchCV has the highest score of 0.99048 compared to 0.96190 thereby showing that the combination of hyperparameters found by GridSearchCV resulted in a better-performing model on th f1_micro scoring metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Qd MNIST Search Quest II\n",
    "\n",
    "For the MNIST dataset, we chose the RandomForestClassifier, which is a versatile learning model known for its effectiveness in classification tasks. We think it would be good for the complexity of the MNIST dataset by combining multiple decision trees, thereby improving overall predictive accuracy and mitigating overfitting.\n",
    "\n",
    "The RandomForestClassifier was configured with a set of hyperparameters defined in the tuning_parameters. These parameters cover various aspects such as the number of trees (n_estimators), tree depth (max_depth), minimum samples required to split an internal node (min_samples_split), and other crucial settings.\n",
    "\n",
    "To efficiently search through this hyperparameter space, we employed RandomizedSearchCV.\n",
    "\n",
    "To ensure reproducibility, we set the random_state parameter, and a higher number of iterations (n_iter=100) in RandomizedSearchCV allows for an extensive exploration of hyperparameter combinations, increasing the likelihood of finding optimal settings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-17T13:19:20.070131Z",
     "start_time": "2023-11-17T13:13:37.124241Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA: mnist..\n",
      "  org. data:  X.shape      =(70000;  784), y.shape      =(70000)\n",
      "  train data: X_train.shape=(49000;  784), y_train.shape=(49000)\n",
      "  test data:  X_test.shape =(21000;  784), y_test.shape =(21000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:578: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:578: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:578: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:578: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:578: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/joblib/externals/loky/process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:578: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:578: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:578: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:578: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:578: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:578: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:578: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:578: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:578: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:578: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:578: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:578: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:578: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:578: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:578: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:578: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:578: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:578: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:578: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:578: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:578: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:578: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:578: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:578: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:578: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:578: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:578: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:578: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:578: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:578: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:578: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:578: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:578: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:578: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:578: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:578: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:578: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:578: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:578: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:578: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:578: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:578: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:578: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:578: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:578: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:578: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:578: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:578: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:578: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:578: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:578: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:578: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:578: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:578: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:578: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEARCH TIME: 342.19 sec\n",
      "\n",
      "Best model set found on train set:\n",
      "\n",
      "\tbest parameters={'warm_start': False, 'oob_score': True, 'n_estimators': 200, 'min_samples_split': 10, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.0, 'max_leaf_nodes': None, 'max_features': 'sqrt', 'max_depth': 30, 'criterion': 'entropy', 'class_weight': 'balanced', 'ccp_alpha': 0.0, 'bootstrap': True}\n",
      "\tbest 'f1_micro' score=0.9628163265306122\n",
      "\tbest index=80\n",
      "\n",
      "Best estimator CTOR:\n",
      "\tRandomForestClassifier(class_weight='balanced', criterion='entropy',\n",
      "                       max_depth=30, min_samples_leaf=2, min_samples_split=10,\n",
      "                       n_estimators=200, oob_score=True, random_state=83)\n",
      "\n",
      "Grid scores ('f1_micro') on development set:\n",
      "\t[ 0]: 0.568 (+/-0.020) for {'warm_start': False, 'oob_score': False, 'n_estimators': 100, 'min_samples_split': 5, 'min_samples_leaf': 1, 'min_impurity_decrease': 0.2, 'max_leaf_nodes': None, 'max_features': 'sqrt', 'max_depth': 30, 'criterion': 'entropy', 'class_weight': 'balanced_subsample', 'ccp_alpha': 0.1, 'bootstrap': True}\n",
      "\t[ 1]: 0.550 (+/-0.007) for {'warm_start': True, 'oob_score': False, 'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.2, 'max_leaf_nodes': 10, 'max_features': 'sqrt', 'max_depth': 20, 'criterion': 'entropy', 'class_weight': None, 'ccp_alpha': 0.2, 'bootstrap': True}\n",
      "\t[ 2]: 0.765 (+/-0.010) for {'warm_start': False, 'oob_score': False, 'n_estimators': 100, 'min_samples_split': 10, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.0, 'max_leaf_nodes': 5, 'max_features': 'log2', 'max_depth': 10, 'criterion': 'gini', 'class_weight': 'balanced', 'ccp_alpha': 0.0, 'bootstrap': True}\n",
      "\t[ 3]: 0.655 (+/-0.018) for {'warm_start': True, 'oob_score': True, 'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.0, 'max_leaf_nodes': 20, 'max_features': 'log2', 'max_depth': None, 'criterion': 'entropy', 'class_weight': 'balanced_subsample', 'ccp_alpha': 0.2, 'bootstrap': True}\n",
      "\t[ 4]: 0.475 (+/-0.051) for {'warm_start': False, 'oob_score': True, 'n_estimators': 10, 'min_samples_split': 5, 'min_samples_leaf': 1, 'min_impurity_decrease': 0.0, 'max_leaf_nodes': 5, 'max_features': 'sqrt', 'max_depth': 30, 'criterion': 'entropy', 'class_weight': None, 'ccp_alpha': 0.2, 'bootstrap': True}\n",
      "\t[ 5]: 0.620 (+/-0.024) for {'warm_start': True, 'oob_score': False, 'n_estimators': 10, 'min_samples_split': 10, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.1, 'max_leaf_nodes': 10, 'max_features': 'sqrt', 'max_depth': 20, 'criterion': 'entropy', 'class_weight': 'balanced', 'ccp_alpha': 0.0, 'bootstrap': True}\n",
      "\t[ 6]: 0.764 (+/-0.012) for {'warm_start': False, 'oob_score': True, 'n_estimators': 100, 'min_samples_split': 2, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.0, 'max_leaf_nodes': 5, 'max_features': 'log2', 'max_depth': 20, 'criterion': 'gini', 'class_weight': 'balanced_subsample', 'ccp_alpha': 0.0, 'bootstrap': True}\n",
      "\t[ 7]: 0.099 (+/-0.010) for {'warm_start': True, 'oob_score': True, 'n_estimators': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_impurity_decrease': 0.0, 'max_leaf_nodes': None, 'max_features': 'sqrt', 'max_depth': 30, 'criterion': 'gini', 'class_weight': 'balanced', 'ccp_alpha': 0.2, 'bootstrap': True}\n",
      "\t[ 8]: 0.682 (+/-0.009) for {'warm_start': True, 'oob_score': True, 'n_estimators': 200, 'min_samples_split': 10, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.0, 'max_leaf_nodes': 5, 'max_features': 'sqrt', 'max_depth': 30, 'criterion': 'entropy', 'class_weight': 'balanced_subsample', 'ccp_alpha': 0.1, 'bootstrap': True}\n",
      "\t[ 9]: 0.568 (+/-0.020) for {'warm_start': False, 'oob_score': True, 'n_estimators': 100, 'min_samples_split': 10, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.2, 'max_leaf_nodes': 20, 'max_features': 'sqrt', 'max_depth': 20, 'criterion': 'entropy', 'class_weight': 'balanced_subsample', 'ccp_alpha': 0.0, 'bootstrap': True}\n",
      "\t[10]: 0.112 (+/-0.000) for {'warm_start': True, 'oob_score': True, 'n_estimators': 100, 'min_samples_split': 2, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.0, 'max_leaf_nodes': 20, 'max_features': 'sqrt', 'max_depth': None, 'criterion': 'gini', 'class_weight': None, 'ccp_alpha': 0.1, 'bootstrap': True}\n",
      "\t[11]: 0.102 (+/-0.005) for {'warm_start': False, 'oob_score': False, 'n_estimators': 10, 'min_samples_split': 5, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.1, 'max_leaf_nodes': 10, 'max_features': 'sqrt', 'max_depth': None, 'criterion': 'gini', 'class_weight': 'balanced_subsample', 'ccp_alpha': 0.2, 'bootstrap': True}\n",
      "\t[12]: 0.097 (+/-0.007) for {'warm_start': False, 'oob_score': False, 'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.2, 'max_leaf_nodes': 20, 'max_features': 'sqrt', 'max_depth': None, 'criterion': 'gini', 'class_weight': 'balanced_subsample', 'ccp_alpha': 0.2, 'bootstrap': True}\n",
      "\t[13]: 0.475 (+/-0.051) for {'warm_start': True, 'oob_score': True, 'n_estimators': 10, 'min_samples_split': 5, 'min_samples_leaf': 1, 'min_impurity_decrease': 0.2, 'max_leaf_nodes': 20, 'max_features': 'sqrt', 'max_depth': 10, 'criterion': 'entropy', 'class_weight': None, 'ccp_alpha': 0.2, 'bootstrap': True}\n",
      "\t[14]: 0.404 (+/-0.099) for {'warm_start': False, 'oob_score': False, 'n_estimators': 10, 'min_samples_split': 2, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.0, 'max_leaf_nodes': 20, 'max_features': 'log2', 'max_depth': None, 'criterion': 'entropy', 'class_weight': 'balanced', 'ccp_alpha': 0.2, 'bootstrap': True}\n",
      "\t[15]: 0.098 (+/-0.002) for {'warm_start': True, 'oob_score': True, 'n_estimators': 100, 'min_samples_split': 5, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.2, 'max_leaf_nodes': 10, 'max_features': 'sqrt', 'max_depth': 30, 'criterion': 'gini', 'class_weight': 'balanced', 'ccp_alpha': 0.1, 'bootstrap': True}\n",
      "\t[16]: 0.112 (+/-0.000) for {'warm_start': True, 'oob_score': False, 'n_estimators': 100, 'min_samples_split': 2, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.2, 'max_leaf_nodes': None, 'max_features': 'sqrt', 'max_depth': None, 'criterion': 'gini', 'class_weight': None, 'ccp_alpha': 0.0, 'bootstrap': True}\n",
      "\t[17]: 0.620 (+/-0.024) for {'warm_start': True, 'oob_score': True, 'n_estimators': 10, 'min_samples_split': 2, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.1, 'max_leaf_nodes': 10, 'max_features': 'sqrt', 'max_depth': 30, 'criterion': 'entropy', 'class_weight': 'balanced', 'ccp_alpha': 0.0, 'bootstrap': True}\n",
      "\t[18]: 0.928 (+/-0.005) for {'warm_start': False, 'oob_score': False, 'n_estimators': 10, 'min_samples_split': 5, 'min_samples_leaf': 1, 'min_impurity_decrease': 0.0, 'max_leaf_nodes': None, 'max_features': 'sqrt', 'max_depth': 10, 'criterion': 'entropy', 'class_weight': None, 'ccp_alpha': 0.0, 'bootstrap': True}\n",
      "\t[19]: 0.101 (+/-0.006) for {'warm_start': False, 'oob_score': True, 'n_estimators': 200, 'min_samples_split': 10, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.0, 'max_leaf_nodes': None, 'max_features': 'log2', 'max_depth': None, 'criterion': 'gini', 'class_weight': 'balanced', 'ccp_alpha': 0.2, 'bootstrap': True}\n",
      "\t[20]: 0.705 (+/-0.007) for {'warm_start': False, 'oob_score': False, 'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.1, 'max_leaf_nodes': 20, 'max_features': 'log2', 'max_depth': 10, 'criterion': 'entropy', 'class_weight': None, 'ccp_alpha': 0.1, 'bootstrap': True}\n",
      "\t[21]: 0.102 (+/-0.005) for {'warm_start': False, 'oob_score': False, 'n_estimators': 10, 'min_samples_split': 10, 'min_samples_leaf': 1, 'min_impurity_decrease': 0.2, 'max_leaf_nodes': 10, 'max_features': 'log2', 'max_depth': 10, 'criterion': 'gini', 'class_weight': 'balanced_subsample', 'ccp_alpha': 0.2, 'bootstrap': True}\n",
      "\t[22]: 0.097 (+/-0.007) for {'warm_start': True, 'oob_score': False, 'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.1, 'max_leaf_nodes': 20, 'max_features': 'sqrt', 'max_depth': 20, 'criterion': 'gini', 'class_weight': 'balanced_subsample', 'ccp_alpha': 0.0, 'bootstrap': True}\n",
      "\t[23]: 0.097 (+/-0.007) for {'warm_start': True, 'oob_score': False, 'n_estimators': 100, 'min_samples_split': 5, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.1, 'max_leaf_nodes': 20, 'max_features': 'sqrt', 'max_depth': 10, 'criterion': 'gini', 'class_weight': 'balanced_subsample', 'ccp_alpha': 0.0, 'bootstrap': True}\n",
      "\t[24]: 0.663 (+/-0.014) for {'warm_start': False, 'oob_score': True, 'n_estimators': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_impurity_decrease': 0.1, 'max_leaf_nodes': 5, 'max_features': 'sqrt', 'max_depth': 30, 'criterion': 'entropy', 'class_weight': 'balanced_subsample', 'ccp_alpha': 0.1, 'bootstrap': True}\n",
      "\t[25]: 0.617 (+/-0.019) for {'warm_start': False, 'oob_score': True, 'n_estimators': 10, 'min_samples_split': 10, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.1, 'max_leaf_nodes': 5, 'max_features': 'sqrt', 'max_depth': 10, 'criterion': 'entropy', 'class_weight': 'balanced', 'ccp_alpha': 0.1, 'bootstrap': True}\n",
      "\t[26]: 0.772 (+/-0.008) for {'warm_start': True, 'oob_score': False, 'n_estimators': 100, 'min_samples_split': 10, 'min_samples_leaf': 1, 'min_impurity_decrease': 0.0, 'max_leaf_nodes': 10, 'max_features': 'sqrt', 'max_depth': 10, 'criterion': 'gini', 'class_weight': None, 'ccp_alpha': 0.0, 'bootstrap': True}\n",
      "\t[27]: 0.636 (+/-0.014) for {'warm_start': True, 'oob_score': True, 'n_estimators': 100, 'min_samples_split': 10, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.2, 'max_leaf_nodes': 5, 'max_features': 'log2', 'max_depth': 30, 'criterion': 'entropy', 'class_weight': 'balanced_subsample', 'ccp_alpha': 0.1, 'bootstrap': True}\n",
      "\t[28]: 0.837 (+/-0.008) for {'warm_start': False, 'oob_score': True, 'n_estimators': 100, 'min_samples_split': 5, 'min_samples_leaf': 1, 'min_impurity_decrease': 0.0, 'max_leaf_nodes': 20, 'max_features': 'sqrt', 'max_depth': 30, 'criterion': 'entropy', 'class_weight': 'balanced', 'ccp_alpha': 0.0, 'bootstrap': True}\n",
      "\t[29]: 0.098 (+/-0.002) for {'warm_start': False, 'oob_score': False, 'n_estimators': 100, 'min_samples_split': 10, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.0, 'max_leaf_nodes': None, 'max_features': 'log2', 'max_depth': None, 'criterion': 'gini', 'class_weight': 'balanced', 'ccp_alpha': 0.2, 'bootstrap': True}\n",
      "\t[30]: 0.099 (+/-0.010) for {'warm_start': True, 'oob_score': True, 'n_estimators': 10, 'min_samples_split': 2, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.1, 'max_leaf_nodes': 20, 'max_features': 'log2', 'max_depth': 10, 'criterion': 'gini', 'class_weight': 'balanced', 'ccp_alpha': 0.1, 'bootstrap': True}\n",
      "\t[31]: 0.101 (+/-0.006) for {'warm_start': False, 'oob_score': True, 'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.2, 'max_leaf_nodes': 10, 'max_features': 'sqrt', 'max_depth': 10, 'criterion': 'gini', 'class_weight': 'balanced', 'ccp_alpha': 0.1, 'bootstrap': True}\n",
      "\t[32]: 0.549 (+/-0.011) for {'warm_start': True, 'oob_score': True, 'n_estimators': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_impurity_decrease': 0.1, 'max_leaf_nodes': None, 'max_features': 'sqrt', 'max_depth': 10, 'criterion': 'entropy', 'class_weight': None, 'ccp_alpha': 0.2, 'bootstrap': True}\n",
      "\t[33]: 0.396 (+/-0.076) for {'warm_start': True, 'oob_score': False, 'n_estimators': 10, 'min_samples_split': 10, 'min_samples_leaf': 1, 'min_impurity_decrease': 0.2, 'max_leaf_nodes': 10, 'max_features': 'log2', 'max_depth': 30, 'criterion': 'entropy', 'class_weight': 'balanced', 'ccp_alpha': 0.2, 'bootstrap': True}\n",
      "\t[34]: 0.102 (+/-0.005) for {'warm_start': False, 'oob_score': False, 'n_estimators': 10, 'min_samples_split': 5, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.1, 'max_leaf_nodes': None, 'max_features': 'log2', 'max_depth': None, 'criterion': 'gini', 'class_weight': 'balanced_subsample', 'ccp_alpha': 0.2, 'bootstrap': True}\n",
      "\t[35]: 0.099 (+/-0.010) for {'warm_start': False, 'oob_score': False, 'n_estimators': 10, 'min_samples_split': 5, 'min_samples_leaf': 1, 'min_impurity_decrease': 0.0, 'max_leaf_nodes': None, 'max_features': 'log2', 'max_depth': 10, 'criterion': 'gini', 'class_weight': 'balanced', 'ccp_alpha': 0.1, 'bootstrap': True}\n",
      "\t[36]: 0.722 (+/-0.020) for {'warm_start': True, 'oob_score': False, 'n_estimators': 10, 'min_samples_split': 2, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.0, 'max_leaf_nodes': 10, 'max_features': 'sqrt', 'max_depth': 10, 'criterion': 'entropy', 'class_weight': 'balanced', 'ccp_alpha': 0.0, 'bootstrap': True}\n",
      "\t[37]: 0.112 (+/-0.000) for {'warm_start': False, 'oob_score': False, 'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_impurity_decrease': 0.1, 'max_leaf_nodes': 5, 'max_features': 'log2', 'max_depth': 20, 'criterion': 'gini', 'class_weight': None, 'ccp_alpha': 0.2, 'bootstrap': True}\n",
      "\t[38]: 0.578 (+/-0.011) for {'warm_start': True, 'oob_score': False, 'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 1, 'min_impurity_decrease': 0.2, 'max_leaf_nodes': None, 'max_features': 'sqrt', 'max_depth': 30, 'criterion': 'entropy', 'class_weight': 'balanced', 'ccp_alpha': 0.2, 'bootstrap': True}\n",
      "\t[39]: 0.112 (+/-0.000) for {'warm_start': False, 'oob_score': True, 'n_estimators': 10, 'min_samples_split': 5, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.0, 'max_leaf_nodes': 20, 'max_features': 'log2', 'max_depth': 20, 'criterion': 'gini', 'class_weight': None, 'ccp_alpha': 0.1, 'bootstrap': True}\n",
      "\t[40]: 0.596 (+/-0.005) for {'warm_start': True, 'oob_score': False, 'n_estimators': 10, 'min_samples_split': 5, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.0, 'max_leaf_nodes': 20, 'max_features': 'log2', 'max_depth': 30, 'criterion': 'entropy', 'class_weight': None, 'ccp_alpha': 0.1, 'bootstrap': True}\n",
      "\t[41]: 0.101 (+/-0.006) for {'warm_start': False, 'oob_score': True, 'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_impurity_decrease': 0.1, 'max_leaf_nodes': None, 'max_features': 'log2', 'max_depth': 30, 'criterion': 'gini', 'class_weight': 'balanced', 'ccp_alpha': 0.1, 'bootstrap': True}\n",
      "\t[42]: 0.701 (+/-0.016) for {'warm_start': True, 'oob_score': True, 'n_estimators': 200, 'min_samples_split': 10, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.0, 'max_leaf_nodes': 5, 'max_features': 'sqrt', 'max_depth': None, 'criterion': 'entropy', 'class_weight': 'balanced', 'ccp_alpha': 0.0, 'bootstrap': True}\n",
      "\t[43]: 0.097 (+/-0.007) for {'warm_start': False, 'oob_score': False, 'n_estimators': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_impurity_decrease': 0.1, 'max_leaf_nodes': 20, 'max_features': 'sqrt', 'max_depth': 20, 'criterion': 'gini', 'class_weight': 'balanced_subsample', 'ccp_alpha': 0.2, 'bootstrap': True}\n",
      "\t[44]: 0.097 (+/-0.007) for {'warm_start': True, 'oob_score': False, 'n_estimators': 100, 'min_samples_split': 10, 'min_samples_leaf': 1, 'min_impurity_decrease': 0.2, 'max_leaf_nodes': 10, 'max_features': 'log2', 'max_depth': 20, 'criterion': 'gini', 'class_weight': 'balanced_subsample', 'ccp_alpha': 0.0, 'bootstrap': True}\n",
      "\t[45]: 0.576 (+/-0.012) for {'warm_start': True, 'oob_score': True, 'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 1, 'min_impurity_decrease': 0.0, 'max_leaf_nodes': 20, 'max_features': 'sqrt', 'max_depth': 10, 'criterion': 'entropy', 'class_weight': 'balanced_subsample', 'ccp_alpha': 0.2, 'bootstrap': True}\n",
      "\t[46]: 0.097 (+/-0.007) for {'warm_start': True, 'oob_score': False, 'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 1, 'min_impurity_decrease': 0.0, 'max_leaf_nodes': 10, 'max_features': 'sqrt', 'max_depth': 10, 'criterion': 'gini', 'class_weight': 'balanced_subsample', 'ccp_alpha': 0.2, 'bootstrap': True}\n",
      "\t[47]: 0.653 (+/-0.016) for {'warm_start': True, 'oob_score': False, 'n_estimators': 200, 'min_samples_split': 10, 'min_samples_leaf': 1, 'min_impurity_decrease': 0.2, 'max_leaf_nodes': 10, 'max_features': 'log2', 'max_depth': 30, 'criterion': 'entropy', 'class_weight': 'balanced_subsample', 'ccp_alpha': 0.2, 'bootstrap': True}\n",
      "\t[48]: 0.097 (+/-0.007) for {'warm_start': False, 'oob_score': True, 'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 1, 'min_impurity_decrease': 0.1, 'max_leaf_nodes': None, 'max_features': 'log2', 'max_depth': 30, 'criterion': 'gini', 'class_weight': 'balanced_subsample', 'ccp_alpha': 0.1, 'bootstrap': True}\n",
      "\t[49]: 0.097 (+/-0.007) for {'warm_start': False, 'oob_score': False, 'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.1, 'max_leaf_nodes': 5, 'max_features': 'log2', 'max_depth': 20, 'criterion': 'gini', 'class_weight': 'balanced_subsample', 'ccp_alpha': 0.0, 'bootstrap': True}\n",
      "\t[50]: 0.690 (+/-0.009) for {'warm_start': False, 'oob_score': False, 'n_estimators': 200, 'min_samples_split': 10, 'min_samples_leaf': 1, 'min_impurity_decrease': 0.1, 'max_leaf_nodes': 10, 'max_features': 'sqrt', 'max_depth': 30, 'criterion': 'entropy', 'class_weight': 'balanced_subsample', 'ccp_alpha': 0.0, 'bootstrap': True}\n",
      "\t[51]: 0.101 (+/-0.006) for {'warm_start': False, 'oob_score': True, 'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.2, 'max_leaf_nodes': 5, 'max_features': 'sqrt', 'max_depth': 30, 'criterion': 'gini', 'class_weight': 'balanced', 'ccp_alpha': 0.0, 'bootstrap': True}\n",
      "\t[52]: 0.651 (+/-0.017) for {'warm_start': True, 'oob_score': True, 'n_estimators': 200, 'min_samples_split': 10, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.2, 'max_leaf_nodes': 5, 'max_features': 'log2', 'max_depth': 20, 'criterion': 'entropy', 'class_weight': 'balanced', 'ccp_alpha': 0.0, 'bootstrap': True}\n",
      "\t[53]: 0.608 (+/-0.053) for {'warm_start': True, 'oob_score': True, 'n_estimators': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_impurity_decrease': 0.0, 'max_leaf_nodes': None, 'max_features': 'sqrt', 'max_depth': 20, 'criterion': 'entropy', 'class_weight': 'balanced_subsample', 'ccp_alpha': 0.1, 'bootstrap': True}\n",
      "\t[54]: 0.097 (+/-0.007) for {'warm_start': False, 'oob_score': True, 'n_estimators': 200, 'min_samples_split': 10, 'min_samples_leaf': 1, 'min_impurity_decrease': 0.0, 'max_leaf_nodes': None, 'max_features': 'log2', 'max_depth': None, 'criterion': 'gini', 'class_weight': 'balanced_subsample', 'ccp_alpha': 0.1, 'bootstrap': True}\n",
      "\t[55]: 0.112 (+/-0.000) for {'warm_start': True, 'oob_score': True, 'n_estimators': 10, 'min_samples_split': 10, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.1, 'max_leaf_nodes': 5, 'max_features': 'log2', 'max_depth': 20, 'criterion': 'gini', 'class_weight': None, 'ccp_alpha': 0.0, 'bootstrap': True}\n",
      "\t[56]: 0.710 (+/-0.007) for {'warm_start': True, 'oob_score': True, 'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.0, 'max_leaf_nodes': 20, 'max_features': 'log2', 'max_depth': 10, 'criterion': 'entropy', 'class_weight': None, 'ccp_alpha': 0.1, 'bootstrap': True}\n",
      "\t[57]: 0.347 (+/-0.024) for {'warm_start': True, 'oob_score': False, 'n_estimators': 10, 'min_samples_split': 2, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.2, 'max_leaf_nodes': None, 'max_features': 'log2', 'max_depth': 10, 'criterion': 'entropy', 'class_weight': None, 'ccp_alpha': 0.0, 'bootstrap': True}\n",
      "\t[58]: 0.112 (+/-0.000) for {'warm_start': False, 'oob_score': False, 'n_estimators': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_impurity_decrease': 0.1, 'max_leaf_nodes': 10, 'max_features': 'log2', 'max_depth': None, 'criterion': 'gini', 'class_weight': None, 'ccp_alpha': 0.1, 'bootstrap': True}\n",
      "\t[59]: 0.825 (+/-0.009) for {'warm_start': True, 'oob_score': True, 'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.0, 'max_leaf_nodes': 10, 'max_features': 'log2', 'max_depth': None, 'criterion': 'gini', 'class_weight': 'balanced', 'ccp_alpha': 0.0, 'bootstrap': True}\n",
      "\t[60]: 0.636 (+/-0.014) for {'warm_start': False, 'oob_score': True, 'n_estimators': 100, 'min_samples_split': 10, 'min_samples_leaf': 1, 'min_impurity_decrease': 0.2, 'max_leaf_nodes': 5, 'max_features': 'log2', 'max_depth': 20, 'criterion': 'entropy', 'class_weight': 'balanced_subsample', 'ccp_alpha': 0.0, 'bootstrap': True}\n",
      "\t[61]: 0.660 (+/-0.007) for {'warm_start': False, 'oob_score': True, 'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.1, 'max_leaf_nodes': 5, 'max_features': 'sqrt', 'max_depth': 10, 'criterion': 'entropy', 'class_weight': None, 'ccp_alpha': 0.1, 'bootstrap': True}\n",
      "\t[62]: 0.817 (+/-0.015) for {'warm_start': True, 'oob_score': False, 'n_estimators': 100, 'min_samples_split': 5, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.0, 'max_leaf_nodes': 10, 'max_features': 'log2', 'max_depth': 30, 'criterion': 'gini', 'class_weight': 'balanced_subsample', 'ccp_alpha': 0.0, 'bootstrap': True}\n",
      "\t[63]: 0.590 (+/-0.032) for {'warm_start': False, 'oob_score': False, 'n_estimators': 10, 'min_samples_split': 10, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.1, 'max_leaf_nodes': 10, 'max_features': 'sqrt', 'max_depth': 30, 'criterion': 'entropy', 'class_weight': None, 'ccp_alpha': 0.0, 'bootstrap': True}\n",
      "\t[64]: 0.404 (+/-0.099) for {'warm_start': False, 'oob_score': True, 'n_estimators': 10, 'min_samples_split': 5, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.1, 'max_leaf_nodes': 5, 'max_features': 'log2', 'max_depth': 20, 'criterion': 'entropy', 'class_weight': 'balanced', 'ccp_alpha': 0.2, 'bootstrap': True}\n",
      "\t[65]: 0.773 (+/-0.008) for {'warm_start': False, 'oob_score': True, 'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.0, 'max_leaf_nodes': 10, 'max_features': 'sqrt', 'max_depth': 30, 'criterion': 'entropy', 'class_weight': None, 'ccp_alpha': 0.0, 'bootstrap': True}\n",
      "\t[66]: 0.102 (+/-0.005) for {'warm_start': False, 'oob_score': True, 'n_estimators': 10, 'min_samples_split': 2, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.2, 'max_leaf_nodes': 10, 'max_features': 'log2', 'max_depth': 10, 'criterion': 'gini', 'class_weight': 'balanced_subsample', 'ccp_alpha': 0.1, 'bootstrap': True}\n",
      "\t[67]: 0.633 (+/-0.017) for {'warm_start': True, 'oob_score': True, 'n_estimators': 100, 'min_samples_split': 5, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.1, 'max_leaf_nodes': None, 'max_features': 'log2', 'max_depth': 10, 'criterion': 'entropy', 'class_weight': 'balanced', 'ccp_alpha': 0.2, 'bootstrap': True}\n",
      "\t[68]: 0.962 (+/-0.003) for {'warm_start': False, 'oob_score': True, 'n_estimators': 100, 'min_samples_split': 10, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.0, 'max_leaf_nodes': None, 'max_features': 'sqrt', 'max_depth': 20, 'criterion': 'gini', 'class_weight': 'balanced_subsample', 'ccp_alpha': 0.0, 'bootstrap': True}\n",
      "\t[69]: 0.653 (+/-0.019) for {'warm_start': False, 'oob_score': True, 'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.1, 'max_leaf_nodes': 10, 'max_features': 'log2', 'max_depth': 30, 'criterion': 'entropy', 'class_weight': 'balanced', 'ccp_alpha': 0.2, 'bootstrap': True}\n",
      "\t[70]: 0.112 (+/-0.000) for {'warm_start': False, 'oob_score': True, 'n_estimators': 10, 'min_samples_split': 2, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.2, 'max_leaf_nodes': 10, 'max_features': 'log2', 'max_depth': 20, 'criterion': 'gini', 'class_weight': None, 'ccp_alpha': 0.2, 'bootstrap': True}\n",
      "\t[71]: 0.097 (+/-0.007) for {'warm_start': True, 'oob_score': True, 'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_impurity_decrease': 0.0, 'max_leaf_nodes': 5, 'max_features': 'sqrt', 'max_depth': 20, 'criterion': 'gini', 'class_weight': 'balanced_subsample', 'ccp_alpha': 0.2, 'bootstrap': True}\n",
      "\t[72]: 0.480 (+/-0.056) for {'warm_start': False, 'oob_score': False, 'n_estimators': 10, 'min_samples_split': 10, 'min_samples_leaf': 1, 'min_impurity_decrease': 0.2, 'max_leaf_nodes': None, 'max_features': 'sqrt', 'max_depth': None, 'criterion': 'entropy', 'class_weight': 'balanced', 'ccp_alpha': 0.0, 'bootstrap': True}\n",
      "\t[73]: 0.097 (+/-0.007) for {'warm_start': False, 'oob_score': False, 'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.2, 'max_leaf_nodes': 20, 'max_features': 'log2', 'max_depth': 20, 'criterion': 'gini', 'class_weight': 'balanced_subsample', 'ccp_alpha': 0.1, 'bootstrap': True}\n",
      "\t[74]: 0.609 (+/-0.011) for {'warm_start': False, 'oob_score': False, 'n_estimators': 10, 'min_samples_split': 2, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.1, 'max_leaf_nodes': 20, 'max_features': 'log2', 'max_depth': 30, 'criterion': 'entropy', 'class_weight': 'balanced', 'ccp_alpha': 0.1, 'bootstrap': True}\n",
      "\t[75]: 0.112 (+/-0.000) for {'warm_start': False, 'oob_score': True, 'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.0, 'max_leaf_nodes': 10, 'max_features': 'log2', 'max_depth': 20, 'criterion': 'gini', 'class_weight': None, 'ccp_alpha': 0.1, 'bootstrap': True}\n",
      "\t[76]: 0.765 (+/-0.010) for {'warm_start': False, 'oob_score': True, 'n_estimators': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_impurity_decrease': 0.0, 'max_leaf_nodes': 5, 'max_features': 'log2', 'max_depth': 20, 'criterion': 'gini', 'class_weight': 'balanced', 'ccp_alpha': 0.0, 'bootstrap': True}\n",
      "\t[77]: 0.097 (+/-0.007) for {'warm_start': False, 'oob_score': True, 'n_estimators': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_impurity_decrease': 0.2, 'max_leaf_nodes': 20, 'max_features': 'sqrt', 'max_depth': 30, 'criterion': 'gini', 'class_weight': 'balanced_subsample', 'ccp_alpha': 0.1, 'bootstrap': True}\n",
      "\t[78]: 0.652 (+/-0.018) for {'warm_start': True, 'oob_score': True, 'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.1, 'max_leaf_nodes': None, 'max_features': 'log2', 'max_depth': 20, 'criterion': 'entropy', 'class_weight': 'balanced_subsample', 'ccp_alpha': 0.2, 'bootstrap': True}\n",
      "\t[79]: 0.112 (+/-0.000) for {'warm_start': True, 'oob_score': True, 'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 1, 'min_impurity_decrease': 0.2, 'max_leaf_nodes': 5, 'max_features': 'log2', 'max_depth': None, 'criterion': 'gini', 'class_weight': None, 'ccp_alpha': 0.1, 'bootstrap': True}\n",
      "\t[80]: 0.963 (+/-0.002) for {'warm_start': False, 'oob_score': True, 'n_estimators': 200, 'min_samples_split': 10, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.0, 'max_leaf_nodes': None, 'max_features': 'sqrt', 'max_depth': 30, 'criterion': 'entropy', 'class_weight': 'balanced', 'ccp_alpha': 0.0, 'bootstrap': True}\n",
      "\t[81]: 0.112 (+/-0.000) for {'warm_start': True, 'oob_score': True, 'n_estimators': 200, 'min_samples_split': 10, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.1, 'max_leaf_nodes': None, 'max_features': 'sqrt', 'max_depth': 10, 'criterion': 'gini', 'class_weight': None, 'ccp_alpha': 0.1, 'bootstrap': True}\n",
      "\t[82]: 0.720 (+/-0.016) for {'warm_start': False, 'oob_score': False, 'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.0, 'max_leaf_nodes': 5, 'max_features': 'sqrt', 'max_depth': 20, 'criterion': 'gini', 'class_weight': 'balanced', 'ccp_alpha': 0.0, 'bootstrap': True}\n",
      "\t[83]: 0.585 (+/-0.012) for {'warm_start': True, 'oob_score': True, 'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_impurity_decrease': 0.2, 'max_leaf_nodes': 20, 'max_features': 'log2', 'max_depth': 30, 'criterion': 'entropy', 'class_weight': None, 'ccp_alpha': 0.0, 'bootstrap': True}\n",
      "\t[84]: 0.577 (+/-0.011) for {'warm_start': True, 'oob_score': True, 'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.2, 'max_leaf_nodes': 5, 'max_features': 'sqrt', 'max_depth': None, 'criterion': 'entropy', 'class_weight': 'balanced', 'ccp_alpha': 0.0, 'bootstrap': True}\n",
      "\t[85]: 0.099 (+/-0.010) for {'warm_start': False, 'oob_score': False, 'n_estimators': 10, 'min_samples_split': 5, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.1, 'max_leaf_nodes': 5, 'max_features': 'sqrt', 'max_depth': 30, 'criterion': 'gini', 'class_weight': 'balanced', 'ccp_alpha': 0.1, 'bootstrap': True}\n",
      "\t[86]: 0.102 (+/-0.005) for {'warm_start': False, 'oob_score': False, 'n_estimators': 10, 'min_samples_split': 5, 'min_samples_leaf': 1, 'min_impurity_decrease': 0.2, 'max_leaf_nodes': 5, 'max_features': 'log2', 'max_depth': 10, 'criterion': 'gini', 'class_weight': 'balanced_subsample', 'ccp_alpha': 0.2, 'bootstrap': True}\n",
      "\t[87]: 0.547 (+/-0.013) for {'warm_start': False, 'oob_score': False, 'n_estimators': 100, 'min_samples_split': 10, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.0, 'max_leaf_nodes': 5, 'max_features': 'sqrt', 'max_depth': 30, 'criterion': 'entropy', 'class_weight': None, 'ccp_alpha': 0.2, 'bootstrap': True}\n",
      "\t[88]: 0.637 (+/-0.017) for {'warm_start': True, 'oob_score': False, 'n_estimators': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_impurity_decrease': 0.0, 'max_leaf_nodes': 5, 'max_features': 'log2', 'max_depth': None, 'criterion': 'entropy', 'class_weight': 'balanced_subsample', 'ccp_alpha': 0.2, 'bootstrap': True}\n",
      "\t[89]: 0.112 (+/-0.000) for {'warm_start': False, 'oob_score': False, 'n_estimators': 10, 'min_samples_split': 2, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.2, 'max_leaf_nodes': 10, 'max_features': 'log2', 'max_depth': 30, 'criterion': 'gini', 'class_weight': None, 'ccp_alpha': 0.0, 'bootstrap': True}\n",
      "\t[90]: 0.097 (+/-0.007) for {'warm_start': False, 'oob_score': True, 'n_estimators': 100, 'min_samples_split': 10, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.2, 'max_leaf_nodes': 5, 'max_features': 'sqrt', 'max_depth': 30, 'criterion': 'gini', 'class_weight': 'balanced_subsample', 'ccp_alpha': 0.1, 'bootstrap': True}\n",
      "\t[91]: 0.739 (+/-0.009) for {'warm_start': False, 'oob_score': True, 'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.0, 'max_leaf_nodes': 5, 'max_features': 'log2', 'max_depth': 20, 'criterion': 'entropy', 'class_weight': 'balanced_subsample', 'ccp_alpha': 0.1, 'bootstrap': True}\n",
      "\t[92]: 0.655 (+/-0.018) for {'warm_start': True, 'oob_score': True, 'n_estimators': 200, 'min_samples_split': 10, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.0, 'max_leaf_nodes': 5, 'max_features': 'log2', 'max_depth': 30, 'criterion': 'entropy', 'class_weight': 'balanced_subsample', 'ccp_alpha': 0.2, 'bootstrap': True}\n",
      "\t[93]: 0.112 (+/-0.000) for {'warm_start': False, 'oob_score': False, 'n_estimators': 10, 'min_samples_split': 5, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.1, 'max_leaf_nodes': 5, 'max_features': 'sqrt', 'max_depth': 10, 'criterion': 'gini', 'class_weight': None, 'ccp_alpha': 0.0, 'bootstrap': True}\n",
      "\t[94]: 0.112 (+/-0.000) for {'warm_start': True, 'oob_score': False, 'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_impurity_decrease': 0.0, 'max_leaf_nodes': 5, 'max_features': 'log2', 'max_depth': None, 'criterion': 'gini', 'class_weight': None, 'ccp_alpha': 0.2, 'bootstrap': True}\n",
      "\t[95]: 0.112 (+/-0.000) for {'warm_start': False, 'oob_score': True, 'n_estimators': 100, 'min_samples_split': 10, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.0, 'max_leaf_nodes': 20, 'max_features': 'sqrt', 'max_depth': 10, 'criterion': 'gini', 'class_weight': None, 'ccp_alpha': 0.1, 'bootstrap': True}\n",
      "\t[96]: 0.740 (+/-0.008) for {'warm_start': True, 'oob_score': False, 'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.1, 'max_leaf_nodes': None, 'max_features': 'log2', 'max_depth': 10, 'criterion': 'entropy', 'class_weight': 'balanced', 'ccp_alpha': 0.1, 'bootstrap': True}\n",
      "\t[97]: 0.097 (+/-0.007) for {'warm_start': True, 'oob_score': False, 'n_estimators': 100, 'min_samples_split': 2, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.0, 'max_leaf_nodes': 5, 'max_features': 'sqrt', 'max_depth': 10, 'criterion': 'gini', 'class_weight': 'balanced_subsample', 'ccp_alpha': 0.1, 'bootstrap': True}\n",
      "\t[98]: 0.577 (+/-0.013) for {'warm_start': False, 'oob_score': False, 'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.2, 'max_leaf_nodes': None, 'max_features': 'sqrt', 'max_depth': 20, 'criterion': 'entropy', 'class_weight': 'balanced_subsample', 'ccp_alpha': 0.1, 'bootstrap': True}\n",
      "\t[99]: 0.631 (+/-0.036) for {'warm_start': False, 'oob_score': False, 'n_estimators': 10, 'min_samples_split': 2, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.1, 'max_leaf_nodes': None, 'max_features': 'sqrt', 'max_depth': 30, 'criterion': 'entropy', 'class_weight': 'balanced_subsample', 'ccp_alpha': 0.1, 'bootstrap': True}\n",
      "\n",
      "Detailed classification report:\n",
      "\tThe model is trained on the full development set.\n",
      "\tThe scores are computed on the full evaluation set.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98      2077\n",
      "           1       0.99      0.98      0.99      2385\n",
      "           2       0.95      0.97      0.96      2115\n",
      "           3       0.97      0.94      0.95      2117\n",
      "           4       0.96      0.97      0.96      2004\n",
      "           5       0.96      0.96      0.96      1900\n",
      "           6       0.97      0.98      0.97      2045\n",
      "           7       0.97      0.96      0.96      2189\n",
      "           8       0.95      0.95      0.95      2042\n",
      "           9       0.95      0.94      0.94      2126\n",
      "\n",
      "    accuracy                           0.96     21000\n",
      "   macro avg       0.96      0.96      0.96     21000\n",
      "weighted avg       0.96      0.96      0.96     21000\n",
      "\n",
      "\n",
      "CTOR for best model: RandomForestClassifier(class_weight='balanced', criterion='entropy',\n",
      "                       max_depth=30, min_samples_leaf=2, min_samples_split=10,\n",
      "                       n_estimators=200, oob_score=True, random_state=83)\n",
      "\n",
      "best: dat=mnist, score=0.96282, model=RandomForestClassifier(bootstrap=True,ccp_alpha=0.0,class_weight='balanced',criterion='entropy',max_depth=30,max_features='sqrt',max_leaf_nodes=None,min_impurity_decrease=0.0,min_samples_leaf=2,min_samples_split=10,n_estimators=200,oob_score=True,warm_start=False)\n",
      "\n",
      "OK(grid-search)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Setup data\n",
    "X_train, X_test, y_train, y_test = LoadAndSetupData(\n",
    "    'mnist')  # 'iris', 'moon', or 'mnist'\n",
    "\n",
    "# Setup search parameters\n",
    "model = RandomForestClassifier(\n",
    "    random_state=83\n",
    ")  \n",
    "\n",
    "tuning_parameters = {\n",
    "    'n_estimators': [10, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'class_weight': [None, 'balanced', 'balanced_subsample'],\n",
    "    'max_leaf_nodes': [None, 5, 10, 20],\n",
    "    'min_impurity_decrease': [0.0, 0.1, 0.2],\n",
    "    'oob_score': [True, False],\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "    'bootstrap': [True],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'warm_start': [True, False],\n",
    "    'ccp_alpha': [0.0, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "CV = 5\n",
    "VERBOSE = 0\n",
    "\n",
    "# Run GridSearchCV for the model\n",
    "grid_tuned = RandomizedSearchCV(model, \n",
    "                                tuning_parameters, \n",
    "                                n_iter=100, \n",
    "                                random_state=69, \n",
    "                                cv=CV, \n",
    "                                scoring='f1_micro', \n",
    "                                verbose=VERBOSE, \n",
    "                                n_jobs=-1)\n",
    "\n",
    "start = time()\n",
    "grid_tuned.fit(X_train, y_train)\n",
    "t = time() - start\n",
    "\n",
    "# Report result\n",
    "b0, m0 = FullReport(grid_tuned, X_test, y_test, t)\n",
    "print('OK(grid-search)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Conclusion__\n",
    "\n",
    "We made various adjustments, tweaking parameters like the number of iterations (n_iter), max-depth, min sample split, and others. Despite these changes, the accuracy score stayed close to an average of 0.96, with only a slight 0.001 difference after tuning. This hints that the dataset might not contain enough information to achieve a significantly higher accuracy score. The best result is as follows:\n",
    "\n",
    "Best Result: Dataset=MNIST, Score=0.96553, Model=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced_subsample', criterion='entropy', max_depth=20, max_features='sqrt', max_leaf_nodes=None, min_impurity_decrease=0.0, min_samples_leaf=1, min_samples_split=5, n_estimators=200, oob_score=False, warm_start=True)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-17T13:19:20.077257Z",
     "start_time": "2023-11-17T13:19:20.069718Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "attachments": {
    "roboflow-2.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SWMAL Exercise\n",
    "\n",
    "## Advanced CNN using Roboflow\n",
    "\n",
    "### Finding a dataset\n",
    "We went to roboflow and found the face detection dataset which was already labeled, then we downloaded it and created a project with YOLOv8 as the model. After that we uploaded to roboflow project.\n",
    "\n",
    "<img src=\"Dataset.png\"  style=\"height:500px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Generating the model\n",
    "In roboflow we followed the step by step guide to generate the model. We used the default settings. \n",
    "\n",
    "<img src=\"GenerateModel.png\" style=\"height:500px\">\n",
    "\n",
    "### Training the model\n",
    "After having generated the model we then trained it. This again was done following the roboflow steps. We press train with roboflow and select fast option, then the Train from previous checkpoint option. We then wait for the model to train this took around two hours.\n",
    "\n",
    "### Training graphs\n",
    "\n",
    "Below are pictures of the result of training. \n",
    "There is the mAP, Box loss, Class loss and object loss:\n",
    "<img src=\"graphs.png\" style=\"height:500px\">\n",
    "\n",
    "\n",
    "<img src=\"Numbers.png\" style=\"height:500px\">\n",
    "\n",
    "### Conclussion\n",
    "\n",
    "Precision: 92.1% \n",
    "\n",
    "mAP (Average of average precision metric): 87,5%\n",
    "\n",
    "Recall (percentage of relevant labels that were correctly classified): 72.1%\n",
    "\n",
    "Overall the precision is good in the low 90s, but the recall is not as good. This means that the model is good at finding faces, but it is not as good at finding all the faces. In terms of the train, validate and test split the dataset is not equally split in desired ratio.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
