{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T10:01:51.869489Z",
     "start_time": "2023-11-30T10:01:51.865318Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h1 align=\"center\">SWMAL</h1>\n",
       "<h3 align=\"center\">Assignment O3</h3>\n",
       "<h3 align=\"center\">Group 24</h3>\n",
       "<h5 align=\"center\">November 17 2023</h5>\n",
       "\n",
       "\n",
       "|Name|Student Number |\n",
       "|:---|:---|\n",
       "|Sean Harboe Bateman|200203025|\n",
       "|Martin Stokholm Lauridsen|201908195|\n",
       "|Christain Duwe Konnerup|202010016|"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown,display\n",
    "\n",
    "display(Markdown(\"header.md\"))"
   ]
  },
  {
   "attachments": {
    "model_plot-2.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Networks (CNNs)\n",
    "A CNN is a neural network model that is specialized in working with images or videos in a 2D dimension. A CNN is used for processing the images or videos in a grid. So in general CNN is used for series data and pattern recognition.\n",
    "\n",
    "To make a CNN there has to be different layers, these layers is the foundation for creating a functional CNN model. The layers also called convolutional layers, these layers is what gives the entire networks it's name. One of the important terms when talking about CNN's is filters. Filters is what gives a CNN the functionality for pattern recognition.\n",
    "\n",
    "`Convolutional layers` these layers are what applies the different filters to the different neurons data. These layers are linear operations that can apply 1 or more filters to a neuron at once, so the different neurons have different biases. Applying a convolutional layer to neuron will multiply the pixels from the neuron data with the bias from all the filters. After applying the filters the sum of region that the filter is applied to is made. When this has happened to all the regions, there will automatically generate a new matrix where every region is made of a sum. This new matrix is used by the network to learn the different features that are in the dataset. These layers can help determine a pattern in the dataset.\n",
    "\n",
    "`Fully Connected layers` is a combination multiple convolutional and pooling layers. A fully connected layer is a true copy of a real neural network, where every neuron from a previous layer is connected to every neuron in a new layer.\n",
    "\n",
    "`Pooling layers` is used to reduce the image into smaller regions. This is done by segmenting the image into groups of pixels. There is different ways of doing pooling. There is max pooling which takes the max value from a group of the neighbouring regions pixels and inputs it into the feature map instead of its own value. The other pooling method is called average pooling. When using average pooling it takes the average value of all the regions in the local region it is in. The reason for using pooling is to find the most active regions of pixels and shrink down the dimensions.\n",
    "\n",
    "`Multiple channels` is often used when working with processing of images or videos. Multiple channels allow the CNN to have different channels for the different color spectrum's. The multiple channels can also be used to create outlines on the different images. Each convolutional filter is applied to every multiple channel independently.\n",
    "\n",
    "`Activation Functions` is used to teach the model the complex relations between all the features in the data used. Activation functions is non-linear. Some examples on activation functions would be `Relu` or `softmax`.\n",
    "\n",
    "`Generlization` is used to ensure a models performance with unseen data, so that it does not matter how big the dataset is the model should still be able to perform somewhat decent. We used a stratified k-fold to make sure we had cross-validation on the dataset.\n",
    "\n",
    "`Learning Curve` can be seen in the plots we have made that illustrates the training loss and accuracy from the different iterations. Training loss measures the performance of the model while doing training. It is possible to see that over time that the training loss gets smaller and the prediction value gets closer to the actual value the longer it trains. The same happens to the accuracy, from start to finish its possible to see it grow closer to a score of 1.\n",
    "\n",
    "`Code Setup`\n",
    "- Import libraries needed\n",
    "- Get data from mnist\n",
    "- Setup train and test data with reshaping\n",
    "- Create CNN model\n",
    "- Initial setup for stratified k-fold\n",
    "- Setup array to store test accuracy\n",
    "- For loop that creates the model fits the model\n",
    "- Plotting the training loss and accuracy\n",
    "- Printing average score\n",
    "\n",
    "\n",
    "![model_plot-2.png](attachment:model_plot-2.png)\n",
    "\n",
    "`Testing different epochs` we tried a lot of different combinations of epochs, folds and some different layers. however the best score was while using 6 folds and 20 epochs, and the final average score we ended up getting is `0.9927`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T09:34:50.115056Z",
     "start_time": "2023-11-30T09:20:25.324149Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0354 - accuracy: 0.9920\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0561 - accuracy: 0.9894\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0534 - accuracy: 0.9892\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0621 - accuracy: 0.9887\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0546 - accuracy: 0.9888\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0445 - accuracy: 0.9894\n",
      "Test average accuracy: 0.9894000291824341\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import keras\n",
    "from keras.utils import plot_model\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "(x_train, y_train ), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape((-1,28,28,1)).astype('float32') / 255.0\n",
    "x_test = x_test.reshape((-1,28,28,1)).astype('float32') / 255.0\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes=10)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes=10)\n",
    "\n",
    "def create():\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Conv2D(32,(3,3), activation='relu', input_shape=(28,28,1)))\n",
    "    model.add(keras.layers.MaxPooling2D((2, 2)))\n",
    "    model.add(keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(keras.layers.MaxPooling2D((2, 2)))\n",
    "    model.add(keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(64, activation='relu'))\n",
    "    model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "    plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)\n",
    "\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "folds = 6\n",
    "kfold = StratifiedKFold(n_splits=folds, shuffle=True, random_state=50)\n",
    "test_accuracy = []\n",
    "\n",
    "training_loss = []\n",
    "training_accuracy = []\n",
    "\n",
    "for train, val in kfold.split(x_train,y_train.argmax(1)):\n",
    "\n",
    "    model = create()\n",
    "\n",
    "    x_train_kfold, x_val_kfold = x_train[train], x_train[val]\n",
    "    y_train_kfold, y_val_kfold = y_train[train], y_train[val]\n",
    "\n",
    "    epoch_loss = []\n",
    "    epoch_accuracy = []\n",
    "\n",
    "    for epochs in range(20):\n",
    "        modelhis = model.fit(x_train_kfold, y_train_kfold, epochs=1, batch_size=64, verbose=0)\n",
    "\n",
    "        epoch_loss.append(modelhis.history['loss'][0])\n",
    "        epoch_accuracy.append(modelhis.history['accuracy'][0])\n",
    "\n",
    "    training_loss.append(epoch_loss)\n",
    "    training_accuracy.append(epoch_accuracy)\n",
    "\n",
    "    test_loss, test_accuracy = model.evaluate(x_test,y_test)\n",
    "\n",
    "avg_accuracy = np.mean(test_accuracy)\n",
    "print(f'Test average accuracy: {avg_accuracy}')\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(np.mean(training_loss, axis=0), label='Training Loss')\n",
    "plt.title('Training Losss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(np.mean(training_accuracy, axis=0), label='Training Accuracy')\n",
    "plt.title('Training Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Conlusion`\n",
    "We have worked with CNN's and trained a model in processing images. Throughout the exercise we have tried a lot of different methods of doing processing on images using CNN's. We ended on the final version of our CNN which can maintain a high accuracy when using the MNIST dataset. We have tried different setup of layers, epochs and folds. The final result gave an accuracy of `0.9927`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SWMAL Exercise\n",
    "\n",
    "## Generalization Error\n",
    "\n",
    "In this exercise we are going to explain important overall concepts in training. \n",
    "\n",
    "First we look Figure 5.3 from Deep Learning (Ian Goodfellow, et. al. [DL]).\n",
    "\n",
    "<img src=\"https://itundervisning.ase.au.dk/SWMAL/L08/Figs/dl_generalization_error.png\" alt=\"WARNING: could not get image from server.\" style=\"height:500px\">\n",
    "\n",
    "The figure shows the typical relationship between the error and the capacity, where the test error and generelization error behave differently.The left side of the plot shows the underfitting regime where both errors are very high. Following an increase in capacity the training error gets lower. Meanwhile the gap between the training error and the generalization error gets increased. and then we are in the overfitting regime. Then the capacity is too large.  \n",
    "\n",
    "### Qa) On Generalization Error\n",
    "\n",
    "Explanation of concepts in the figure above:\n",
    "\n",
    "#### Training error\n",
    "The training error is the blue line in graph and describes the error in relation to the capacity of the training model as a percentage. The training error indicates how well the model understands patterns in the training data, where a low training error indicates that the model has a good understanding of the training data.\n",
    "\n",
    "#### Generalization error\n",
    "The green line on the graph is the generalization error and describes the error in the training model when it is tested on new data. The generalization error indicates how well the model can predict new data, where a low generalization error indicates that the model can predict new data well.\n",
    "\n",
    "#### Underfitting\n",
    "When the capacity of the model is too low, the model will not be able to understand the patterns in the training data. This will result in a high training error and a high generalization error. This is called underfitting and can be corrected by increasing the capacity of the model.\n",
    "\n",
    "#### Overfitting\n",
    "When the capacity of the model is too high, the model will be able to understand the patterns in the training data very well. This will result in a low training error and a high generalization error. This is called overfitting and can be corrected by decreasing the capacity of the model.\n",
    "\n",
    "#### Generalization gap\n",
    "The generalization gap is the vertical difference between the training error and the generalization error. The generalization gap is high when the model is overfitting and low when the model is underfitting.\n",
    "\n",
    "#### Optimal capacity \n",
    "When fitting the model we want to find the optimal capacity where the model can recoqnize patterns in the training set that can be used on new data but without being too specific and picking up noise in the training data. This is the point where the generalization error is lowest.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qb A MSE-Epoch/Error Plot\n",
    "\n",
    "Now we are taking a look at the SGD model for fitting polynomial, that is _polynomial regression_ which is similar to the Gron one, described in [HOML] (\"Polynomial Regression\" + \"Learning Curves\"). \n",
    "\n",
    "#### Part 1\n",
    "So as we've seen before there is a function for GenerateData that seed random data points for and also adds some noise. Then the data is split into the training and validation sets.\n",
    "\n",
    "In the pipeline we again use the polynominial feature but with a 90 degree, and no bias in order to get a model with very high capacity. The second preprocessor is the standard scaler which standardizes the features in our data set. By removing the mean and centerring the feautre distribution around 0 and scaling the variance to 1.\n",
    "\n",
    "lastly the poly_scaler is transformed into the training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T09:34:50.345728Z",
     "start_time": "2023-11-30T09:34:50.113343Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape= (25, 1)\n",
      "X_val  .shape= (25, 1)\n",
      "y_train.shape= (25,)\n",
      "y_val  .shape= (25,)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "# Run code: Qb(part I)\n",
    "# NOTE: modified code from [GITHOML], 04_training_linear_models.ipynb\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "def GenerateData():\n",
    "    m = 100\n",
    "    X = 6 * np.random.rand(m, 1) - 3\n",
    "    y = 2 + X + 0.5 * X**2 + np.random.randn(m, 1)\n",
    "    return X, y\n",
    "\n",
    "X, y = GenerateData()\n",
    "X_train, X_val, y_train, y_val = \\\n",
    "    train_test_split( \\\n",
    "        X[:50], y[:50].ravel(), \\\n",
    "        test_size=0.5, \\\n",
    "        random_state=10)\n",
    "\n",
    "print(\"X_train.shape=\",X_train.shape)\n",
    "print(\"X_val  .shape=\",X_val.shape)\n",
    "print(\"y_train.shape=\",y_train.shape)\n",
    "print(\"y_val  .shape=\",y_val.shape)\n",
    "\n",
    "poly_scaler = Pipeline([\n",
    "        (\"poly_features\", PolynomialFeatures(degree=90, include_bias=False)),\n",
    "        (\"std_scaler\", StandardScaler()),\n",
    "    ])\n",
    "\n",
    "X_train_poly_scaled = poly_scaler.fit_transform(X_train)\n",
    "X_val_poly_scaled   = poly_scaler.transform(X_val)\n",
    "\n",
    "X_new=np.linspace(-3, 3, 100).reshape(100, 1)\n",
    "plt.plot(X, y, \"b.\", label=\"All X-y Data\")\n",
    "plt.xlabel(\"$x_1$\", fontsize=18, )\n",
    "plt.ylabel(\"$y$\", rotation=0, fontsize=18)\n",
    "plt.legend(loc=\"upper left\", fontsize=14)\n",
    "plt.axis([-3, 3, 0, 10])\n",
    "plt.show()\n",
    "\n",
    "print('OK')      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 2\n",
    "\n",
    "First thing is a function Train with the parameters X_train, y_train, X_val, y_val, n_epochs and verbose. The function is used to train the model and return the training and validation errors. The errors are saved in arrays. \n",
    "The Train function then uses the SGDRegressor to fit the model to the training data. It runs for 1 iteration with constant as the learning rate.\n",
    " \n",
    "The model is then used to predict the training and validation sets.\n",
    "The mean squared error is then calculated for both the training and validation sets. \n",
    "The errors are then saved in the arrays train_errors and val_errors. \n",
    "The function then returns the errors arrays.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T09:34:50.600502Z",
     "start_time": "2023-11-30T09:34:50.346359Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...n_epochs= 500\n",
      "  epoch=   0, mse_train=11.85, mse_val=14.58\n",
      "  epoch=   1, mse_train=11.51, mse_val=14.10\n",
      "  epoch=   2, mse_train=11.15, mse_val=13.60\n",
      "  epoch=   3, mse_train=10.81, mse_val=13.13\n",
      "  epoch=   4, mse_train=10.49, mse_val=12.70\n",
      "  epoch=   5, mse_train=10.18, mse_val=12.30\n",
      "  epoch=   6, mse_train=9.88, mse_val=11.92\n",
      "  epoch=   7, mse_train=9.60, mse_val=11.56\n",
      "  epoch=   8, mse_train=9.33, mse_val=11.23\n",
      "  epoch=   9, mse_train=9.07, mse_val=10.91\n",
      "  epoch=  10, mse_train=8.82, mse_val=10.62\n",
      "  epoch=  11, mse_train=8.59, mse_val=10.34\n",
      "  epoch=  12, mse_train=8.36, mse_val=10.07\n",
      "  epoch=  13, mse_train=8.14, mse_val=9.82\n",
      "  epoch=  14, mse_train=7.93, mse_val=9.57\n",
      "  epoch=  15, mse_train=7.72, mse_val=9.34\n",
      "  epoch=  16, mse_train=7.53, mse_val=9.12\n",
      "  epoch=  17, mse_train=7.34, mse_val=8.91\n",
      "  epoch=  18, mse_train=7.16, mse_val=8.71\n",
      "  epoch=  19, mse_train=6.98, mse_val=8.52\n",
      "  epoch=  20, mse_train=6.81, mse_val=8.33\n",
      "  epoch=  21, mse_train=6.65, mse_val=8.15\n",
      "  epoch=  22, mse_train=6.49, mse_val=7.98\n",
      "  epoch=  23, mse_train=6.34, mse_val=7.81\n",
      "  epoch=  24, mse_train=6.19, mse_val=7.65\n",
      "  epoch=  25, mse_train=6.05, mse_val=7.49\n",
      "  epoch=  26, mse_train=5.91, mse_val=7.34\n",
      "  epoch=  27, mse_train=5.77, mse_val=7.20\n",
      "  epoch=  28, mse_train=5.64, mse_val=7.06\n",
      "  epoch=  29, mse_train=5.52, mse_val=6.92\n",
      "  epoch=  30, mse_train=5.40, mse_val=6.79\n",
      "  epoch=  31, mse_train=5.28, mse_val=6.66\n",
      "  epoch=  32, mse_train=5.16, mse_val=6.54\n",
      "  epoch=  33, mse_train=5.05, mse_val=6.42\n",
      "  epoch=  34, mse_train=4.94, mse_val=6.30\n",
      "  epoch=  35, mse_train=4.84, mse_val=6.18\n",
      "  epoch=  36, mse_train=4.73, mse_val=6.07\n",
      "  epoch=  37, mse_train=4.63, mse_val=5.97\n",
      "  epoch=  38, mse_train=4.54, mse_val=5.86\n",
      "  epoch=  39, mse_train=4.44, mse_val=5.76\n",
      "  epoch=  40, mse_train=4.35, mse_val=5.66\n",
      "  epoch=  41, mse_train=4.26, mse_val=5.56\n",
      "  epoch=  42, mse_train=4.17, mse_val=5.47\n",
      "  epoch=  43, mse_train=4.09, mse_val=5.37\n",
      "  epoch=  44, mse_train=4.01, mse_val=5.28\n",
      "  epoch=  45, mse_train=3.93, mse_val=5.20\n",
      "  epoch=  46, mse_train=3.85, mse_val=5.11\n",
      "  epoch=  47, mse_train=3.77, mse_val=5.03\n",
      "  epoch=  48, mse_train=3.70, mse_val=4.95\n",
      "  epoch=  49, mse_train=3.63, mse_val=4.87\n",
      "  epoch=  50, mse_train=3.56, mse_val=4.79\n",
      "  epoch=  51, mse_train=3.49, mse_val=4.71\n",
      "  epoch=  52, mse_train=3.42, mse_val=4.64\n",
      "  epoch=  53, mse_train=3.36, mse_val=4.57\n",
      "  epoch=  54, mse_train=3.29, mse_val=4.49\n",
      "  epoch=  55, mse_train=3.23, mse_val=4.43\n",
      "  epoch=  56, mse_train=3.17, mse_val=4.36\n",
      "  epoch=  57, mse_train=3.11, mse_val=4.29\n",
      "  epoch=  58, mse_train=3.06, mse_val=4.23\n",
      "  epoch=  59, mse_train=3.00, mse_val=4.16\n",
      "  epoch=  60, mse_train=2.95, mse_val=4.10\n",
      "  epoch=  61, mse_train=2.89, mse_val=4.04\n",
      "  epoch=  62, mse_train=2.84, mse_val=3.98\n",
      "  epoch=  63, mse_train=2.79, mse_val=3.93\n",
      "  epoch=  64, mse_train=2.74, mse_val=3.87\n",
      "  epoch=  65, mse_train=2.70, mse_val=3.81\n",
      "  epoch=  66, mse_train=2.65, mse_val=3.76\n",
      "  epoch=  67, mse_train=2.60, mse_val=3.71\n",
      "  epoch=  68, mse_train=2.56, mse_val=3.66\n",
      "  epoch=  69, mse_train=2.52, mse_val=3.60\n",
      "  epoch=  70, mse_train=2.47, mse_val=3.56\n",
      "  epoch=  71, mse_train=2.43, mse_val=3.51\n",
      "  epoch=  72, mse_train=2.39, mse_val=3.46\n",
      "  epoch=  73, mse_train=2.35, mse_val=3.41\n",
      "  epoch=  74, mse_train=2.31, mse_val=3.37\n",
      "  epoch=  75, mse_train=2.28, mse_val=3.32\n",
      "  epoch=  76, mse_train=2.24, mse_val=3.28\n",
      "  epoch=  77, mse_train=2.20, mse_val=3.24\n",
      "  epoch=  78, mse_train=2.17, mse_val=3.20\n",
      "  epoch=  79, mse_train=2.14, mse_val=3.15\n",
      "  epoch=  80, mse_train=2.10, mse_val=3.12\n",
      "  epoch=  81, mse_train=2.07, mse_val=3.08\n",
      "  epoch=  82, mse_train=2.04, mse_val=3.04\n",
      "  epoch=  83, mse_train=2.01, mse_val=3.00\n",
      "  epoch=  84, mse_train=1.98, mse_val=2.96\n",
      "  epoch=  85, mse_train=1.95, mse_val=2.93\n",
      "  epoch=  86, mse_train=1.92, mse_val=2.89\n",
      "  epoch=  87, mse_train=1.89, mse_val=2.86\n",
      "  epoch=  88, mse_train=1.86, mse_val=2.82\n",
      "  epoch=  89, mse_train=1.84, mse_val=2.79\n",
      "  epoch=  90, mse_train=1.81, mse_val=2.76\n",
      "  epoch=  91, mse_train=1.79, mse_val=2.73\n",
      "  epoch=  92, mse_train=1.76, mse_val=2.70\n",
      "  epoch=  93, mse_train=1.74, mse_val=2.67\n",
      "  epoch=  94, mse_train=1.71, mse_val=2.64\n",
      "  epoch=  95, mse_train=1.69, mse_val=2.61\n",
      "  epoch=  96, mse_train=1.67, mse_val=2.58\n",
      "  epoch=  97, mse_train=1.65, mse_val=2.55\n",
      "  epoch=  98, mse_train=1.62, mse_val=2.52\n",
      "  epoch=  99, mse_train=1.60, mse_val=2.50\n",
      "  epoch= 100, mse_train=1.58, mse_val=2.47\n",
      "  epoch= 101, mse_train=1.56, mse_val=2.45\n",
      "  epoch= 102, mse_train=1.54, mse_val=2.42\n",
      "  epoch= 103, mse_train=1.52, mse_val=2.40\n",
      "  epoch= 104, mse_train=1.50, mse_val=2.37\n",
      "  epoch= 105, mse_train=1.49, mse_val=2.35\n",
      "  epoch= 106, mse_train=1.47, mse_val=2.33\n",
      "  epoch= 107, mse_train=1.45, mse_val=2.30\n",
      "  epoch= 108, mse_train=1.43, mse_val=2.28\n",
      "  epoch= 109, mse_train=1.42, mse_val=2.26\n",
      "  epoch= 110, mse_train=1.40, mse_val=2.24\n",
      "  epoch= 111, mse_train=1.38, mse_val=2.22\n",
      "  epoch= 112, mse_train=1.37, mse_val=2.20\n",
      "  epoch= 113, mse_train=1.35, mse_val=2.18\n",
      "  epoch= 114, mse_train=1.34, mse_val=2.16\n",
      "  epoch= 115, mse_train=1.32, mse_val=2.14\n",
      "  epoch= 116, mse_train=1.31, mse_val=2.12\n",
      "  epoch= 117, mse_train=1.30, mse_val=2.10\n",
      "  epoch= 118, mse_train=1.28, mse_val=2.08\n",
      "  epoch= 119, mse_train=1.27, mse_val=2.06\n",
      "  epoch= 120, mse_train=1.26, mse_val=2.05\n",
      "  epoch= 121, mse_train=1.24, mse_val=2.03\n",
      "  epoch= 122, mse_train=1.23, mse_val=2.01\n",
      "  epoch= 123, mse_train=1.22, mse_val=2.00\n",
      "  epoch= 124, mse_train=1.21, mse_val=1.98\n",
      "  epoch= 125, mse_train=1.19, mse_val=1.97\n",
      "  epoch= 126, mse_train=1.18, mse_val=1.95\n",
      "  epoch= 127, mse_train=1.17, mse_val=1.94\n",
      "  epoch= 128, mse_train=1.16, mse_val=1.92\n",
      "  epoch= 129, mse_train=1.15, mse_val=1.91\n",
      "  epoch= 130, mse_train=1.14, mse_val=1.89\n",
      "  epoch= 131, mse_train=1.13, mse_val=1.88\n",
      "  epoch= 132, mse_train=1.12, mse_val=1.87\n",
      "  epoch= 133, mse_train=1.11, mse_val=1.85\n",
      "  epoch= 134, mse_train=1.10, mse_val=1.84\n",
      "  epoch= 135, mse_train=1.09, mse_val=1.83\n",
      "  epoch= 136, mse_train=1.08, mse_val=1.81\n",
      "  epoch= 137, mse_train=1.07, mse_val=1.80\n",
      "  epoch= 138, mse_train=1.06, mse_val=1.79\n",
      "  epoch= 139, mse_train=1.06, mse_val=1.78\n",
      "  epoch= 140, mse_train=1.05, mse_val=1.77\n",
      "  epoch= 141, mse_train=1.04, mse_val=1.76\n",
      "  epoch= 142, mse_train=1.03, mse_val=1.74\n",
      "  epoch= 143, mse_train=1.02, mse_val=1.73\n",
      "  epoch= 144, mse_train=1.02, mse_val=1.72\n",
      "  epoch= 145, mse_train=1.01, mse_val=1.71\n",
      "  epoch= 146, mse_train=1.00, mse_val=1.70\n",
      "  epoch= 147, mse_train=0.99, mse_val=1.69\n",
      "  epoch= 148, mse_train=0.99, mse_val=1.68\n",
      "  epoch= 149, mse_train=0.98, mse_val=1.67\n",
      "  epoch= 150, mse_train=0.97, mse_val=1.67\n",
      "  epoch= 151, mse_train=0.97, mse_val=1.66\n",
      "  epoch= 152, mse_train=0.96, mse_val=1.65\n",
      "  epoch= 153, mse_train=0.95, mse_val=1.64\n",
      "  epoch= 154, mse_train=0.95, mse_val=1.63\n",
      "  epoch= 155, mse_train=0.94, mse_val=1.62\n",
      "  epoch= 156, mse_train=0.93, mse_val=1.61\n",
      "  epoch= 157, mse_train=0.93, mse_val=1.61\n",
      "  epoch= 158, mse_train=0.92, mse_val=1.60\n",
      "  epoch= 159, mse_train=0.92, mse_val=1.59\n",
      "  epoch= 160, mse_train=0.91, mse_val=1.58\n",
      "  epoch= 161, mse_train=0.91, mse_val=1.58\n",
      "  epoch= 162, mse_train=0.90, mse_val=1.57\n",
      "  epoch= 163, mse_train=0.90, mse_val=1.56\n",
      "  epoch= 164, mse_train=0.89, mse_val=1.56\n",
      "  epoch= 165, mse_train=0.89, mse_val=1.55\n",
      "  epoch= 166, mse_train=0.88, mse_val=1.54\n",
      "  epoch= 167, mse_train=0.88, mse_val=1.54\n",
      "  epoch= 168, mse_train=0.87, mse_val=1.53\n",
      "  epoch= 169, mse_train=0.87, mse_val=1.52\n",
      "  epoch= 170, mse_train=0.86, mse_val=1.52\n",
      "  epoch= 171, mse_train=0.86, mse_val=1.51\n",
      "  epoch= 172, mse_train=0.85, mse_val=1.51\n",
      "  epoch= 173, mse_train=0.85, mse_val=1.50\n",
      "  epoch= 174, mse_train=0.84, mse_val=1.50\n",
      "  epoch= 175, mse_train=0.84, mse_val=1.49\n",
      "  epoch= 176, mse_train=0.84, mse_val=1.49\n",
      "  epoch= 177, mse_train=0.83, mse_val=1.48\n",
      "  epoch= 178, mse_train=0.83, mse_val=1.48\n",
      "  epoch= 179, mse_train=0.82, mse_val=1.47\n",
      "  epoch= 180, mse_train=0.82, mse_val=1.47\n",
      "  epoch= 181, mse_train=0.82, mse_val=1.46\n",
      "  epoch= 182, mse_train=0.81, mse_val=1.46\n",
      "  epoch= 183, mse_train=0.81, mse_val=1.45\n",
      "  epoch= 184, mse_train=0.81, mse_val=1.45\n",
      "  epoch= 185, mse_train=0.80, mse_val=1.45\n",
      "  epoch= 186, mse_train=0.80, mse_val=1.44\n",
      "  epoch= 187, mse_train=0.80, mse_val=1.44\n",
      "  epoch= 188, mse_train=0.79, mse_val=1.43\n",
      "  epoch= 189, mse_train=0.79, mse_val=1.43\n",
      "  epoch= 190, mse_train=0.79, mse_val=1.43\n",
      "  epoch= 191, mse_train=0.78, mse_val=1.42\n",
      "  epoch= 192, mse_train=0.78, mse_val=1.42\n",
      "  epoch= 193, mse_train=0.78, mse_val=1.42\n",
      "  epoch= 194, mse_train=0.77, mse_val=1.41\n",
      "  epoch= 195, mse_train=0.77, mse_val=1.41\n",
      "  epoch= 196, mse_train=0.77, mse_val=1.41\n",
      "  epoch= 197, mse_train=0.77, mse_val=1.40\n",
      "  epoch= 198, mse_train=0.76, mse_val=1.40\n",
      "  epoch= 199, mse_train=0.76, mse_val=1.40\n",
      "  epoch= 200, mse_train=0.76, mse_val=1.40\n",
      "  epoch= 201, mse_train=0.75, mse_val=1.39\n",
      "  epoch= 202, mse_train=0.75, mse_val=1.39\n",
      "  epoch= 203, mse_train=0.75, mse_val=1.39\n",
      "  epoch= 204, mse_train=0.75, mse_val=1.39\n",
      "  epoch= 205, mse_train=0.74, mse_val=1.39\n",
      "  epoch= 206, mse_train=0.74, mse_val=1.38\n",
      "  epoch= 207, mse_train=0.74, mse_val=1.38\n",
      "  epoch= 208, mse_train=0.74, mse_val=1.38\n",
      "  epoch= 209, mse_train=0.73, mse_val=1.38\n",
      "  epoch= 210, mse_train=0.73, mse_val=1.38\n",
      "  epoch= 211, mse_train=0.73, mse_val=1.37\n",
      "  epoch= 212, mse_train=0.73, mse_val=1.37\n",
      "  epoch= 213, mse_train=0.73, mse_val=1.37\n",
      "  epoch= 214, mse_train=0.72, mse_val=1.37\n",
      "  epoch= 215, mse_train=0.72, mse_val=1.37\n",
      "  epoch= 216, mse_train=0.72, mse_val=1.37\n",
      "  epoch= 217, mse_train=0.72, mse_val=1.36\n",
      "  epoch= 218, mse_train=0.72, mse_val=1.36\n",
      "  epoch= 219, mse_train=0.71, mse_val=1.36\n",
      "  epoch= 220, mse_train=0.71, mse_val=1.36\n",
      "  epoch= 221, mse_train=0.71, mse_val=1.36\n",
      "  epoch= 222, mse_train=0.71, mse_val=1.36\n",
      "  epoch= 223, mse_train=0.71, mse_val=1.36\n",
      "  epoch= 224, mse_train=0.70, mse_val=1.36\n",
      "  epoch= 225, mse_train=0.70, mse_val=1.36\n",
      "  epoch= 226, mse_train=0.70, mse_val=1.36\n",
      "  epoch= 227, mse_train=0.70, mse_val=1.36\n",
      "  epoch= 228, mse_train=0.70, mse_val=1.35\n",
      "  epoch= 229, mse_train=0.70, mse_val=1.35\n",
      "  epoch= 230, mse_train=0.69, mse_val=1.35\n",
      "  epoch= 231, mse_train=0.69, mse_val=1.35\n",
      "  epoch= 232, mse_train=0.69, mse_val=1.35\n",
      "  epoch= 233, mse_train=0.69, mse_val=1.35\n",
      "  epoch= 234, mse_train=0.69, mse_val=1.35\n",
      "  epoch= 235, mse_train=0.69, mse_val=1.35\n",
      "  epoch= 236, mse_train=0.68, mse_val=1.35\n",
      "  epoch= 237, mse_train=0.68, mse_val=1.35\n",
      "  epoch= 238, mse_train=0.68, mse_val=1.35\n",
      "  epoch= 239, mse_train=0.68, mse_val=1.35\n",
      "  epoch= 240, mse_train=0.68, mse_val=1.35\n",
      "  epoch= 241, mse_train=0.68, mse_val=1.35\n",
      "  epoch= 242, mse_train=0.67, mse_val=1.35\n",
      "  epoch= 243, mse_train=0.67, mse_val=1.35\n",
      "  epoch= 244, mse_train=0.67, mse_val=1.35\n",
      "  epoch= 245, mse_train=0.67, mse_val=1.35\n",
      "  epoch= 246, mse_train=0.67, mse_val=1.35\n",
      "  epoch= 247, mse_train=0.67, mse_val=1.35\n",
      "  epoch= 248, mse_train=0.67, mse_val=1.35\n",
      "  epoch= 249, mse_train=0.67, mse_val=1.35\n",
      "  epoch= 250, mse_train=0.66, mse_val=1.35\n",
      "  epoch= 251, mse_train=0.66, mse_val=1.35\n",
      "  epoch= 252, mse_train=0.66, mse_val=1.35\n",
      "  epoch= 253, mse_train=0.66, mse_val=1.36\n",
      "  epoch= 254, mse_train=0.66, mse_val=1.36\n",
      "  epoch= 255, mse_train=0.66, mse_val=1.36\n",
      "  epoch= 256, mse_train=0.66, mse_val=1.36\n",
      "  epoch= 257, mse_train=0.66, mse_val=1.36\n",
      "  epoch= 258, mse_train=0.65, mse_val=1.36\n",
      "  epoch= 259, mse_train=0.65, mse_val=1.36\n",
      "  epoch= 260, mse_train=0.65, mse_val=1.36\n",
      "  epoch= 261, mse_train=0.65, mse_val=1.36\n",
      "  epoch= 262, mse_train=0.65, mse_val=1.36\n",
      "  epoch= 263, mse_train=0.65, mse_val=1.36\n",
      "  epoch= 264, mse_train=0.65, mse_val=1.36\n",
      "  epoch= 265, mse_train=0.65, mse_val=1.37\n",
      "  epoch= 266, mse_train=0.65, mse_val=1.37\n",
      "  epoch= 267, mse_train=0.64, mse_val=1.37\n",
      "  epoch= 268, mse_train=0.64, mse_val=1.37\n",
      "  epoch= 269, mse_train=0.64, mse_val=1.37\n",
      "  epoch= 270, mse_train=0.64, mse_val=1.37\n",
      "  epoch= 271, mse_train=0.64, mse_val=1.37\n",
      "  epoch= 272, mse_train=0.64, mse_val=1.37\n",
      "  epoch= 273, mse_train=0.64, mse_val=1.37\n",
      "  epoch= 274, mse_train=0.64, mse_val=1.38\n",
      "  epoch= 275, mse_train=0.64, mse_val=1.38\n",
      "  epoch= 276, mse_train=0.64, mse_val=1.38\n",
      "  epoch= 277, mse_train=0.63, mse_val=1.38\n",
      "  epoch= 278, mse_train=0.63, mse_val=1.38\n",
      "  epoch= 279, mse_train=0.63, mse_val=1.38\n",
      "  epoch= 280, mse_train=0.63, mse_val=1.38\n",
      "  epoch= 281, mse_train=0.63, mse_val=1.39\n",
      "  epoch= 282, mse_train=0.63, mse_val=1.39\n",
      "  epoch= 283, mse_train=0.63, mse_val=1.39\n",
      "  epoch= 284, mse_train=0.63, mse_val=1.39\n",
      "  epoch= 285, mse_train=0.63, mse_val=1.39\n",
      "  epoch= 286, mse_train=0.63, mse_val=1.39\n",
      "  epoch= 287, mse_train=0.63, mse_val=1.40\n",
      "  epoch= 288, mse_train=0.62, mse_val=1.40\n",
      "  epoch= 289, mse_train=0.62, mse_val=1.40\n",
      "  epoch= 290, mse_train=0.62, mse_val=1.40\n",
      "  epoch= 291, mse_train=0.62, mse_val=1.40\n",
      "  epoch= 292, mse_train=0.62, mse_val=1.40\n",
      "  epoch= 293, mse_train=0.62, mse_val=1.41\n",
      "  epoch= 294, mse_train=0.62, mse_val=1.41\n",
      "  epoch= 295, mse_train=0.62, mse_val=1.41\n",
      "  epoch= 296, mse_train=0.62, mse_val=1.41\n",
      "  epoch= 297, mse_train=0.62, mse_val=1.41\n",
      "  epoch= 298, mse_train=0.62, mse_val=1.42\n",
      "  epoch= 299, mse_train=0.62, mse_val=1.42\n",
      "  epoch= 300, mse_train=0.61, mse_val=1.42\n",
      "  epoch= 301, mse_train=0.61, mse_val=1.42\n",
      "  epoch= 302, mse_train=0.61, mse_val=1.42\n",
      "  epoch= 303, mse_train=0.61, mse_val=1.43\n",
      "  epoch= 304, mse_train=0.61, mse_val=1.43\n",
      "  epoch= 305, mse_train=0.61, mse_val=1.43\n",
      "  epoch= 306, mse_train=0.61, mse_val=1.43\n",
      "  epoch= 307, mse_train=0.61, mse_val=1.43\n",
      "  epoch= 308, mse_train=0.61, mse_val=1.44\n",
      "  epoch= 309, mse_train=0.61, mse_val=1.44\n",
      "  epoch= 310, mse_train=0.61, mse_val=1.44\n",
      "  epoch= 311, mse_train=0.61, mse_val=1.44\n",
      "  epoch= 312, mse_train=0.61, mse_val=1.44\n",
      "  epoch= 313, mse_train=0.61, mse_val=1.45\n",
      "  epoch= 314, mse_train=0.60, mse_val=1.45\n",
      "  epoch= 315, mse_train=0.60, mse_val=1.45\n",
      "  epoch= 316, mse_train=0.60, mse_val=1.45\n",
      "  epoch= 317, mse_train=0.60, mse_val=1.46\n",
      "  epoch= 318, mse_train=0.60, mse_val=1.46\n",
      "  epoch= 319, mse_train=0.60, mse_val=1.46\n",
      "  epoch= 320, mse_train=0.60, mse_val=1.46\n",
      "  epoch= 321, mse_train=0.60, mse_val=1.47\n",
      "  epoch= 322, mse_train=0.60, mse_val=1.47\n",
      "  epoch= 323, mse_train=0.60, mse_val=1.47\n",
      "  epoch= 324, mse_train=0.60, mse_val=1.47\n",
      "  epoch= 325, mse_train=0.60, mse_val=1.48\n",
      "  epoch= 326, mse_train=0.60, mse_val=1.48\n",
      "  epoch= 327, mse_train=0.60, mse_val=1.48\n",
      "  epoch= 328, mse_train=0.60, mse_val=1.48\n",
      "  epoch= 329, mse_train=0.60, mse_val=1.49\n",
      "  epoch= 330, mse_train=0.59, mse_val=1.49\n",
      "  epoch= 331, mse_train=0.59, mse_val=1.49\n",
      "  epoch= 332, mse_train=0.59, mse_val=1.49\n",
      "  epoch= 333, mse_train=0.59, mse_val=1.50\n",
      "  epoch= 334, mse_train=0.59, mse_val=1.50\n",
      "  epoch= 335, mse_train=0.59, mse_val=1.50\n",
      "  epoch= 336, mse_train=0.59, mse_val=1.50\n",
      "  epoch= 337, mse_train=0.59, mse_val=1.51\n",
      "  epoch= 338, mse_train=0.59, mse_val=1.51\n",
      "  epoch= 339, mse_train=0.59, mse_val=1.51\n",
      "  epoch= 340, mse_train=0.59, mse_val=1.51\n",
      "  epoch= 341, mse_train=0.59, mse_val=1.52\n",
      "  epoch= 342, mse_train=0.59, mse_val=1.52\n",
      "  epoch= 343, mse_train=0.59, mse_val=1.52\n",
      "  epoch= 344, mse_train=0.59, mse_val=1.52\n",
      "  epoch= 345, mse_train=0.59, mse_val=1.53\n",
      "  epoch= 346, mse_train=0.59, mse_val=1.53\n",
      "  epoch= 347, mse_train=0.59, mse_val=1.53\n",
      "  epoch= 348, mse_train=0.58, mse_val=1.53\n",
      "  epoch= 349, mse_train=0.58, mse_val=1.54\n",
      "  epoch= 350, mse_train=0.58, mse_val=1.54\n",
      "  epoch= 351, mse_train=0.58, mse_val=1.54\n",
      "  epoch= 352, mse_train=0.58, mse_val=1.55\n",
      "  epoch= 353, mse_train=0.58, mse_val=1.55\n",
      "  epoch= 354, mse_train=0.58, mse_val=1.55\n",
      "  epoch= 355, mse_train=0.58, mse_val=1.55\n",
      "  epoch= 356, mse_train=0.58, mse_val=1.56\n",
      "  epoch= 357, mse_train=0.58, mse_val=1.56\n",
      "  epoch= 358, mse_train=0.58, mse_val=1.56\n",
      "  epoch= 359, mse_train=0.58, mse_val=1.57\n",
      "  epoch= 360, mse_train=0.58, mse_val=1.57\n",
      "  epoch= 361, mse_train=0.58, mse_val=1.57\n",
      "  epoch= 362, mse_train=0.58, mse_val=1.57\n",
      "  epoch= 363, mse_train=0.58, mse_val=1.58\n",
      "  epoch= 364, mse_train=0.58, mse_val=1.58\n",
      "  epoch= 365, mse_train=0.58, mse_val=1.58\n",
      "  epoch= 366, mse_train=0.58, mse_val=1.59\n",
      "  epoch= 367, mse_train=0.58, mse_val=1.59\n",
      "  epoch= 368, mse_train=0.58, mse_val=1.59\n",
      "  epoch= 369, mse_train=0.58, mse_val=1.59\n",
      "  epoch= 370, mse_train=0.57, mse_val=1.60\n",
      "  epoch= 371, mse_train=0.57, mse_val=1.60\n",
      "  epoch= 372, mse_train=0.57, mse_val=1.60\n",
      "  epoch= 373, mse_train=0.57, mse_val=1.61\n",
      "  epoch= 374, mse_train=0.57, mse_val=1.61\n",
      "  epoch= 375, mse_train=0.57, mse_val=1.61\n",
      "  epoch= 376, mse_train=0.57, mse_val=1.61\n",
      "  epoch= 377, mse_train=0.57, mse_val=1.62\n",
      "  epoch= 378, mse_train=0.57, mse_val=1.62\n",
      "  epoch= 379, mse_train=0.57, mse_val=1.62\n",
      "  epoch= 380, mse_train=0.57, mse_val=1.63\n",
      "  epoch= 381, mse_train=0.57, mse_val=1.63\n",
      "  epoch= 382, mse_train=0.57, mse_val=1.63\n",
      "  epoch= 383, mse_train=0.57, mse_val=1.64\n",
      "  epoch= 384, mse_train=0.57, mse_val=1.64\n",
      "  epoch= 385, mse_train=0.57, mse_val=1.64\n",
      "  epoch= 386, mse_train=0.57, mse_val=1.64\n",
      "  epoch= 387, mse_train=0.57, mse_val=1.65\n",
      "  epoch= 388, mse_train=0.57, mse_val=1.65\n",
      "  epoch= 389, mse_train=0.57, mse_val=1.65\n",
      "  epoch= 390, mse_train=0.57, mse_val=1.66\n",
      "  epoch= 391, mse_train=0.57, mse_val=1.66\n",
      "  epoch= 392, mse_train=0.57, mse_val=1.66\n",
      "  epoch= 393, mse_train=0.57, mse_val=1.67\n",
      "  epoch= 394, mse_train=0.57, mse_val=1.67\n",
      "  epoch= 395, mse_train=0.56, mse_val=1.67\n",
      "  epoch= 396, mse_train=0.56, mse_val=1.67\n",
      "  epoch= 397, mse_train=0.56, mse_val=1.68\n",
      "  epoch= 398, mse_train=0.56, mse_val=1.68\n",
      "  epoch= 399, mse_train=0.56, mse_val=1.68\n",
      "  epoch= 400, mse_train=0.56, mse_val=1.69\n",
      "  epoch= 401, mse_train=0.56, mse_val=1.69\n",
      "  epoch= 402, mse_train=0.56, mse_val=1.69\n",
      "  epoch= 403, mse_train=0.56, mse_val=1.70\n",
      "  epoch= 404, mse_train=0.56, mse_val=1.70\n",
      "  epoch= 405, mse_train=0.56, mse_val=1.70\n",
      "  epoch= 406, mse_train=0.56, mse_val=1.70\n",
      "  epoch= 407, mse_train=0.56, mse_val=1.71\n",
      "  epoch= 408, mse_train=0.56, mse_val=1.71\n",
      "  epoch= 409, mse_train=0.56, mse_val=1.71\n",
      "  epoch= 410, mse_train=0.56, mse_val=1.72\n",
      "  epoch= 411, mse_train=0.56, mse_val=1.72\n",
      "  epoch= 412, mse_train=0.56, mse_val=1.72\n",
      "  epoch= 413, mse_train=0.56, mse_val=1.73\n",
      "  epoch= 414, mse_train=0.56, mse_val=1.73\n",
      "  epoch= 415, mse_train=0.56, mse_val=1.73\n",
      "  epoch= 416, mse_train=0.56, mse_val=1.74\n",
      "  epoch= 417, mse_train=0.56, mse_val=1.74\n",
      "  epoch= 418, mse_train=0.56, mse_val=1.74\n",
      "  epoch= 419, mse_train=0.56, mse_val=1.74\n",
      "  epoch= 420, mse_train=0.56, mse_val=1.75\n",
      "  epoch= 421, mse_train=0.56, mse_val=1.75\n",
      "  epoch= 422, mse_train=0.56, mse_val=1.75\n",
      "  epoch= 423, mse_train=0.56, mse_val=1.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch= 424, mse_train=0.56, mse_val=1.76\n",
      "  epoch= 425, mse_train=0.55, mse_val=1.76\n",
      "  epoch= 426, mse_train=0.55, mse_val=1.77\n",
      "  epoch= 427, mse_train=0.55, mse_val=1.77\n",
      "  epoch= 428, mse_train=0.55, mse_val=1.77\n",
      "  epoch= 429, mse_train=0.55, mse_val=1.78\n",
      "  epoch= 430, mse_train=0.55, mse_val=1.78\n",
      "  epoch= 431, mse_train=0.55, mse_val=1.78\n",
      "  epoch= 432, mse_train=0.55, mse_val=1.78\n",
      "  epoch= 433, mse_train=0.55, mse_val=1.79\n",
      "  epoch= 434, mse_train=0.55, mse_val=1.79\n",
      "  epoch= 435, mse_train=0.55, mse_val=1.79\n",
      "  epoch= 436, mse_train=0.55, mse_val=1.80\n",
      "  epoch= 437, mse_train=0.55, mse_val=1.80\n",
      "  epoch= 438, mse_train=0.55, mse_val=1.80\n",
      "  epoch= 439, mse_train=0.55, mse_val=1.81\n",
      "  epoch= 440, mse_train=0.55, mse_val=1.81\n",
      "  epoch= 441, mse_train=0.55, mse_val=1.81\n",
      "  epoch= 442, mse_train=0.55, mse_val=1.82\n",
      "  epoch= 443, mse_train=0.55, mse_val=1.82\n",
      "  epoch= 444, mse_train=0.55, mse_val=1.82\n",
      "  epoch= 445, mse_train=0.55, mse_val=1.82\n",
      "  epoch= 446, mse_train=0.55, mse_val=1.83\n",
      "  epoch= 447, mse_train=0.55, mse_val=1.83\n",
      "  epoch= 448, mse_train=0.55, mse_val=1.83\n",
      "  epoch= 449, mse_train=0.55, mse_val=1.84\n",
      "  epoch= 450, mse_train=0.55, mse_val=1.84\n",
      "  epoch= 451, mse_train=0.55, mse_val=1.84\n",
      "  epoch= 452, mse_train=0.55, mse_val=1.85\n",
      "  epoch= 453, mse_train=0.55, mse_val=1.85\n",
      "  epoch= 454, mse_train=0.55, mse_val=1.85\n",
      "  epoch= 455, mse_train=0.55, mse_val=1.86\n",
      "  epoch= 456, mse_train=0.55, mse_val=1.86\n",
      "  epoch= 457, mse_train=0.55, mse_val=1.86\n",
      "  epoch= 458, mse_train=0.55, mse_val=1.86\n",
      "  epoch= 459, mse_train=0.55, mse_val=1.87\n",
      "  epoch= 460, mse_train=0.55, mse_val=1.87\n",
      "  epoch= 461, mse_train=0.55, mse_val=1.87\n",
      "  epoch= 462, mse_train=0.55, mse_val=1.88\n",
      "  epoch= 463, mse_train=0.54, mse_val=1.88\n",
      "  epoch= 464, mse_train=0.54, mse_val=1.88\n",
      "  epoch= 465, mse_train=0.54, mse_val=1.89\n",
      "  epoch= 466, mse_train=0.54, mse_val=1.89\n",
      "  epoch= 467, mse_train=0.54, mse_val=1.89\n",
      "  epoch= 468, mse_train=0.54, mse_val=1.89\n",
      "  epoch= 469, mse_train=0.54, mse_val=1.90\n",
      "  epoch= 470, mse_train=0.54, mse_val=1.90\n",
      "  epoch= 471, mse_train=0.54, mse_val=1.90\n",
      "  epoch= 472, mse_train=0.54, mse_val=1.91\n",
      "  epoch= 473, mse_train=0.54, mse_val=1.91\n",
      "  epoch= 474, mse_train=0.54, mse_val=1.91\n",
      "  epoch= 475, mse_train=0.54, mse_val=1.92\n",
      "  epoch= 476, mse_train=0.54, mse_val=1.92\n",
      "  epoch= 477, mse_train=0.54, mse_val=1.92\n",
      "  epoch= 478, mse_train=0.54, mse_val=1.92\n",
      "  epoch= 479, mse_train=0.54, mse_val=1.93\n",
      "  epoch= 480, mse_train=0.54, mse_val=1.93\n",
      "  epoch= 481, mse_train=0.54, mse_val=1.93\n",
      "  epoch= 482, mse_train=0.54, mse_val=1.94\n",
      "  epoch= 483, mse_train=0.54, mse_val=1.94\n",
      "  epoch= 484, mse_train=0.54, mse_val=1.94\n",
      "  epoch= 485, mse_train=0.54, mse_val=1.95\n",
      "  epoch= 486, mse_train=0.54, mse_val=1.95\n",
      "  epoch= 487, mse_train=0.54, mse_val=1.95\n",
      "  epoch= 488, mse_train=0.54, mse_val=1.95\n",
      "  epoch= 489, mse_train=0.54, mse_val=1.96\n",
      "  epoch= 490, mse_train=0.54, mse_val=1.96\n",
      "  epoch= 491, mse_train=0.54, mse_val=1.96\n",
      "  epoch= 492, mse_train=0.54, mse_val=1.97\n",
      "  epoch= 493, mse_train=0.54, mse_val=1.97\n",
      "  epoch= 494, mse_train=0.54, mse_val=1.97\n",
      "  epoch= 495, mse_train=0.54, mse_val=1.97\n",
      "  epoch= 496, mse_train=0.54, mse_val=1.98\n",
      "  epoch= 497, mse_train=0.54, mse_val=1.98\n",
      "  epoch= 498, mse_train=0.54, mse_val=1.98\n",
      "  epoch= 499, mse_train=0.54, mse_val=1.99\n",
      "OK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Run code: Qb(part II)\n",
    "\n",
    "def Train(X_train, y_train, X_val, y_val, n_epochs, verbose=False):\n",
    "    print(\"Training...n_epochs=\",n_epochs)\n",
    "    \n",
    "    train_errors, val_errors = [], []\n",
    "    \n",
    "    sgd_reg = SGDRegressor(max_iter=1,\n",
    "                           penalty=None,\n",
    "                           eta0=0.0005,\n",
    "                           warm_start=True,\n",
    "                           early_stopping=False,\n",
    "                           learning_rate=\"constant\",\n",
    "                           # Had to change this to 0 instead of \"inf\" to fix the error \n",
    "                           tol=-float(0), \n",
    "                           random_state=42)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        \n",
    "        sgd_reg.fit(X_train, y_train)\n",
    "        \n",
    "        y_train_predict = sgd_reg.predict(X_train)\n",
    "        y_val_predict   = sgd_reg.predict(X_val)\n",
    "\n",
    "        mse_train=mean_squared_error(y_train, y_train_predict)\n",
    "        mse_val  =mean_squared_error(y_val  , y_val_predict)\n",
    "\n",
    "        train_errors.append(mse_train)\n",
    "        val_errors  .append(mse_val)\n",
    "        if verbose:\n",
    "            print(f\"  epoch={epoch:4d}, mse_train={mse_train:4.2f}, mse_val={mse_val:4.2f}\")\n",
    "\n",
    "    return train_errors, val_errors\n",
    "\n",
    "n_epochs = 500\n",
    "train_errors, val_errors = Train(X_train_poly_scaled, y_train, X_val_poly_scaled, y_val, n_epochs, True)\n",
    "\n",
    "print('OK')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 3\n",
    "\n",
    "The code below is used to plot the training and validation errors. Here we can see which model is the best and this is also indicated with an annotation on the graph. This is when the RMSE is the lowest near the dotted horizontal line going parralel to the x-axis. this model will be the best model for new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T09:34:50.685705Z",
     "start_time": "2023-11-30T09:34:50.605148Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "# Run code: Qb(part III)\n",
    "\n",
    "best_epoch = np.argmin(val_errors)\n",
    "best_val_rmse = np.sqrt(val_errors[best_epoch])\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.annotate('Best model',\n",
    "             xy=(best_epoch, best_val_rmse),\n",
    "             xytext=(best_epoch, best_val_rmse + 1),\n",
    "             ha=\"center\",\n",
    "             arrowprops=dict(facecolor='black', shrink=0.05),\n",
    "             fontsize=16,\n",
    "            )\n",
    "\n",
    "best_val_rmse -= 0.03  # just to make the graph look better\n",
    "plt.plot([0, n_epochs], [best_val_rmse, best_val_rmse], \"k:\", linewidth=2)\n",
    "plt.plot(np.sqrt(train_errors), \"b--\", linewidth=2, label=\"Training set\")\n",
    "plt.plot(np.sqrt(val_errors), \"g-\", linewidth=3, label=\"Validation set\")\n",
    "plt.legend(loc=\"upper right\", fontsize=14)\n",
    "plt.xlabel(\"Epoch\", fontsize=14)\n",
    "plt.ylabel(\"RMSE\", fontsize=14)\n",
    "plt.show()\n",
    "\n",
    "print('OK')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qc)  Early Stopping\n",
    "\n",
    "Now we are going to implement early stopping in the code above.\n",
    "The early stopping could be implemented as a pseudo code like this:\n",
    "\n",
    "```python\n",
    "best_val_error = float(\"inf\")\n",
    "best_epoch = None\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    ...\n",
    "   \n",
    "    if val_error < best_val_error:\n",
    "        best_val_error = val_error\n",
    "        best_epoch = epoch\n",
    "    \n",
    "    if val_error > best_val_error:\n",
    "        printf(\"early stopping\")\n",
    "        break\n",
    "``` \n",
    "\n",
    "Where we stop the training when the validation error ( val_error ) is higher than the best validation error ( best_val_error )."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qd) Explain the Polynomial RMSE-Capacity plot\n",
    "\n",
    "#### Why does the _training error_ keep dropping, while the _CV-error_ drops until around capacity 3, and then begin to rise again?\n",
    "\n",
    "As the model complexity increases the model becoumes more better at fitting the training data. It continues to decrease as the model adjusts to noice in the training data.\n",
    "\n",
    "For the validation RMSE it is initially decresing as the model is learning the patterns in the training data. When the model complexity increases the model starts to overfit the training data and the validation RMSE starts to increase. This leads to the model being worse for new unseen data becuase it becomes to specific to the training data.\n",
    "\n",
    "#### What does the x-axis _Capacity_ and y-axis _RMSE_ represent?\n",
    "The x-axis with capacity represents the complexity of the model, specifilly the degree of polynominal features of the regression model. The y-axis with RMSE represents the error of the model.\n",
    "\n",
    "#### Increasing the model capacity. What happens when you do plots for `degrees` larger than around 10? Relate this with what you found via Qa+b in `capacity_under_overfitting.ipynb`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T09:34:50.834563Z",
     "start_time": "2023-11-30T09:34:50.692344Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterating...degrees= range(1, 8)\n",
      "  degree=   1, rmse_training=0.48, rmse_cv=0.64\n",
      "  degree=   2, rmse_training=0.17, rmse_cv=0.24\n",
      "  degree=   3, rmse_training=0.11, rmse_cv=0.14\n",
      "  degree=   4, rmse_training=0.11, rmse_cv=0.21\n",
      "  degree=   5, rmse_training=0.10, rmse_cv=0.31\n",
      "  degree=   6, rmse_training=0.10, rmse_cv=0.34\n",
      "  degree=   7, rmse_training=0.10, rmse_cv=0.44\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "# Run and review this code\n",
    "# NOTE: modified code from [GITHOML], 04_training_linear_models.ipynb\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from math import sqrt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def true_fun(X):\n",
    "    return np.cos(1.5 * np.pi * X)\n",
    "\n",
    "def GenerateData():\n",
    "    n_samples = 30\n",
    "    #degrees = [1, 4, 15]\n",
    "    degrees = range(1,8)\n",
    "\n",
    "    X = np.sort(np.random.rand(n_samples))\n",
    "    y = true_fun(X) + np.random.randn(n_samples) * 0.1\n",
    "    return X, y, degrees\n",
    "\n",
    "np.random.seed(0)\n",
    "X, y, degrees  = GenerateData()\n",
    "\n",
    "print(\"Iterating...degrees=\",degrees)\n",
    "capacities, rmses_training, rmses_validation= [], [], []\n",
    "for i in range(len(degrees)):\n",
    "    d=degrees[i]\n",
    "    \n",
    "    polynomial_features = PolynomialFeatures(degree=d, include_bias=False)\n",
    "    \n",
    "    linear_regression = LinearRegression()\n",
    "    pipeline = Pipeline([\n",
    "            (\"polynomial_features\", polynomial_features),\n",
    "            (\"linear_regression\", linear_regression)\n",
    "        ])\n",
    "    \n",
    "    Z = X[:, np.newaxis]\n",
    "    pipeline.fit(Z, y)\n",
    "    \n",
    "    p = pipeline.predict(Z)\n",
    "    train_rms = mean_squared_error(y,p)\n",
    "\n",
    "    # Evaluate the models using crossvalidation\n",
    "    scores = cross_val_score(pipeline, Z, y, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "    score_mean = -scores.mean()\n",
    "    \n",
    "    rmse_training=sqrt(train_rms)\n",
    "    rmse_validation=sqrt(score_mean)\n",
    "    \n",
    "    print(f\"  degree={d:4d}, rmse_training={rmse_training:4.2f}, rmse_cv={rmse_validation:4.2f}\")\n",
    "    \n",
    "    capacities      .append(d)\n",
    "    rmses_training  .append(rmse_training)\n",
    "    rmses_validation.append(rmse_validation)\n",
    "    \n",
    "plt.figure(figsize=(7,4))\n",
    "plt.plot(capacities, rmses_training,  \"b--\", linewidth=2, label=\"training RMSE\")\n",
    "plt.plot(capacities, rmses_validation,\"g-\",  linewidth=2, label=\"validation RMSE\")\n",
    "plt.legend(loc=\"upper right\", fontsize=14)\n",
    "plt.xlabel(\"Capacity\", fontsize=14)\n",
    "plt.ylabel(\"RMSE\", fontsize=14)\n",
    "plt.show()\n",
    "\n",
    "print('OK')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Increasing the model capacity. What happens when you do plots for `degrees` larger than around 10? Relate this with what you found via Qa+b in `capacity_under_overfitting.ipynb`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T09:34:50.984886Z",
     "start_time": "2023-11-30T09:34:50.832387Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterating...degrees= range(1, 12)\n",
      "  degree=   1, rmse_training=0.48, rmse_cv=0.64\n",
      "  degree=   2, rmse_training=0.17, rmse_cv=0.24\n",
      "  degree=   3, rmse_training=0.11, rmse_cv=0.14\n",
      "  degree=   4, rmse_training=0.11, rmse_cv=0.21\n",
      "  degree=   5, rmse_training=0.10, rmse_cv=0.31\n",
      "  degree=   6, rmse_training=0.10, rmse_cv=0.34\n",
      "  degree=   7, rmse_training=0.10, rmse_cv=0.44\n",
      "  degree=   8, rmse_training=0.10, rmse_cv=0.60\n",
      "  degree=   9, rmse_training=0.10, rmse_cv=4.61\n",
      "  degree=  10, rmse_training=0.10, rmse_cv=38.94\n",
      "  degree=  11, rmse_training=0.10, rmse_cv=154.97\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "# Run and review this code\n",
    "# NOTE: modified code from [GITHOML], 04_training_linear_models.ipynb\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from math import sqrt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def true_fun(X):\n",
    "    return np.cos(1.5 * np.pi * X)\n",
    "\n",
    "def GenerateData():\n",
    "    n_samples = 30\n",
    "    #degrees = [1, 4, 15]\n",
    "    degrees = range(1,12)\n",
    "\n",
    "    X = np.sort(np.random.rand(n_samples))\n",
    "    y = true_fun(X) + np.random.randn(n_samples) * 0.1\n",
    "    return X, y, degrees\n",
    "\n",
    "np.random.seed(0)\n",
    "X, y, degrees  = GenerateData()\n",
    "\n",
    "print(\"Iterating...degrees=\",degrees)\n",
    "capacities, rmses_training, rmses_validation= [], [], []\n",
    "for i in range(len(degrees)):\n",
    "    d=degrees[i]\n",
    "    \n",
    "    polynomial_features = PolynomialFeatures(degree=d, include_bias=False)\n",
    "    \n",
    "    linear_regression = LinearRegression()\n",
    "    pipeline = Pipeline([\n",
    "            (\"polynomial_features\", polynomial_features),\n",
    "            (\"linear_regression\", linear_regression)\n",
    "        ])\n",
    "    \n",
    "    Z = X[:, np.newaxis]\n",
    "    pipeline.fit(Z, y)\n",
    "    \n",
    "    p = pipeline.predict(Z)\n",
    "    train_rms = mean_squared_error(y,p)\n",
    "\n",
    "    # Evaluate the models using crossvalidation\n",
    "    scores = cross_val_score(pipeline, Z, y, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "    score_mean = -scores.mean()\n",
    "    \n",
    "    rmse_training=sqrt(train_rms)\n",
    "    rmse_validation=sqrt(score_mean)\n",
    "    \n",
    "    print(f\"  degree={d:4d}, rmse_training={rmse_training:4.2f}, rmse_cv={rmse_validation:4.2f}\")\n",
    "    \n",
    "    capacities      .append(d)\n",
    "    rmses_training  .append(rmse_training)\n",
    "    rmses_validation.append(rmse_validation)\n",
    "    \n",
    "plt.figure(figsize=(7,4))\n",
    "plt.plot(capacities, rmses_training,  \"b--\", linewidth=2, label=\"training RMSE\")\n",
    "plt.plot(capacities, rmses_validation,\"g-\",  linewidth=2, label=\"validation RMSE\")\n",
    "plt.legend(loc=\"upper right\", fontsize=14)\n",
    "plt.xlabel(\"Capacity\", fontsize=14)\n",
    "plt.ylabel(\"RMSE\", fontsize=14)\n",
    "plt.show()\n",
    "\n",
    "print('OK')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After increacing the capacity we now see that the RMSE of the validation goes exponetial and at 10 capacity it is grown very much. This is because the model is overfitting the training data and is not able to predict new data. This is also what we found in Qa+b in `capacity_under_overfitting.ipynb` where we saw that the model was overfitting the training data and was not able to predict new data when degress was too high."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SWMAL Exercise\n",
    "\n",
    "## Model capacity and under/overfitting\n",
    "\n",
    "### Qa) Explain the polynomial fitting via code review\n",
    "\n",
    "In the code below the underfitting and overfitting concepts are demonstrated in polynomial regression.\n",
    "\n",
    "The first function definition `true_fun` is the true function we want to fit, and the second function `GenerateData` generates the data samples from the true function, with some added noise. \n",
    "\n",
    "Next part that is defined is the degress which are used to fit the polynomial regression model.  \n",
    "\n",
    "The next part is the for loop, where we fit the polynomial regression models of different degrees (1, 4, 15) to the data, and evaluates their performance using cross-validation. \n",
    "\n",
    "The true function is a cosine curve with added random noise. The code uses scikit-learn's Pipeline to create a polynomial regression model and calculates mean squared error scores for each degree. The results show how model complexity (degree) affects performance, highlighting the trade-off between underfitting and overfitting. \n",
    "\n",
    "Finally the loop ends with prints of the cross-validation sub-scores for each fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T09:34:51.132596Z",
     "start_time": "2023-11-30T09:34:50.993637Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterating...degrees= [1, 4, 15]\n",
      "  degree=   1, score_mean=-0.41,  PolynomialFeatures(degree=1, include_bias=False)\n",
      "    CV sub-scores:  mean = -0.41,  std = 0.43\n",
      "      CV fold 0  =>  score = -1.2\n",
      "      CV fold 1  =>  score = -0.2\n",
      "      CV fold 2  =>  score = -0.044\n",
      "      CV fold 3  =>  score = -0.36\n",
      "      CV fold 4  =>  score = -0.28\n",
      "      CV fold 5  =>  score = -0.3\n",
      "      CV fold 6  =>  score = -0.18\n",
      "      CV fold 7  =>  score = -0.0086\n",
      "      CV fold 8  =>  score = -0.25\n",
      "      CV fold 9  =>  score = -1.3\n",
      "  degree=   4, score_mean=-0.04,  PolynomialFeatures(degree=4, include_bias=False)\n",
      "    CV sub-scores:  mean = -0.043,  std = 0.071\n",
      "      CV fold 0  =>  score = -0.25\n",
      "      CV fold 1  =>  score = -0.042\n",
      "      CV fold 2  =>  score = -0.027\n",
      "      CV fold 3  =>  score = -0.029\n",
      "      CV fold 4  =>  score = -0.0049\n",
      "      CV fold 5  =>  score = -0.0049\n",
      "      CV fold 6  =>  score = -0.019\n",
      "      CV fold 7  =>  score = -0.038\n",
      "      CV fold 8  =>  score = -0.012\n",
      "      CV fold 9  =>  score = -0.0029\n",
      "  degree=  15, score_mean=-182663732.56,  PolynomialFeatures(degree=15, include_bias=False)\n",
      "    CV sub-scores:  mean = -1.8e+08,  std = 5.5e+08\n",
      "      CV fold 0  =>  score = -1.8e+09\n",
      "      CV fold 1  =>  score = -3.4e+04\n",
      "      CV fold 2  =>  score = -0.0051\n",
      "      CV fold 3  =>  score = -0.007\n",
      "      CV fold 4  =>  score = -0.0092\n",
      "      CV fold 5  =>  score = -0.069\n",
      "      CV fold 6  =>  score = -0.051\n",
      "      CV fold 7  =>  score = -0.079\n",
      "      CV fold 8  =>  score = -0.074\n",
      "      CV fold 9  =>  score = -3.5e+03\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABG8AAAHOCAYAAAAmKyQdAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAD3QklEQVR4nOzdd3iTZRfH8W/SvVtaZil7DwERkCFLkCHKEBfIUEEciHsP3IK+TmQ4AZmKICIyVDYCArJn2XuW2ULput8/QgKhBZqudPw+15WL9skzTppwkp7e97ktxhiDiIiIiIiIiIjkSlZ3ByAiIiIiIiIiIlen4o2IiIiIiIiISC6m4o2IiIiIiIiISC6m4o2IiIiIiIiISC6m4o2IiIiIiIiISC6m4o2IiIiIiIiISC6m4o2IiIiIiIiISC6m4o2IiIiIiIiISC6m4o2IiIiIiIiISC6m4o1kq1GjRmGxWBw3X19fihUrRosWLfjwww85evSou0PMEfv37+fpp5+mWbNmhIaGYrFYGDVqlLvDEhHJFsr9aXv99dexWCzUqFHD3aGIiGSYcryNK5/vmzdv7vQzs9/atm2bs0FLnqbijeSIkSNHsnTpUv766y+GDh1K7dq1GTx4MFWrVuXvv/92d3jZbvv27YwbNw5vb2/at2/v7nBERHJEQc/9l1uzZg3/+9//KFq0qLtDERHJEgU9x7v6+b5cuXIsXbrU6fb5559nf6CSb3i6OwApGGrUqMFNN93k+P6uu+7imWeeoUmTJnTp0oVt27bl+Afa8+fP4+fnlyPXatq0KceOHQNg5cqVTJgwIUeuKyLiTgU999slJSXx4IMP0q9fP9auXcvx48dz9PoiItmhoOd4Vz/f+/n5cfPNN+dEaJJPaeSNuE2pUqX45JNPOHv2LF9//bXTfStXruTOO++kUKFC+Pr6UqdOHX7++edU51i8eDENGzbE19eXyMhI3njjDb777jssFgu7d+927FemTBk6dOjAlClTqFOnDr6+vrz99tsAHD58mH79+lGyZEm8vb0pW7Ysb7/9NklJSU7XSkhI4L333qNKlSr4+PhQuHBhHnzwQUfSvharVf/VRESgYOV+u0GDBnHixAnef/99F35SIiJ5T0HK8fp8LzlNI2/Erdq3b4+HhwcLFy50bJs3bx5t27alQYMGjBgxgpCQECZOnMi9997LuXPn6N27NwDr1q2jdevWVKpUidGjR+Pv78+IESMYO3ZsmtdatWoVmzdv5vXXX6ds2bIEBARw+PBh6tevj9Vq5c0336R8+fIsXbqU9957j927dzNy5EgAUlJS6NixI4sWLeLFF1+kUaNG7Nmzh4EDB9K8eXNWrlyZ43/JFRHJqwpS7t+0aRPvvfceU6ZMITAwMGt+gCIiuVhByvGu2LFjB4UKFeLMmTOULl2a++67j9dff12/Q0j6GZFsNHLkSAOYFStWXHWfokWLmqpVqzq+r1KliqlTp45JTEx02q9Dhw6mePHiJjk52RhjzN13320CAgLMsWPHHPskJyebatWqGcDs2rXLsb106dLGw8PDbN261emc/fr1M4GBgWbPnj1O2//3v/8ZwGzcuNEYY8yECRMMYCZPnuy034oVKwxghg0blo6fhvMxI0eOTPcxIiJ5iXL/pbgaNGhg7r//fse2Zs2amerVq1/zOBGR3Ew5PrXrfb5/7bXXzLBhw8zcuXPNH3/8Yfr37288PT1N06ZNHY9d5Ho01kvczhjj+Hr79u1s2bKF7t27A7Y+AfZb+/btOXToEFu3bgVgwYIFtGzZkoiICMfxVquVe+65J83r3HDDDVSqVMlp2/Tp02nRogUlSpRwula7du0c17DvFxoayh133OG0X+3atSlWrBjz58/Psp+HiEhBUBBy/6effsq2bdvUkFJECpyCkONd8d577/HYY4/RokUL2rdvz5AhQxg0aBALFy7kt99+y7LrSP6maVPiVnFxccTExFCzZk0Ajhw5AsDzzz/P888/n+Yx9kaPMTExaTZBu1pjtOLFi6faduTIEX7//Xe8vLyuea0jR45w6tQpvL29r7mfiIhcX0HI/Xv37uXNN99k0KBBeHt7c+rUKcD2S0tKSgqnTp3Cx8dHw+VFJN8pCDk+KzzwwAM8//zzLFu2jM6dO2frtSR/UPFG3OqPP/4gOTmZ5s2bAziq7K+88gpdunRJ85jKlSsDEB4e7ngzuNzhw4fTPM5isaTaFhERwQ033HDVJpIlSpRw7BceHs6sWbPS3C8oKCjN7SIiklpByP07d+7k/PnzPPXUUzz11FOp7g8LC+Opp57SqBwRyXcKQo7PSmp8LOml4o24zd69e3n++ecJCQmhX79+gC1xV6xYkbVr1/LBBx9c8/hmzZoxY8YMjh8/7nhTSElJYdKkSemOoUOHDsyYMYPy5csTFhZ2zf0mTpxIcnIyDRo0SPf5RUTEWUHJ/bVr12bevHmptj/99NOcPn2akSNHUrJkSZfOKSKS2xWUHJ8VRo8eDaDlwyXdVLyRHLFhwwbHPNKjR4+yaNEiRo4ciYeHB7/++iuFCxd27Pv111/Trl072rRpQ+/evYmMjOTEiRNs3ryZVatWOZL3a6+9xu+//86tt97Ka6+9hp+fHyNGjCAuLg5IXxX7nXfe4a+//qJRo0YMGDCAypUrEx8fz+7du5kxYwYjRoygZMmS3HfffYwbN4727dvz1FNPUb9+fby8vNi/fz/z5s2jY8eO1x3u+MsvvwC2v8aCbblE+8ojXbt2df2HKiKSyxXk3B8aGur4q/OV25OSktK8T0QkLynIOd4uPZ/vFy1axPvvv0/nzp0pV64c8fHxzJw5k2+++YaWLVtyxx13uPiTlwLLzQ2TJZ+zd6O337y9vU2RIkVMs2bNzAcffGCOHj2a5nFr164199xzjylSpIjx8vIyxYoVMy1btjQjRoxw2m/RokWmQYMGxsfHxxQrVsy88MILZvDgwQYwp06dcuxXunRpc/vtt6d5rWPHjpkBAwaYsmXLGi8vL1OoUCFTt25d89prr5nY2FjHfomJieZ///ufqVWrlvH19TWBgYGmSpUqpl+/fmbbtm3X/Vlc/nO48iYikp8o91+dVpsSkbxOOf6S9Hy+37Ztm2nfvr2JjIw0Pj4+xtfX19SsWdO8//77Jj4+/rrXELGzGHNZK3CRfOC2225j9+7dREdHuzsUERHJIcr9IiL5l3K8iKZNSR737LPPUqdOHaKiojhx4gTjxo3jr7/+4vvvv3d3aCIikk2U+0VE8i/leJG0qXgjeVpycjJvvvkmhw8fxmKxUK1aNcaMGcMDDzzg7tBERCSbKPeLiORfyvEiadO0KRERERERERGRXEyLyouIiIiIiIiI5GIq3oiIiIiIiIiI5GJuKd78+++/dO7cmVKlSuHj40PRokVp2LAhzz33nDvCcUliYiJVqlRh0KBB1913/vz5WCwWLBYLo0aNSnOfli1bYrFYKFOmjNP2uLg4Bg8eTK1atQgODiYoKIjy5ctzzz33sGDBgjSvkdbt8us2bdqUp59+OgOPOmcYY2jatCkWi4X+/fun+7i///6bhg0b4u/vT0REBL179+bo0aOp9tu+fTs9evSgVKlS+Pn5Ub58eZ599lliYmKy8mEAttfJ22+/TZkyZfDx8aFKlSoMGTIk1X4bN27k8ccfp2HDhgQEBGCxWJg/f/5Vz7tjxw58fHxYunRplsU6bdo0PD09OXbsWKbO4+rzd+bMGd5//32aN29OsWLFCAwMpGbNmgwePJj4+HinfXfv3n3V1/jEiRMzFXdasvr5O3nyJKGhoUydOjXLY81LlPsvUe6/JCO5/7XXXqNOnToUKlQIX19fypUrxyOPPMKePXuc9vvvv/944oknqFmzJkFBQRQtWpRWrVoxd+7c7Hgo6c4d3333HZ06daJMmTL4+flRoUIFHnvsMQ4dOpTmeXNb7r/Wa69KlSrpOkdefu9O7/NXUHK/cvslBT23L168mD59+lC3bl18fHywWCzs3r073cdfuHCBjz/+mBo1ahAQEEDRokVp164dS5Yscdpv3759dO7cmXLlyhEQEEBISAh16tThq6++IikpKYsf1fUdPXqU3r17ExERgb+/Pw0bNmTOnDmp9kvv47P78ccfKVy4MGfPns2yWJ999llq1aqVoWPLlCmT5uvy0UcfdflcmzZtcrxGVq5cmer+efPm0bp1a4oUKUJgYCA33HADX375JcnJyRmKPTNWrVpFq1atCAwMJDQ0lC5durBz585U+x0+fJj+/ftTrlw5/Pz8KF26NA8//DB79+512u+NN97gxhtvJCUlxfVgcnpt8unTpxur1WpatmxpJkyYYObPn28mTJhgnnvuORMZGZnT4bjs888/N0WKFDGxsbHX3XfevHkGMEFBQaZJkyap7t+5c6exWCwmODjYlC5d2rE9KSnJNGrUyAQFBZl33nnHzJo1y8yaNcsMGTLE3Hbbbebdd99NdY0PPvjALF26NNXt6NGjjn3nz59vvLy8zJYtWzL3Q8gmQ4YMMcWLFzeAeeKJJ9J1zPz5842np6fp2LGj+fPPP83YsWNNZGSkqVGjhomPj3fsd/ToURMeHm7Kli1rRo0aZebOnWs++eQTExgYaGrXrm2Sk5Oz9LH06dPH+Pj4mI8++sjMmzfPvPzyy8ZisZj333/fab9Ro0aZ4sWLm/bt25s77rjDAGbevHlXPW+nTp3M7bffnqWx9uzZ07Ro0SLT53H1+Vu/fr2JiIgwzzzzjPntt9/MnDlzzFtvvWV8fX3NrbfealJSUhz77tq1ywDmySefTPUaP378eKZjv1J2PH9vvfWWqVChgrlw4UKWx5sXKPdfotzvLCO5//HHHzeDBw8206ZNM/PmzTNDhw41xYsXN0WLFnXKCc8995y56aabzKeffmrmzJljpk2bZtq3b28AM3r06Cx/LOnNHSVKlDDdu3c348aNM/Pnzzdff/21KVmypClevLg5fPhwqvPmttyf1mvu888/N4B5+eWXr3t8Xn/vduX5y++5X7n9EuV22+u9dOnSplOnTqZ58+YGMLt27Ur38T169DBWq9W89tprZs6cOWbSpEmmbt26xtPT0/z777+O/TZv3mx69uxpfvjhB/P333+bGTNmmP79+xvAPPzww9nwyK4uPj7e1KhRw5QsWdKMHTvW/Pnnn6Zjx47G09PTzJ8/P0OPzxhj4uLiTGRkpPn444+zNN7SpUubt99+O8PHNm7cONXrcufOnS6dJykpyTRo0MCUKFHCAGbFihVO9//111/GarWa5s2bm6lTp5q//vrLPPnkkwYwAwYMyFDsGbV582YTFBRkbrnlFvPHH3+YyZMnm+rVq5sSJUo4/X+Mj483FStWNBEREWbo0KFm3rx5ZsSIEaZo0aImMjLSnDlzxrHvqVOnTGhoqPnhhx9cjifHizdNmzY15cuXN4mJianuy+o34euJi4tzaf/ExEQTGRmZrg8mxlxKwH369DGAiY6Odrr/9ddfNyVLljTt2rVzSvJz5841wFWf0Mt/TvZrTJo0KV0x1ahRw/Tt2zdd++akXbt2mcDAQDNlyhSXPsDXq1fPVKtWzen19M8//xjADBs2zLHt22+/NYD5+++/nY7/4IMPDGBWrVqVNQ/EGLNhwwZjsVjMBx984LS9b9++xs/Pz8TExDi2Xf5cTpo06Zq//G/atMkAZtasWdeNATAjR4687n4JCQkmNDTUfPXVV9fd91oy8vzFxsam+WHp448/NoBZtGiR0/mBLH8DS0t2PX+HDx82np6eZty4cdkSd26n3H+Jcv8lGc39aZkxY4YBzPfff+/YduTIkVT7JSUlmRtuuMGUL18+w9dKiyu5I624VqxYYQCnX+SMyd25/3K9e/c2FovFbNu27br75vX3bleev/ye+5XbL1Fud34s9s9z6S3exMfHGw8PD/PAAw84bT948GC6f2m/5557jKenp1MRODOaNWtmevXqdc19hg4dagCzZMkSx7bExERTrVo1U79+fcc2Vx/fsGHDjK+vrzl58uQ1r29/zaTn57x8+XIDmA0bNlx337SULl06S/6Q8PHHH5vIyEjzxRdfpFm86d69u/Hx8Un1e8Jtt91mgoODM319u/S8Z959990mIiLCnD592rFt9+7dxsvLy7z44ouObX/99ZcBzHfffed0/Pjx4w1gpkyZ4rS9f//+plKlSk5/rE6PHJ82FRMTQ0REBJ6eqVcpt1pThzN+/HgaNmxIYGAggYGB1K5dm++//95pnx9++IFatWrh6+tLoUKF6Ny5M5s3b3bap3fv3gQGBrJ+/Xpuu+02goKCuPXWWwFISEjgvffeo0qVKvj4+FC4cGEefPDBVEOJp02bxoEDB+jRo4dLj7l169ZERUXxww8/OLalpKQwevRoevXqlepx24cCFy9ePM3zpfVzSq8ePXowfvz4LB1+lxUeeeQRWrduTefOndN9zIEDB1ixYgU9evRwej01atSISpUq8euvvzq2eXl5ARASEuJ0jtDQUAB8fX2dtv/999/ceuutBAcH4+/vT+PGjdMc/piWqVOnYozhwQcfdNr+4IMPcv78eWbNmuXY5spzOXz4cIoVK0br1q3Tfcz1zJkzh9OnT7v0c09LRp6/gIAAAgICUm2vX78+YBsSm1G58fkrWrQorVu3ZsSIEek+Jj9R7rdR7neWkdxxNYULFwZweo0VKVIk1X4eHh7UrVs3zRyTU7kjrbjq1q2Lh4dHqrhyc+63O3v2LJMmTaJZs2ZUqFDhmvvmh/duV56//J77ldttlNttMvNYrFYrVqs11f/34OBgrFZrqv/vaSlcuDBWqxUPDw+n7ZnJDdfz66+/UrlyZRo2bOjY5unpyQMPPMDy5cs5cOAA4PrjGz58OHfccYcj32WFyZMnU7lyZapXr55l53TVtm3bePPNNxk2bBjBwcFp7uPl5YW3tzd+fn5O20NDQ1P9nIwxDBs2jNq1a+Pn50dYWBhdu3ZNc1qTq5KSkpg+fTp33XWXU6ylS5emRYsWmXq/6tGjB9HR0cybN8+lmHK8eNOwYUP+/fdfBgwYwL///ktiYuJV933zzTfp3r07JUqUYNSoUfz666/06tXLaU77hx9+yMMPP0z16tWZMmUKX3zxBevWraNhw4Zs27bN6XwJCQnceeedtGzZkt9++423336blJQUOnbsyKBBg+jWrRt//PEHgwYN4q+//qJ58+acP3/ecfwff/xBkSJFqFatmkuP2Wq10rt3b3788UfHPL0///yT/fv3p/qQAHDTTTfh5eXFU089xbhx4646B/5yKSkpJCUlpbpdqXnz5sTFxV2zr4pdcnJymue88pah+XqX+e6771i+fDlfffWVS8dt2LABgBtuuCHVfTfccIPjfoBOnTpRqlQpnnvuOTZu3EhsbCwLFy5k0KBB3HHHHVStWtWx79ixY7ntttsIDg5m9OjR/PzzzxQqVIg2bdqkK9Fv2LCBwoULU6xYsVQxXR63q/744w+aNm2aqTfGK02ePJmGDRtSokSJDJ8jo8/f1dh7UaT1xjJo0CC8vb3x9/enSZMmTJs2LdU+ufX5A9v/v3/++YdTp05l+Bx5lXK/cv+VsiJ3JCUlcf78eVavXs3TTz9NpUqV6NKly3WPWbRoUaoc4+7csWDBApKTk1PFlVtz/+UmTpxIXFwcffr0ue6++fW9+2rPH+Tv3K/crtyeVby8vHj88ccZPXo0U6dO5cyZM+zevZu+ffsSEhJC3759Ux1jjCEpKYmTJ0/y008/MWrUKJ577jmnYmJmc8P1bNiw4ar5DGz9EV19fPv372f9+vW0aNEi0/FdbvLkydx1112ZOsfChQsJCgrCy8uLatWq8cknn6S7D40xhj59+tChQwfuvPPOq+736KOPkpCQwIABAzh48CCnTp1izJgx/Prrr7z44otO+/br14+nn36aVq1aMXXqVIYNG8bGjRtp1KgRR44cydRj3bFjB+fPn7/q87t9+3ZHn87GjRtTt25d3nrrLVasWEFsbCyrVq3i1Vdf5cYbb6RVq1ZOx9etW5fAwED++OMP14JyaZxOFjh+/Lhp0qSJAQxgvLy8TKNGjcyHH35ozp4969hv586dxsPDw3Tv3v2q5zp58qTx8/Mz7du3d9q+d+9e4+PjY7p16+bY1qtXrzSHLE6YMMEAZvLkyU7b7cNfLx++W7VqVdO2bdt0P9bLhz7a58FOnz7dGGMbgtW8eXNjjDG333670/BKY4z5/vvvTWBgoOPnVLx4cdOzZ0+zcOHCNK9xtdu+ffuc9k9ISDAWi8W89NJL142/dOnS1zy3/TZw4MB0/0yutH//fhMSEmK+/vprxzbSOXR+3LhxBjBLly5Ndd8jjzxivL29nbYdPHjQNGzY0Cn2u+++22loZVxcnClUqJC54447nI5NTk42tWrVchr+eDWtW7c2lStXTvM+b29v88gjj6R537Wm3Rw5csQAZtCgQanuS05ONomJiU43Lk4duHxbUlKS03FJSUkmIiLCfPLJJ9d9TFeTmecvLWvXrjV+fn6mc+fOTtsPHjxo+vbta37++WezaNEiM27cOHPzzTcbwHz77beO/XLr82dnH1I5c+bM68aR3yj3K/dfLityx6FDh5ziadCggTlw4MB1j3vttdcMYKZOnerY5s7cYYwxZ86cMVWrVjVRUVFO/x9ya+6/UoMGDUxoaKg5f/78dffNb+/dxlz9+bPLz7lfuV25/WpcnTZljDEpKSnmzTffNFar1RFPqVKlzOrVq9Pc/8MPP3TsZ7FYzGuvveZ0vyu5ISUlJVVObdq0qenZs2eq7Zfz8vIy/fr1SxXbkiVLDGDGjx/v8uP76aefDGCWLVuW6rxJSUlOsfz9998GMNu3b3fafuW0xTVr1hjA/Pfff2n+LNPj8ccfNz/88INZsGCBmTp1qunevbsBUk0Fu5ohQ4aYsLAwR2+wkSNHpjltyhjbVFp7TxzAeHh4mI8++shpn6VLlxog1fvZvn37jJ+fn9O0poy8Z9qn806YMCFVfPbpuwcPHnRsO3PmjKMHpv3WvHlzp2m3l2vcuLFp0KBBOn5yl+R48cZuxYoVZtCgQaZr164mIiLCAKZMmTLm2LFjxhhjvv76awPO8wevZJ/f/vPPP6e6r127dqZo0aKO7+1J/vL5asbY5tSFhoaahISEVE9osWLFzD333OPYNyQkxPTs2TPVta48zj537cp5qy1atDBdunQxx48fN97e3ubHH380xqSd5I2xNTMaP368GTBggKlfv76xWq3GYrE4vXDt1xg8eLBZsWJFqltCQkKq84aFhaXrP9m6devSPOeVt+t9WL7yP8vl/yk6dOhgmjZt6jTfz9XiTVqJ7ZFHHjE+Pj6O70+cOGHq1atnqlevbsaNG2cWLlxohg0bZooXL25uu+02RyK2f8D65ZdfUj2vL730krFYLI75l1d73lu3bm2qVKmSZsze3t5pJnhjrv3L/+rVq9P8kGKMMQMHDkzXm/GVr7E5c+akelO98g3hevPVM/P8XWnXrl0mKirKVKpU6apJ7nIJCQmmTp06Jjw8PNc/f3Zr1641kHo+bEGi3K/cb0zW5I7ExESzYsUKs3jxYvPtt9+aihUrmkqVKjl9kLqSvYfKc88957Tdnbnj/PnzplWrVsbf3z/V+1luzf2X27Bhg0vPXX57777W82dXEHK/crty+5UyUrx59913jb+/v3nnnXfMvHnzzG+//WZat25tIiIi0uxxdejQIbNixQoze/Zs89JLLxlvb2/Tv39/x/2u5IbrFc4uv13+mLy8vMyjjz6aKjZ78ebyX/zT+/g+++wzA6TZCLhZs2bpivHKXj1vvPGGKVOmjNO2q73WXWFvFH29HmS7d+82gYGBTnnwasWblStXmiJFipg77rjD/P7772bu3Lnm9ddfN97e3uadd95x7Pfaa68Zi8Vijhw5kuqx3HzzzU7FuYy8Z9qLNxMnTkz1eOzFm0OHDhljbL+XtGvXzkRFRZlvv/3WLFy40IwePdpUrFjR3HjjjebUqVOpztG5c2dTsmTJa/+Ar+C24s3lEhISzDPPPGMA88ILLxhjjHnvvfcMYPbu3XvV48aMGWPAubGp3cMPP2w8PT0d3/fq1cv4+/un2q9Vq1bXfAJbtmzp2Detv7zYG6lefrP/8nZlkh87dqzx8vIyr776qgkJCTHnzp0zxlw9yV9pw4YNplixYsbLy8vRvMrVxmbGGFO8eHFz1113XXe/Kz/MXe12vQ959jdY+61Zs2bGGNsvu56enmbZsmXm5MmTjhtg+vbta06ePJnmm5TdrFmzDGD++OOPVPd17drVFC9e3PH9Sy+9ZLy8vFJ9qLc3kRs1apQxxvYcXe8/9d69e6/5vN93332mcOHCqWKKjY01gHnllVfSfDzX+uU/req93YEDB1K98YLtLyeXb1u3bp3TcY899pipW7eu07Yr/ypzrb++ZPb5u9zu3btNmTJlTNmyZVP9VelaBg0aZACzadMmY0zuff7stm7dagAzZMiQdD/G/Ey5X7k/s7njcvv27TOenp5XbWr5ww8/GKvVah555JFUH1DdlTvi4+NN27Ztja+vb6qmvMbkztx/Jfv/4av9ZfxK+em9+3rPn11By/3K7QUzt1/J1eLNpk2bjMViSbU4RUJCgqlQoYJjZNO12D8X2gsJ6c0NxthGTVyZU2+88UbToUOHVNsvXz2uWLFi5u67704Vy/Tp0w1gZs+e7fLjS2tUh92WLVucYhkxYoQBzLRp05y2X/lzr1q1qtMfLq71WnfFsmXLDDiPakvL7bffbm6++Wan9317s+d58+Y5FTcaNGhgatasmaowaB+1tGPHDmOMcTQPv9qtXLlyjmMz8p65ZcsWA5ihQ4emejzPP/+8sVgsjhGnw4cPN5C6ELVjxw4DmLfeeivVOe6//34THh5+zZ/blVJ3F3MDLy8vBg4cyGeffeaYU2xvPLh//36ioqLSPC48PBwgzbmjBw8eJCIiwmmbxWJJtV9ERATh4eFOjeguFxQU5LTviRMnnO4vUaIEK1ascNpWuXLlNM/VpUsXnnjiCQYNGkTfvn1TNWG6nurVq3Pffffx+eefEx0d7Wjs6qqTJ0+m+tmkpXz58k7zkK9m4MCBvPXWW1e9/6233qJ///6O7+0/0w0bNpCUlMTNN9+c6phvv/2Wb7/9ll9//ZVOnTqled4aNWoAsH79etq3b+903/r16x33A6xZs4bIyMhUzeLq1avniAVw/FyGDBmSZlxgaz4IXPV5r1mzJhMnTuTw4cNOc+fXr1/vFLcr7HFd+foD22swrb4FZcqU4aabbkrzfCkpKfz6668MGDDAafvvv//OhQsXnM59NZl9/uz27NlD8+bNMcYwf/58SpYsec39L2eMAS41yMutz5+d/flLz/+/gkC5P32U+9OnZMmSlChRgujo6FT3jRw5kj59+tCrVy9GjBiR6jXhjtxx4cIFOnXqxLx58/jtt98czVbTiis35f7LJSQkMGbMGOrWrUvt2rXTdUx+ee9Oz/NnV9Byv3J7+uS33J5Za9euxRjj+P9t5+XlRa1atViwYMF1z2H/GUZHR1OnTh2XckNQUFCq3BkUFER4ePhVcyrYcoc9T1zuytzhyuO7PPdfmf+ufD3GxsY64ihTpkyaMW7evJnNmzc7NQd35bV+LVd+Fr+aDRs2sGfPHsLCwlLd16JFC0JCQhx9wdasWcP999+fqvF0vXr1SElJYfPmzZQrV46IiAgsFguLFi3Cx8cn1Xkv35aR98zy5cvj5+d31ee3QoUKjkbEa9aswcPDgxtvvNFpv3LlyhEeHp5m37QTJ064/L6Q48WbQ4cOpdlt3d5F3v5Dve222/Dw8GD48OFO3bsv17BhQ/z8/Bg7dix33323Y/v+/fuZO3cuXbt2vW48HTp0YOLEiSQnJ9OgQYNr7lulShV27NjhtM3b2/ua/6Ev5+fnx5tvvsnChQt57LHHrrpfTEwMQUFBeHt7p7pvy5YtQPo/WF3p4MGDxMfHp6s525Uf5q7merGUKVMmzWTSu3dvmjdvnmp7ixYt6NSpE0899dQ1f1GOjIykfv36jB07lueff97xH3zZsmVs3bqVp59+2inGOXPmcODAASIjIx3bly5dCuAoGDRu3JjQ0FA2bdrk9MaUlqs97x07duT1119n9OjRvPTSS47to0aNws/Pj7Zt217zvGkpXbo0fn5+qV5/GbVkyRIOHz6cqmlZzZo1032OzD5/AHv37qV58+YkJyczf/58Spcune7rJyYm8tNPPxEREeFY3SS3Pn929s73rjZHzA+U+5X77bIid6Rl+/bt7N+/P1UTxFGjRtGnTx8eeOABvvvuuzR/4cvp3HHhwgU6d+7M3LlzmTJlCm3atEnznLkx919u2rRpHD9+nHfeeSfdx+SH9+70Pn92+Tn3K7crt2cV+3WXLVtGs2bNHNsvXLjAqlWr0vXHPfvKPRn5XJhRnTt35vHHH+fff/91vOaSkpIYO3YsDRo0cDwuVx5flSpVAFvD3KxYGWry5MmUKFHCqYDlymv9Wn788UeAqxbH7CZOnOho7ms3a9YsBg8ezIgRI5weZ4kSJVi5ciXJyclOBZwrc3+HDh0YNGgQBw4c4J577sn0Y7mSp6cnd9xxB1OmTOGjjz5yFCr37t3LvHnzeOaZZ5xiTk5OZsWKFU65Jzo6mpiYmDRfvzt37nT5806OF2/atGlDyZIlueOOO6hSpQopKSmsWbOGTz75hMDAQJ566inAlhheffVV3n33Xc6fP8/9999PSEgImzZt4vjx47z99tuEhobyxhtv8Oqrr9KzZ0/uv/9+YmJiePvtt/H19WXgwIHXjee+++5j3LhxtG/fnqeeeor69evj5eXF/v37mTdvHh07dnQspdm8eXPeeecdzp07h7+/f4Ye/7PPPsuzzz57zX3mzZvHU089Rffu3WnUqBHh4eEcPXqUCRMmMGvWLHr27JnqBbBt2zaWLVuW6lwlS5Z02te+T3q6l2f0w1x6XSv5R0ZGpvpw7+npSbNmzZw6ww8ePJjWrVtz99138/jjj3P06FFefvllatSo4dTx/4knnmDcuHG0bt2al19+maioKDZs2MB7771H0aJF6d69OwCBgYEMGTKEXr16ceLECbp27UqRIkU4duwYa9eu5dixYwwfPvyaj6t69eo8/PDDDBw4EA8PD+rVq8eff/7JN998w3vvvUehQoUc+547d44ZM2YAl56bBQsWcPz4cQICAmjXrh1gS7ANGzZM8znOiF9++YUaNWpQqVKlDJ8js8/f0aNHadGiBYcOHeL777/n6NGjHD161LH/5a/dZ599lsTERBo3bkyxYsXYt28fQ4YMYc2aNYwcOdKR2HPr82e3bNkywsPDs/3/Vm6k3K/cb5fZ3LFu3TqeeeYZunbtSrly5bBaraxfv57PPvuM8PBwnn/+ecexkyZN4uGHH6Z27dr069eP5cuXO527Tp06+Pj45Hju6Nq1KzNnzuS1114jPDzc6TkMDg52/CKWG3P/5b7//nv8/Pzo1q3bVffJj+/d6X3+7PJz7lduV26/3LFjxxwjSOyjFWbOnEnhwoUpXLiwU9HiytzQpEkT6tWrx1tvvcW5c+do2rQpp0+fZsiQIezatYsxY8Y4jh04cCBHjhyhadOmREZGcurUKWbNmsW3337L3XffTd26dYGsyQ3X89BDDzF06FDuvvtuBg0aRJEiRRg2bBhbt27l77//duznyuNr0KABfn5+LFu27JqrMqXXL7/8QpcuXdL840V6jR8/nilTpnD77bdTunRpTp06xaRJk5g4cSK9e/emVq1ajn0XLFjArbfeyptvvsmbb74JpF3c2b17N2BbeenyQtIzzzzDgAEDuOOOO+jXrx/+/v7MmTOHTz75hFatWjmu1bhxYx555BEefPBBVq5cSdOmTQkICODQoUMsXryYmjVrXrOwmh5vv/029erVo0OHDrz88svEx8fz5ptvEhERwXPPPefY78EHH+Szzz7jrrvu4vXXX6dy5crs3LmTDz74gICAAB599FGn88bExLBt2zaefPJJ1wJyaZJVFvjpp59Mt27dTMWKFU1gYKDx8vIypUqVMj169HD0rbjcjz/+aOrVq2d8fX1NYGCgqVOnjhk5cqTTPt9995254YYbjLe3twkJCTEdO3Y0GzdudNqnV69eJiAgIM2YEhMTzf/+9z9Tq1Ytx3WqVKli+vXrZ7Zt2+bYb/v27cZisaTZSC0t6Z23euXc2H379pnXX3/dNG7c2BQrVsx4enqaoKAg06BBAzNkyBCn+X/Xa651Zdf1Hj16mJo1a6YrfneBtBsfcpV5tX/++ae5+eabja+vrylUqJDp2bOnOXLkSKr9Vq1a5WgM5ePjY8qVK2f69OmT5vzrBQsWmNtvv90UKlTIeHl5mcjISHP77benew5yQkKCGThwoClVqpTx9vY2lSpVMl9++WWq/dKab2q/pbVSgYeHxzWbcdoBqf6fXC4qKirLVhNI69rpef6u99q9PL7vv//e1K9f3xQqVMh4enqasLAw06ZNG8c84ivlxucvJSXFlC5d2jz55JPpiiG/Ue5PTbnfWXpzx+HDh80DDzxgypcvb/z9/Y23t7cpV66cefTRR1Pl8yt7M1x5u7InQE7ljmvFdOX7XG7N/Xv37jVWqzXNhq9XxpTf3rtdef7ye+5Xbk+tIOf2a8V/5f+NtLadOnXKvPbaa6Zq1arG39/fFClSxDRv3tzMmDHDab9p06aZVq1amaJFixpPT08TGBho6tevb7788ktHI/PLZTQ3NGvWLFXj37QcPnzY9OzZ0xQqVMj4+vqam2++2fz111+p9kvv4zPG9txWq1btute2/8yv1lto+/btGe5nc7mlS5eaW2+91dGnyd/f39SrV88MGzYsVZ8ke0zXe7+51mpTkydPNk2aNDEREREmICDAVK9e3bz77ruOBtOX++GHH0yDBg1MQECA8fPzM+XLlzc9e/Y0K1euvOb1r/eeabdy5Upz6623Gn9/fxMcHGw6depktm/fnmq/bdu2mR49epgyZcoYHx8fU6pUKXPvvfemyl/G2N7bvby8HCtvpZflYuCSTnfccQdJSUnMnDnT3aG47MyZM5QoUYLPPvuMvn37ujsccVF8fDylSpXiueeecxrS7arly5fToEED1q1bly//CphbzZkzh9tuu42NGzc6hsNK3qHcL+6i3J+3KffnbsrtklutXLmSevXqsWzZsutOAbyWjz76iP/9738cOnQoVQ8ZcZ9bbrmFUqVKMW7cOJeOU/HGRRs2bKBOnTosWbIkVcOp3O7tt9/mp59+Yt26dXh65ope1eKi4cOH89Zbb7Fz504CAgLcHY64oEWLFlSoUIFvv/3W3aFIBij3izsp9+ddyv25m3K75Gb33nsvcXFxTJ8+3d2hSBZauHAht912G5s2baJcuXIuHav/6S6qUaMGI0eO5PDhw+4OxWXBwcGMGjVKCT4Pe+SRRzh16hQ7d+7UX07zkJMnT9KsWTMef/xxd4ciGaTcL+6k3J83Kffnfsrtkpt98sknfP/995w9ezbLVvUS94uJieHHH390uXADGnkjIiIiIiIiIpKrXXtBdhERERERERERcSsVb0REREREREREcjG3TJJMSUnh4MGDBAUFZWq9eRGRvMQYw9mzZylRogRWa8GqnSvvi0hBpdyv3C8iBU925H63FG8OHjxIVFSUOy4tIuJ2+/bto2TJku4OI0cp74tIQafcLyJS8GRl7ndL8cbeLXvfvn0EBwe7IwQRkRx35swZoqKiCuSKAcr7IlJQKfenzv1fL9jBkLnbuevGSN7uWMNd4YmIZJvsyP1uKd7Yh00GBwfrQ7yIFDgFcei48r6IFHTK/Zdyv39gEFYff7z9AvWeICL5Wlbm/oI18VZERERERHIFg3F3CCIieYaKNyIiIiIikmPsf4g2qt2IiKSbijciIiIiIpJjLNiqN6rdiIikn1t63ojkRcnJySQmJro7DMnFvLy88PDwcHcYIpKFlPvlepT7XaeRN5LbKffL9bgj96t4I3IdxhgOHz7MqVOn3B2K5AGhoaEUK1asQDamFMlPlPvFFcr9rrH/lNTzRnIb5X5xRU7nfhVvRK7DnsCLFCmCv7+/PphJmowxnDt3jqNHjwJQvHhxN0ckIpmh3C/podyfMZZL1RuRXEW5X9LDXblfxRuRa0hOTnYk8PDwcHeHI7mcn58fAEePHqVIkSIaRi+SRyn3iyuU+12nnjeSGyn3iyvckfvVsFjkGuxzXf39/d0cieQV9teK5kmL5F3K/eIq5X7XXOp5o/KN5B7K/eKqnM79Kt6IpIOGTEp66bUikn/o/7Okl14rGaPSjeRG+v8s6ZXTrxUVb0REREREJMfYf+HRwBsRkfRT8UZEMmT+/PlYLBaXuvGXKVOGzz//PNtiEhGR7KXcL1lB/YpF8hbl/txBxRuRfKp3795YLBYeffTRVPc9/vjjWCwWevfunfOBiYhItlHul7xAPW9EspZyf8Gg4o1IPhYVFcXEiRM5f/68Y1t8fDwTJkygVKlSboxMRESyi3K/5HYaeSOS9ZT78z8Vb0TysRtvvJFSpUoxZcoUx7YpU6YQFRVFnTp1HNsuXLjAgAEDKFKkCL6+vjRp0oQVK1Y4nWvGjBlUqlQJPz8/WrRowe7du1Ndb8mSJTRt2hQ/Pz+ioqIYMGAAcXFx2fb4REQkNeV+ye0cTT5VvRHJMsr9+Z+KNyIuMsZwLiEpx28ZHVr84IMPMnLkSMf3P/zwAw899JDTPi+++CKTJ09m9OjRrFq1igoVKtCmTRtOnDgBwL59++jSpQvt27dnzZo19OnTh5dfftnpHOvXr6dNmzZ06dKFdevW8dNPP7F48WL69++fobhFRHILd+V95X7Jr7SYj+QFyv3K/bmNp7sDEMlrzicmU+3N2Tl+3U3vtMHf2/X/sj169OCVV15h9+7dWCwW/vnnHyZOnMj8+fMBiIuLY/jw4YwaNYp27doB8O233/LXX3/x/fff88ILLzB8+HDKlSvHZ599hsVioXLlyqxfv57Bgwc7rvPxxx/TrVs3nn76aQAqVqzIl19+SbNmzRg+fDi+vr6Z/hmIiLiDu/I+KPdL/mY09EZyMeV+5f7cRsUbkXwuIiKC22+/ndGjR2OM4fbbbyciIsJx/44dO0hMTKRx48aObV5eXtSvX5/NmzcDsHnzZm6++eZLw5yBhg0bOl3nv//+Y/v27YwbN86xzRhDSkoKu3btomrVqtn1EEVE5ArK/ZKbOXreqHYjkqWU+/M3FW9EXOTn5cGmd9q45boZ9dBDDzmGMQ4dOtTpPvuwTMsVY5iNMY5t6Rm6mZKSQr9+/RgwYECq+9QkTUTyMnflffu1M0q5X3Itx2vMzXGIXINy/9Up97uHijciLrJYLBkaxuhObdu2JSEhAYA2bZzfhCpUqIC3tzeLFy+mW7duACQmJrJy5UrHUMhq1aoxdepUp+OWLVvm9P2NN97Ixo0bqVChQvY8CBERN8mLeR+U+yX3urTalKo3knsp91+i3J87qGGxSAHg4eHB5s2b2bx5Mx4ezpX8gIAAHnvsMV544QVmzZrFpk2b6Nu3L+fOnePhhx8G4NFHH2XHjh08++yzbN26lfHjxzNq1Cin87z00kssXbqUJ554gjVr1rBt2zamTZvGk08+mVMPU0RELqPcL7mVY7Ep1W5Espxyf/6l4o1IAREcHExwcHCa9w0aNIi77rqLHj16cOONN7J9+3Zmz55NWFgYYBv+OHnyZH7//Xdq1arFiBEj+OCDD5zOccMNN7BgwQK2bdvGLbfcQp06dXjjjTcoXrx4tj82ERFJm3K/5EaWi2NvVLsRyR7K/fmTxWR0HbJMOHPmDCEhIZw+ffqqLyqR3CA+Pp5du3ZRtmxZdU2XdLnWa6Yg576C/Ngl71HuF1cp96ftao99wvK9vDJlPa2qFuW7Xje5MUKRS5T7xVU5nfs18kZERERERHLMpVapGnsjIpJeKt6IiIiIiEiOUc8bERHXqXgjIiIiIiI5Rj1vRERcp+KNiIiIiIjkHMfIG5VvRETSS8UbERERERHJMfaeNyrdiIikn4o3IiIiIiKSYywXm95o4I2ISPqpeCMiIiIiIjlGI29ERFyn4o2IiIiIiOQYi3reiIi4TMUbERERERHJMfbijYiIpJ+KNyKSbYwxPPLIIxQqVAiLxcKaNWvcFsvu3bvdHoOISEGg3C/X41gqXANvRPIN5f7sp+KNSD5jsViueevdu3eOxTJr1ixGjRrF9OnTOXToEDVq1MiR6/bu3ZtOnTo5bYuKisrRGEREcpJyv3J/XqKRNyJZQ7m/YOV+T3cHICJZ69ChQ46vf/rpJ9588022bt3q2Obn5+e0f2JiIl5eXtkSy44dOyhevDiNGjXKlvO7wsPDg2LFirk7DBGRbKHcnzbl/tzNqGWxSKYo96ctv+Z+jbwRyWeKFSvmuIWEhGCxWBzfx8fHExoays8//0zz5s3x9fVl7NixvPXWW9SuXdvpPJ9//jllypRx2jZy5EiqVq2Kr68vVapUYdiwYVeNo3fv3jz55JPs3bsXi8XiOFeZMmX4/PPPnfatXbs2b731luN7i8XCd999R+fOnfH396dixYpMmzbN6ZiNGzdy++23ExwcTFBQELfccgs7duzgrbfeYvTo0fz222+OvzrMnz8/zeGTCxYsoH79+vj4+FC8eHFefvllkpKSHPc3b96cAQMG8OKLL1KoUCGKFSvmFKeISG6h3K/cnxdp2pRI5ij3F6zcr+KNiKuMgYS4nL9l4Secl156iQEDBrB582batGmTrmO+/fZbXnvtNd5//302b97MBx98wBtvvMHo0aPT3P+LL77gnXfeoWTJkhw6dIgVK1a4FOPbb7/NPffcw7p162jfvj3du3fnxIkTABw4cICmTZvi6+vL3Llz+e+//3jooYdISkri+eef55577qFt27YcOnSIQ4cOpfkXgAMHDtC+fXvq1avH2rVrGT58ON9//z3vvfee036jR48mICCAf//9l48++oh33nmHv/76y6XHIiJ5nLvyvnK/cn8+ZbGo543kAcr9yv25LPdr2pSIqxLPwQclcv66rx4E74AsOdXTTz9Nly5dXDrm3Xff5ZNPPnEcV7ZsWTZt2sTXX39Nr169Uu0fEhJCUFBQhoct9u7dm/vvvx+ADz74gCFDhrB8+XLatm3L0KFDCQkJYeLEiY6hn5UqVXIc6+fnx4ULF6553WHDhhEVFcVXX32FxWKhSpUqHDx4kJdeeok333wTq9VW277hhhsYOHAgABUrVuSrr75izpw5tG7d2uXHJCJ5lLvyPij3K/fnS/aWN5o2Jbmacr9yfy7L/SreiBRAN910k0v7Hzt2jH379vHwww/Tt29fx/akpCRCQkKyOjzAljztAgICCAoK4ujRowCsWbOGW265JVNzdjdv3kzDhg0df/0DaNy4MbGxsezfv59SpUqligOgePHijjhERPIS5X7l/tzC/uPP7yNvjp29wOLtx6hQOIiaJbPn/4zI9Sj355/cr+KNiKu8/G3VcHdcN4sEBDhX8q1WK+aKT1CJiYmOr1NSUgDbEMoGDRo47efh4eHSta93LbsrE7TFYnHEcWXztYwwxjglcPs2+7XSE4eIFBDuyvv2a2cR5X7l/tzCsVS4m+PIDsYYxi7bw9Q1B1m19yTGQKCPJ/+83JIQv+xpFCvZRLlfuT+X5X4Vb0RcZbFk2TDG3KJw4cIcPnzYKbFd3uCraNGiREZGsnPnTrp3757pa13eGf/MmTPs2rXLpXPccMMNjB49+qod8729vUlOTr7mOapVq8bkyZOdHvOSJUsICgoiMjLSpXhEJJ/Lh3kflPuV+93HcmneVL7z88p9vPHbRsf3vl5WYi8kMXH5Xvo1K+/GyMRlyv3K/bmMGhaLCM2bN+fYsWN89NFH7Nixg6FDhzJz5kynfd566y0+/PBDvvjiC6Kjo1m/fj0jR47k008/delaLVu2ZMyYMSxatIgNGzbQq1cvl6v4/fv358yZM9x3332sXLmSbdu2MWbMGMfSiGXKlGHdunVs3bqV48ePp1nhf/zxx9m3bx9PPvkkW7Zs4bfffmPgwIE8++yzjnmvIiL5mXK/cr+75OeeN5NW7gfg/vqlWPbKrbzTsQYAo5bsJjE59/wFXwou5f68m/vzTqQikm2qVq3KsGHDGDp0KLVq1WL58uU8//zzTvv06dOH7777jlGjRlGzZk2aNWvGqFGjKFu2rEvXeuWVV2jatCkdOnSgffv2dOrUifLlXftLVHh4OHPnziU2NpZmzZpRt25dvv32W0c1vm/fvlSuXJmbbrqJwoUL888//6Q6R2RkJDNmzGD58uXUqlWLRx99lIcffpjXX3/dpVhERPIq5X7lfnfJrz1v9sTEsXLPSawWeLpVRYqF+NKxdgkiAn04dDqeGesPXf8kItlMuT/v5n6LuXISWg44c+YMISEhnD59muDg4Jy+vEi6xcfHs2vXLsqWLYuvr6+7w5E84FqvmYKc+wryY5e8R7lfXKXcn7arPfZZGw7z6Nj/qFs6jMmPpV7WN6/6/O9oPv97G7dUjGDMw5d6hQyZs41P/oqmRmQwv/dvkqr3huQOyv3iqpzO/Rp5IyIiIiIiOebSyJv8M/TGGMOvqw8A0LmOcw+N7jeXxtfLyoYDZ/h31wl3hCci+YCKNyIiIiIikmPyY7/iVXtPsSfmHH5eHrSpXszpvkIB3tx1Y0kAvlvkWrNWERE7FW9ERERERCTH2KcN5aOBN/y62taouF2NYgT4pF7Q96Emtl4hc7Yc4cCp8zkam4jkDyreiIiIiIhIjslvI28uJCXz+1pbM+LON6a97HD5woHUKhmCMbByt6ZOiYjrVLwREREREZEc4+jXm0+G3szbcozT5xMpGuxDo/IRV92vTqkwAFbvPZVDkYlIfqLijYiIiIiI5BhHw2L3hpFl/t58BIA7biiBh/XqK0nVKRUKwOp9p3IgKhHJb1S8ERERERGRHGMhfy2VveZiMaZh+fBr7nfjxZE3mw6eJj4xObvDEpF8RsUbERERERHJcflh1tSZ+ER2HIsFoFZU6DX3LRnmR3iAN4nJho0Hz+RAdCKSn6h4IyIiIiIiOccxbSrvV2827D+NMbbCTESgzzX3tVgsl6ZO7T2ZA9GJSH6i4o2I5DiLxcLUqVPdHYaIiOQg5X6xy0/9iu39a6436sbO0bRYfW+kgFDuzzoq3ojkU0ePHqVfv36UKlUKHx8fihUrRps2bVi6dKm7QxMRkWyi3C95geVix+L8ULxZe7EIU7tkaLr2r3OxyLNGK05JFlLuLxg83R2AiGSPu+66i8TEREaPHk25cuU4cuQIc+bM4cSJE+4OTUREsolyv+QFjpE3bo0ia6zdfwqA2henQ13PDVGhWCxw4NR5jpyJp2iwb/YFJwWGcn/BoJE3IjkkOhpmzoRt27L/WqdOnWLx4sUMHjyYFi1aULp0aerXr88rr7zC7bffDsCnn35KzZo1CQgIICoqiscff5zY2FjHOUaNGkVoaCjTp0+ncuXK+Pv707VrV+Li4hg9ejRlypQhLCyMJ598kuTkSysmlClThnfffZdu3boRGBhIiRIlGDJkyDXjPXDgAPfeey9hYWGEh4fTsWNHdu/e7bh//vz51K9fn4CAAEJDQ2ncuDF79uzJ2h+aiEg2UO6/OuX+gsuxVHgeH3pz6PR5jpy5gIfVQvUSwek6JtDHk8pFgwBYrdE3+ZZy/9Up92ecijci2ezECWjbzlC5MrRvD5Uq2b4/mY196gIDAwkMDGTq1KlcuHAhzX2sVitffvklGzZsYPTo0cydO5cXX3zRaZ9z587x5ZdfMnHiRGbNmsX8+fPp0qULM2bMYMaMGYwZM4ZvvvmGX375xem4jz/+mBtuuIFVq1bxyiuv8Mwzz/DXX3+lGce5c+do0aIFgYGBLFy4kMWLFxMYGEjbtm1JSEggKSmJTp060axZM9atW8fSpUt55JFHHEOuRURyI+V+5X65uvyyVLh9ylSlokH4e6d/QoO9afEa9b3Jd5T7lfuzlXGD06dPG8CcPn3aHZcXSbfz58+bTZs2mfPnz2f4HG3aphgv/wQT3mGViXzsbxPeYZXx8k8wbdqmZGGkqf3yyy8mLCzM+Pr6mkaNGplXXnnFrF279qr7//zzzyY8PNzx/ciRIw1gtm/f7tjWr18/4+/vb86ePevY1qZNG9OvXz/H96VLlzZt27Z1Ove9995r2rVr5/geML/++qsxxpjvv//eVK5c2aSkXPp5XLhwwfj5+ZnZs2ebmJgYA5j58+e7/kNwg2u9Zgpy7ivIj13yHuV+5X5XKfen7WqPffG2Y6b0S9PNbZ8ucFNkWePDGZtN6Zemm5cnr3PpuJ+W7zWlX5pu7hmxJJsik4xQ7lfud1VO536NvBHJRtHRMHuWheCWGwisfhDP4HgCqx8kuOVGZs+yZOtQyrvuuouDBw8ybdo02rRpw/z587nxxhsZNWoUAPPmzaN169ZERkYSFBREz549iYmJIS4uznEOf39/ypcv7/i+aNGilClThsDAQKdtR48edbp2w4YNU32/efPmNOP877//2L59O0FBQY6/HBQqVIj4+Hh27NhBoUKF6N27N23atOGOO+7giy++4NChQ5n98YiIZBvl/kvfK/dLWi71vMnb06bW7LMNp6gdFeLScfaRN+v2nyYpOSWrwxI3Ue6/9L1yf/ZQ8UYkG+3YYfvXN8q5WZhvVAwA27dn7/V9fX1p3bo1b775JkuWLKF3794MHDiQPXv20L59e2rUqMHkyZP577//GDp0KACJiYmO4728vJzOZ7FY0tyWknL9Dx5XG+6YkpJC3bp1WbNmjdMtOjqabt26ATBy5EiWLl1Ko0aN+Omnn6hUqRLLli1z6WchIpJTlPud90uLcn8B5+h5494wMiM5xbB+/2kg/cuE25UvHEiQjyfnE5PZeuRsNkQn7qDc77xfWpT7M0fFG5FsZC9ex+8r5LQ9fl84ABUq5Gw81apVIy4ujpUrV5KUlMQnn3zCzTffTKVKlTh48GCWXefKBLts2TKqVKmS5r433ngj27Zto0iRIlSoUMHpFhJy6S9ZderU4ZVXXmHJkiXUqFGD8ePHZ1m8IiJZSbn/0vfK/ZIWe8+bPFy7YcexWOISkvH39qBikSCXjrVaLY6Cz9p9p7MhOnEH5f5L3yv3Zw8Vb0SyUaVK0Kat4czcGsRujCTpjC+xGyM5M7c6bdoaKlbMnuvGxMTQsmVLxo4dy7p169i1axeTJk3io48+omPHjpQvX56kpCSGDBnCzp07GTNmDCNGjMiy6//zzz989NFHREdHM3ToUCZNmsRTTz2V5r7du3cnIiKCjh07smjRInbt2sWCBQt46qmn2L9/P7t27eKVV15h6dKl7Nmzhz///JPo6GiqVq2aZfGKiGQl5X7lfrm2/LDa1JqLK0XVjAzBw+p6M9VKF1ec2nEs9jp7Sl6h3K/cn93S3xZdRDJkwngL93fzZPb02o5tbdoaJozPvq7pgYGBNGjQgM8++4wdO3aQmJhIVFQUffv25dVXX8XPz49PP/2UwYMH88orr9C0aVM+/PBDevbsmSXXf+655/jvv/94++23CQoK4pNPPqFNmzZp7uvv78/ChQt56aWX6NKlC2fPniUyMpJbb72V4OBgzp8/z5YtWxg9ejQxMTEUL16c/v37069fvyyJVUQkOyj3K/fL1V3qeZN3rdl/CoDaLk6ZsitXOACAnSre5CvK/cr92cli3FDyPnPmDCEhIZw+fZrg4OCcvrxIusXHx7Nr1y7Kli2Lr69vps61bZttrmuFCmRb5T03KFOmDE8//TRPP/20u0Nxi2u9Zgpy7ivIj13yHuV+1yn3K/en5WqPffmuE9zz9VLKRQQw9/nm7gswEzoMWcSGA2cY1v1G2tcs7vLxS3fEcP+3yyhVyJ+FL7bIhgjFVcr9rlPuz9ncr5E3IjmkYsX8nbxFRCQ15X6R1BzTptwbRoYlpxi2HbGNmKlWPGO/lJW/OPJm/8lzxCcm4+vlkWXxifsp90t2UM8bERERERHJMY5pU3m0583eE+e4kJSCj6eVqEL+GTpH4SAfgnw8STGwJ+ZcFkcoIvmRRt6ISJbavXu3u0MQEZEcptwvrsjrI2+iLy7vXbFoYIaaFYNtKeVyhQNYu/80O4/FUrmYaytWieQGyv05SyNvREREREQkB2Vf89acEH3YVryxrxiVUeULBwJacUpE0kfFGxERERERyXF5dNYUW49kTfHm0opTcZmOSUTyPxVvRNIhJSXF3SFIHqHXikj+of/Pkl56rbjm0rSpvFm9sTcrrqyRN/mS/j9LeuX0a0U9b0SuwdvbG6vVysGDBylcuDDe3t5YLHl7qK9kD2MMCQkJHDt2DKvVire3t7tDEpEMUu6X9FLuz5hLDYvdGkaGJCansPO4rdhSsWhgps5Vvojt+J3H4jDGKM+4mXK/pJe7cr+KNyLXYLVaKVu2LIcOHeLgwYPuDkfyAH9/f0qVKoXVqoGNInmVcr+4SrnfNfZfiPNi8Wb38TgSkw0B3h5Ehvpl6lylw/2xWuDshSSOnb1AkWDfLIpSMkK5X1yV07lfxRuR6/D29qZUqVIkJSWRnJzs7nAkF/Pw8MDT01N/pRHJB5T7Jb2U+12Xl39Sjn43xYIy/Zz7eHoQVcifPTHn2HEsTsWbXEC5X9LLHblfxRuRdLBYLHh5eeHl5eXuUEREJIco94tkD0fPmzw49Max0lSRrFnau1xEwMXiTSwNy4dnyTklc5T7JbfS2E4REREREckxlotjb/Je6QaiLzYrrlQsa4o39qbFWnFKRK5HxRsREREREckxl0beuDeOjIh2LBOeuWbFduW04pSIpFO+nzYVHQ07dkCFClCxorujERGRnKDcLyKS+2X1UuHZnfvjE5PZHWMbIZPZZcLtyhcOAFS8EZHry7cjb06cgLbtDJUrQ/v2UKmS7fuTJ90dmYiIZBflfhGR3C+rR97kVO7fcSyWFAOh/l4UDvLJknPaR94cOHWe+EQ1yBWRq8u3I2+6dTfMXZhEeIcN+EadIH5fIebOrcH93TyZNTMv97gXEZGrUe4XEcn9srrnTU7lfseUqSKZX2nKLiLQm2BfT87EJ7HreBxViwdnyXlFJP/JlyNvoqNh9iwLwS03EFj9IJ7B8QRWP0hwy43MnmVh2zZ3RygiIllNuV9EJG/IypE3OZn7LzUrzpp+N2Bb2aicmhaLSDrky+LNjh22f32jTjht942KAWD79pyOSEREsptyv4hI3nBp0ErmqzeXcn+M0/bsyP2OZcKzqN+NXXk1LRaRdMiXxZvy5W3/xu8r5LQ9fl84YGtiJiIi+Ytyv4hI3uCYNpUFI2/Kl4ewVhvwCLzgtD07cv/WI9lTvCl3sWnxruMaeSMiV5erijfR0TBzJpke3lipErRpazgztwaxGyNJOuNL7MZIzsytTpu2RiuPiIjkIsr9IiIFi33kzYWErMn9hW44jOWK32oSD4Rlae6Pu5DE/pPnbdfM4uJNVCF/APadOJel5xWR/CVXFG+yo0P8hPEWWjb1JGZ6bQ4Mv5WY6bVp2dSTCePVsFJEJDdQ7hcRKXhOnIB+/WxDbk6fNpnO/fGJySR52UbdnJxXhQsHQwEoVS8mS3P/9qO2KU0RgT4UCvDOsvMCRIX5AbDvpIo3InJ1uWK1qezoEB8WBrNm2pqUbd9uGzJZsaI+vIuI5BbK/SIiBU+37oZ/1ydTpApYfRMJ77A6U7n/4CnbaBh/bw/+HFOOGStD+HzdvwSVOUlYWNbFfWnKVNY1K7azj7w5cuYC8YnJ+Hp5ZPk1RCTvc3vxxt4hPryDrUM8cPFfC7On12bbNjI13LFixcwdLyIiWU+5X0Sk4LHn/oguti7CFmvmc/++i1OZosL8qVTJQmTpUIZssHDwdDwHT52nRKhflsS+LZv63QCEB3jj5+XB+cRkDpw672hgLCJyObdPm9LqICIiBY9yv4hIwWPP/T7FTjltz0zu339xqlHJi1OPAnw8qVrcVmBZtTcT83CvYF8mvGI2jLyxWCyUUt8bEbkOtxdvtDqIiEjBo9wvIlLw2HP/hUOhTtszk/v3nbg48uZi8QOgbinbfKn/9mRd8SY7R94ARBWy9705ny3nF5G8z+3FG60OIiJS8Cj3i4gUPPbcH/tPZcC2VHhmc/+VI28AbixtK96s2nsq0zEDnI1P5ODpeAAqFcme4k3JMFvxab9G3ojIVbi95w3YVge5v5sns6fXdmxr09ZodRARkXxmzNLdnMObE3EJVOkBhyNh7x5PYjeUJPmMH/VvP8ngQQEY44/FovcAEZH8ZsJ4C117erEDIMVCzPTamfrcbx+pYi9+ANx4ceTNxgOns6QB8LaLK00VCfIhxN8rU+e6Gsdy4VpxSkSuIlcUb7Q6iIhIwTB41lasPpc+YBMBwRGXvt0PdPwGQvy8uKFkCHVKhdGsUmFqR4XiYdX7gohIXhcWZivg1H8frB6G6OjMfe4/cLHYYZ92BLZROEWCfDh69gLr9p+mftlCVzs8XbJ7yhRctlz4CU2bEpG05YrijZ1WBxERyd/aVC9KicKFKBTgg6eHhaRkQ1JKCifPJXDwlG1lkJ3H4zh9PpFF246zaNtxvpyzjYhAb1pULkLH2pE0Kh+OVYUcEZE8y+PiyEoDVKhggIzl9HMJSRyPTQCcR95YLBbqlg5j5obD/LfnZKaLN/ZmxdlavNHIGxG5DvcWb3bMhdBC4B8OQcXBLww0TF5EJN/6pNYhgkMvgKcvBERAUDHwDXXK/YnJKWw9fJY1+06xbGcMC7Ye43hsApP+28+k//ZTMsyPe2+K4t56URQJ9nXfgxERkfTZOhNCw8HLFwIK4+EZjq10YyE5xeDpkbHP/wcuTpkK9vUkxM95OtPlxZvMinaMvMm+JbztxZtT5xI5G59IkG/2TM8SkbzLvcWbn3uCz2XJ2sMHQktBkSpQuCoUrQ5RDSC4uPtiFBGRrDOlr3PeB1shJ7S0I/d7FatBjagG1IgszQM3lyYhKYUVu08wY/0hpq09yP6T5/nkr2iGzN3OXXVL8mizcpQOD3DP4xERkeu7IveHApt8fNhrimCZPAmKVoOiNWyf+wPC033afY5mxf6p7qtzse/N6r0nMcZkqo/aNscy4dk38ibQx5Mwfy9Onktk34nzVCuh4o2IOHNv8aZoDfBMhLjjcP4EJF+AmG222+bfL+0XVgZKNYKKraBCK/ANcVvIIiKSCZE32fJ+4nmIOwbxpyApHo5vtd347dK+hcpD6UZ4V2xN4/ItaVyhJq/fXo2ZGw4x7t+9/LfnJBOW7+WnFXu5s1YJnrutstNSsSIikkuUqAteSZB47mLuP42/5QJVLPtg0z7Y9OulfSMqQ+mGULENlGsO3lfP6/tP2pcJ90t1X43IYLw9rMTEJbAn5hxlIjJW5D99PpHDZ2wrTVXMxpE3YBt9c/LcafadPEe1EsHZei0RyXvcW7x5aBYEX0xMifEQexhO7ISjW+DoJji0Bg5vgJO7bbe148HqCaUbQfXOtptfmBsfgIiIuKTn1Et5H2xFnLOHIGYnHNtsy/8HV9veA07ssN1WjwEPbyhzC341utCl2p10ubERy3edYNj87czfeoypaw4yY/1hejUqTf8WFbNtNRAREcmAXr855f74c2dp8+7PlLUc4us2/viciIYDqy4V8o9vhf9G2UZmlm0GNe6Cqh3A27kAs+/E1Ufe+Hh6ULNkCP/tOcl/e05muHhjb1ZcPMSX4GyeyhQV5s+6/acdj0tE5HK5p2Gxl69thE1YGSjf8tL2+NOwbwXsWgDRs+B4NOxaaLvNfBkqt4M6PWzHWK3uil5ERDLCyw8KlbPdKra6tP38Sdi3HHYugK0z4OQu2DHHdvvjeajagfo39qR+71vYcPAMg2ZuYfH243y7aBeT/tvPK+2qcM9NUVpuXEQkF7J6B7DHFGOPKUZ8/dvwsferiYuBfctg53zYOgtO74Vts223PwKhWke4sadtepXF4liZyb5S05Xqlg7jvz0nWbnnJHfVLZmhWKNzYMqUXcmLI4jsI4pERC6Xe4o3V+MbYvtAX7EV3PYuxOyALdNh7UTbX2Y3TbXdwitCg35Q637wyd4hjSIiks38wqBSG9utzfu2wv3m3225P2YbrJ9kuxWpTo0G/RjT824W7IrlgxmbiT4Sy0uT1zN51QE+6FyTCkX0niAikpt4XLZiYEqKuXRHQDhUud12a/fRxc/602DdRNso/DXjbLfitaHBoxw+WRRIe+QNQJ2oUADW7T+V4VgdzYpz4L0k6uLj2K8Vp0QkDXlvqEp4eWj8FDy2BPothPr9wCfY9mF+xvPwWTWYP9g2YkdERPI+iwUKV4amz0P/FdBnLtz0EHj5w9GN8PsALJ/XoPmx8cx4tA6v314VPy8Plu86QfsvFjF03naSL//lQERE3Oqy2g3J5ir52WKxLV7S4hUYsAYenAW1H7BNpTq0BqY+yjcnHuJBj5mUCk57lGWNSFufzOgjZ7mQlJyhWLcdvVi8KZb9I28cy4Wf0MgbEUkt7xVv7CwWKF4L2n8Ez26Cdh/bmlvGn4b5H8BnNWH+ILhw1t2RiohIVrFYoGRd6PAZPLsZbnvPtkrhuRj4eyCeQ2rTx/Ibfz95Ey2rFCEhOYWPZ2/lvm+WqoeAiEguYbFYHAWclPQU1y0WWxPjTkPhmU1w65ukBBWnCCcZ6DWGChOawNJhkHTB6bCSYX6E+nuRmGyIPhyboVjt06Yq5cC0Kfv0r30nz2GuVtQSkQIr7xZvLucTBA0esf1FtusPULgKXDgN8z+EL2+ElSMhOcndUYqISFbyC4VGT8KTq6HTcFvfnHMx8PdbRI5tyve1t/G/rjUJ9PFkxe6TtPtiEb+u3u/uqEVEhEtTp6468uZqAsLhlufYcs9iXkl8mENEYI07ArNfga/qwcZf4eI5LRYLNUrYRt+sP+D6qPxT5xI4dtZWEKqYA9OmIsP8sFjgXEIyJ+ISsv16IpK35I/ijZ3Vw9aN/rGl0HWkbSRO3FGY/jSMaGJrfCkiIvmLhyfU7gZPrIBOIyCkFJw5gGXqY3T97wHm3ONLvTJhxF5I4pmf1vLKlPXEJ2Zs+LyIiGQN68WG8hmd1rr/TBITkm/lifDvoMPnEFgMTu2BSb3hhzZwcA1waerUhoOuF2+2HraN4I8M9SPAJ/tbhfp4elA0yBeAfWpaLCJXyFfFm+homDkTtu2wQo0u8PgyaDvI1vjy2Gb48U6Y8gjEHnN3qCIikkUcuX+nJ9S+3zYKs9Vbtn5oh9ZSdNKd/FTiJ15qVgSLBSYs30vXEUs0jUpExI0cI28yWLxZFW0rbgR6h8BND8KAVdD8FVs/tH3/wrctYNYr1C7iAcCGDIy8WbffdkyNyODr7Jl1oi6uOKX3KBG5Ur4o3pw4AW3bGSpXhvbtoVIl2/cnz3rDzY/BgNVQry9ggXU/wVc3waoxjiGVIiKS91w198f6QpNnbLm/zgMAWFeN4rH19/FHi6OE+Xmy4cAZOgxZzJLtx938KERECqaMFm/suf+jobbixu8T/Wy5Py4Amr8MT66yjcQ3KbBsGK3m3kEr639sOXSWhKQUl6619uIqVTeUDHXpuMywrzi1TytOicgV8kXxplt3w9yFSYR3WE3kY3MI77CauQuTuL/bxTcDvzC4/X/QZw4Uqwnxp2Bafxh/L5w97NbYRUQkY66b+wMioONQ6D0DIirDueNUW/I0SyqMoUmkhdPnE+n5w3LGLtvj3gciIlIA2Ys3KS7+MdWe+/0r2T7D+0TFOOf+4OK2HpgPTIGwsnjGHeI770943zKMHfsPuHQte/GmVg4Wb0pqxSkRuYo8X7yJjobZsywEt9xAYPWDeAbHE1j9IMEtNzJ7loVt2y7buWRd6DsfWr8DHt6wbTYMbQAbJrsrfBERyQCXcn+ZxvDoYttweqsnftt+Z0z8AF4rv5ukFMPrUzcw8LcNJCW79hdZERHJOA9Hz5v0H3N57vcMjgfAt8TptHN/hVvh8aXQ+ClSsHC350JKT7wVdsxL17VOxCU4Cig1S4akP8hMsq84tV8jb0TkCnm+eLNjh+1f36gTTtt9o2IA2L79igM8PKHxU9BvoW2p8fhT8MtD8Ft/SFCSFBHJC1zO/Z7etuH0ff6GwlWwxB2j74FX+a38NLxJZPTSPTw6dhXnE9TIWEQkJ1gzMG3qUu6Pcdp+1dzv5Qet32Fs1RHsTimKf/wRGNMZ/n77uivR2kfdlIsIIMTPK90xZlaUY+SNfi8REWd5vnhTvrzt3/h9hZy2x+8LB6BChascWKSqbRpV0xcAC6weY2tsdnRz9gUrIiJZIsO5v0QdeGQBNOwPQK0DE1lR7CMqeh7l781H6PbdMi3PKiKSA+wjb1yZNuXI/QfCnLZfL/eHVmlKu4QPmeXbDjCw+FMYdTuc3n/Va63bZ2tWXCsqNN3xZYXIUNvIm4On40nJYDNnEcmf8nzxplIlaNPWcGZuDWI3RpJ0xpfYjZGcmVudNm0NFSte42APL2j5OvT8DQKLwrEt8E0LWDcpx+IXERHXZSr3e/lCm/eh28/gV4iQUxuZ5fc6nXxXs3rvKboO10pUIiLZLSMNi+25P3ZpJcC29kjsxhLXzf01I0M4jy9PxfYi+a6RttUI9y2DEU1gx9w0j1nnaFacc1OmAIqF+GK1QEJSCsfjLuTotUUkd8vzxRuACeMttGzqScz02hwYfisx02vTsqknE8Zb0neCcs3g0X+gfEtIOg9T+sCsV687nFJERNwn07m/UhtbL5xSjfBIjOVzPmZgwK/sOn6We75eyo5jsdn7AERECjDrxd9Ckl1sWDxhvIWGjWxfp8R7ETO9znVzf+lC/gT5eHIhKYXoiFa29gkl6sD5kzD2Llj8udMqtMYYt6w0BeDlYaVosC8AB0/F5+i1RSR3yxfFm7AwmDXTQnQ0zJhha2Y2a6aFsLDrH+sQWBi6/wK3PG/7ftlQGNMJ4mxzaKOjYeZMnBuhiYiI22RJ7g+JhF7ToMFjADyYPIkJgZ8Te/oE94xYysylZ5T7RUSygWPalItTg8LC4LMhtv5khUM905X7rVYL1SODAdhw4DQUKgsPzoI6D9iWFP97IPzyICTEAfDP6niOxybgYbFQvURwBh5d5tinTh04qRWnROSSfFG8satYEdq149rD5a/F6gG3vgH3jAHvQNi9iOSvW9Kn81YqV4b27W3DNdu2M5w8maWhi4hIBmU693t4QbtB0Pkb8PTl5qSVTPd/B79z+3nkp6V06nNSuV9EJItlpGGxXdwF2+j4wqGe6c79NUrYpj9tOGDrZYOXL9z5Fdz+KVi9YOOvJH3bjm53HqRNt1MAnDsURKc7rTme+0vYizenNIVXRC7JV8WbLFPtTlsz47AyeJzZzceVW9Pp/u+IfGwO4R1WM3dhEvd3UwMxEZF8pda98NBsCCpB6ZS9TPUcSD2/TRR7YAmF7/5XuV9EJAs5lgp3cdoUwNl4W/Em0Ncz3cfYl/teby/eAFgsUO9h6D0d/CPwPLaWjyq2pFGLWQBYvZPckvsjLy4XrmlTInI5FW+upkgVdrSYwz97GxDme5qfK77I/WGzCKx+kOCWG5k9y6Jh9CIi+U2J2uy8dQ6rDt1AhMdpJni/TwePZfiXO07o7auV+0VEsoi9YXFKiuvH2kfeBPi4ULyJvDjy5uAZziVc0dey1M3savU3m45VpmTQIaYWeYkW1tV4FTrnls/99pE3+zVtSkQuo+LNNUQfiODWH6cxNf4WvCzJfOz1DY97TMU36jgA27e7OUAREclyWw+VoOnImcy+UA8fSyJDvIbQy2M2fmWP4V3ipHK/iEgWsGZi5E3sxeJNkAvFm7IRAUQV8iMhKYXF246nun/LkbI0+v5PFiXUJMBygW+9PqGrxwJ8o2z9L3My95d0TJtS8UZELlHx5hrKl4cLyb702fgOQ5PuBOBFr595k3FYSKFCBTcHKCIiWa58eYhLDKTHhkGMTmqN1WJ422s0L3j9RNF7/sWEnr7+SURE5JoujbzJePEmwMcj3cdYLBZurVIUgL83H0l1f/nycPpCKPdEf8Tk5FvwtKTwP6+v6ZswGzA5+rn/0rQpFW9E5BIVb66hUiVo09ZwZm5NBq59joFnHwLgkSJTmNv/YSqWS3RzhCIiktXsuf/U3Fo8t/Y1Poq9H4D+nr8xOGAEb/y5hOgjZ90cpYhI3paZhsX24k2gj5dLx7WuZivezN1yNFXRyJ77z+0qwXOJjzI84Q4ABpb8msmPvErFCjnX98Y+ber0+UTHYxURUfHmOiaMt9CyqScx02vzzqefcd8v35OY4kXz8CnwUw9IVCMxEZH85lLur8NLn4ygz7QvSTZW7vecx5tJX9Lr23/YfTzO3WGKiORZHrbaTcamTdkbFrsw8gagftlCBPl6cjw2gTX7T6W6f8J4CyUbHAUsvPrP6zwz+wMAuhQfBr8/BSnJLseaEYE+noT42QpTWi5cROxUvLkoOhpmziRVM7KwMJg100J0NMyYAe/+2hWvHhPA0xeiZ8KEeyFBH+BFRPKi9Ob+l37qhcc9IzFWTzp6LOHtCx/R+9vFHD6tAr6ISEZkZtqUvWGxK6tNAXh5WGleuQgAX/9+JFXuj7ee53zIMQA+G1CSx398AjoOA4sVVo2GXx+F5JwZCRMZqqlTIuKswBdvTpyAtu0MlStD+/a2IZNt2xlOnnTer2JFaNfO9i8VW0P3X8ArAHbOh7F3wQUNoRcRySsylPurd8Jy33iMhw+3efzH2+feo8/3Czl1LsEtj0FEJC+zNyxOykDx5mwGVpsCW+7/b5qtePP7qiOpcv/PK/aTYqBB2UL0vivQlvvrdIe7vgOrJ6z/GX7pDcnZ3zrBseKUijciclGBL950626YuzCJ8A6riXxsDuEdVjN3YRL3d7vOG0nZW6Dnb+ATAnuXwtiuKuCIiOQRGc79ldpg6T6JFC9/mnms48WT7/DoyMWcT8iZofQiIvmFY+RNBqZNOUbeuFi86dbd8N/sMIwB78KxRHRe4cj9ySmGn1fuA+C++lHOB9a4C+4dCx7esPl3mNQ72ws4JS82Lda0KRGxK9DFm+homD3LQnDLDQRWP4hncDyB1Q8S3HIjs2dZUg2lTCWqHvT6DXxDYN8yGHe3CjgiIrlcpnN/uWZYH5hMiqc/TT3W89jhgQwYu5TE5JQciV9EJD/wyJKGxekv3thzf1DjrVwc9ENApaOO3P/TguMcOHWeYF9P2tUonvoEldvB/RPAwwe2TIdfHszWAk6JUF9A06ZE5JICXbzZscP2r2/UCaftvlExAGzfno6TlKgDPaZeGoEz7m64EJu1gYqISJbJktxfuhHWB34h2dOPZh7reGDXK7z5y0pMBv6CLCJSEOV08eZ6uf+X//YC0OXGkvh6XaURcoVWcN+4SyNwfnko2wo4kaH+ABxQ8UZELirQxZvy5W3/xu8r5LQ9fl84ABUqpPNEkTdCz18vFXAm3q9VqEREcqksy/1lGuPxwC8ke9gKOC03vMSQvzZnYaQiIvmXhyXj06bsq0250vPmark/JcETn8gTrDtxBIB760Vdeaiziq3hXnsBZxpMfSxbVqGKDFPDYhFxVqCLN5UqQZu2hjNzaxC7MZKkM77EbozkzNzqtGlrbE3K0iuyLvSYAt6BsGsh/NwTktTEUkQkt8nS3F+mCR4P/EyS1YfWHqsos+hZJq3YnV2hi4jkG1bHyBvXj7X3vAlyYbWpK3N/SqLt1yDviFiKPbCUpBRDrahQqhYPTsfJboN7frzYxHgSTH8GsnjkpX3a1JEz8ZqWKyJAAS/eAEwYb6FlU09iptfmwPBbiZlem5ZNPZkw3uL6yUreBN1+si0jvm02/PpItlTiRUQkc7I095dtiud9Y0m2eHKnx1LMtKdZuPVI1gctIpKP2EfeJLtY9EhJMcRdbBLvasPiy3P/vs/acHTyTQScKYw98/e8uXT6T1a5HXT55tIy4rNfy9ICTkSAD96eVlIMHD6tEf0iAq5lvHwoLAxmzbQ1qNy+3TZcvmLFDHx4tyvTxDaUcsJ9sPFX20icO4fg6IwmIiJul+W5v9JtWLt+T8qkB7nHYx4/jn+GYo+NoFKxdPwFV0SkAHKsNuViz5u4hCTH164uFe6c+61UqFCUihWLsv/kOfadOM/N5Qpd/ySXq3EXJJyDaf1h2VDwDYbmL7t2jquwWi2UCPFld8w5Dpw6T1Qh/yw5r4jkXQV+5I1dxYrQrh2uDZe/6slaQdcfbJX41WNgzjtZcFIREclqWZn7LdU7kXzHEAB6Wv5gznevcjz2QuZPLCKSD1kz2LDY3qzYy8OCj2fGfpW5MveXDPOnYflwLBn5Y+uNPaDtYNvX8z+EFd9nKKa0RGq5cBG5jIo32aXandDhc9vXiz+FpcPcGo6IiGQ/r7oPcK65rWD/WNIYJnz9AfGJmj4rInIlj4t1ElcbFtv73QT4eGas2JIdbn4Umr5o+/qP52Dj1Cw5bWToxeKNmhaLCCreZK+6vaDlG7avZ78C6352bzwiIpLt/Js/xck6jwPw2JkvGT1quJYQFxG5QkZH3pyNd32Z8BzR4lWo+yBgYEpf2Lkg06csEaoVp0TkEhVvststz0GDx2xfT30Mds53azgiIpL9wu78gCPlu+JpSaHn/rf55bep7g5JRCRXyWjD4rgLGWtWnO0sFrj9E6h6JyQnwE8PwJGNmTqlRt6IyOVUvMluFgu0+QCqd4GUJPipR6YTuYiI5HIWC0W7fc2BwrfgZ0mg5eonWbjsX3dHJSKSa2S0YXHshUQgFxZvAKwecNd3ULoxXDgDY7vC6QMZPp2jeKOeNyKCijc5w2qFTsMvJfJxd2cqkYuISB7g4Ulkn4kc8KtMuOUspWf2JHrnLndHJSKSK1yaNuXacbEXR964utJUjvH0gfvGQURlOHvQ9rk//nSGTuVoWHzqvKbfioiKNznGyxfuHQsRleDMARh/D8SfcXdUIiKSnXwCKfrobxzzKEppy2ESxtzDiVMZ+xAvIpKfZHTaVGz8xZE3vrm0eAPgFwYP/AKBReHoRtvI++REl09TPMQPiwUuJKUQE5eQDYGKSF6i4k1O8i8E3X+BgCJwZANMfhiSk9wdlYiIZCPPkOL49J7CGQKpYaLZMqIHSUnK/SJSsGV82tTFhsXeubh4AxBaCrr9DF4BsGuBbRUqFwtV3p5WCgf6AJo6JSIq3uS8sNJw/0Tw9IVtf8Kfr7k7IhERyWbBUTU4fef3JBoPGsUvYMn3z7s7JBERt7JmdOSNvWFxbh55Y1eiNnT9HrDAqtGw9CuXT3H51CkRKdhUvHGHknWh89e2r/8dAf9+4954REQk20Xd2JYt9d4BoOmhkayYOtTNEYmIuI/Hxd9CXF0q3N6wONf2vLlS5Xa2xUsA/nwDNk936XA1LRYRO7cWb+ITk915efeq3gluHWj7etZLsP1vt4YjIiLZr2aH/iyP7AVArdVvsGOlcr+IFEyXGhZnbKnwoLxSvAG4+TG46WHAwJS+cGhtug/VyBsRsXNr8abd5wv5btFOziUU0Ln/TZ6B2t3BpMCkh+D4NndHJCIi2eymhz7jP/8meFuSCZv+EKcO7XR3SCIiOc4zg8Wbs/G23xvyzMgbAIsF2n0E5VtC4jmY0A1ij6br0JKhKt6IiI1bizfHYhN474/N3DJ4HsPmb+dsvOtd2PM0iwU6fAZRDeDCaZhwH5w/5e6oREQkG1k9PKjQbxzbrWUoxGlO/dCV5PhYd4clIpKj7KtNpbjY8ybO3rA4L/S8uZyHJ3T9AcIrwJn98NMDkHThuoc5Rt5o2pRIgefW4s1bd1SjVCF/YuIS+GjWVhoPmstnf0Vz6lwBWgrP08e2hHhwSYjZDr88pBWoRETyuZCQULh/AjEmmDKJO9j2TQ9ISXF3WCIiOSaj06Ycq035eGR5TNnOL8y2cIlPCOz7F/549rorUEWG+gMaeSMibi7edL0pirnPNeOze2tRvnAAZ+KT+GLONpoMnsfgWVs4Hnv9anS+EFgE7p8AXv6wYw78PdDdEYmISDarULEam5sNJ8F4UOXEXLZNVu4XkYIj0yNvfLyyPKYcEVER7v4BLFZYPRb+/fqau5cI9QXg9PlER+FKRAomt6825elhpXOdkvz5TDOGdruRKsWCiL2QxPD5O2gyeC7v/L6Jw6fj3R1m9it+A3Qabvt66VewbpJ74xERkWzXpGUHZpV5CYDyG4ZwZMWvbo5IRCRnZHTkzdkL9p43eXDkjV2FVtD6XdvXs1+FXYuuumuQrxfBF6eIaeqUSMHm9uKNnYfVwu03FGfmU7fwXc+bqFUyhPjEFH74ZxdNP5rH61PXs//kOXeHmb2qd4JbnrN9Pa2/S53oRUQkb2rX8wVm+XXAajEE/vE48Ye2uDskEZFs5+Eo3rh2nH3kTVBeHXlj1/AJqHkPmGSY1AtO7b3qrpFh9qlT+fx3IRG5plxTvLGzWCy0qlaUqU805seH6lOvTBgJySmMXbaX5h/P54VJa9l1PM7dYWafFq9BhdaQFA8TH4C4GHdHJCIi2cjLw0rtvsNZRVUCOMfpkXdj4k+7OywRkWyVkWlTySmGcwm2pcLz9MgbsC1ccscXUOwGOBdja2CcmPbImkjHilMFYDaCiFxVrive2FksFppWKsykRxsx8ZGbaVIhgqQUw6T/9nPrJ/N5auJqoo+cdXeYWc/qAXd9B4XKwem98EtvNTAWEcnnihUKJrnrKA6aQhRN2MuBkb3UwFhE8rWMTJuKS7j0mTjPrTaVFm9/uG8c+IfbRtz//nSaDYxLasUpESEXF28ud3O5cMb2acCUxxtxa5UipBj4bc1BbvtsIY+O+Y8NB/LZXyj9QuG+8eAVALsWwtx33R2RiIhks3o1qvDPjZ9zwXhS8sg8jsz80N0hiYhkGw9b7YZkF0bexMbbijdeHhZ8PPP4yBu70FJw9yiweMC6ibDiu1S7XBp5o+KNSEGWJ4o3djeWCuP73vWY/mQT2tUoBsCsjYfpMGQxD41awaq9J90cYRYqUhU6fmX7+p/PYdM0t4YjIiLZ76477mR8xAAAIlb8j3Ob/3JzRCIi2cPe8ybFlZE3jpWm8sGom8uVbQqt3rJ9PesV2Lfc6e5Ix8gb9bwRKcjyVPHGrkZkCMMfqMufzzSlY+0SWC0wd8tRugxbwgPf/cuynTEYF5cdzJVqdIGG/W1fT30cjkW7Nx4REclWVquFTg+9wu8erfAghZRJD2FO7nF3WCIiWS4j06YurTSVz4o3AI2ehGodISURfu4JsUcdd2nkjYhAHi3e2FUqGsQX99Vh7nPNueemknhaLSzefpz7vlnGPV8vZUH0sbxfxGn1NpRuAgln4ececCHW3RGJiEg2CgvwpmT3r1ifUpbAlDPEjLwfki64OywRkSyVkYbF+XbkDdgaGHccChGV4ewh+OUhR99L+8ibo2cvkJCkfmgiBVWeLt7YlYkI4KOutZj/QnN63Fwabw8rK3afpNcPy+k09B/+2nQk7xZxPDzh7pEQWAyObYHpz6TZyExERPKPOuWKs+mWoZw0gUSc2UjMlOfdHZKISJbKyMgbe8+bfFm8AfAJgnvHgncg7F4E894HIDzAGx9PK8bAodMafSNSUOWL4o1dyTB/3u1Ug0UvteDhJmXx9bKydv9p+v64knZfLGL6uoMuvUHkGoFFbAUciwes/xlW/uDuiEREJJvd06oRY4q/CkD4ph85/98EN0ckIpJ17CNvkl34aB5rH3mTH1aauprCleDOL21fL/4Uts7CYrFo6pSI5K/ijV3RYF/e6FCNf15qyePNyxPo48mWw2fpP341rT9bwOT/9pOUnMeGHJZudFkjs5fhwCq3hiMiItnLYrHQq+cjjPK8GwDr9KcxR7e4OSoRkayRkYbFsfl52tTlatwF9fvZvv61H5zcc1nTYhVvRAqqfFm8sQsP9OHFtlVY/FILnm5VkWBfT3Yei+O5SWtp8cl8Jizfy4WkZHeHmX6NnoQqHSA5AX7uBefz0epaIiKSSoi/F7UeGMSSlOr4mHhOj74fEuLcHZaISKbZp00lpaT/D6r5ftrU5W57DyJvgvhTMKkXpYJtS6Nr5I1IwZWvizd2of7ePN2qEv+83JIX21amUIA3+06c55Up62n+8XxG/bOL+MQ8UMSxNzILKwun98LUJ9T/RkQkn6tTJoKdzb7ksAkjNG4npyY9qdwvInmeo2GxC4PhYxMKUPHG0xvuHgV+YXBwNfec/AbQyBuRgqxAFG/sgny9eLx5Bf55qSVvdKhG0WAfDp2O563fN9Fk8Dy+WbjD0cU+1/ILtSVyD2/Y+gcsG+7uiEREJJt1b1mX0cXfINlYCN02mQsrf3R3SCIimeJx8beQZBeK0faRN/lyqfC0hEZB568BqHXwJ9pal2vkjUgBVqCKN3Z+3h483KQsC15owXudahAZ6sfx2At8MGMLTQbP5au52zgTn+juMK+uRG1o84Ht67/ehP3/uTUcERHJXhaLhb49evCN5/2272e8AEc2uTkqEZGM87Dafg1xZTER+x9Zg/Jzw+IrVWoDjZ8C4COvr0k5scvNAYmIuxTI4o2dr5cHD9xcmvkvNOejrjdQJtyfk+cS+d+f0TQeNJdP/9zKybgEd4eZtnp9oFonSEmESb3h3Al3RyQiItmoUIA3dbu/y4KUG/A2FzgzpjtciHV3WCIiGWIfeZPiysibCwVs5I1dyze4ULwewZbzvBb3ESkJ8e6OSETcoEAXb+y8PKzcc1MUfz/bjC/uq03FIoGcjU/iy7nbaTx4Lh/O2MzRs7ksSVostmUE7f1vpqkHgohIfle/XATRDT/hsAkjOHYnZ3592t0hiYhkiNW+VLhWm7o+Dy+sd//ACRNITetO4me+5u6IRMQNVLy5jKeHlY61I5n9dFNGPHAj1YoHcy4hma8X7uSWwfN4a9pGDuameaa+Ibb+N1Yv2DIdln/r7ohERCSbPdSmHl9HvEaysRC8ZRKJq8a7OyQREZfZlwpX8SZ9vAqV4gOvAQD4r/4Otvzh5ohEJKepeJMGq9VC2xrF+WNAE37ofRO1o0K5kJTCqCW7afbxPF6Zsp69MefcHaZNidpw27u2r/98DQ6tdWs4IiKSvTysFvr17ME31rsBMNOfhePb3ByViIhrHKtNuTByPO6CbXXYwILU8+YyeyOa8m1Se9s3Ux+HU/vcG5CI5CgVb67BYrHQskpRfn28EeP6NKBB2UIkJhsmLN9Li0/m8+zPa9hxLBf0G2jwKFRuD8kJMOlBuHDW3RGJiEg2KhbiS6Wub7MkuRreKec5O/YBSMxl03tFRK7BmoGRN2ftq015F8ziTclCfnyUdB9HgqpD/CmY/DAk5+JFVkQkS6l4kw4Wi4XGFSL4qV9Dfu7XkFsqRpCcYpiy6gCtPl3AkxNWs+XwGXcGCB2HQnAknNgBfzznvlhERCRH3Fq9BEtrf8hxE0zQqS3ETX/F3SGJiKSbfdqUC7Wbgrna1GVKFfInEU9Gl3gTfIJh378w/0N3hyUiOUTFGxfVL1uIMQ834LcnGtOqalGMgd/XHqTt54vo++NK1u0/5Z7A/AvBXd+DxQrrfoI1E9wTh4iI5Jj+HW/hyyBbwT5g7Q8kb/rdzRGJiKSPqw2Lk5JTOJ9omzZV4FabuigqzB+ANbGhcMcXto2LPoWdC9wXlIjkGBVvMqhWVCjf9bqJGQNu4fYbimOxwF+bjnDnV//Q64flrNzthqW7SzeE5hf/8vrHc3B8e87HICIiOcbH04Pevfow0nQAIHHK43B6v5ujEhG5PlcbFsclJDu+DvDxyJaYcrtS4bbizb6T56BGF7ixJ2BgyiMQd9y9wYlItlPxJpOqlQhmaLcb+euZZnS5MRIPq4UF0cfoOmIp932zlCXbj2NycgnvW56DMrdAYhxMfgiSLuTctUVEJMeVKxxI0O3vsjalHL5JZzg74UFISb7+gSIibuRqw2L7SlPeHlZ8PAtm8cY+8ubgqXiSklOg7WCIqAyxh20NjHPydw4RyXEq3mSRCkUC+fSe2sx9rhn314/Cy8PCsp0n6Pbdv3QZvoS5W47kTBHH6gFdvgG/MNvKU3+/nf3XFBERt7qrXlmmln+HWONL0OHlxM8d5O6QRESuyXrxt5B0j7yxLxNeQPvdABQJ8sHb00pyiuHQ6Xjw9oeuP4CHD2ybDf+OcHeIIpKNVLzJYqXDA/iwyw0seKEFvRuVwcfTyuq9p3ho1Eo6DFnMrA2HSHGlM1tGBJeAjsNsXy8bCtv+zt7riYiIW1ksFp65ty2fevcDwHvx/zB7lro5KhGRq7vUsDh9n4sdK00V0ClTYFuhq2SYHwB7T5yzbSxWA9q8b/v6rzfh8Ho3RSci2U3Fm2xSItSPt+6szqKXWvBI03L4e3uw8eAZHh27irZfLOS3NQdcWhrRZVXaQ/1HbF9PfRRij2bftURExO2Cfb24/YFn+DX5FqykcG7iQ3D+lLvDEhFJk4eLDYvPJRTsZcLtShW62PfGXrwBqNcHKreH5AT45WFIOHeVo0UkL1PxJpsVCfLl1fZVWfxSS/q3qECQjyfRR2J5auIaWn26gEkr95GYnJI9F2/9DhSpBnHHbPNgU7LpOiIikivULR3GkSbvsielCAHnDxI35Un1QBCRXMnqYsPi8xcbFvt6FdyRN3Cp782+k5cVaCwWuPMrCCwGx7fC7FfdFJ2IZCcVb3JIoQBvnm9TmcUvt+TZ1pUI9fdi1/E4XvhlHc0/ns/YZXu4kJTFDSa9/GzLh3v4wPa/YPnXWXt+ERHJdfq2rs3XhV8lyVgJ2DaNpNXj3B2SiEgqro68iU+y/RHS16tg//piH3mz98R55zsCwqHL14AF/hsJm3/P+eBEJFsV7OznBiF+Xgy4tSKLX2rJK+2qEBHozYFT53l96gaafjSP7xfvcvxlIUsUraZ5sCIiBYiH1UL/HvcxzHIvACnTn4eYHW6OSkTEmWOp8HSODryQqJE3AFGFbD1vnKZN2ZVrDo0H2L7+rT+cPpBzgYlItlPxxk0CfTzp16w8i19qyVt3VKNYsC9Hzlzg3embaDJ4LsPn73AsiZhp9fpApXa2ebCT+0Di+esfIyIieVaJUD8qdnmdpcnV8E45z9nxvSE50d1hiYg42KdNpXdWv2PkTQFdJtwuKq2eN5dr8TqUqAPxp2x9L9U2QSTfUPHGzXy9POjduCwLXmzOB51rUjLMj5i4BAbP2kLjQXP54u9tnD6XyQ/cFgt0/AoCi8KxLfDnG1kTvIiI5FrtbijJgurvcMoEEBSzjvN/vefukEREHBzTplwceeNTwKdN2Ys3MXEJjuXTnXh6Q5fvwMsfdi2EpUNyOEIRyS4FO/vlIj6eHnRrUIp5zzfnf3fXolxEAKfPJ/LZ39E0HjyXj2ZtISb2QsYvEBABnS4uH77iW9g6K2sCFxGRXGtAlxZ84fcEAD7LvsDsXuzmiEREbDxcbFgcb582VcBH3gT7ehHi5wVc0bT4chEVoN1g29dz3oWDa3ImOBHJVire5DJeHla61i3JX882Y8j9dahcNIjYC0kMm7+DJoPn8d70TRw9E5+xk1doBTc/bvv6tye0fLiISD7n7+3JXT3680tKM6wYzk18GM6fdHdYIiKO4g1ASjoKOPGJalhsd2m58Gu0QqjTA6reASmJMPlhSIjLoehEJLso++VSHlYLd9QqwcynbuHrHnWpGRnC+cRkvlu8iyYfzeONqRs4cCoDvWtuHQhFa8C547blw7WErIhIvlYjMoSzzT9gV0pRAuIPc3byAOV+EXE7+7QpSN/UqXg1LHawNy3ee7W+N2Brm3DHlxBUAmK2w+zXcig6EckuKt7kclarhTbVizGtf2NGPViPuqXDSEhKYcyyPTT7aB4v/bKO3cddqKR7+cJd34Gn78Xlw7/NvuBFRCRX6NW8OqOKvUaSsRK0fRqJqye4OyQRKeCsl/0Wkp6pU/FJ9p43Kt5ct2mxnX8h6DwCx/LhW/7I/uBEJNuoeJNHWCwWmlcuwi+PNmR83wY0rhBOUorhp5X7aPnJfJ6euJptR86m72RFqkLrd2xf//UGHN2cfYGLiIjbWa0WnnjgXr623gNAyvTn4ORu9wYlIgWa07SpdI280bQpu6iwdBZvAMo1g0b9bV9PexLOHs7GyEQkOyn75TEWi4VG5SMY1+dmJj/WiBaVC5NiYOqag9z2+UIeH/cfGw+evv6J6j9i64GTFG9bPjwpE82QRUQk1ysS7EvluwayIqUSPinnOD3uQUhOY6USEZEcYL182lQ6Rt5c0FLhDo6eN1drWHyllm9AsZpwLsbWNkHLh4vkSSre5GF1S4cx8sH6TH+yCW2qF8UYmLH+MLd/uZiHR61g9d5rNKW0WKDjMPAPhyMbYM47ORe4iIi4RasaJVhY/X3OGj9Cjq8ibu5H7g5JRAoo54bF199fPW8uibqsYbFJTw8zTx/b8uGevrBjDiz/JpsjFJHsoOJNPlAjMoSve9zE7KebcmetElgtMGfLUToPW8ID3/3Lvztj0j4wqCjc+ZXt66Vfwc75ORaziIi4xxNdbmWY36MA+P7zMWb/SjdHJCIFUcYbFuvXl8hQPywWOJ+YzPHYhPQdVKQKtH7X9vVfb6ptgkgepOyXj1QuFsSX99fh72eb0bVuSTysFhZvP8693yzjnhFLWRh9LHV1vkp7qNvb9vWvj8G5Ezket4iI5BxfLw/u7PkMf6Q0xIMUzo5/EC7EujssESlgrFYXp01d7Hnjo2lTeHtaKR7sC1xnxakr1e8LFVpD8gW1TRDJg1S8yYfKFQ7kf3fXYv7zzeneoBTeHlaW7z5Bzx+W02nYEv7edMS5iNPmAwivAGcPwvRntISsiEg+V7VECKdaDuaACSf43F5OTX3B3SGJSAFknzqVrobFSRp5czn71Kn96e17AxfbJgy91DZh7rvZFJ2IZAdlv3wsqpA/73euycIXW/Bg4zL4ellZu+8UfX5cSfsvFzNj/SFSUgx4B0CXb8HqCZumwtqJ7g5dRESyWbdmNzCm2MukGAuhm8eTsGGau0MSyZdiL6gx+NXYp06la6lw9bxxYi/e7I1xoXgDzm0TlnwFOxdkcWQikl1UvCkAioX4MvCO6ix6sSWPNitPgLcHmw+d4fFxq7jt84X8uno/ScVqQ/OXbQfMeEFLyIqI5HMWi4U+PXox1nonAIm/9tcSsiJZbN3+U9z6yXx3h5FrWS/+JpK+4o2WCr9c2YgAAHYdj3P9YEfbBAO/Pgrnr7HIiYjkGsp+BUjhIB9ebleFf15uyVO3ViTY15PtR2N55qe13PrpAn727UpKyQaQcBam9IOUZHeHLCIi2Sgi0IfSd7/PxpTSBCSfJmZ8H02dFclCn/0VTdwFfZ66moyMvFHPG5tyF4s3OzJSvAFb24RC5dU2QSQPcbl407t3bxYuXJgdsUgOCfX35pnWlVj8ckteaFOZQgHe7Ik5x4tTNnH30d4keATAvmWw+FN3hyoiuYRyf/7VrFoUC2t+SLzxIvzQIs4uHObukETyhVV7TzJv6zGnJbHzmuzO/famxelZbepCkn3kjYo3YOtxCbDzaGz6lgu/kncA3PUtWDxg46+w7qcsjlBEsprLxZuzZ89y2223UbFiRT744AMOHDiQHXFJDgj29eKJFhVY/FILXr+9KkWCfPjvTAgvn+8BQMq8QcTvXu7mKEXykTw8r1y5P397qHNbRvo/BIDP/LdIOaIlZEUy67O/ogF4pvxBN0eScdmd+x0Ni13qeaOJAwClw/2xWuDshSSOxWZw1ajIutD8FdvXfzwPJ/dkXYAiBZkxsGN+lp/W5ew3efJkDhw4QP/+/Zk0aRJlypShXbt2/PLLLyQmJmZ5gJL9/L096XNLORa+2IJ3O1ZnWWBrpic3wGqSODyqF1//vZ4z8XpuRTIlejb81N3dUWSYcn/+5uPpQater7PQ1MLbJHBiTC9ISnB3WCJ51ordJ1i07TidPZfQe9/r7g4nw7I79zumTV1n5IgxRiNvruDr5UHJMFvT4p3HMjh1CuCWZyHqZlvbhF/VNkEkS6z8AX5+IMtPm6HSdXh4OE899RSrV69m+fLlVKhQgR49elCiRAmeeeYZtm3bltVxSg7w9fKgR8MyzH+xJUltP+WoJZwyHCRg/kAaD5rLp39u5dQ5fZgXcVnsMfjtCXdHkWnK/flbxWLBHGv5KSdMIBGxWzn2+5vuDkkkz/r0z2hKcJwPvEe5O5RMy87c75g2dZ2RN/bCDYCPp0be2JUrbOt7k6nijdUDunwN3kGwdyn883nWBCdSUB3fBrNfy5ZTZyr7HTp0iD///JM///wTDw8P2rdvz8aNG6lWrRqfffZZVsUoOczb00qnxjUI7/49AA94zqFewnK+nLudxoPm8uHMzRw7m8HhmSIFjTEwrT/EHYOIyu6OJkso9+dfXZrW5adiLwAQvnYE56PnuzcgkTxoyY7j/LvzGJ95D8cvJRaK13F3SFkiO3K/feRNSsq197NPmQKNvLlcuYiLfW+OxWbuRGFloP1Htq/nfQAHVmXufCIFVVICTO4DSeehTJMsP73LxZvExEQmT55Mhw4dKF26NJMmTeKZZ57h0KFDjB49mj///JMxY8bwzjvvZHmwkrM8KrSAhv0BGB70Aw2LJhOXkMzXC3bSZPBc3pq2kUOnz7s5SpHcJToaZs4Exx8i/xsJ0bPAwxs6fuXW2DJDub9gsFgs3NfzcaZZb8WKIX5SXzh/yt1hieR69twfHW349M9o+nr8QQPrZvAKgDu/cHd4GZbdud8jnQ2L7cuEe1gteHlo5I1d+SIXV5zKbPEGoNb9UK0jpCTBlL6QkInRPCIFRKrP/QsGwaE14BcGt3+e5dfzdPWA4sWLk5KSwv3338/y5cupXbt2qn3atGlDaGhoFoQnbtfyDdgxD5+jGxlfaixz23zJl/N2sHbfKUYt2c34f/fS9aaSPNasPFGF/N0drYjbnDgB3bobZs+6tKrIQ5228V3dV7EAtHoLilR1V3iZptxfcIQFeFP0ns/ZPaEVZRKPcGDc40T2Ge/usERypStzv2+5Y7S8ZzXPef9s26HdYChUzo0RZk52536PdE6bcjQr1pQpJ46RNxldLvxyFgt0+Bz2LYeY7fDn69BBo2lF0pLW5/5nuy7hfzU+s33u7/A5BBfL8uu6XLz57LPPuPvuu/H19b3qPmFhYezatStTgUku4eVrW0bwmxZYts3m1krTafn4w/yzPYYv525j+a4TjP93Lz+t2EfnOpE83ry8Y+lCkYKkW3fD3IVJhHfYgG/UCZL2BfNYkeexJJ2Hss2gwWMQmwV/GXMT5f6CpUGVUoyr+QEl1/clcv8fxCwdS3jDrG+8J5LXOef+GPy8zvG511C8LclQpQPUeQDOnnV3mBmW3bnfsdrU9UbeJNlXmtKUqcuVv9jzZt+Jc1xISsbHM5M/H/9C0Gk4jOlka7hasQ1Ubpv5QEXymSs/93sd8ObJko9hMSlQuztU7wRnzmT5dV0uX/fo0eOaCVzyoaLVbaMGAGa/juX4NppUjODnfg356ZGbuaViBMkphl/+20+rTxcwYMJqth7Oux9URFwVHQ2zZ1kIbrmBwOoH8QyO57VaX3FT8TWcOB/KrtrDwZq3/1qo3F/w3NO5C5MC7wfA988XSYrZ7d6ARHKZ1Ln/Aq8FjaGi9QCHYouwo/qXttEMeVh25/6LtZt0jLzRSlNpKRzkQ6CPJykG9sacy5qTlm8BN19cZOG3JyD2aNacVySfSOtz//9uGESZkH3sPFmaHZUGZdu18/ZvE5JzGjwK5Zrbmi9N6eNYQrZBuXDGPNyAXx9vRKuqRUgxMG3tQdp8vpB+Y1ayfv9p98YtkgN27LD96xt1AoCbLFt43OM3APpN/5wtByPdFZpIhnl5WGny4CDWmooEmDgOj+6tJWRFLnNl7m9uXUNvzz8B6D11ONH7w90VWp7hGHlzvdWmLk6b8vHSry6Xs1gsjtE3WdL3xu7WN6FIdTh3HH7rb1t8QUSAy3N/DAAdrEu5y2MxycZKj1+/IXpPcLZdWxlQ0sdqhU4jbM2XDq2F+R843V2nVBjf9arHHwOa0L5mMSwWmL3xCHd8tZgHRy7nvz0n3RS4SPYrX972b/y+QgRxjs+9h+FhMUw43pZfNnWmQgX3xieSUVERwRy/7SvijA8lz6xmz+8fujskkVzj8twfzmk+9voagK+PduHPHa2U+9PBaklnw+KLS4X7ZnZaUD5kb1ewIzPLhV/J3jbBwxu2zYaV32fduUXyOHvuTz7nQ3FieN/L9v/js0MPsGTfzdma+1W8kfQLLg53XFwxYfHnsHtxql2qlwhhWPe6/Pl0UzrXicRqgXlbj3HX8CV0+3YZS3Ycx6h6L/lMpUrQpq3hzNwavB73MyUtx9l9oTj9xw2nTVtDxYrujlAk425tfDN/RD4NQOTqTzmzY4V7AxLJJRy5f0EVPvT4nsKW02xJKM0L475Q7k8nlxsWa+RNKuUibCNvdmZl8QZStU3gWHTWnl8kj6pUCW5rm4KXbzyfeA0nxHKOVQkVeXPC4GzP/cqA4ppqHaH2A4CBKf2uuoRsxaJBfHZvbeY+15z76kXh5WFhyY4Yun37L3ePWMr8rUdVxJF8ZcJ4C293+o17w/8kOcVK93GjqHdzGBPG5+1+ByIAt/d8gYUeDfEkmbiJD2K0hKwIYMv9b/X4ktu8VnLBeHLvqDE0ahSk3J9O6W5YbJ82pZE3qdhH3uw8ng2LIjR4LM22CSIF3ZPvHeex8Mk08tjEOePDkzHP0bSJX7bnfhVvxHXtBkFYWTizH/547pq7lokIYNBdNzD/hRb0algab08rK/ecpPfIFXQc+g+zNx6+7jxnkbwgzLKPV2o8C8CuqOcZNedmZs20EBbm5sBEskCArxeFu43giAmjeOI+on98yt0hieQKnrGbeKbw/wCYV+gZfllQS7nfBY5pUynX3u+Co2GxfnW5UvkiF3veHI3N+j+MXtk2Yd77WXt+kTzqv5V/85znzwC8ndSTg2HBTPo1KdtzvzKguM4nCLp8CxYP2PALrPv5uodEhvrxdscaLH6xBX2alMXPy4N1+0/Tb8x/tP9yEb+vPXjdIbMiuVZKMvzaDy6chsibqPDQixouL/lO1fJlWF3X1vOm8v5J7Fn6i5sjEnGzpARiJ/TGjwRWe9Sidf9XlPtdlO5pU1oq/KrKhAdgscCZ+CRi4rJhZMz/27vvuKrr9o/jrzPYS0FxILhw75F7kuVsmpWalu3S9q67u/p1t8t2lpVZmpZlNsyZuGfuLe4tDkD2OJzz++MLCAqCyuEw3s/H434IZ34Od1x8v9f3uq6Pfw24/lPj6+Ufw/6lxf8eImXIkejT3HH0/3A3ZZJUrz/L/frjADaXwEY9St7I5Qm9Cno+Z3z991MQe7BITwv29+Q/g5qy7LnejO5dH18PKztPJPDI1A1cM3Yxv647QkZhl19ESpvlH8PB5eDmAzePB4ubq1ck4hR9r7udef63AOA/70mSYo65eEUirpMw5/+okbyLWIcvSQM/xWJRYuFSWUyX1jal5M2FPN0shFTyApww9yZbk+ugzQjAATMehBRtRCIV18npz1LffJxYcyA+t3xB6zCj3GbDIef/Xih5I5ev+1MQ2hHS4uG3+yHTVuSnBvl68Ezfxix/LoIn+jQkwMuNfaeTePqXTUR8sIgpqw+RZtOWtFIGHF1/rox4wLsQVN+16xFxIpPJxFX3fMRuU20qO85y6Nu7tIWsVEz7l+Kz9jMAJlR+nK5tWrp4QWWTOetMxFbowGK1TV1Mztyb4twu/Hz93obAesbYhJlPKPZLhZS+7W/anpwOwN5u74N3IG2ykjcbD8c5/f0VAeXyWaxGlYG7HxxeBcvGXvJLBHi78VifBix/PoLn+zemiq87h2NSeHHGFnq+u4jvlu8nJV1JHCml0pNg+r1gt0GT66H1cFevSMTpKgf4kXLdV6Q63GiStJpN099x9ZJESlZKLBm/3ocZBz/behFx872YTBpQfDlyBhYXkrzJvqCngcX5q181a8ep004cJu/hC4O/AbMVts2ATVOd914ipVFCNPw5GoAp5kG07nkTAG3CKgGw4VCc0zfkUfJGrkzlOjDwA+PrRW/D4cvbQtbXw8qDPeuz9NkI/juoKdX8PTgRn8prf22n+7uRfLV4L4lpRa/sESkRc56HmL3gHwLXfQw6eJcKomXbzqys/wQAjbe8z+Gd2j5cKgiHA8dfj+OWdJx99uqsbvRszlVXuXTnBhYXtfJGyZv8ZFfe7DnpxMobgJB20OsF4+tZz0DMPue+n0hpYbfD7w/hnhbLdnttdjR7EqvFSKU0reGPm8XEmaR0DsekOHUZSt7IlWt1G7QYAo5MYxvB1PjLfikvdwt3d6vLkmd7878bmxNSyYvTiem8NXsn3d6J5JMFuzmbklGMixe5TNv/hPU/ACa46SvwDnT1ikRKVI/hL7DOoyMepgxs0+4hNdnJJw0ipcHGKZi2/06Gw8Iz9kd4fEAbV6+oTMsZWFzkmTc6dclP4+p+AOw4fvnH4EXW7Qmo3Q3SE2H6fZCp43KpANZ8BXsXkIY7j2aMpkeTWjl3ebpZaFozAIANh50790YRUIrHwA+gUhjEHoDZz17SU6OiYPZs2L373G0eVgt3dKrNomd68d4tLalXxYe45AzGzo+i29uRvD93FzHOmKgvUhTxx+CvR42vuz0Odbu7dDkirmCxmAkd9S2nqURd+0E2TLi07cPzi/0ipdqZvTiyjnHG2obQrsvVhAV5u3hRZVvOwOIiVt6obSp/TWr4YzLB8bOpnE5Mc+6bmS1w81fgGQBH18LiS2udVeyXMufEVpj/XwBezxjOIXMYXeoH5XlIm9BKgNE65UxK3kjx8AzI2j7cbPTAbv6l0KfExEC//g4aNYIBA6BhQ+P72FwJSzeLmSHtQ5n/ZE8+GdqGhtV8SUiz8dnCPXR7J5I3/t7OyYRUJ34wkfPYM40B3SmxULMN9HrR1SsScZng6qEc62XMO+t8+lf+nVf4DISixH6RUseWDtPvwZSeyMrMpkxzv5HRvcNdvaoyz1zUyhubKm8uxtfDSt0qxtybbcdKoPomoJbRLg6w5H04sKzQpyj2S5mUngzT74HMdA5W6cHkzD50rBeIj4c1z8Oy5944e2ixIqAUn7BOubYPf9KowrmIYcMdRC6xETRoAyEPLSBo0AYil9gYOuzCP+AWs4nrW9VkzmM9+PKOdjQP8Sc5PZOvl+6n2zsLeeWPrRyLc26PoQgAyz+CA0uNbcEHfwtWd1evSMSlWvYazL/VhwJQf/kzHDl08RkIlxL7RUqNhW/AsQ2cxZcnMh7ikT6NCfByc/WqyjxrUQcWa6vwQjXPatvYevRsybxhs5ugzR2A49xFrSwOh4P41AwS02wkp9uwZdoV+6VsmvcSnNoJvtV50zoGMNG7UfAFD2sTasw+234s3qk7JlsLf4jIJej+NOxdCIdXkTL5XhbXm039hm40aJD3YVFRMHeOiaBBW/Ftdgwg618Tc2e2ZvduLngOGFdo+jWvTt9m1VgUdYpPF+xm/aE4vl95kClrDjG4bS0e6lWf2kE+zv+sUvEcWQuR2duCv6dtwUWytBn1IfvfW01d2z72Tbyb9W3n06RR8cV+EZfatwiWG1UGz6bfi3eVMIZ3qu3aNZUTOZU32ir8ijUP8efPTcdKLnkD0O8dOLgSYvaSMOVRltX4AWuVRD5evZGtR89VAHlYLRw/0xD/iDh8mx0HFPulDNjxF6ydAEDyoM+JnGSM7Ojd+MLkTWigF0E+7pxJSmfbsXjaOmmQvSKgFC+LlbirvybR5o/XmX/594N38i2L3LvX+NczNCbP0z1DzwCwZ8/F38ZkMrKe0x/qwpR7O9K5XhAZmQ5++vcwvd9fxBM/b2TPyYTi/GRS0aXGG2WTjkxodjO0Hqa+bZEsVg8vMgdNJMXhTnv7Bv795VWnxH6REpd0Bn57AHDwU+bVzLV34K7WTfhnnlmxvxhkz7zJLKT4ImdgsWbeFKh5SFblzbESTN54+HL22m/JsLvhd/hP/h7/Iff8vCxP4gaMrd4DI3bg3TA6z+2K/VJqnT0Kfz5ifN3lUZbYmpGR6SDYywdb7IVFAiaTiaY1/QHn7vqm5I0Uu9sfCuX+WcYMhJe6v8/1t0+4oCyyflbBQurhvDv0JO2oCYC1iDVhJpOJLuFVmHp/J359sDM9G1bF7oAZG45yzYdLGP3j+pKZvC/l36ynjVbAgDBiu31IvwGob1sklzEvtOTZdS8B8HKdcVwzaqLTYr9IiXA44I/RkHiC425hvJpxBz7xVbjzmmDF/mJiKWrblE1bhRemWVbb1OGYFM4ml9wOULc90ZqXlxrbh7/X6i0auB8m9WAQ9bf3Zufr/dj+f315tEtzHDYzZjd7nucq9kupZM+EGQ8YrYA1WhPT5mWe+/gkAHuWVi0w9vt7Gq202clmZ1DyRopVdkn8vJBwfrb1wmxy8GXD16l9zQrmzjHlXKVq2BD69nMQH9mcxG0hpJ/05dh33Yhb1ASAa6+99AOi9nUC+f7uDvw5pivXNq2GwwF/bzlO/4+Xcu/3a9nk5AFSUn4dnzMVNv+Mw2SBwV8z9O4A9W2L5JId+6eaejArswPupky+qvUmNQesdHrsF3GWkzPHQ9RsMk1u3JP4IKkOT/b/2ZCgQRsV+4uJ2XRpW4V7qG2qQAFeboQFGrufbSuh6pvs2D+pfhuWZjbHy5TOZ26fYkmCyL+8OXzAgre7lSevr03dvV2wxRrrc2SaOD65k2K/lEqnfx8LB5ZitxrzLYeOtBLjcQoAnyZHC4z92cnl5HQlb6SMyF0S/6ptJHvtNahhiuGzJq8DjjxlkVOnmIjoYeXMzNYcn9gD21nvYjkZblmrEuNHtmfO4925rlVNTCb4Z0c0N3y+nBHfrubfAzGFv4gIxs4I99y0G78lTwHw8oIX6H5HR+bOMeEfYczssPqn4tvsGP4R2/KcpIpUJOdifyzPZ9zLEUcV6pqj+aDhu5ismSUS+0WKS0wMPDR4MwGr/wPAKzGj2O6oQ/zaOni3OaDYX4wsWWcihc68sWlgcVE0DzHaNkqqdWrvXvCqH41blRSezHiI0w5/mpgP8b/GHwF526FmTAigyZGu2OK8MFkc+LU9qNgvpUpMDDw5ZCWVNr4FwF2/fED3m+uzcH0CFt80ACw+GQXGfm93Iz6lKHkjZUXukvgUPHkk4xHSHFb6evzL6Ku+JjzXrpqVK8Oc2SbmzgUcJgKvKd6T4cbV/fl0aBv+ebInN7cNwWI2sXT3aYZ8uZLbvlrJst2ncRRypUcqtjvvSGV0tbvxdU9iRXpzxgf0ZuWarANIzewQyZE79sfjy2Ppo8l0mBjstpQHbvugRGO/yJUaNSKRx2uOwsOazvz0dkz26klmshtnlzdQ7C9mRW2byhlYrJk3F5XdOrXlaMmMDPCrlkLQwE0AnKIyT2U8BMAo79lc13DWBbF//t/uvBDRGocdfJseV+yXUuX+kbE8VuterOZMpqf2ZFZYY1auycSn2dELHptf7PfKSt6obUrKjPNL4jefbcyrh41APrbff2jgt+WC52Rm/fftrAOi+lV9GXtraxY+1YuhHcJws5hYvT+GO75dzc3jVhC5M1pJHLlAVBT0ynydttU3E+vw5Qn7g3g3i8avs3FUcf7MjtTDQQB5DlREKorzY//qs6147/QIAN6r/wH7ji2/4DnOjv0ilyMqCq6zPE+joD2ccFTmWft9gIn06ADsaW6K/cVMbVPFK3to8bYS2HEqI9PO2FXrsXhlkB7tT+L2miyI68jnJ24DYPItD9Mg+MKT3np+gcSvuvAXRrFfXClql4PbvB6jdsARDtir8Qoj8G12DL8uu/BtceSCx+cX+9U2JWVS7pL4o+Ou5u3vXmdVbF/czWnwyyhIyzuBu6ABlsV9QBQW5M1bN7dgybO9uatLHTysZjYciuPuiWsZ+MkyZm85XuiVH6k44tfO4anOnwHwTMYDRGP89+nT5BiYHJxdYJyk2uI9SdwWQnxkM/r2c2irS6mwzo/9L437iHWpbfE1pVIr8mF2HT2V5/ElFftFLkXy6l+4t+0k7A4TT2Q8TCxGG4pbUIJivxMUeWBxhgYWF0XzrN1u9p1OIiHVuUOLv19xgPWH4vD1sNI4pi1n/mrD0XFX88TXnxGV2Bp/t1iYfi9k2vI8r359iFvegMwUtzy3K/aLK6WvnMCQZn+Q7rDyaMYYEjHmM/m2OIrFKyMr5te8aOzPaZtS5Y2UJdkl8VFRMGsWREWZ6PTmOPCrCWd2G7v25HL+FVtnHxDVCPDi1eubsfS53jzQox7e7ha2H4/noR/X0/ejJfy+4Si2THvhLyTl19mjtDnwIABfRg/mH3u7nLtSDweBw0Tnq86dpJ6Z2ZqIHlamTjG5asUiLnd+7N+5y0Kb5ycTbw6gmekA2yY+Rnyuk4mSjv0ihTqzl5YHHwdg7OlhrLQ3y7kr9XAVxX4nKErlTabdQXpmdtuUTl0uJsjXg5oBngDsOJ7gtPeJTUrnkwVGJfJ/BzUl8g+fnNi/bac7DV/8Dtz94NAKWPx2nuc2bAh9rzVx+tcOZP/fnry/imK/uM6JLTQ9ZOyY9vqR+9nsqH/uvqz/RoPiwjgzs81FY7+Xm5I3UoY1aAD9+xv/4hMEt3wLJjNsmgobp+Z57PlXbEvigCjYz5MXBjRh+XMRPBoRjp+nld0nE3n85430GbuYaf8eJt2mJE6Fk2mD6fdiSY9ld1Irnv7xk3xPLJcszp2gNE5aK1d29eJFXC937DdXCsF00zgAbs74mx8nfpGnTdUVsV8kX7Y0+HUUZlsim+O78EnqEADs6RbFfifKrry52DWzNNu5EyFV3hSuWVbr1FYntk59vGA38ak2mtTwZ3C7WsB5x/2B9eC6j4wHL3kf9i3K8/ypU0z0bBlA4qYwAMxmh2K/uEZaIvwyCrM9jdWxfXnnp9dyjvuT91bF4p0BDhPzvwotNPbnJG/UNiXlQu0u0MvIavL3U3AqKueuC6t1Su6AqLKPO09e24hlz0Xw9LUNqeztxoEzyTw7fTO931/EpFUHnTp4SkqZxe8YV4rc/Qh++Du6dfUp8MQyz4GKiOTLr8VATja/D4Bhx9/mp3nn5t+4MvaL5DH/v3B8E3gFsuHqVzBXTSYzxY2jX0Yo9jvRueRNwdmb7GHFoORNUTTPGlrsrB2n9p1KZPKqgwD8Z2CTnP8PL9DiFmg7EnDAb/dD4smcu7Jj/59vhWMxmfCsfYZXPotR7JeSN+sZozPEryaNnhtHRA+3nOP+zAQvAK5tUp1gP89CY7+XdpuScqf7U1C3B2QkwS93QUZKnrtdeUAU4OXGmIgGLHsughcHNKaKrwdH41J4+fet9Hh3Id8s3Udyuq3wF5Kya+9CWPKe8fV1HxFQt75OLEWKQfCNb3I6oDkBpmQaLX+cVbtP5LlfJ8PiUjv+gtVfAhDb9xPeW2Oc9D5xdSNmTndX7HeinLapIlTeuFlMBScKJEfOduFOqrx5a/ZObHYHVzcOpmt4lYs/uN87ULUJJEbDb/eBPe9Jbdc2XgztGArAh/9EaQMRKVkbfoRNU4zOkMHfUKlmUM5x//Q/M6ja3hi4Pap77SK9nNqmpPwxW+Dmr8GnKpzcBrOfc/WKLuDjYeX+HvVZ9lxvXru+GTUCPDmZkMb//t5Bt3cW8vnCPU4fAicukHDCOLDAYVwpanFLzl06sRS5QlZ3gu6cTIrZl7bm3URNeYbjZ1MKf56Is8UegN9HG193HsNL22qSmGajdWglHhsUptjvZJasMxH7RU7atU34pWlRy6i82X0ykZik9GJ97ZV7zzB/ezQWs4kXBjQp/Anu3jBkIrh5G61TS8de8JDRvcNxt5hZsz+GlXvPFOt6RQp0cofRCQJGZ0idrjl3NWgAMZUOk2rLJDzYl071Agt4kbxUeSPlk191I4GDCdZ/D5unuXpF+fJ0s3BnlzosfqY3b93cgrBAb2KS0nlv7i66vh3Jh/OjiEsu3j+K4iJZc25IOgXBzaD/u65ekUi5Ywqsi/mmLwAY6fiTCRPGaa6YuJYtzagCTjsLta5iYehDzNpyAovZxJs3tVCVRwmw5FTeXCx5k71NuJI3RRHs50nj6n44HLB096nCn1BEDoeD9+buBGB4xzDCg32LuKDGMPAD4+tFb8L+JXnurhHgxdAORvXN2PmqvpESkJ7VAWJLgXq9jc6QXDYdjuPdubsAuLNLHUymov0t8NJuU1Ju1e8NPZ81vv7r8Tzzb0obd6uZoR3CiHyqJx/e1or6VX2IT7Xx8YLddHtnIe/M2cnpxDRXL1OuxOJ34MBScPOBW78HNy9Xr0ikXPJocQPxre4FYHTc+3zy2wIXr0gqtPn/hWMbwLMSKTd8w3/+NI5F7ulWl6ZZWy6Lc5mzZ95ctPImK3mjnaaKrGejqgAsjiq+5M3iqFOsPxSHp5uZMRGXuJ9362HQejg47MbFslzzbwAe7h2Ou9XM2oOxrD8UV2xrFsnX30/DqZ3gm1VQYD6XGD6ZkMoDk9aRbrPTp0kwwzuEFfll1TYl5VvP56BO96z5N3dCerKrV3RRVouZm9rUYt4TPfl8WFsaV/cjMc3GuEV76fZOJP/313ai41NdvUw5T1QUzJ4Nu3cX8IA9C3LNufkYqqg+XsSZ/K97i/jAllQyJdFn63P8snqvq5ck5VChsX/7HzlzbrjpKz76N4WjcSmEVPLi8T76O1BSsitv7BetvMlqm3LTaUtR9WxoJG+WRJ266M+2qBwOBx/ON5KbIzrVJtjP89JfZMB7ULWxMf9m+j155t9U8/fk+lY1Afhh5YErXq9UXIXG/vWTzs25ueVb8K2ac1e6zc7Dk9dzIj6V8GBfPrytdU6CuSi025SUb2YLDP4WfILh5Hb4+0koA6WSFrOJgS1rMOvR7owf0Y6WtQJIzbAzYfl+ur+7kJd/38qR2NKdiKoIYmKgX38HjRrBgAHQsKHxfWxsrgedPWJcAcIB7e6ClkNctFqRCsTqjv+IyaRa/Wht3kvyzBfZcCi28OeJFEGRYv+Zvefm3HR5lK2+nflm2X4A/u+GZni7W0t+4RVUTuXNxZI3WQOLtdNU0bWvHYiPu4XTielsPx5/xa+3cNdJNh05i5ebhQd61r+8F3H3gSHfG/Nv9i+BRW/nufuuLnUAmLXlOCcTdDFULk2RYv+JLTDraePr3i9CnW45d+0/ncSDk9ex9mAsfp5Wxo9oh5+n2yWtwTtX25Sz2v+UvBHX8qsGt0wwsp+bpsL6H1y9oiIzm01c26w6f4zuyvd3d6B97cqk2+xMWnWQXu8t4tlfN3HgdJKrl1lhDRvuIHKJjaBBGwh5aAFBgzYQucTG0GFZwdSWDr+MgpQYqN7S2BFBREpG5dq4Dx4PwJ2WOfz6/ac6WJdiUWjsT0+GaSMhPQHCupDR6z88++tmMu0OBraowdVNqrn2A1Qw1iK0TaVlKHlzqdytZrpk7QS1aNfJQh59cQ6Hg7FZVTcju9Smiq/H5b9YcGO47hPj6yXvwu75OXc1DwmgbVglMjId/LTm8JUsWSqgQmN/6lkj9ttSIfwa6GbMuTkal8Lz0zfTZ+xiIneexGI28cnQNtSrWsSZTrl4ZiVvMu0OMjKVvJHyqm53iHjZ+HrWM3B8k2vXc4lMJhM9G1bllwc789P9negaHoTN7mDa2iNEfLCIx3/awO7oBFcvs0KJioK5c0z4R2zFt9kxrP6p+DY7hn/ENubOMRmllP+8AkfWgEcA3PoDuF1GCbCIXDZzkwGkd34MgBdsn/O/iX9qgLFckSLF/lnPQPRWY9fLWyYwfvlhth+Pp5K3G69e38zVH6HCyR4Krbap4pfdOnWlc2/mb49m69F4fNwtPNDjMqtucms5BNrfY3z9230Qdy5Rc2dW9c2Pqw+ScbH940VyKTT2Rzngj9EQsw8CQkm9bhwzt57gzglr6P5OJD/9e5hMu4OIxsH8OaYrvRsFX9Y6vHIlmJ3VOqUoKKVD18ehYT/ITDOyoillr4TeZDLRqV4QP97biekPdSGicTB2B/y+8RjXfLiEhyavY+vRs65eZoWwN2uEhmdoTJ7bPUONLSgTV8+AVcauN9z0JQTWLcnliUgW9z7/JaVmZ3xNqYw+9Rr/+/1f7TQil62w2J+64gfYODlr1sEE9qT68fE/xmCE/w5qSlW/K6gokMtizt5t6iK/9mnZbVPaKvySZCdv1h+K42xKxmW9Rqb9XNXNnV3qEOjjXjyL6/cW1GxjHO//cqex8xvQv3kNqvh6EB2fxrxt0cXzXlLuFRb7bcs+hx1/4TC78U/zd+nyyUbGTNnA4qhT2B3QNTyI6Q91ZsJdV9GsZsBlr8PNYsbNYsQ0Zw0tVvJGSgezGW4cB5XCIPYA/PYA2O2FD50qpdrVrsyEu65i5iPd6N+8OgCzt55g0KfLuHviv6zXfAenqp91YSj1cGCe21MPB9G4yi5aHTg364DGA0p4dSKSw2LFa+j3pHlWpZH5CO02vcqklQfKbOwX17pY7G9XYz3NDmbPOngJe+3uPDd9M+mZdno1qspNbUJKeLUCl1p5o+TNpQgN9KZ+VR8y7Q6W7zl9Wa/xx8aj7DyRgJ+nlft71Cu+xVk9YMhE8KwER9fBnOcBOLDPTIdAY9vw7zW4WIroYrG/R+1lND78XwAm+N7HvQscxCSlUyPAkzG9w1n0dC9+vLcT7WoHnv+yl8XTyTtOKXkjpYd3INw6CayesHsuP9z/7sWHTpUBzUMCGHdHO+Y/0YMbW9fEbILInSe5+YsV3PHNalbtO6OrzE7QsCH07ecgPrI5idtCsMV7krgtBMeyMObdPRyzLcnY6ezqV1y9VBHxq4bH0B/INFm5wbKC/TPH0vKa02U69otrFBT73VZW5+87R2C2p0GjAdDtSSYs38+6g7H4uFt446YWmExF31FEik+RBhZnbxWutqlL1rOh0f6xeNelt06lZmTywTyj6ubhXuFU8i6mqptslevA4G8AE6ydwAcjJtOoEYx/rjYOu4k1+2NYvevKhy1L+VdQ7PddE8jvw+/C5Mjkd3s3Xj/ZFS83Cy8OaMySZ3vzdN9G1KniU6xryW6dSk63FevrZtM4fSldaraGgWPhj4e5I+Rt/h5WieUBDUg9HEhkZHOGDrMyZ3bZO8BqUM2Pj25vw2N9GvLFwj3M2HCUZXtOs2zPaa6qU5kxEQ3o0aCKDh6L0dQpJoYOszJ3ZuusWxwsfWQEoV67wT8EbvkOLAqBIqVC7S6Yr30d5r7Ai24/suW2uqxKakHqoSplOvZLyTs/9ptNmax5bDDVPI5AYD246Uv2nknmvbm7AHhhQBNCKnm5cMUVm8VU+MBiVd5cvp6NqjJh+X4WR53C4XBc0nHm5FUHORqXQnV/T0Z1reOcBTa4Bnq9AIve5OGwp5g5xJ3dVYLITPDAGpDKg+8eYsO3zZ3z3lKunB/73czpLHl8IJXdTrHDHsbz6ffQq1Ewr9/QnNBAb6etI3vHKSPpXPznGUphS6kT5TOcL9eOwmxy8FX4/1E34OCFAwfLqLpVfHhvSCsWPdOLEZ1q424x8++BWO6csIYbP1/O/O3RqsQpJpUrw5zZJqKiYNYsODXjY7oF/gVmN2NAsW9VVy9RRHLZHfgQU7fdjJspky+8PqamX3S5if1Sci6I/T+/QbuAhcb2xLdNxubmx1PTNpFms9O9QRWGdwxz9ZIrNEvWmchF26ayZt54WHXacqk61g3E083MifhU1h4segljfGoGny/cA8AT1zRwauIsqsYz/B11LV5uqfzQ+EWq+J/CGmDsPnja9xjbdjin/UTKl/Nj/8lJL9LUbw3xDm8eyHiCG68KZ8KdVzk1cQO52qbSnTNwW1FQSp29e+GxOe+wIaMBlUxJjHcbixepOUOn9uxx8QKLQa3K3rx+Y3OWPtebe7rVxcvNwqYjZ7nvh7X0/3gpMzcfu2gJsRRdgwbQv8ECqmx6zbih/ztQq71rFyUiF9i7z8R9f3zKTlsowaY4vnT/EHcy8Aw1ZjWUh9gvJadBA+hf+w8Ct31g3HDdJ1CtGV8t2cfGw3H4eVh5Z3BLVby6mLlIlTfaKvxyebpZuLG1Mc/pkwVFz4CPX7yP2OQMwoN9Gdy2lrOWB8DefWbumDGeA5nVCDWf4hO3z7CQicMOFq8Mpq854dT3l/KlQQPoX30ylaK+BuDxjIdp36Ytb97UIqdN05m83J3bNqXkjZQ69etDeqYHI3e8wSmHP03Mh3nPbXzOEKrwcBcvsBhV8/fk5UFNWfZcbx7uVR9fDys7TyQwZsoGrv1wMb+tP4JNWyVemZh98Ovd4LBDmxHQ/u4CH6ohqSKuU78+JGX4MmLnW5x1eNPWvIdXrROxZxhlx+Up9ksJiN4OMx4yvu48BloOYeeJeD76x5jh8cr1zaiZ1S6l2O86liLNvMlqm9JuU5dldO9wrGYTS3efZu2BmEIfvzs6ga+X7gPg2b6NsFqce7pYvz7EpVZmxM63SHZ40MOyhWetP5Fx2g+ADWcPF/IKIrkcWYdj5hMAjM24BZ8Wg3jvllb5Jm6cEfuz26Y0sFgqjOyhU7vmRnDXrjfIcFgYZFnFfYmR9O3noEEDV6+w+AX5evBsv8Yse643j/dpgL+nlb2nknhy2iYiPljMT2sOkW5TEueSpSXCT3dAahyEtIeBH0A+V1ljYoyhqGV9QLZIWZYd+zfN7sd9e17F7jAxzLqQu4L/pMPwA+Uy9ouTpMTCT8MgIwnq9oQ+r5GakcljUzeSkemgT5NgBrcNUewvBXJ2m7pI5U1aTuWNTlsuR2igN0PaG9UzH2YlLwuSmpHJI1M3kGaz06NhVa5pWs3p68uO/atnXc+YfS8A8ID1b66JOgAO2HDsDIfOJDt9HVIOJETj+PkOTJnpzM1sz5LqdzL21lY5cSabM2N/9sDiVCVvpCKZOsVERA8rs34eyaOz3gXgjR6v88ubC/I8rrxdLavk7c7jfRqy/PkInuvXmCAfdw7FJPP8b1vo9d5Cvl9xwGnBoNxxOOCPh+HkNvCtBrdNMramzMew4Q4il9gIGrSBkIcWEDRoA5FLbAwdptY1kZKUHft/mfIALy4wtvZ81TqR2mG/sWjXyZzHlbfYL8XIngm/3gOx+yEgLGc4/btzdrErOoEqvu68dbPRLqXY73rZbVO2zMJn3qht6vKN7h2Om8XE8j1nWLO/4Oqbt2fvZOcJ4/fk/SEl11aYHfu/m/wEby0zqia+6v0sQ2vFAfDLOqP6RrFfCmRLh2kjMSUcY4+9Ji+bRvPR0Ha45VM55szY75mz25SSN1KB5B46df1r93C2/kjMJgd+c+6G07vL/dUyP083HupVn6XP9eblQU0J9vPg2NlUXvlzG93fXcjXS/aRlOacXspyY/G7sP2PcwOK/Wvm+7CoKJg7x4R/xFZ8mx3D6p+qIakiLpI79vd88QkSwm7C3ZTJF24f8saUeazeFV+uY78Ug/n/hb0LwOoFt/8IPkEsiTrFhOX7AXjvllZU9fNQ7C8lilZ5k73blE5bLletyt4MaR8KwIfz86++idwZzcQVBwDj9yTYz7Oklpcn9rd+8mWSavTB05LCf5Nfpwpn+XnNEfr2tyv2S/4cDvj7STi8igSHF/dnPMmzN3TIdxtwZ8d+tU1JhdagAfQfYCJg6PsQ2gnSzsKU27h/ZGyFuFrm7W7lnm51WfJsb16/sTkhlbw4lZDGG7N20O2dSD6L3E18aoarl1n6bP8DFr1pfD1oLIR1KvChe/ca/3qG5r0SVZ4GZIuUNdmx3++Oz7FXa0EVUzwfO97lvq+WsGhdYrmP/XKZNvwIKz8zvr5pHNRoSUxSOk/9sgmAEZ1q07txMKDYX1rkDCwuwm5Tqry5MtnVNyv3neGjf6JyKrkdDgdztp7gqWnG78mornVyfk9KmhH7LfiM/BaCGuCVcpxvPT8kLjGBFYdOKPZL/lZ/CRsmkYmZMRmP0rRFOwa3Dcn3oc6O/TltU6q8kQrN6gG3TYaAUIjZy/2VR1E5YmOFuVrm6WZhRKfaLHy6F+8ObkmdIG9ikzN4f14UXd+OZOy8XcQmpbt6maXD8c0w40Hj644PQduRF314/frGv9kDsbOlHg4CNCRVxKXcfTAPnYrduypNzQd5x+cjgocurzCxXy7BoVUw83Hj657PQbObcDgcPPvrZk4lpBEe7MuLA5rkPFyxv3TIGVh8kXPw7IHFHhpYfEVCKnlxd9e6AHz0z26u/XAJU1Yf4rbxq3hw8jpikzNoHuLP8/0bu3ilgFclGPoTeAbQiijesH5LQM/tiv1yoT0LYO6LALyZMZSdvh1446YWBbb8OTv2e7qrbUrE4FsVbp+CzezNtfUX8maTD/PcXRGulrlbzdx6VSj/PNmTj29vTYNgXxJSbXwSuYeu70Ty1qwdnExIdfUyXSchOmtIZTLU6w3X/q/Qp2QPyouPbE7ithBs8Z4kbgshPrJZuR2QLVKmVArFfPuPZJrc6W/5l6f8fspzd0WI/VKI2IPw8x2QmQ5NroeezwPw3fID/LMjGneLmY9vb52zhSso9pcW2eMo7Bfdbco4CfJQ29QVe75/Yz6+vTXV/D04FJPMizO2sGZ/DJ5uZh6JCOfn+zuXniRZlXC45TvsmBliXcKDlX/Lc7div3AqCn4ZBQ47v9p78m3mAF69rhkBXm4FPsXZsd/bzdgh01ltU1anvKqIs9RoycmuX1Fz6Qju8f6bAxlVmZR5LVCxrpZZLWZuaB3CdS1rMnfbCT5buIdtx+L5ask+Jq44wNAOYTzQsx41ArxcvdSSk5ECPw2Fs4chsD4MMYZUFsXUKSaGDrMyd2brnNv69nMwdUrJDOoTkUKEdeRUx4+ovuphHrPOYL+9Br/buwEVK/ZLPlLjYertkHQKqreAm74Es5nNR+J4a/YOAP4zqAnNagZc8FTFftcrUttU9m5TpSWpUIaZTCZuaB1CnybV+HzhHqasOUTvRsE807cRNSuVwmPG8Ks53fZNgtc/z4vWKRx0VGO+vT2g2F/hJZ2BKUMg7Sy73JryYsLdRDSuRr/m1Qt9qjNjv5e7kWTWzBuRLDWvvp7vDmfvQvID3VK3V9irZWazif4tajDzkW5MuKs9rUMrkWazM3HFAXq8u5AXfttSMbZXtNuNVqmj68CrMgz/xfi3iHIPyps1yxhmNme2icpFfwkRcbLq/Ybz87HHAXjHbTztTTtJP+lXIWO/ZMm0wa+j4OR28K0OQ38Gdx/iUzMYM2UDGZkO+jWrzohOtfN9umK/6xVlYHGqBhYXOx8PK8/2a8zG/17Lh7e1Lp2JmyzB1z3Ib3FDMJscfOz2OY2Tj1bY437JYkuDn4dD7AESvWsxNOFRzG4evHZ9syLtkObM2J898yZFbVMi59z43pPMOzUMi8nOF14fU321OxE9rBX2apnJZCKicTVmPNyFH+/tSMe6gWRkOpi65hC9P1jEU9M2sfdUoquX6TwL34Dtvxs7S902GYLqX9bLNGgA/fujAwGRUurat19hWcx1eJhsjHcfS3i1PbS56WiFjf0V3pznYc8/xs5Sw36CgBAcDgcvTN/CoZhkalX24p1bCt/uWLHfdSxFqLxJ08Diis1k4qpnPmGJrSXepjS+9Xgfj8XBFfq4v0JzOODPR+DQSuwe/tyZ8iQx+PN4n4aEBnpf0ks5I/Z7uTu3bUrJGymTKgeauPbjj0kO7oa/RwIbnh7CnJ9PVPirZSaTia7hVfj5gc5Me6AzPRpWJdPuYPr6I/QZu5gxU9az80S8q5dZvNZPgqXvG19f/wnU6eba9YiI01QONNPt/fGkBrYh0JTId27vkh66iuWHj7l6aVLSVn4B/35tfH3zeKjZBoAJyw/w95bjWM0mPh3a5qKzD8T1zg0sLkrljZI3FVVoiDfzmr9NlD2EEJ9o9r1+K3N+T6zwx/0V0uJ3YPPPYLIwoeZrrEupTqNqftzTra6rVwao8kakYFZ3vO+aBEHhuCUfyep7THD1qkqNDnUD+eHuDvwxuivXNK2GwwEzNx+n30dLuf+HtWw+EufqJV65Pf/AX48ZX3d/CloPc+16RMT53L3xHPUTjoBa1Dcf52u3D3j+5zUs33Pa1SuTkrLt95zdRejzGjS9HoA1+2N4c5Yx5+blQU1pE6Yzu9Iup22qSJU3Om2pyG7o1IS7M57htCMAj9gtMG0kZGa4ellSkjZMhkVvAXCw8+v8b0c1AP53U3PcLKUjPmjmjcjFeAfC8F/BpyqcUCDPT6vQSnw9sj2zH+vOwJY1MJlg3vZorv9sOXdOWMO6gzFOff+oKJg9m+LfyvH4Jph2JzgyoeVtEPFyMb+BiJRaftUxDf8Vh4c/7c1RvGv+nAd/WMOGQ7GuXplkcVrsP7gSfrsfcMBV90JXI4F/Mj6V0VPWk2l3cEPrmozsnP+cGyldzIVU3mTaHWRk7SOugcUVW/valXGvUpdR6c9gs3jB3kjjAt5Fqrak5Dkt9u/5B/58FAB71yd5aEdLAG5pV4ur6gRe7Jklyit7tylV3ogUILAuDPsZ3LyzAvnjCuT5aFLDn8+HtWX+Ez25uW0IFrOJxVGnGDxuJUPHr2LFntM4ivHnFhMD/fo7aNQIBgwwtubr199BbHGcW8Udgh+HQHoi1O0B138GRRhQJiLlSHATTLdPwWFxZ4BlDY/bf+CuCWvKX2toGePU2H96t7GrYGYaNBoA/d8Fk4l0m50xUzZwKiGNRtX8eOvmFkUaWimulz3zxm7P//7UXFev1TZVsZlMJm5tH8oWRz3e8nkWTGbY+CMsetvVSxOcHPuPb85zwfZ7rxFsPx5PgJcbL/RvXAxvUHy83LPaplR5I3IRIe3glu+yAvlkiHzd1SsqtcKDfRl7a2sin+rJ0A6huFlMrNx3hmHfrOaWL1eycNfJYkniDBvuIHKJjaBBGwh5aAFBgzYQucTG0GFX+NpJZ2DSzZAYDcHNjAHFVvcrXq+IlEF1u2O6cRwA91hnc3vGDO74Zg0HTie5eGEVl9Nif/wxmHQTpMRCSHsY/C2YjYPk1/7axpoDMfh5WPlyRDu8swZGSumXM/OmgLap3MkbD6tOWyq6W9rVws1i4tuTjTjS5X/GjYvfhn+/de3CxHmxP2YfTB6cc8H2ZO/3+WC+UdbzbL9GBPl6FMPqi49m3ogUVaN+MOgj4+ulH8CqcS5dTmlXO8iHt25uyeJnenNXlzp4WM2sOxjLqO/+5brPljFn64mL9qBfTFQUzJ1jwj9iK77NjmH1T8W32TH8I7Yxd47p8ksp0xLhx1vgzG7wr2VsCe4ZcJkvJiLlQotb4FrjIP4Ft6n0TpnL8G9WczQuxcULq3icFvuTY4yk/dnDEBRuVNu6G7uKTFp5gB9XH8Jkgo+HtqZuFZ/i+0DidGbTxdumUm1GSY67xZzTYiUVVxVfDwa0qAHAJ2e7QY9njTv+fsqYhSUu4bTYnxBtxP6kk1CtBY5bJ/HSX1EkptloFVqJ268KK9bPURy8VXkjcgna3QkR/zG+nvM8bP7FtespA2pW8uLV65ux9Lne3N+jHl5uFrYejefByevo//FS/tx07KJbeOZn717jX8/QvPN0PEPPALBnz2Us1JYOP98Bx9aDVyCMmAEBIZfxQiJS7nR5BLoYvfBvu31D4/hlDPt6FSfOprp4YRWLU2J/ejJMvR1O7QC/GnDHb+BTBYAVe07z6l/bAXiuX2MiGle77LWLaxQ2sDi78sZDw4oly4hOxjyrPzYe42zHZ6DdXYADfrsP9i126doqKqfE/tSz8ONgiN0PlevAHdP5c1cS87dH42Yx8fbNLXLiR2mS3d6ZkpFZrOMosikSSvnT/Wno+KDx9e8PQtQ8166njAj28+TFAU1Y/nwEj0SE4+dhZVd0Ao9O3cA1Yxfzy9rDZGQW0JR+nvr1jX9TD+cdIJZ6OAiA8PBLXJw9E2Y8APsWgpuPMaS6asNLfBERKdeu+T9oPRwLdr5w/5TqMesY9vUqTiYogVNSij3229Lhlzvh8GqjyvKO6VDZOHE7cDqJh7MGFN/UJoQHetS70uWLC2RvEFNg5U1G9k5Tmncjhna1K9Okhj9pNju/rD8CA8dCk+sgMx1+Gg5H17l6iRVOscf+9GSYOszYjMYnGEbM4CQBvPLnNgAeiWhAkxr+V7psp8ieeeNwQJqtaOdNl0LJGyl/TCbo+xa0GAJ2G0wbAfuXuHpVZUagjztPXduIZc9H8ESfhlTydmPf6SSe+XUzvd9fxORVB3O27SxIw4bQt5+D+MjmJG4LwRbvSeK2EOIjm9G3n4MGDS5hQXa7MV1+229gdoPbfoBa7fI8xGmT7UWk7DCZ4LpPoGF/PEjnO4/38DuzieFfr+Z0YpqrV1chFGvsz7QZV9J3zwOrFwz9Gao1AyA2KZ1RE/8lLjmDOn6VuLelBhSXVTltUwVW3hgnP9omXLKZTKac6psfVx/Cjhlu/gbqdIf0BGM+SvQ2F6+yYinW2G9LM87dDi4DD3+441cclevynxlbiUvOoGkNf/qE1C+1x/1euRLNzph7o0go5ZPZDDeOM3ajsKXClNvh8L+uXlWZEuDlxmN9GrDsuQhe6N+YKr7uHIlN4T+/b6XHuwuZsGz/RYPS1CkmInpYOTOzNUfHXc2Zma2J6GFl6pRLOMB2OIz2t42TjWHUt3wL4X1y7nbqZHsRKXssVhgyEer2wJtUfvB4F8up7QwdrwqcklIssd9uhz8fge2/g8Udbp8MtTsDRiXGqAlr2X86CdtZL5a+1Y7mTS2K/WVUYQOLsy8WaZtwye2G1jXx87Cy/3QSy/eeBjdPGDrVGGaeEgs/3AinL6dXRy5XscT+TBtMv8fYFtzN25htWaMVf246xrzt0VjNJpIXtaRZE3OpPe63mE24Zw1XT3XC3Bslb6T8srgZO1DV6wUZSUbf5PFNrl5VmePrYeWBnvVZ+mwEr17XlOr+nkTHp/F/M7fT7Z1Ixi3aS2Ka7YLnVa4Mc2abiIqCWbOM6pg5s01UrlzEN3Y4YMH/wZqvjO9vHAdNb8jzEKdNtheRssvNE26fCrU6EEAiUzzewn5qF7ePX0V0vBI4zlYssX/2s7BpCpgscMuEnKS93e7g6V82sfFoLPY0K2mnfKkxcrlifxlWWOVNWk7ljZI3co6Ph5XB7WoB8MPKg8aNHn5wx69QrYUx4PaHGyD2oAtXWbFccey3Z8Ifo2HHX1lJ+ykQ1omo6ARe+G0LAJWOhbNinnepP+7Prr5JVvJG5BK5eRq//KGdjMFXP9wAxze7elVlkpe7hbu61mXxs71486YW1KrsxZmkdN6Zs5Oub0fy0T9RnE3OuOB5DRpA//5cWsmkwwEL34BlY43vB46FVrfneYjTJtuLSNnn4WtcsavegkDO8rPHG3B6N7ePX8Xxs9qFqiRcduyf/Rz8+zVggpu+NGZZAA6Hg7dm72Dm5uM4Mk2kHQ/AJ/yUYn8ZlzOwuNCZNzplkbzu6GTsNLRgRzT7TycZN3pVNja0CGoA8Ufg+0EQd8iFq6x4Liv22zONasvNPxlJ+yHfQ/3exKdm8OCkdSSnZ9KqRhDrfggvE8f92TtOpSl5I3IZ3H1g+LRcpZTXGwOw5LJ4WC0M6xjGwqd78cGQVtSr4sPZlAw++mc33d6J5L25O4lJSr/8N3A4YOGbsOQ94/u+b8FV91zwMKdMtheR8sOrEoz4A4KbUYU4pnm8AWf2MOTLlRw8k+Tq1cn5sttks6str/8UWt6ac/eXi/fx9dL9AJyZ3RK3wLz/Hyr2l02FtU2l2jSwWPIXHuzH1Y2DsTvgy0V7z93hWxXu/BMC6xmJm4mDIO6w6xYqF5c923Ljj0biZvA30HgAdruDp6ZtYt/pJGoGeDK8ThtwmMvEcb9Xrh2nipuSN1IxeAbAiN8gpJ2RwPleCZwr5WYxM7hdLeY/2ZNPh7ahUTU/EtJsfL5wL13fjuSNv7dz8lJbFBwOWPQWLHkXgFNt34TOD+f70GKfbC8i5Y9PkHEQH9yUKsQyzfMNrHH7GPLlSqKiE1y9OsnmcMDcF2H1lwBEd/wU2o7IuXvqmkO8M2cnAPd3aELStlqK/eVEdtuU3UG+2+pmDyz2sOqURS70cG/jF/63DUc4FperqtK/Jtw5EyrXhbiDMHGgEjilkd0Ofz0CGydjx8LxLl9D85sB+DRyD/O3R+NuMTPujna0buIBlI3j/nPbhWu3KZHL5xkAd/wGNdtCSgx8fx0cXe/qVZV5FrOJ61rVZPZj3Rk/oh0tQgJIycjk66X76fbuQl7+fStH44rQpuBwkDLzNVj8DgBPzn2D4BtGFziIrFgn24tI+eVTBUb+CVWbUNURw3TP/xGQuJdbv1rJpsNxrl6d2O2k/vY0rPoCgPv++pjqA0bmxP7ZW47z0gzjYstDverz4s31FPvLkezKGzASOOfLbpvyUOWN5KNd7cp0qhdIRqaDr5fuy3tnQAjc9fe5BM53AyBmX/4vJCUv00batIdgw2Qy7WaG/TqemtcOpl9/B5/M3ceH/0QB8NoNzWgVWqlMHfdnt01ptymRK+VVyeiFzW6h+v56OLjyil9WW1WD2Wzi2mbV+XNMVyaOuop2tSuTbrMzadVBer67kOd+3Vxwq4LdDrOfw2vdhwC8fPhhprVpUuggsmKZbC8i5Z9vVbjzLwhuRpAjlume/yMkJYphX69i6e5Tl/2yiv1XKNMGf4zGc8s32B0mnjj4NLM7hubE/kEPnuCRqRuwO+D2q0J5tm8jQLG/PLHk2uI9v9apnK3CtduUFGBMb+OsfeqaQ5xOTMt7Z0AI3DUTAuvD2UNGAufUrit+T8X+K2RLh19H4bHzJ2x2Cw8eeIllPSoTNGgDq+P3MnbhDgAevboBQzuE5TytrMR+r6zkTWrGhRu6XCklb6Ti8aoEI3+H2l0hPQEm3wx7F17WS2mr6guZTCZ6NQrm1wc7M+W+jnSpH4TN7uDntYfp/f4invh5I3tO5mpXsGcaJZNZcw6ePvgEk6p2K9IgsiuebC8iFYdvVeMgvmZb/B3xTPN8k0YZOxj13b/8vuHoJb2UYn8xyMyA3+6FTVOw2S2MPvACM6q1zYn9la9fx5Gw9djsDq5rVZM3bmqBKetEX7G//DDnOhPJb2ixBhZLYbqGB9GqVgCpGXa+W77/wgcE1IJRsyG4KSQch+/6X/bmJYr9xSAjBX4eDjv+JM3mzqh9rzG/ZpOc2B/Q3UiuDW8dzhN98pbTlJXYr7YpkeLm4QfDf4X6EZCRDFNuhW2/X/LLaKvqgplMJrrUr8KU+zox/aHO9GpUFbsDZmw4yjUfLuHhH9ex/VA0/HInbJiMAzMjZ3zJT17d87xOUQaRXdZkexGpeLwDYeQfENYZH0cSUz3fphsbePznjXy1eG++Mzfyo9h/hdISYcptsG0GdpMbt/4ykb982ud5iGfYGUwWB22r1uDDW1vlaa/Jpthf9llzZW/yrbzRwGIphMlkypl988OKg/nufIpfNaOFqkYrSD5jzMA5sOyS30ux/wqlxMGkm2H3PDLNXlz/01QW+je94GFxK8Lp6t8wJ2F/vtIe+71zKm/UNiVSfNy9YehPxjakmenwy12w5usiP11bVRddu9qBTBzVgb/GdKNvs2o4HLB0yz7iv7kBdvyF3ezO8W7fMWnz0DIxiExEyjBPf7hjOtSPwMORyrceH3CzeQlvzd7Jf37fii3z4lfKFPuvUNIZY9fHvQvAzZtjPX9ixs7rL4j9JhMk76rGG4NaY7XocLW8yl15k5lP8jQtu21KlTdyEdc0qZazccbY+QW0RXkHGu2zYZ0hLd5IImz/s8jvodh/heKPG21rh1aAhz/HIqYzb28f0k7453lYWrQ/Z5c2pEGD0tUKdSlydpvSzBuRYmb1gCHfQ7tRgANmPQ2Rbxg7XxRCW1Vfuha1AvhqRHvm39eQ2QFv0cm8gwSHF8NTn+G5gzXoPvhMmRhEJiJlnLsPDP0ZWtyKxZHJWPcvecD6Fz+uPsjd368lITWfK7dZFPuvQOxBmHAtHF0HXpVh5J/U6tUnZwhl6uHKOX9+U/YG0yatDU0a6VC1PMs988ae78ybrMobzbyRizCbTbxynVHBMWnVQbYdO5v/Az0DjNmXjQZCZppR/b12QpHeQ7H/CpzeDd9eCye3gW81GDWLWl270GnoYbzCjJ+nww4pB4I4M60TffuV3qqaosiuFFTljYgzmC0w6EPo9YLx/ZJ3YcaDYEu76NO0VfVlOrGVBn/cSK20vdi8qvJ1/U9ZQ3OW7j7NofBV1B+1lqStIRwdF1FqB5GJSDlgdYebvoLOYwB4wTqVt9wnsjzqBLeMW8nhmOR8n6bYf5mOrIVvroYze8C/Ftw9D0KvAowhlG1vOIFHSCwmEyRtq0nrxLb89KNO2Mu73O1w+Q8sVtuUFE2X8CoMbFkDuwNe+WNbwW2wbl5w6w/Q9k4jYzDzCZj/X2PzjItQ7L9M+5fCN32MgdGB9eGeeRyw1mP4N6s5HrYZs6eNtGMBHP0ygpM/dyoXx/05u005YeaNtdhfUaQsMpmg1/NGNvjvp2DzTxB3CG6bDD5BOQ+LijIy7+Hh57aqjoxsDpjwDD1D6uGgXJUi+Qee3K9RlrPKlyVqHvw6CtITISgc6/BfeDKwHkNikhm3eC+/rj1Cim8M1W5bQx2/StzdKZwREcEU0PIqInJlzGbo+wb41YB5/2GoeT51vE5xf/QYrvtsGZ8Pa0vX8CqK/Vdq24ysiyKpUK0FDPvZ2AUGcDgcTNu8jxNhOzEB3WqE8p9RLWjcSIG/IjCZTJhMRsFzfm1TqWqbkkvwn4FNWLjzJGsPxvLb+qMMblcr/wdarHDdx0bsX/w2LP/Y2Eb8pvHGWIUsiv1XaMNk+OtxsGdASHtSh/zI+HUJfL5wCWk2Ox5WM4/3aUivGnU5MNSc9TMq+7Hfy815u00peSOSW/tRULk2TLvT6Mn85moY9jMxlkYMG+5g7pxzAaVvPwfjvjDx0MNW5s5snef2/DLGMTHk+xpTp5S+KenFzuGA1V/B3BeMqxx1usNtk4yyeSA00Js3b2rBIxHhfLV4H1PXHOJAQhz/nb+WqVv9eSQinH7NqmPOZ2CliMgV6zIGKteB3+6jc8ZGZvq8zh3JjzPyWxtBRxrz7+S6gBF/FPsvgcMBS9+HyP8Z3zfoC7d8a2wagFFp8frM7UxccQCAe7vV5aWBTQocUinlk8VkwuZw5Fv4kD2w2EOVN1IENQK8ePTqBrw9eydvzd5Jn6bVCPByy//BJhP0fgGC6sMfo2HHX3B2ANw+hRhbTR33Xwl7JkS+Dss+NL5vdjORjV7l1fE7OJRV1dotvApv3NSc2kE+ADRp5KrFFr/srcKdMfPG5Cjq1grFKD4+noCAAM6ePYu/v3/hTxApaSd3wpQhRvWNuy+vbf2SN/7oh3/EVjxDY0g9HEh8ZHMieliZM9sYUrZnz8Wz6v36GxPqC3qNcisjxShJ3TTV+L7NCBg41mhZKMCphDS+WbaPySsPkpQV+MKDfRnduz7XtaxZZodXVuTYV5E/u5QhxzbC1Nsh4TjJZj8eSB3NUntLMuK8MJntWVdZFfuLJC0Bfn8YdmQNBO30MFz7P6NVGaMd5vGfNjJn2wnAuGJ+b/d6rlqtU1Xk+FeUz97wP7NJt9lZ/nwEIZW88tx3+/iVrNoXwydD23B9q5olsWQp49Jtdvp/vIS9p5Lo06QaX41ol+9udXkcXGlsX518BnyCeerfiXz6d4eLHvdv3WUj2hLN8fRYjp1N5cTZVOJTM2gQ7EvzkAB+HR/AmjkB+PfcUbFif0osTL8X9vwDQFLHJ3ji5ADm7TgFQHV/T14a2IRBLWuU20T9j6sP8tKMrfSu58PEB3oXa+xX8kYkywVljYmnjB2oDhpbCb5/fARfVO6LPWtUVOK2EM7MbE1UVOFlkFFR0KgRBA3agG+zYzm3X8prlElxh+DnO+D4JjBZONn6/1jnNprwBqYifd7YpHS+W3GA75bvJyHVKD2sHeTNw73qc1ObWrhby1YSpyLHvor82aV0uyD2xx8z4tbRdWQ6zLxru5WvMq8ju/JGsb8IzuyFn4bBqZ1gdiO6/XusN43K+RmfOJvK/ZPWsvnIWdwtZsbe1opBLcvviXlFjn9F+exNXp5DSkYmS5/tTWigd577bvx8ORsPxzF+RDuubVa9JJYs5cCGQ7HcNn4V6TY7D/SoxwsDmlzwmAtif8x+I/ZHbyUj08pLR0czLbgDeWN/K36MPM3KE0eYv/1ETltfQezpFszu56ovyn3sj94GPw2H2P3YLV5Mr/wqr52sS2K6DTeLiXu61eORiHB8PMp3889v64/w5LRNdKzlxbRHri7W2F+2znxEnCAmxrgy2qgRDBhg9LT26+8gNqMqjPyd/dUfBuDpGpOY6PYOVTAm2F/KdPkKOaE+ai581ROOb8LuGcRz23+j2o1jGDDQdO5nHHvxl6js486T1zRk+fMRPNO3EZW93Th4Jpnnpm+h9/uLmLTygFMmuYtI+Vdg7M+sCaNmc7jqCCwmOy+4/cR4t7EEkAiAV71owKHYX5BtM2B8Lzi1E7tPdZ7Y8jfVB47K+Rn3HBzDoE+WsfnIWSp7u/HDPR3KdeJGCpddFaGBxVJc2oRV5r1bWgLw1ZJ9TFt7OOe+AmO/qS7cM49jQYNxs9h4N+xjPnL7HB9SAPCqe5Lqdy7jxblr+GvTMVIz7NQJ8ub+HvV4/cbmfDOyPVPu68h/BzWlY7UQbAkeeRI3UI5jv8MBG340BhPH7ud4Whh9dn7EM0dCSUy34Znsz493duP5/o3LfeIGzs28SXPCOUr5/+mJFGLYcKOkPWjQudLIyMjmDB1mZcqPboyc8ia141oz/sZH6GHZwizzCzye8TDzDvcFijZdPveE+txXX8vlhHpbOix4DVZ+ZnxfoxV3zZrET//UJGjQhgt+xkUpHfX3dGN073BGda3DlNWH+GrJPo7GpfDyH9v4JHIPD/Sox7COYXi7K6SJSNFcPPZ7MOznT2iW3IaPBzzHtZZ1NDW/yKPpY1jv1ZAqN2wgOLQ5UHD7J1Sw2J+RAnNegHXfGd+HduKOPyby64IqWbH/DLYETw5Uj8eU5KBxdT++Htn+gkoLqXiyO1ps+SRv0mzZA4uVvJFLc0PrEPadSuLjBbt5acYWqvp60LtxcCGx34fbfvmGDrY2vHPNf7nRsoJWpr2MyXiUbd51sXhn4Gm1cHuHUG5qE0LLWgEXtP50qV+FbsHQuFkm1e5Yjke1hJz7bAmeQDmL/WkJWZu9/AzAv/E9GJV8L4mhVhwOSD/px7FfOvDf3e7Mme3itZaQnJk32ipcpHhFRcHcOSb8I7bi2+wYVv9UfJsdwz9iG3PnmLjxJger19mYFt2Pjt/9w46UugSb4pjs9hbPZMxgYP+0IpU9Zk+oj49sTuK2EGzxniRuC8k1od75n7VEnN4DE/qeS9x0fJDdPeYz6c/aBf6Md+8u+st7u1u5t3s9lj7bm/+7oRk1Azw5lZDG//7eQbd3FvL5wj0kpGY457OJSLlRtNifyYTDt9D1h9nsSw2hluk009z/j9Hm3/FvfITRfy5lxZ7TF32fChP7o7fB11dnJW5M0O1JorrOZOpfNXL9jNPwDDmLyeIgeVc13r22ixI3ApyrvLHnu9tUduWNTlnk0j3epwGDWtYgI9PBqIn/8sQP25j3j73Q2P/pvhH0WzyRo/Yg6pqj+c39FUYxhyrRdVnxQgSvXt+MVqGVCpzZ0rAhXNvHzJlpnUncWR17hvHfr2dIHO1GRhEeXuJTS5zj6Dqj0nLzz2Ays772EwxxPExiJeNiqskEHtUS8O+945KP+cuy7MobJW9EillhJe1LlxgH99WGrmKve3XajV3B+HV3YjY5eK7TR/w+4Go4sbVI7zV1iomIHlbOzGzN0XFXc2ZmayJ6WPOdUF/m2O2w6kv4shscWw+eleD2KdD/HfYc8ACKt23A083CyM51WPRMb94Z3IKwQG9iktJ5b+4uur4dydj5UcQlp1/ppxKRcupSYv92S21af7iKKVtuwWqy84z7NP70eh3vhH0M+2Y1L/++lcS0grcDLd+xPxOWjjVaZE9uA5+qMOI36PMKe/cbO7x41s6b4MpMtXLq93YcPahKSTGobUqcxWQy8f6QVtzRKQyAGdsPUP3OZXjVPZXncdmxf+XWJKrcvoIady5nTycrA9LfYl5GezxMNl7x/IGVXZ8lMP14kd47J/b/0Y7DY/txdqVRinm6xm5enLEVez7/vZcZtnSIfAO+uQbO7AH/EBZ2nsjgXVeBhx2HLe/ft3LbLlaA7MqbVCfsNqXkjVRouUvac8suaQfj4N7iaSN4yL9UHrWaF+13c8u070m3BmI9vcXIOC95HzIvXvFRuTLMmW0iKgpmzTKu/M6ZXQ62C4zZDz9cD3OeA1sK1OsFDy2HxgOBwn/GV1I66m41c9tVYUQ+1ZMPb2tF/ao+xKfa+GTBbrq+Hcnbs3dyOjHt8t9ARMqlS439fneu49HUMYyc8SUZlgCaOaKY4/kSd1tm8+Oq/fT9cAlLd+c9GchWbmP/qSij0nLBa2DPgEYD4MHlUD8CgLr1HPhdtQ+Ld95EesreaoCpfLUNyBUxmy6WvMlqm7IqeSOXx9PNwv9ubMF3o64i0MsD9yqJWLzzHrObrJnUGjOfkPsW4141keyCmpiUSgzb8i4PzhyLzeyD25GlMK4LrP2OfPe2zyVv7Dex5pvGvH5DM8wmmLrmEB/+E+Wsj+xcJ7bAN1fDknfBkQnNB/NHp5+5e6EVB5CwKZSkXXmHi5fLVuGL8M5O3qjyRqR4XaykvVt34yAi98G9W2AymGH6jhs5cv1q42DVngGRr8NXPeDQqkLfs0ED6N+/HEyZt6UbSasvOsGBpeDmDQPehxG/Q0CtnIeVRNuA1WLmpja1mP9ETz4f1pYmNfxJSs/ky8V76fZOJK/9tY0TZ1Ov/I1EpFy4vNhvYtLmoRy5bgXU6427I43/uk1iltcrVD67jRHfruHxnzZwMiH/WFNuYn9GCkT+zziBOfIvePjDjeOMaku/agAcjknmlUWrCIzYgckMtgQPbAke5bNlTK5YQW1TDoeDVJvapqR49G4UzD9P96DS6TBs8Z557rN4Z2DxScdhN2FL8Dh3u5cNHBa+WncPRwYtg7DOkJ4IMx+H7/pD9PZC3zd37B/RuQ5vDzYGKX8auYfp644U62d0qrREmPuSUWl5YjN4BcKQifxS5zUe/+sQDgeM6FSb9jQnPrJF+W4VLkR2pWByIbuRXQ7VrEqFN3WKiaHDrMyd2Trntr79HFm3O4iMbA6Y8Aw9Q+rhoJwAVK9lMLSYApunwdwX4OR24ypk25Fw9SvgU8Vln8np9i+FWU8b28AC1O0Bgz6CoPr5PvxiP+PiZDabGNiyBgNaVGfBjpN8GrmbTUfO8t3yA/y46hBD2tfiwZ71NWdBRC479tdtXQtazYB1E2H+KzRO28ufHv/lB9s1jN04mAU7TvLktQ0Z0ak2Vks5O+Hc/Y8R+2P3G9836AsDP4BKoQDYMu1MXHGAsfOjSE7PxMvNQsC+JqyeEkb2drvOiP1SthVUeZOeaSc7n+OhtikpBoE+7ix8rwVDhzn4Z0UKnmExmD0yaFHfk/de9eaVp71YvMiEf8S2C2J/nbb1oPXfsPpLo2Xo8Cr4qjt0Hg09ngEPvyKt4db2oRw4ncQXi/by/G+bqVXZi471ggp/oqs4HLBzJsx+HuKzkk1Nb4D+7/H3fjvPTl+PwwEjO9fmteubEdfTxNBhJqcf85dm2TNv0m3Fn7wxORz5TAdzsvj4eAICAop1z3ORK7V7t9GLGR5+7spobCwMHeZg7pxzASc7AOUpeU+Ogfkvw4bJxvce/tD9Kej4ILjlze6Xaaf3wPz/wq6/je+9q0DfN6DlbVDA0Lbc8vsZO5PD4WDZntN8umAPaw4Ysy2sZhM3tglhdO9w6lbxcf4icqnIsa8if3Yp3a4o9idEw9wXYeuvAMSb/BibfhOTM/tQJ7gSLw5oTO9GwQUOtSwzorfBvP/A3kjje78a0P8daHJ9TuzfcCiWF2dsZcfxeAA61Ank/SGtCAvyLvHYX9pU5PhXlM/e492FHIpJZvpDnWlX+1zF29mUDFq9Ng+AXf/rh4dap6QYXVHsjzsMc543khoAPsHQ+0VoMwIshddG2O0Oxkxdz6wtJ6jk7cZfY7qVzguLxzYY1TYHlxvfVwqDAR9Aw2vZeDiO275aSZrNzh2dwnj9huZ5/tZV5Lifkp5Jk//OwZ6WzOGPbi3W2K/kjUgRFDkAHVwBs58zygkBAsKg1/NGcqMIwbzUij9mDKVc9x3YbWCyQLu7IOI/4B1Y6NNLg9X7zvDZwj0s3W0MzzSbYFDLmozuHU6j6kW7WnKlKnLsq8ifXcquIsf+vZEw50U4tQOAg9Tg/fTB/G3vRMd6VXm+f2NahVYqkTUXq9iDsOQ92PgjOOxgdoOOD0DP58DT+D0+GpfCB3N3MWPjURwOqOTtxgv9GzOkXShmcxlPWhWTihz/ivLZe7+/iP2nk5j2QGc61D13THEyPpUOby7AZIJ9bw4o+0lQKTOKHPt3zoJ5L0HMPuP74KZGEqfRQDBfvPIyJT2T28evZNORs7QJq8S0BzrjVlqqNU/vgcXvwJZpxvdWT+g8xrgw7e7N0bgUbvhsOacT0+jTJJivRrTPaX8UIzlX78VZSt6IlAl2u7Fl3oL/g4Rjxm2V60D3p6HV7WBxc+nyLsnZI7DsQ1j/A2RmDZ1s0BeufR2qNnLt2i7T+kOxfB65hwU7T+bc1rdZNR6JaEDzkACnvndFjn0V+bNLBZFpgw0/wMI3IckYXrzXUZOPM25ipr0zvRpX57GrG5SNJE7Mflj6AWyaaiTswaiyueY1CKwHwNnkDL5cspdvl+3PKQ0f3LYWLw5oTJCvR0GvXCFV5PhXlM9+9QeL2Hsqian3daJz/XPtI4fOJNPjvYV4uVnY8Xq/klqyyKWxpcPab2HR25AaZ9xWrTn0fBYaX3fRJM6R2GT6f7yUhFQbY3qH83RfFx9bn95tJOy3/GIk7MG4AB3xck57bGKajVvGrWDniQSa1PDn1wc74+NRhi9QO0njl2eTnJhY7Mkb/aRFipvZDK2HGv2g/34Nyz+B2APw5xhY9BZcdQ+0vQt8SnF/65G1sGocbP/93IF77a5GFVHdHi5d2pVqG1aZb++6iq1Hz/LFoj3M3nqCuduimbstmt6NqjImogHtapf1bWBEpMRZrND+bmh+C6z+ClZ+Rv3UY3zi/jnPOKbx/e5rGbGzF60b1uG+7nXpFl6ldFUSOBxwaKUR+3fOPHfgXq839HoBwjoCcCYxjW+X7eeHlQdztkjvWDeQlwY2oWWtSi5avJRl1qyT2/MHFmtYsZQJVnfo9JBxgXbFZ0b8j94K00ZCUDh0eMA4L8hnJk6tyt68dXMLxkzZwOeL9tCtQRU6lfT8G4cD9i0yZvlEzQWyfg8b9jOO+2u2yfVQB8/8somdJxKo6ufBt3e2V+KmAN7uVpKd8LqqvBFxtvQk+PdbWPEpJGVVe1g9oflgaDXUSIoUUlpZIlLiYNsM2DAJjq47d3vtbllJm+4uW5oz7Y5O4POFe/hz0zGyZyV2DQ9iTO8GdKoXWKwnVxU59lXkzy4VVGo8rPkKVn4OKbEAJDk8+COzC9Mze5BYtR13d6/LoJY1XXvwm3QGtv0G6783toDNVv9qI/aHdgBg76lEJq08yM//HiYla/vTRtX8eLpvI/o0KQdzfZyoIse/onz2/h8vZcfxeH64uwM9GlbNuX3zkTiu/2w5NQI8WfnC1SW1ZJErkxwDq74wkjhpxgwwPPyNCpbWQ6Fm2wvmRD7zyyZ+WXeEGgGezH6sO5W83Z2/zsSTRoXN+kk5Lb+AsZNuz2fzJG2yfbd8P6/9tR03i4lpD3SmTZgudhak69uRHI4+o7YpEWeLioK9e50wYMuWBlt/g9Xj4Pimc7cHhEKLIdB4kBEoSzKRkxoPexfAtt9h12zITDNut7gbV487PgA1W5fcelzowOkkxi3ay/T1R7BlZXHa167MmIhwejasWiwnJhU59lXkzy5lg9Nif3qycYC8+ktjV8IsB+zV+MPelaXmqwhv2ZVbO4TRJrRSySRBUmKNnaO2/25cabVnGLdbvaDVbcaV4mpNSbNlsnDnSX5cfShnXhhAi5AAxkSEc02TapprUwQVOf4V5bMP+nQpW4/G892oq+jdKDjn9jX7Y7j1q5XUreLDwqd7ldCKpaJxWuxPSzRaT1d/CWf2nLu9SkNocSs0HmDMyDGZSEqzcd2ny9h3OomBLWvw+bC2xbiQXJLOwO65xsXaPQvAYSTicfeF1sOM2F8lPN+nbjocxy1friAj08Gr1zXlrq51nbPGcuLqDxax+8gpJW9EnCUmBoYNL8KE+SvlcMDhNcYAyG0zzmXlAXyrQYNroU53COtkTHUvzgN5W7qRODq00hiweWDZuYN2MP6ItBpqlH76Bhf8OhfhtD+CJeRoXApfLd7LT/8ezpnjUFwnKhU59lXkzy6lW4nG/gPLYOMUHNv/wJSRlHPXMUcgCzPbsMurFVWa9qR7u1a0qlWp+BIjtjQ4uv5c7D+44txBO0CNVtDydmh1OxkelVizP4Y/Nx5j1tbjJKQarVEmE1zduBp3dqmdb8tXWY/9zlSR419RPvsNny1j05GzfHtne65uUi3n9iVRpxg5YQ2Nq/sx5/Gy3bItpU+JxX67HfYtNBI5O2aCLeXcfQFh0LAv1OnKdremXDdxL5l2B58Pa8vAljWu/L0zUoxq+oMrYc8/cGTNuZZYgFpXGRVBLW8Fz4LnPp5NzmDgp0s5EptC/+bV+WJ425y/AYr9+bvu02Vs2ndcyRsRZ+nX30HkEhv+EVvxDI0h9XAg8ZHNiehhZc5sJ11ZzEiBXbNg+59GBjw9Ie/9fjWhRkuo2thIrATWBb/qRpLHWsBASIcDUs9CwgljYPLp3cbV3pM7jMSNLTXv44MaQKN+RvVP9ZaXnSwqsT+CJeRkfCrjl+zjx9WHcloEGlf3Y3TvcAa0qHFZU/UrcuyryJ9dSjeXxP70JNgxE8eOP7DvicSS+2AeOOKowh5TXdICGxFQuwW1w5tSPaQOJt/qxnyF/DgcxrDMhBMQfxRORRml8NHbjXao7MrKbFWbQKP+OFrcwgFLHdbsP8OiXadYuvt0ziwbgBoBntzQOoThHcPy3cq2vMV+Z6jI8a8on/2mL5az4VAc40e049pm1XNun7ftBPdPWkfr0Er8PrprSS1ZKgiXxP7UeNjxJ+z4y5gzc94xeZxHTVYlh3DIEsbtA/viXyM867g/uOANTxwOo5oy4bixO+ypnXByp3Hsf2JL3ou0ANVbGK1RLYZAlcKzLQ6Hgwcnr2PutmjCAr2Z+Wg3/D3dFPsLceuXK1m164iSNyLOEBUFjRpB0KAN+DY7lnN74rYQzsxsTVRUCWSTbelwcJmRxDm0Co5vPDcsOD/ufuDmaczPMVuNK6u2FKNE//yD9Ny8AiGsM9TuYgwjK6A88lLl/iNo8UshZW81UjaHcXUvJ/4RLAFnEtOYsHw/3684N5yzXlUfRvcK5/rWNS9pW8eKHPsq8meX0qtUxP6MVDiwFFvUfJL2LMMvdgdm7AU+PM3ig8PiicndE6vFDbM9DZMttdDY7/Cpii2kI6eC2rPVpzObkyqz43g8Gw7HEZOUnuexQT7uXNO0Gje0DqFj3cCLVgCV19hfnCpy/CvKZ79l3ArWHozlyzva0q/5uWqDPzcd49GpG+hUL5Cf7u9cUkuWCqBUxP70ZCOBs2+hURkTvZWcYcEXMBkDj63Zx/1m47g/IwUyks/tCJsf3+pQu7MxY7Nhv5xdo4rqx9UHeWnGVtwtZqY/1IUWtYwKHcX+ixs5YQ2LthzUblMizrB3r/GvZ2hMnts9Q88AsGdPCQRxqzvUjzD+B8REJ/HWI+tJPrCTZlV30KzqTsICDlPT7wQe1nSjSuf8Sp08i69kZOsD60NwY+Mqa/UWRq9tMc/ViYqCuXNMVL52B8nbQ0jZd67lau5cB2vXQvv2xfqWJSbI14Nn+jbm/u71mbjiABOW72ffqSSe+mUTHy2I4qGe4QxuF4KH1eLqpYrIJSoVsd/NExpcg7XBNQQAMScSePuxtdji1tMibAtNA6Oo6RFNNVMs7qZMPDKTIDMJCjhWTzD5cdYaxHFLCActYewzhbIhI4z1Z4NIO5N9YnAm638Gd6uZFiEBdAuvQkTjYFqEBBSpZas8x34pOdn/rWWel7NMzcjebUp/X6V4lYrY7+5tzL1pPACA2ONneffxdaTHbOCqDktpYDlCcEoC1T1P42axGWMWco9aOJ93kJGoqRJuHPMHNzZaYivXveyq+t3RCbw+05jV9my/RjmJG8X+wnk7KW4peSMC1K9v/Jt6ODBPBj71sLFdX3jxFKdckmF3eRO5pBP4tiRzixeV+2zD0zuG1E2Vsa4IoX/3RL77KtW4amvPOJeNd/MyyivdvEpsrdl/BJN31iTjpD9BgzbklKDGzG/Ogw9ZWftv2c7CB3i78VifBtzTvS6TVh7k22X7OByTwosztvBp5G4e6FGP2zuE6SBTpAwplbF/lC+RS7qBb1syl2TF/tAzZJzywTfajWZNo2ncIo6TMfHEJ6eShhupuJPqcOc0AaRR0C4lRuIm0Med8Kq+1A/2pUGwL23CKtG0pv9lJaArQuwX57NknVhmntcMkJaVvPHS31UpZqUx9g+925/IJd3Btx0+6QMI6LwPhxlStlbFbVkt+nZNZsKXqUarlT3zXPW9m7dx3F/QOIXLlJqRySNTN5CaYadHw6rcnWtAsWJ/4bzclbwRcZqGDY0+zcjI5oAJz9AzpB4OIj6yGX37OWjQoGQDUHZGu1Kv3cQtapqnrNO32XESMTPxj9a8+F7pGA6W/Ucw7VCV89Z6DDCxbmZrdu8uHWu9Ur4eVh7qVZ+7utRh6ppDfLVkL8fPpvLqX9v5bOFe7u9Rl+Eda7t2618RKZKyFPut/mmcTQ3hr68G8kFWSX9qRiZnktI5nZBGTFI6abZM0mx20mx23CwmPK0WPN0s+Hu5EeznQVU/j2JNMFek2C/OY8mpvMlbepOaYXyviyJS3Ep77Ld0MLIjJhN4NzpFos2N7/5owwsleNz/9uyd7DyRQJCPO+8PaZmnGlOxv3DOils6uxDJMnWKiaHDrMyd2TrntuzBWyUtO6Nt8Tbq4l1a1lkEDRtC23YO1q8zlfq1Fhcvdwt3d6vL8E5h/LL2CF8u3suR2BTenLWTLxbt5Z6udRnZpQ4BXgUMmBORUqEsx35PNwshlbwIqVRylZa5VcTYL8Wv8Lap4m31FoHSHvtj89zvVe8kUHLxdP72aCauOADA+0NaEeznmed+xf7CeTup8kbRUCRL5cowZ7aJqCiYNcvIgs+Z7ZqJ6dkZ7cxko/w99XBgnvuLs6wzKgpmz4bdu6/sdb4cZ/yxc+ZaSyMPq4U7OtVm4dO9eO+WltSt4kNccgYfzI+i29uRfDBv1wXDQEWk9FDsv7LXqaixX4qPJetc2W7P2zaVajOSN5opJ85QlmK/2T0Ta0ByicT+o3EpPP3LJgBGda1D78bB+T5Osf/inNXuqcobkfM0aOD6THFOOeeSBrgFnyX2n2YUd1lncW/xd9VVpasEtaS5WcwMaR/KzW1r8feW43wWuZuo6EQ+jdzDt8v2c0en2tzWKsjVyxSRAij2K/aLa+S0TZ0380ZtU1ISSnfsP43J4sDik074HRupW68Tl1t7UZTYn5Fp59GpGzibkkHLWgG80L9Jga+n2H9xmnkjUsHklHPOCQCTgzPFXNY5bLixxV/QoK05Q8YiI5szdNjlb/FXmkpQXcViNnF9q5oMalGDeduj+WzhbrYejWf8kn1MWLjd1csTkVJOsV8qGnP2wOLzK2/UNiUVSEGx3xqQTOh9S0jxjeWjf3bzdN9Gl/X6RYn9H86PYt3BWPw8rHw2tC3u1ov/7in2F+yG1jVpEmTl6o+K93WVvBEppbLLOXfvhj17TFitYLMZZYhXms3OHowWNGjrBUPG5l7BkLG8ay6etZZVZrOJfs2r07dZNRZFneLTBbtZu/tY4U8UkQpNsV8qmuzKG7sqb6QCKzj2e7MjuSWPTt3AZwv30K5OZXo3yr+VqSBFif0HMqL5YpExfOftwS0JC/K+xDUr9udWq7I3/pbAwh94iZS8ESnlnFHOmT0YzVlDxkpDCWppYTKZ6N0omF4Nq/LPxgNc+5GrVyQiZYFiv1QU5wYW5z/zxrOQq/8i5Ul+cbQBNfl3fwyTVh3kyZ838vej3al5CYPqC4v9izbG8+GWDQCM7FybgS1rXPGaxTkUDUUqoOzBaBoyVnJMJhMd62vmjYi4jmK/lEaWAtqm0nLaplR5I/KfQU1oERJAbHIGo6esJy0ruVkUF4v9Zp9Uxu/8l+T0TLqFV+HlQU2Lc9lSzJS8EamAsgejxUc2J3FbCLZ4TxK3heQaMubqFYqISHFT7JfSSG1TIoXzsFr4Ynhb/D2tbDgUxyNTNpCRaS/ScwuM/Ysb02DUWk4lpVKvqg+fD2+Lm0XpgdJMbVMiFZSGjImIVDyK/VLanBtYnPd2DSwWySs00Jsv72jHXRP/Zd72aJ7+ZRNjb22dkwC9mPNjv8ndRuN715Lsc5ZK3m5MuPMqArzcnPwJ5EopeSNSQWnImIhIxaPYL6WNtaDKm6y2EA9V3ojk6BJehXHD2/LApHX8sfEY3u4W3rypBSbTxeN47ti/cUc6X0etIer0WbzdLYwf0Z46VXxK6BPIlVDyRqSC05AxEZGKR7FfSosCBxZnt01ZlbwRye3qJtX48LbWPPbTBqauOczJ+DTeHtySqn4ehT7XMyiZcbvXsO90EoE+7nx311W0Cq3k/EVLsVAdooiIiIiIuET2iI0LkzdqmxIpyHWtavLeLa1wt5hZsPMk/T5awj/bowt8fHK6jQ/nR3HNh4vZdyqJmgGeTHugsxI3ZYwqb0RERERExCWyd5vSwGKRSzO4XS2a1vTn8Z82sis6gXt/WEvbsEr0ahRMr0ZV8XSzsO9UEntOJjBp1UGi49MAaF+7Mp8MbXNJ241L6aDkjYiIiIiIuERBbVPaKlykcE1q+PPHmK58MG8X3yzbz/pDcaw/FMfY+VEXPLZWZS9e6N+EAS2qFzojR0onJW9ERERERMQlsitvMgsYWKy2KZGL83Sz8NLAptzdrS6Ldp1i0a6TLN9zBhNQt6oP9ar40LZ2ZW5tH6pkaBmn5I2IiIiIiLhE9jbH9lyVN5l2BxmZxvcaWCxSNDUCvBjaIYyhHcJwZCVDVWFTvih5IyIiIiIiLpHdNmXLlbzJHlYMapsSuRxK2pRPqkMUERERERGXyBlYXEDyxsOq0xUREVDyRkREREREXCRnYHGumTepNmOnKXerOed+EZGKTskbERERERFxiZyBxfZzt2VX3niq6kZEJIciooiIiIiIuIQl62wkv7YpzbsRETlHyRsREREREXGJfNumMowyHCVvRETOUfJGRERERERcIr+BxWk5lTc6VRERyaaIKCIiIiIiLmHJd2Cx2qZERM6n5I2IiIiIiLiEOWdgcT5tU1Ylb0REsil5IyIiIiIiLpFdeWN3XDiw2ENtUyIiORQRRURERETEJXIGFueqvEnRblMiIhdQ8kZERERERFzCmpO8OXebdpsSEbmQkjciIiIiIuISObtN5dM25WnVqYqISDZFRBERERERcYn82qbS1DYlInIBJW9ERERERMQlLFlnI3kqb2zZbVM6VRERyaaIKCIiIiIiLpH/VuGqvBEROZ+SNyIiIiIi4hLZW4XblLwREbkoJW9ERERERMQlcgYW50neGG1THhpYLCKSQxFRRERERERcImdgcX67TanyRkQkh5I3IiIiIiLiEvlW3uQMLFbyRkQkm5I3IiIiIiLiEpaLVt7oVEVEJJsiooiIiIiIuERO25T93G1p2ckbqypvRESyKXkjIiIiIiIucbGBxWqbEhE5R8kbERERERFxCXPW2Uietimb2qZERM6niCgiIiIiIi6Rf+WNdpsSETmfkjciIiIiIuIS+Q8szm6b0qmKiEg2RUQREREREXGJcwOLL6y88dDAYhGRHEreiIiIiIiIS5zfNuVwOEizaWCxiMj5lLwRERERERGXOL9tKjtxA2qbEhHJTRFRRERERERcIid5k5WzyW6ZAlXeiIjkpuSNiIiIiIi4RHbyxp5VeZM9rNhiNuFm0amKiEg2RUQREREREXEJsynvwOKcbcKtOk0REclNUVFERERERFwip/ImO3ljy0reqGVKRCQPJW9ERERERMQlsnebstnztk0peSMikpeSNyIiIiIi4hLmrLORTEfetikP7TQlIpKHoqKIiIiIiLjEBW1TOTNvVHkjIpKbkjciIiIiIuIS2W1TmY7z26Z0miIikpuiooiIiIiIuIQ5q/LG4QCHw0GaBhaLiORLyRsREREREXGJ7MobMLYLz2mbUvJGRCQPJW9ERERERMQlsitvwGidUtuUiEj+FBVFRERERMQlLLmSN3a7BhaLiBREyRsREREREXGJPG1TuSpvPNQ2JSKSh5I3IiIiIiLiEuZcZyOZdgepOQOLdZoiIpKboqKIiIiIiLhE7sobuwYWi4gUSMkbERERERFxCUtBA4s180ZEJA8lb0RERERExCVMJhPZxTd2u4O0DLVNiYjkR1FRRERERERcxppVfZPpyD3zRpU3IiK5KXkjIiIiIiIuY84qvVl7IJYNh+IAVd6IiJzP6uoFiIiIiIhIxZU99+aRqRsAqOLrTqd6Qa5ckohIqaPkjYiIiIiIuEzuHacGt63FfwY2obKPuwtXJCJS+ih5IyIiIiIiLjOgRQ02HYnjxQFN6NGwqquXIyJSKil5IyIiIiIiLvPOLS1dvQQRkVJPk8BEREREREREREoxJW9EREREREREREoxJW9EREREREREREoxJW9EREREREREREoxJW9EREREREREREoxJW9EREREREREREoxJW9EREREREREREoxJW9EREREREREREoxJW9EREREREREREoxJW9EREREREREREoxJW9EREREREREREoxJW9EREREREREREoxJW9EREREREREREoxJW9EREREREREREoxJW9EREREREREREoxJW9EREREREREREoxJW9EREREREREREoxJW9EREREREREREoxJW9EREREREREREoxJW9EREREREREREoxJW9EREREREREREoxJW9EREREREREREoxJW9EREREREREREoxJW9EREREREREREoxqyve1OFwABAfH++KtxcRcYnsmJcdAysSxX0RqagU+xX7RaTicUbsd0nyJiEhAYDQ0FBXvL2IiEslJCQQEBDg6mWUKMV9EanoFPtFRCqe4oz9JocLLgPY7XaOHTuGn58fJpOppN9eRMQlHA4HCQkJ1KxZE7O5YnWtKu6LSEWl2K/YLyIVjzNiv0uSNyIiIiIiIiIiUjQVK/0vIiIiIiIiIlLGKHkjIiIiIiIiIlKKKXkjIiIiIiIiIlKKKXkjIiIiIiIiIlKKKXkjIiIiIiIiIlKKKXkjIiIiIiIiIlKKKXkj5d6pU6eoXr06b775Zs5tq1evxt3dnXnz5rlwZSIi4iyK/SIiFY9iv5RnJofD4XD1IkScbdasWdx4442sWLGCxo0b06ZNGwYOHMhHH33k6qWJiIiTKPaLiFQ8iv1SXil5IxXG6NGj+eeff7jqqqvYtGkT//77L56enq5eloiIOJFiv4hIxaPYL+WRkjdSYaSkpNC8eXMOHz7M2rVradmypauXJCIiTqbYLyJS8Sj2S3mkmTdSYezbt49jx45ht9s5ePCgq5cjIiIlQLFfRKTiUeyX8kiVN1IhpKen06FDB1q3bk3jxo0ZO3YsW7ZsoVq1aq5emoiIOIliv4hIxaPYL+WVkjdSITzzzDP8+uuvbNq0CV9fX3r37o2fnx8zZ8509dJERMRJFPtFRCoexX4pr9Q2JeXeokWL+Oijj5g0aRL+/v6YzWYmTZrEsmXLGDdunKuXJyIiTqDYLyJS8Sj2S3mmyhsRERERERERkVJMlTciIiIiIiIiIqWYkjciIiIiIiIiIqWYkjciIiIiIiIiIqWYkjciIiIiIiIiIqWYkjciIiIiIiIiIqWYkjciIiIiIiIiIqWYkjciIiIiIiIiIqWYkjciIiIiIiIiIqWYkjciIiIiIiIiIqWYkjciIiIiIiIiIqWYkjciIiIiIiIiIqWYkjciIiIiIiIiIqXY/wOJdxQ+tpoJHwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1400x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "# NOTE: code from https://scikit-learn.org/stable/auto_examples/model_selection/plot_underfitting_overfitting.html\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def true_fun(X):\n",
    "    return np.cos(1.5 * np.pi * X)\n",
    "\n",
    "def GenerateData(n_samples = 30):\n",
    "    X = np.sort(np.random.rand(n_samples))\n",
    "    y = true_fun(X) + np.random.randn(n_samples) * 0.1\n",
    "    return X, y\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "X, y = GenerateData()\n",
    "degrees = [1, 4, 15]\n",
    "    \n",
    "print(\"Iterating...degrees=\",degrees)\n",
    "plt.figure(figsize=(14, 5))\n",
    "for i in range(len(degrees)):\n",
    "    ax = plt.subplot(1, len(degrees), i + 1)\n",
    "    plt.setp(ax, xticks=(), yticks=())\n",
    "\n",
    "    polynomial_features = PolynomialFeatures(degree=degrees[i], include_bias=False)\n",
    "    \n",
    "    linear_regression = LinearRegression()\n",
    "    pipeline = Pipeline([\n",
    "            (\"polynomial_features\", polynomial_features),\n",
    "            (\"linear_regression\", linear_regression)\n",
    "        ])\n",
    "    pipeline.fit(X[:, np.newaxis], y)\n",
    "\n",
    "    # Evaluate the models using crossvalidation\n",
    "    scores = cross_val_score(pipeline, X[:, np.newaxis], y, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "    \n",
    "    score_mean = scores.mean()\n",
    "    print(f\"  degree={degrees[i]:4d}, score_mean={score_mean:4.2f},  {polynomial_features}\")   \n",
    "\n",
    "    X_test = np.linspace(0, 1, 100)\n",
    "    y_pred = pipeline.predict(X_test[:, np.newaxis])\n",
    "    \n",
    "    # Plotting details\n",
    "    plt.plot(X_test, y_pred          , label=\"Model\")\n",
    "    plt.plot(X_test, true_fun(X_test), label=\"True function\")\n",
    "    plt.scatter(X, y, edgecolor='b', s=20, label=\"Samples\")\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(\"y\")\n",
    "    plt.xlim((0, 1))\n",
    "    plt.ylim((-2, 2))\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.title(\"Degree {}\\nScore(-MSE) = {:.2e}(+/- {:.2e})\".format(degrees[i], scores.mean(), scores.std()))\n",
    "    \n",
    "    # CEF: loop added, prints each score per CV-fold. \n",
    "    #      NOTICE the sub-means when degree=15!\n",
    "    print(f\"    CV sub-scores:  mean = {scores.mean():.2},  std = {scores.std():.2}\")\n",
    "    for i in range(len(scores)):\n",
    "        print(f\"      CV fold {i}  =>  score = {scores[i]:.2}\")\n",
    "        \n",
    "plt.show()\n",
    "print('OK')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qb) Explain the capacity and under/overfitting concept\n",
    "\n",
    "A low degres polynomial regression model will underfit the data, because it will not be able to recoqnize the patternz in the data. This gives a result with a high bias and low variance. We notice this in the plot also where the model is not able to fit the data well and is way off. \n",
    "\n",
    "With the medium degress we get a more balanced fit of the data, and the model is able to recoqnize the patternz in the data. This gives a result with a low bias and low variance. We notice this in the plot also where the model is able to fit the data well and almost follows the true function.\n",
    "\n",
    "Lastly we have a high degree where overfitting is happening. The model is able to fit the data very well, but it is not able to recoqnize the patternz in the data. This gives a result with a low bias and high variance. We notice this in the plot also where the model is able to fit the data very well, but is not able to follow the true function. The model is overfitting the data and is not able to generalize well, this is noticable with how the model correlates very closely with the samples and tries to hit/touch all of them. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qc) Score method\n",
    "\n",
    "The scoring method `neg_mean_squared_error` is the MSE but negated so instead of a high score being good, a low score is good.  \n",
    "\n",
    "In the `MSE` the `J-function` is going from bein a cost function to be more of a score function, because we want to maximize some measure of model performance.\n",
    "\n",
    "If we set it to `mean_squared_error` then it raises an exception.  \n",
    "\n",
    "![exeception.png](exeception.png)\n",
    "\n",
    "\n",
    "This happens because the MSE has minimum theoretical score of 0. \n",
    "The highest score is without any upper bound so can grow very large when the actual values are far from the predictions.\n",
    "\n",
    "The high degree model (15) has a big negative value, because the samples are very far form the predictions. Given that it is a negative value, it is a very good score that indicate the model is overfitting the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SWMAL Exercise\n",
    "\n",
    "\n",
    "## Hyperparameters and Gridsearch \n",
    "\n",
    "\n",
    "### Qa Explain GridSearchCV\n",
    "\n",
    "There are two code cells below: 1) function setup, 2) the actual grid-search.\n",
    "\n",
    "Review the code cells and write a __short__ summary. Mainly focus on __cell 2__, but dig into cell 1 if you find it interesting (notice the use of local-function, a nifty feature in python).\n",
    "  \n",
    "In detail, examine the lines:  \n",
    "  \n",
    "```python\n",
    "grid_tuned = GridSearchCV(model, tuning_parameters, ..\n",
    "grid_tuned.fit(X_train, y_train)\n",
    "..\n",
    "FullReport(grid_tuned , X_test, y_test, time_gridsearch)\n",
    "```\n",
    "and write a short description of how the `GridSeachCV` works: explain how the search parameter set is created and the overall search mechanism is functioning (without going into too much detail).\n",
    "\n",
    "What role does the parameter `scoring='f1_micro'` play in the `GridSearchCV`, and what does `n_jobs=-1` mean? \n",
    "\n",
    "\n",
    "\"Cell 1: function setup\n",
    "This cell contains functions and setup related to training and evaluating machine learning models. Key points include:\n",
    "\n",
    "The SearchReport function generates a report based on the results of grid or randomized search. It includes a GetBestModelCTOR function that constructs a string representation of the best model and its parameters.\n",
    "\n",
    "The ClassificationReport function generates a detailed classification report based on the trained model and test data.\n",
    "\n",
    "The FullReport function combines the results of SearchReport and ClassificationReport and prints them.\n",
    "\n",
    "The LoadAndSetupData function loads and sets up the dataset based on the specified mode.\n",
    "\n",
    "There is a TryKerasImport function that checks if the import of Keras or TensorFlow.keras is successful.\n",
    "\n",
    "Cell 2: the actual grid-search\n",
    "This cell performs the actual grid search:\n",
    "\n",
    "Data is loaded using the LoadAndSetupData function for the 'iris' mode.\n",
    "\n",
    "An SVM model (svm.SVC) is defined with a fixed gamma and a set of tuning parameters (tuning_parameters) to be searched through. It also specifies the number of cross-validation folds (CV), verbose level (VERBOSE), and n_jobs=-1 to utilize all available processors.\n",
    "\n",
    "A GridSearchCV object (grid_tuned) is created with the model, tuning parameters, cross-validation strategy, scoring metric ('f1_micro'), verbose level, and the number of parallel jobs.\n",
    "\n",
    "The grid search is executed by calling the fit method on grid_tuned with the training data (X_train and y_train).\n",
    "\n",
    "Results are reported using the FullReport function, which prints the best parameters, best score, and generates a classification report for the test dataset.\n",
    "\n",
    "In summary, the GridSearchCV is used to systematically search through a specified parameter grid for the best hyperparameters of a given model. The parameter set is created based on the provided tuning parameters. The scoring='f1_micro' parameter indicates that the model's performance is evaluated using the F1 micro score. The n_jobs=-1 parameter means that the search is performed in parallel using all available processors, which can significantly speed up the process.\"\n",
    "Answered by chatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T09:34:51.276511Z",
     "start_time": "2023-11-30T09:34:51.136634Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK(function setup)\n"
     ]
    }
   ],
   "source": [
    "# TODO: Qa, code review..cell 1) function setup\n",
    "\n",
    "from time import time\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, train_test_split\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn import datasets\n",
    "\n",
    "import sys,os\n",
    "sys.path.append(os.path.expanduser('../'))\n",
    "from libitmal import dataloaders as itmaldataloaders # Needed for load of iris, moon and mnist\n",
    "\n",
    "currmode=\"N/A\" # GLOBAL var!\n",
    "\n",
    "def SearchReport(model): \n",
    "    \n",
    "    def GetBestModelCTOR(model, best_params):\n",
    "        def GetParams(best_params):\n",
    "            ret_str=\"\"          \n",
    "            for key in sorted(best_params):\n",
    "                value = best_params[key]\n",
    "                temp_str = \"'\" if str(type(value))==\"<class 'str'>\" else \"\"\n",
    "                if len(ret_str)>0:\n",
    "                    ret_str += ','\n",
    "                ret_str += f'{key}={temp_str}{value}{temp_str}'  \n",
    "            return ret_str          \n",
    "        try:\n",
    "            param_str = GetParams(best_params)\n",
    "            return type(model).__name__ + '(' + param_str + ')' \n",
    "        except:\n",
    "            return \"N/A(1)\"\n",
    "        \n",
    "    print(\"\\nBest model set found on train set:\")\n",
    "    print()\n",
    "    print(f\"\\tbest parameters={model.best_params_}\")\n",
    "    print(f\"\\tbest '{model.scoring}' score={model.best_score_}\")\n",
    "    print(f\"\\tbest index={model.best_index_}\")\n",
    "    print()\n",
    "    print(f\"Best estimator CTOR:\")\n",
    "    print(f\"\\t{model.best_estimator_}\")\n",
    "    print()\n",
    "    try:\n",
    "        print(f\"Grid scores ('{model.scoring}') on development set:\")\n",
    "        means = model.cv_results_['mean_test_score']\n",
    "        stds  = model.cv_results_['std_test_score']\n",
    "        i=0\n",
    "        for mean, std, params in zip(means, stds, model.cv_results_['params']):\n",
    "            print(\"\\t[%2d]: %0.3f (+/-%0.03f) for %r\" % (i, mean, std * 2, params))\n",
    "            i += 1\n",
    "    except:\n",
    "        print(\"WARNING: the random search do not provide means/stds\")\n",
    "    \n",
    "    global currmode                \n",
    "    assert \"f1_micro\"==str(model.scoring), f\"come on, we need to fix the scoring to be able to compare model-fits! Your scoreing={str(model.scoring)}...remember to add scoring='f1_micro' to the search\"   \n",
    "    return f\"best: dat={currmode}, score={model.best_score_:0.5f}, model={GetBestModelCTOR(model.estimator,model.best_params_)}\", model.best_estimator_ \n",
    "\n",
    "def ClassificationReport(model, X_test, y_test, target_names=None):\n",
    "    assert X_test.shape[0]==y_test.shape[0]\n",
    "    print(\"\\nDetailed classification report:\")\n",
    "    print(\"\\tThe model is trained on the full development set.\")\n",
    "    print(\"\\tThe scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test, model.predict(X_test)                 \n",
    "    print(classification_report(y_true, y_pred, target_names=target_names))\n",
    "    print()\n",
    "    \n",
    "def FullReport(model, X_test, y_test, t):\n",
    "    print(f\"SEARCH TIME: {t:0.2f} sec\")\n",
    "    beststr, bestmodel = SearchReport(model)\n",
    "    ClassificationReport(model, X_test, y_test)    \n",
    "    print(f\"CTOR for best model: {bestmodel}\\n\")\n",
    "    print(f\"{beststr}\\n\")\n",
    "    return beststr, bestmodel\n",
    "    \n",
    "def LoadAndSetupData(mode, test_size=0.3):\n",
    "    assert test_size>=0.0 and test_size<=1.0\n",
    "    \n",
    "    def ShapeToString(Z):\n",
    "        n = Z.ndim\n",
    "        s = \"(\"\n",
    "        for i in range(n):\n",
    "            s += f\"{Z.shape[i]:5d}\"\n",
    "            if i+1!=n:\n",
    "                s += \";\"\n",
    "        return s+\")\"\n",
    "\n",
    "    global currmode\n",
    "    currmode=mode\n",
    "    print(f\"DATA: {currmode}..\")\n",
    "    \n",
    "    if mode=='moon':\n",
    "        X, y = itmaldataloaders.MOON_GetDataSet(n_samples=5000, noise=0.2)\n",
    "        itmaldataloaders.MOON_Plot(X, y)\n",
    "    elif mode=='mnist':\n",
    "        X, y = itmaldataloaders.MNIST_GetDataSet(load_mode=0)\n",
    "        if X.ndim==3:\n",
    "            X=np.reshape(X, (X.shape[0], -1))\n",
    "    elif mode=='iris':\n",
    "        X, y = itmaldataloaders.IRIS_GetDataSet()\n",
    "    else:\n",
    "        raise ValueError(f\"could not load data for that particular mode='{mode}', only 'moon'/'mnist'/'iris' supported\")\n",
    "        \n",
    "    print(f'  org. data:  X.shape      ={ShapeToString(X)}, y.shape      ={ShapeToString(y)}')\n",
    "\n",
    "    assert X.ndim==2\n",
    "    assert X.shape[0]==y.shape[0]\n",
    "    assert y.ndim==1 or (y.ndim==2 and y.shape[1]==0)    \n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=0, shuffle=True\n",
    "    )\n",
    "    \n",
    "    print(f'  train data: X_train.shape={ShapeToString(X_train)}, y_train.shape={ShapeToString(y_train)}')\n",
    "    print(f'  test data:  X_test.shape ={ShapeToString(X_test)}, y_test.shape ={ShapeToString(y_test)}')\n",
    "    print()\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def TryKerasImport(verbose=True):\n",
    "    \n",
    "    kerasok = True\n",
    "    try:\n",
    "        import keras as keras_try\n",
    "    except:\n",
    "        kerasok = False\n",
    "\n",
    "    tensorflowkerasok = True\n",
    "    try:\n",
    "        import tensorflow.keras as tensorflowkeras_try\n",
    "    except:\n",
    "        tensorflowkerasok = False\n",
    "        \n",
    "    ok = kerasok or tensorflowkerasok\n",
    "    \n",
    "    if not ok and verbose:\n",
    "        if not kerasok:\n",
    "            print(\"WARNING: importing 'keras' failed\", file=sys.stderr)\n",
    "        if not tensorflowkerasok:\n",
    "            print(\"WARNING: importing 'tensorflow.keras' failed\", file=sys.stderr)\n",
    "\n",
    "    return ok\n",
    "    \n",
    "print(f\"OK(function setup\" + (\"\" if TryKerasImport() else \", hope MNIST loads works because it seems you miss the installation of Keras or Tensorflow!\") + \")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T09:34:52.422130Z",
     "start_time": "2023-11-30T09:34:51.273268Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA: iris..\n",
      "  org. data:  X.shape      =(  150;    4), y.shape      =(  150)\n",
      "  train data: X_train.shape=(  105;    4), y_train.shape=(  105)\n",
      "  test data:  X_test.shape =(   45;    4), y_test.shape =(   45)\n",
      "SEARCH TIME: 1.14 sec\n",
      "\n",
      "Best model set found on train set:\n",
      "\n",
      "\tbest parameters={'C': 1, 'kernel': 'linear'}\n",
      "\tbest 'f1_micro' score=0.9714285714285715\n",
      "\tbest index=2\n",
      "\n",
      "Best estimator CTOR:\n",
      "\tSVC(C=1, gamma=0.001, kernel='linear')\n",
      "\n",
      "Grid scores ('f1_micro') on development set:\n",
      "\t[ 0]: 0.962 (+/-0.093) for {'C': 0.1, 'kernel': 'linear'}\n",
      "\t[ 1]: 0.371 (+/-0.038) for {'C': 0.1, 'kernel': 'rbf'}\n",
      "\t[ 2]: 0.971 (+/-0.047) for {'C': 1, 'kernel': 'linear'}\n",
      "\t[ 3]: 0.695 (+/-0.047) for {'C': 1, 'kernel': 'rbf'}\n",
      "\t[ 4]: 0.952 (+/-0.085) for {'C': 10, 'kernel': 'linear'}\n",
      "\t[ 5]: 0.924 (+/-0.097) for {'C': 10, 'kernel': 'rbf'}\n",
      "\n",
      "Detailed classification report:\n",
      "\tThe model is trained on the full development set.\n",
      "\tThe scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        16\n",
      "           1       1.00      0.94      0.97        18\n",
      "           2       0.92      1.00      0.96        11\n",
      "\n",
      "    accuracy                           0.98        45\n",
      "   macro avg       0.97      0.98      0.98        45\n",
      "weighted avg       0.98      0.98      0.98        45\n",
      "\n",
      "\n",
      "CTOR for best model: SVC(C=1, gamma=0.001, kernel='linear')\n",
      "\n",
      "best: dat=iris, score=0.97143, model=SVC(C=1,kernel='linear')\n",
      "\n",
      "OK(grid-search)\n"
     ]
    }
   ],
   "source": [
    "# TODO: Qa, code review..cell 2) the actual grid-search\n",
    "\n",
    "# Setup data\n",
    "X_train, X_test, y_train, y_test = LoadAndSetupData(\n",
    "    'iris')  # 'iris', 'moon', or 'mnist'\n",
    "\n",
    "# Setup search parameters\n",
    "model = svm.SVC(\n",
    "    gamma=0.001\n",
    ")  # NOTE: gamma=\"scale\" does not work in older Scikit-learn frameworks,\n",
    "# FIX:  replace with model = svm.SVC(gamma=0.001)\n",
    "\n",
    "tuning_parameters = {\n",
    "    'kernel': ('linear', 'rbf'), \n",
    "    'C': [0.1, 1, 10]\n",
    "}\n",
    "\n",
    "CV = 5\n",
    "VERBOSE = 0\n",
    "\n",
    "# Run GridSearchCV for the model\n",
    "grid_tuned = GridSearchCV(model,\n",
    "                          tuning_parameters,\n",
    "                          cv=CV,\n",
    "                          scoring='f1_micro',\n",
    "                          verbose=VERBOSE,\n",
    "                          n_jobs=-1)\n",
    "\n",
    "start = time()\n",
    "grid_tuned.fit(X_train, y_train)\n",
    "t = time() - start\n",
    "\n",
    "# Report result\n",
    "b0, m0 = FullReport(grid_tuned, X_test, y_test, t)\n",
    "print('OK(grid-search)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qb Hyperparameter Grid Search using an SDG classifier\n",
    "\n",
    "The svm.SVC model has been substituted with an SGDClassifier, and the model's hyperparameters have been adjusted. A  different loss function is now employed. Additionally, there has been set a maximum number of iterations and regularization to mitigate overfitting, though it results in a less flexible model. The parameter eta0 represents the initial learning rate, and penalty determines the type of regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T09:34:56.963101Z",
     "start_time": "2023-11-30T09:34:52.425951Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA: iris..\n",
      "  org. data:  X.shape      =(  150;    4), y.shape      =(  150)\n",
      "  train data: X_train.shape=(  105;    4), y_train.shape=(  105)\n",
      "  test data:  X_test.shape =(   45;    4), y_test.shape =(   45)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEARCH TIME: 4.50 sec\n",
      "\n",
      "Best model set found on train set:\n",
      "\n",
      "\tbest parameters={'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\tbest 'f1_micro' score=0.9904761904761905\n",
      "\tbest index=1672\n",
      "\n",
      "Best estimator CTOR:\n",
      "\tSGDClassifier(alpha=0.001, eta0=0.01, loss='perceptron', max_iter=300,\n",
      "              n_iter_no_change=20, penalty='l1', power_t=0.1, random_state=42)\n",
      "\n",
      "Grid scores ('f1_micro') on development set:\n",
      "\t[ 0]: 0.905 (+/-0.085) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[ 1]: 0.905 (+/-0.085) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[ 2]: 0.905 (+/-0.085) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[ 3]: 0.905 (+/-0.085) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[ 4]: 0.886 (+/-0.238) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[ 5]: 0.886 (+/-0.238) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[ 6]: 0.886 (+/-0.238) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[ 7]: 0.886 (+/-0.238) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[ 8]: 0.914 (+/-0.111) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[ 9]: 0.914 (+/-0.111) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[10]: 0.914 (+/-0.111) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[11]: 0.914 (+/-0.111) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[12]: 0.924 (+/-0.076) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[13]: 0.924 (+/-0.076) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[14]: 0.924 (+/-0.076) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[15]: 0.924 (+/-0.076) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[16]: 0.876 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[17]: 0.876 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[18]: 0.876 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[19]: 0.876 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[20]: 0.905 (+/-0.060) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[21]: 0.905 (+/-0.060) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[22]: 0.905 (+/-0.060) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[23]: 0.905 (+/-0.060) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[24]: 0.905 (+/-0.085) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[25]: 0.905 (+/-0.085) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[26]: 0.905 (+/-0.085) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[27]: 0.905 (+/-0.085) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[28]: 0.886 (+/-0.238) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[29]: 0.886 (+/-0.238) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[30]: 0.886 (+/-0.238) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[31]: 0.886 (+/-0.238) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[32]: 0.914 (+/-0.111) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[33]: 0.914 (+/-0.111) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[34]: 0.914 (+/-0.111) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[35]: 0.914 (+/-0.111) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[36]: 0.924 (+/-0.076) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[37]: 0.924 (+/-0.076) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[38]: 0.924 (+/-0.076) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[39]: 0.924 (+/-0.076) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[40]: 0.876 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[41]: 0.876 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[42]: 0.876 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[43]: 0.876 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[44]: 0.905 (+/-0.060) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[45]: 0.905 (+/-0.060) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[46]: 0.905 (+/-0.060) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[47]: 0.905 (+/-0.060) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[48]: 0.905 (+/-0.085) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[49]: 0.905 (+/-0.085) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[50]: 0.905 (+/-0.085) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[51]: 0.905 (+/-0.085) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[52]: 0.886 (+/-0.238) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[53]: 0.886 (+/-0.238) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[54]: 0.886 (+/-0.238) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[55]: 0.886 (+/-0.238) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[56]: 0.914 (+/-0.111) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[57]: 0.914 (+/-0.111) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[58]: 0.914 (+/-0.111) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[59]: 0.914 (+/-0.111) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[60]: 0.924 (+/-0.076) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[61]: 0.924 (+/-0.076) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[62]: 0.924 (+/-0.076) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[63]: 0.924 (+/-0.076) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[64]: 0.876 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[65]: 0.876 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[66]: 0.876 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[67]: 0.876 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[68]: 0.905 (+/-0.060) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[69]: 0.905 (+/-0.060) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[70]: 0.905 (+/-0.060) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[71]: 0.905 (+/-0.060) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[72]: 0.714 (+/-0.313) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[73]: 0.714 (+/-0.313) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[74]: 0.714 (+/-0.313) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[75]: 0.714 (+/-0.313) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[76]: 0.705 (+/-0.327) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[77]: 0.705 (+/-0.327) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[78]: 0.705 (+/-0.327) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[79]: 0.705 (+/-0.327) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[80]: 0.848 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[81]: 0.848 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[82]: 0.848 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[83]: 0.848 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[84]: 0.848 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[85]: 0.848 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[86]: 0.848 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[87]: 0.848 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[88]: 0.829 (+/-0.273) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[89]: 0.829 (+/-0.273) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[90]: 0.829 (+/-0.273) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[91]: 0.829 (+/-0.273) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[92]: 0.829 (+/-0.273) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[93]: 0.829 (+/-0.273) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[94]: 0.829 (+/-0.273) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[95]: 0.829 (+/-0.273) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[96]: 0.714 (+/-0.313) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[97]: 0.714 (+/-0.313) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[98]: 0.714 (+/-0.313) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[99]: 0.714 (+/-0.313) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[100]: 0.705 (+/-0.327) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[101]: 0.705 (+/-0.327) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[102]: 0.705 (+/-0.327) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[103]: 0.705 (+/-0.327) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[104]: 0.848 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[105]: 0.848 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[106]: 0.848 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[107]: 0.848 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[108]: 0.848 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[109]: 0.848 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[110]: 0.848 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[111]: 0.848 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[112]: 0.829 (+/-0.273) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[113]: 0.829 (+/-0.273) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[114]: 0.829 (+/-0.273) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[115]: 0.829 (+/-0.273) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[116]: 0.829 (+/-0.273) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[117]: 0.829 (+/-0.273) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[118]: 0.829 (+/-0.273) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[119]: 0.829 (+/-0.273) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[120]: 0.714 (+/-0.313) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[121]: 0.714 (+/-0.313) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[122]: 0.714 (+/-0.313) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[123]: 0.714 (+/-0.313) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[124]: 0.705 (+/-0.327) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[125]: 0.705 (+/-0.327) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[126]: 0.705 (+/-0.327) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[127]: 0.705 (+/-0.327) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[128]: 0.848 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[129]: 0.848 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[130]: 0.848 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[131]: 0.848 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[132]: 0.848 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[133]: 0.848 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[134]: 0.848 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[135]: 0.848 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[136]: 0.829 (+/-0.273) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[137]: 0.829 (+/-0.273) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[138]: 0.829 (+/-0.273) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[139]: 0.829 (+/-0.273) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[140]: 0.829 (+/-0.273) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[141]: 0.829 (+/-0.273) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[142]: 0.829 (+/-0.273) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[143]: 0.829 (+/-0.273) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[144]: 0.781 (+/-0.364) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[145]: 0.781 (+/-0.364) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[146]: 0.781 (+/-0.364) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[147]: 0.781 (+/-0.364) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[148]: 0.933 (+/-0.076) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[149]: 0.933 (+/-0.076) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[150]: 0.933 (+/-0.076) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[151]: 0.933 (+/-0.076) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[152]: 0.781 (+/-0.214) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[153]: 0.781 (+/-0.214) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[154]: 0.781 (+/-0.214) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[155]: 0.781 (+/-0.214) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[156]: 0.743 (+/-0.461) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[157]: 0.743 (+/-0.461) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[158]: 0.743 (+/-0.461) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[159]: 0.743 (+/-0.461) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[160]: 0.686 (+/-0.245) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[161]: 0.686 (+/-0.245) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[162]: 0.686 (+/-0.245) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[163]: 0.686 (+/-0.245) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[164]: 0.829 (+/-0.286) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[165]: 0.829 (+/-0.286) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[166]: 0.829 (+/-0.286) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[167]: 0.829 (+/-0.286) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[168]: 0.781 (+/-0.364) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[169]: 0.781 (+/-0.364) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[170]: 0.781 (+/-0.364) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[171]: 0.781 (+/-0.364) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[172]: 0.933 (+/-0.076) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[173]: 0.933 (+/-0.076) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[174]: 0.933 (+/-0.076) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[175]: 0.933 (+/-0.076) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[176]: 0.781 (+/-0.214) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[177]: 0.781 (+/-0.214) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[178]: 0.781 (+/-0.214) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[179]: 0.781 (+/-0.214) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[180]: 0.743 (+/-0.461) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[181]: 0.743 (+/-0.461) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[182]: 0.743 (+/-0.461) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[183]: 0.743 (+/-0.461) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[184]: 0.686 (+/-0.245) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[185]: 0.686 (+/-0.245) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[186]: 0.686 (+/-0.245) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[187]: 0.686 (+/-0.245) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[188]: 0.829 (+/-0.286) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[189]: 0.829 (+/-0.286) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[190]: 0.829 (+/-0.286) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[191]: 0.829 (+/-0.286) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[192]: 0.781 (+/-0.364) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[193]: 0.781 (+/-0.364) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[194]: 0.781 (+/-0.364) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[195]: 0.781 (+/-0.364) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[196]: 0.933 (+/-0.076) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[197]: 0.933 (+/-0.076) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[198]: 0.933 (+/-0.076) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[199]: 0.933 (+/-0.076) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[200]: 0.781 (+/-0.214) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[201]: 0.781 (+/-0.214) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[202]: 0.781 (+/-0.214) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[203]: 0.781 (+/-0.214) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[204]: 0.743 (+/-0.461) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[205]: 0.743 (+/-0.461) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[206]: 0.743 (+/-0.461) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[207]: 0.743 (+/-0.461) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[208]: 0.686 (+/-0.245) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[209]: 0.686 (+/-0.245) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[210]: 0.686 (+/-0.245) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[211]: 0.686 (+/-0.245) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[212]: 0.829 (+/-0.286) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[213]: 0.829 (+/-0.286) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[214]: 0.829 (+/-0.286) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[215]: 0.829 (+/-0.286) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[216]: 0.819 (+/-0.304) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[217]: 0.819 (+/-0.304) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[218]: 0.819 (+/-0.304) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[219]: 0.819 (+/-0.304) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[220]: 0.895 (+/-0.111) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[221]: 0.895 (+/-0.111) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[222]: 0.895 (+/-0.111) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[223]: 0.895 (+/-0.111) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[224]: 0.895 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[225]: 0.895 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[226]: 0.895 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[227]: 0.895 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[228]: 0.790 (+/-0.230) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[229]: 0.790 (+/-0.230) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[230]: 0.790 (+/-0.230) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[231]: 0.790 (+/-0.230) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[232]: 0.962 (+/-0.038) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[233]: 0.962 (+/-0.038) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[234]: 0.962 (+/-0.038) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[235]: 0.962 (+/-0.038) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[236]: 0.886 (+/-0.177) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[237]: 0.886 (+/-0.177) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[238]: 0.886 (+/-0.177) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[239]: 0.886 (+/-0.177) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[240]: 0.819 (+/-0.304) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[241]: 0.819 (+/-0.304) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[242]: 0.819 (+/-0.304) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[243]: 0.819 (+/-0.304) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[244]: 0.895 (+/-0.111) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[245]: 0.895 (+/-0.111) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[246]: 0.895 (+/-0.111) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[247]: 0.895 (+/-0.111) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[248]: 0.895 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[249]: 0.895 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[250]: 0.895 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[251]: 0.895 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[252]: 0.790 (+/-0.230) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[253]: 0.790 (+/-0.230) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[254]: 0.790 (+/-0.230) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[255]: 0.790 (+/-0.230) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[256]: 0.962 (+/-0.038) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[257]: 0.962 (+/-0.038) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[258]: 0.962 (+/-0.038) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[259]: 0.962 (+/-0.038) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[260]: 0.886 (+/-0.177) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[261]: 0.886 (+/-0.177) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[262]: 0.886 (+/-0.177) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[263]: 0.886 (+/-0.177) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[264]: 0.819 (+/-0.304) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[265]: 0.819 (+/-0.304) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[266]: 0.819 (+/-0.304) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[267]: 0.819 (+/-0.304) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[268]: 0.895 (+/-0.111) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[269]: 0.895 (+/-0.111) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[270]: 0.895 (+/-0.111) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[271]: 0.895 (+/-0.111) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[272]: 0.895 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[273]: 0.895 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[274]: 0.895 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[275]: 0.895 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[276]: 0.790 (+/-0.230) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[277]: 0.790 (+/-0.230) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[278]: 0.790 (+/-0.230) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[279]: 0.790 (+/-0.230) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[280]: 0.962 (+/-0.038) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[281]: 0.962 (+/-0.038) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[282]: 0.962 (+/-0.038) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[283]: 0.962 (+/-0.038) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[284]: 0.886 (+/-0.177) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[285]: 0.886 (+/-0.177) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[286]: 0.886 (+/-0.177) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[287]: 0.886 (+/-0.177) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[288]: 0.886 (+/-0.143) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[289]: 0.886 (+/-0.143) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[290]: 0.886 (+/-0.143) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[291]: 0.886 (+/-0.143) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[292]: 0.857 (+/-0.295) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[293]: 0.857 (+/-0.295) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[294]: 0.857 (+/-0.295) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[295]: 0.857 (+/-0.295) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[296]: 0.943 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[297]: 0.943 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[298]: 0.943 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[299]: 0.943 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[300]: 0.838 (+/-0.238) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[301]: 0.838 (+/-0.238) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[302]: 0.838 (+/-0.238) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[303]: 0.838 (+/-0.238) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[304]: 0.962 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[305]: 0.962 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[306]: 0.962 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[307]: 0.962 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[308]: 0.886 (+/-0.114) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[309]: 0.886 (+/-0.114) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[310]: 0.886 (+/-0.114) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[311]: 0.886 (+/-0.114) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[312]: 0.886 (+/-0.143) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[313]: 0.886 (+/-0.143) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[314]: 0.886 (+/-0.143) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[315]: 0.886 (+/-0.143) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[316]: 0.857 (+/-0.295) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[317]: 0.857 (+/-0.295) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[318]: 0.857 (+/-0.295) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[319]: 0.857 (+/-0.295) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[320]: 0.943 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[321]: 0.943 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[322]: 0.943 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[323]: 0.943 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[324]: 0.838 (+/-0.238) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[325]: 0.838 (+/-0.238) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[326]: 0.838 (+/-0.238) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[327]: 0.838 (+/-0.238) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[328]: 0.962 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[329]: 0.962 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[330]: 0.962 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[331]: 0.962 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[332]: 0.886 (+/-0.114) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[333]: 0.886 (+/-0.114) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[334]: 0.886 (+/-0.114) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[335]: 0.886 (+/-0.114) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[336]: 0.886 (+/-0.143) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[337]: 0.886 (+/-0.143) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[338]: 0.886 (+/-0.143) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[339]: 0.886 (+/-0.143) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[340]: 0.857 (+/-0.295) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[341]: 0.857 (+/-0.295) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[342]: 0.857 (+/-0.295) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[343]: 0.857 (+/-0.295) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[344]: 0.943 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[345]: 0.943 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[346]: 0.943 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[347]: 0.943 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[348]: 0.838 (+/-0.238) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[349]: 0.838 (+/-0.238) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[350]: 0.838 (+/-0.238) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[351]: 0.838 (+/-0.238) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[352]: 0.962 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[353]: 0.962 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[354]: 0.962 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[355]: 0.962 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[356]: 0.886 (+/-0.114) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[357]: 0.886 (+/-0.114) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[358]: 0.886 (+/-0.114) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[359]: 0.886 (+/-0.114) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[360]: 0.886 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[361]: 0.886 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[362]: 0.886 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[363]: 0.886 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[364]: 0.762 (+/-0.508) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[365]: 0.762 (+/-0.508) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[366]: 0.762 (+/-0.508) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[367]: 0.762 (+/-0.508) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[368]: 0.895 (+/-0.152) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[369]: 0.895 (+/-0.152) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[370]: 0.895 (+/-0.152) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[371]: 0.895 (+/-0.152) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[372]: 0.800 (+/-0.212) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[373]: 0.800 (+/-0.212) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[374]: 0.800 (+/-0.212) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[375]: 0.800 (+/-0.212) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[376]: 0.952 (+/-0.060) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[377]: 0.952 (+/-0.060) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[378]: 0.952 (+/-0.060) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[379]: 0.952 (+/-0.060) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[380]: 0.876 (+/-0.205) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[381]: 0.876 (+/-0.205) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[382]: 0.876 (+/-0.205) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[383]: 0.876 (+/-0.205) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[384]: 0.886 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[385]: 0.886 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[386]: 0.886 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[387]: 0.886 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[388]: 0.762 (+/-0.508) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[389]: 0.762 (+/-0.508) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[390]: 0.762 (+/-0.508) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[391]: 0.762 (+/-0.508) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[392]: 0.895 (+/-0.152) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[393]: 0.895 (+/-0.152) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[394]: 0.895 (+/-0.152) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[395]: 0.895 (+/-0.152) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[396]: 0.800 (+/-0.212) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[397]: 0.800 (+/-0.212) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[398]: 0.800 (+/-0.212) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[399]: 0.800 (+/-0.212) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[400]: 0.952 (+/-0.060) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[401]: 0.952 (+/-0.060) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[402]: 0.952 (+/-0.060) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[403]: 0.952 (+/-0.060) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[404]: 0.876 (+/-0.205) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[405]: 0.876 (+/-0.205) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[406]: 0.876 (+/-0.205) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[407]: 0.876 (+/-0.205) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[408]: 0.886 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[409]: 0.886 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[410]: 0.886 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[411]: 0.886 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[412]: 0.762 (+/-0.508) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[413]: 0.762 (+/-0.508) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[414]: 0.762 (+/-0.508) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[415]: 0.762 (+/-0.508) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[416]: 0.895 (+/-0.152) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[417]: 0.895 (+/-0.152) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[418]: 0.895 (+/-0.152) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[419]: 0.895 (+/-0.152) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[420]: 0.800 (+/-0.212) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[421]: 0.800 (+/-0.212) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[422]: 0.800 (+/-0.212) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[423]: 0.800 (+/-0.212) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[424]: 0.952 (+/-0.060) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[425]: 0.952 (+/-0.060) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[426]: 0.952 (+/-0.060) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[427]: 0.952 (+/-0.060) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[428]: 0.876 (+/-0.205) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[429]: 0.876 (+/-0.205) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[430]: 0.876 (+/-0.205) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[431]: 0.876 (+/-0.205) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[432]: 0.933 (+/-0.114) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[433]: 0.933 (+/-0.114) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[434]: 0.695 (+/-0.047) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[435]: 0.695 (+/-0.047) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[436]: 0.914 (+/-0.126) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[437]: 0.914 (+/-0.126) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[438]: 0.695 (+/-0.047) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[439]: 0.695 (+/-0.047) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[440]: 0.886 (+/-0.222) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[441]: 0.886 (+/-0.222) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[442]: 0.695 (+/-0.047) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[443]: 0.695 (+/-0.047) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[444]: 0.924 (+/-0.047) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[445]: 0.924 (+/-0.047) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[446]: 0.695 (+/-0.047) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[447]: 0.695 (+/-0.047) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[448]: 0.905 (+/-0.104) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[449]: 0.905 (+/-0.104) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[450]: 0.695 (+/-0.047) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[451]: 0.695 (+/-0.047) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[452]: 0.895 (+/-0.111) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[453]: 0.895 (+/-0.111) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[454]: 0.695 (+/-0.047) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[455]: 0.695 (+/-0.047) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[456]: 0.933 (+/-0.114) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[457]: 0.933 (+/-0.114) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[458]: 0.695 (+/-0.047) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[459]: 0.695 (+/-0.047) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[460]: 0.914 (+/-0.126) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[461]: 0.914 (+/-0.126) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[462]: 0.695 (+/-0.047) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[463]: 0.695 (+/-0.047) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[464]: 0.886 (+/-0.222) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[465]: 0.886 (+/-0.222) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[466]: 0.695 (+/-0.047) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[467]: 0.695 (+/-0.047) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[468]: 0.924 (+/-0.047) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[469]: 0.924 (+/-0.047) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[470]: 0.695 (+/-0.047) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[471]: 0.695 (+/-0.047) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[472]: 0.905 (+/-0.104) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[473]: 0.905 (+/-0.104) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[474]: 0.695 (+/-0.047) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[475]: 0.695 (+/-0.047) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[476]: 0.895 (+/-0.111) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[477]: 0.895 (+/-0.111) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[478]: 0.695 (+/-0.047) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[479]: 0.695 (+/-0.047) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[480]: 0.933 (+/-0.114) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[481]: 0.933 (+/-0.114) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[482]: 0.695 (+/-0.047) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[483]: 0.695 (+/-0.047) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[484]: 0.914 (+/-0.126) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[485]: 0.914 (+/-0.126) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[486]: 0.695 (+/-0.047) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[487]: 0.695 (+/-0.047) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[488]: 0.886 (+/-0.222) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[489]: 0.886 (+/-0.222) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[490]: 0.695 (+/-0.047) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[491]: 0.695 (+/-0.047) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[492]: 0.924 (+/-0.047) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[493]: 0.924 (+/-0.047) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[494]: 0.695 (+/-0.047) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[495]: 0.695 (+/-0.047) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[496]: 0.905 (+/-0.104) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[497]: 0.905 (+/-0.104) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[498]: 0.695 (+/-0.047) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[499]: 0.695 (+/-0.047) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[500]: 0.895 (+/-0.111) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[501]: 0.895 (+/-0.111) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[502]: 0.695 (+/-0.047) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[503]: 0.695 (+/-0.047) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[504]: 0.952 (+/-0.104) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[505]: 0.952 (+/-0.104) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[506]: 0.848 (+/-0.152) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[507]: 0.848 (+/-0.152) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[508]: 0.952 (+/-0.104) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[509]: 0.952 (+/-0.104) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[510]: 0.848 (+/-0.152) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[511]: 0.848 (+/-0.152) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[512]: 0.914 (+/-0.093) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[513]: 0.914 (+/-0.093) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[514]: 0.867 (+/-0.126) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[515]: 0.867 (+/-0.126) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[516]: 0.914 (+/-0.093) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[517]: 0.914 (+/-0.093) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[518]: 0.867 (+/-0.126) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[519]: 0.867 (+/-0.126) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[520]: 0.867 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[521]: 0.867 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[522]: 0.857 (+/-0.104) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[523]: 0.857 (+/-0.104) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[524]: 0.867 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[525]: 0.867 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[526]: 0.857 (+/-0.104) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[527]: 0.857 (+/-0.104) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[528]: 0.952 (+/-0.104) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[529]: 0.952 (+/-0.104) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[530]: 0.848 (+/-0.152) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[531]: 0.848 (+/-0.152) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[532]: 0.952 (+/-0.104) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[533]: 0.952 (+/-0.104) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[534]: 0.848 (+/-0.152) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[535]: 0.848 (+/-0.152) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[536]: 0.914 (+/-0.093) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[537]: 0.914 (+/-0.093) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[538]: 0.867 (+/-0.126) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[539]: 0.867 (+/-0.126) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[540]: 0.914 (+/-0.093) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[541]: 0.914 (+/-0.093) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[542]: 0.867 (+/-0.126) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[543]: 0.867 (+/-0.126) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[544]: 0.867 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[545]: 0.867 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[546]: 0.857 (+/-0.104) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[547]: 0.857 (+/-0.104) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[548]: 0.867 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[549]: 0.867 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[550]: 0.857 (+/-0.104) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[551]: 0.857 (+/-0.104) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[552]: 0.952 (+/-0.104) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[553]: 0.952 (+/-0.104) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[554]: 0.848 (+/-0.152) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[555]: 0.848 (+/-0.152) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[556]: 0.952 (+/-0.104) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[557]: 0.952 (+/-0.104) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[558]: 0.848 (+/-0.152) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[559]: 0.848 (+/-0.152) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[560]: 0.914 (+/-0.093) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[561]: 0.914 (+/-0.093) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[562]: 0.867 (+/-0.126) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[563]: 0.867 (+/-0.126) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[564]: 0.914 (+/-0.093) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[565]: 0.914 (+/-0.093) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[566]: 0.867 (+/-0.126) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[567]: 0.867 (+/-0.126) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[568]: 0.867 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[569]: 0.867 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[570]: 0.857 (+/-0.104) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[571]: 0.857 (+/-0.104) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[572]: 0.867 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[573]: 0.867 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[574]: 0.857 (+/-0.104) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[575]: 0.857 (+/-0.104) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[576]: 0.848 (+/-0.279) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[577]: 0.848 (+/-0.279) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[578]: 0.914 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[579]: 0.914 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[580]: 0.867 (+/-0.220) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[581]: 0.867 (+/-0.220) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[582]: 0.876 (+/-0.076) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[583]: 0.876 (+/-0.076) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[584]: 0.771 (+/-0.440) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[585]: 0.771 (+/-0.440) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[586]: 0.924 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[587]: 0.924 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[588]: 0.667 (+/-0.200) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[589]: 0.667 (+/-0.200) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[590]: 0.895 (+/-0.111) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[591]: 0.895 (+/-0.111) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[592]: 0.695 (+/-0.506) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[593]: 0.695 (+/-0.506) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[594]: 0.924 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[595]: 0.924 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[596]: 0.743 (+/-0.374) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[597]: 0.743 (+/-0.374) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[598]: 0.895 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[599]: 0.895 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[600]: 0.848 (+/-0.279) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[601]: 0.848 (+/-0.279) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[602]: 0.914 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[603]: 0.914 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[604]: 0.867 (+/-0.220) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[605]: 0.867 (+/-0.220) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[606]: 0.876 (+/-0.076) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[607]: 0.876 (+/-0.076) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[608]: 0.771 (+/-0.440) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[609]: 0.771 (+/-0.440) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[610]: 0.924 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[611]: 0.924 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[612]: 0.667 (+/-0.200) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[613]: 0.667 (+/-0.200) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[614]: 0.895 (+/-0.111) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[615]: 0.895 (+/-0.111) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[616]: 0.695 (+/-0.506) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[617]: 0.695 (+/-0.506) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[618]: 0.924 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[619]: 0.924 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[620]: 0.743 (+/-0.374) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[621]: 0.743 (+/-0.374) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[622]: 0.895 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[623]: 0.895 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[624]: 0.848 (+/-0.279) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[625]: 0.848 (+/-0.279) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[626]: 0.914 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[627]: 0.914 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[628]: 0.867 (+/-0.220) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[629]: 0.867 (+/-0.220) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[630]: 0.876 (+/-0.076) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[631]: 0.876 (+/-0.076) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[632]: 0.771 (+/-0.440) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[633]: 0.771 (+/-0.440) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[634]: 0.924 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[635]: 0.924 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[636]: 0.667 (+/-0.200) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[637]: 0.667 (+/-0.200) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[638]: 0.895 (+/-0.111) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[639]: 0.895 (+/-0.111) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[640]: 0.695 (+/-0.506) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[641]: 0.695 (+/-0.506) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[642]: 0.924 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[643]: 0.924 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[644]: 0.743 (+/-0.374) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[645]: 0.743 (+/-0.374) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[646]: 0.895 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[647]: 0.895 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[648]: 0.781 (+/-0.333) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[649]: 0.781 (+/-0.333) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[650]: 0.781 (+/-0.333) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[651]: 0.781 (+/-0.333) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[652]: 0.857 (+/-0.248) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[653]: 0.857 (+/-0.248) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[654]: 0.857 (+/-0.248) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[655]: 0.857 (+/-0.248) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[656]: 0.819 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[657]: 0.819 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[658]: 0.819 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[659]: 0.819 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[660]: 0.867 (+/-0.220) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[661]: 0.867 (+/-0.220) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[662]: 0.867 (+/-0.220) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[663]: 0.867 (+/-0.220) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[664]: 0.752 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[665]: 0.752 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[666]: 0.752 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[667]: 0.752 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[668]: 0.781 (+/-0.245) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[669]: 0.781 (+/-0.245) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[670]: 0.781 (+/-0.245) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[671]: 0.781 (+/-0.245) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[672]: 0.781 (+/-0.333) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[673]: 0.781 (+/-0.333) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[674]: 0.781 (+/-0.333) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[675]: 0.781 (+/-0.333) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[676]: 0.857 (+/-0.248) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[677]: 0.857 (+/-0.248) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[678]: 0.857 (+/-0.248) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[679]: 0.857 (+/-0.248) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[680]: 0.819 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[681]: 0.819 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[682]: 0.819 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[683]: 0.819 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[684]: 0.867 (+/-0.220) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[685]: 0.867 (+/-0.220) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[686]: 0.867 (+/-0.220) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[687]: 0.867 (+/-0.220) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[688]: 0.752 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[689]: 0.752 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[690]: 0.752 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[691]: 0.752 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[692]: 0.781 (+/-0.245) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[693]: 0.781 (+/-0.245) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[694]: 0.781 (+/-0.245) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[695]: 0.781 (+/-0.245) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[696]: 0.781 (+/-0.333) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[697]: 0.781 (+/-0.333) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[698]: 0.781 (+/-0.333) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[699]: 0.781 (+/-0.333) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[700]: 0.857 (+/-0.248) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[701]: 0.857 (+/-0.248) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[702]: 0.857 (+/-0.248) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[703]: 0.857 (+/-0.248) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[704]: 0.819 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[705]: 0.819 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[706]: 0.819 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[707]: 0.819 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[708]: 0.867 (+/-0.220) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[709]: 0.867 (+/-0.220) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[710]: 0.867 (+/-0.220) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[711]: 0.867 (+/-0.220) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[712]: 0.752 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[713]: 0.752 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[714]: 0.752 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[715]: 0.752 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[716]: 0.781 (+/-0.245) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[717]: 0.781 (+/-0.245) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[718]: 0.781 (+/-0.245) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[719]: 0.781 (+/-0.245) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[720]: 0.733 (+/-0.230) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[721]: 0.733 (+/-0.230) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[722]: 0.733 (+/-0.230) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[723]: 0.733 (+/-0.230) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[724]: 0.638 (+/-0.619) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[725]: 0.638 (+/-0.619) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[726]: 0.638 (+/-0.619) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[727]: 0.638 (+/-0.619) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[728]: 0.838 (+/-0.214) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[729]: 0.838 (+/-0.214) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[730]: 0.838 (+/-0.214) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[731]: 0.838 (+/-0.214) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[732]: 0.762 (+/-0.104) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[733]: 0.762 (+/-0.104) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[734]: 0.762 (+/-0.104) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[735]: 0.762 (+/-0.104) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[736]: 0.743 (+/-0.465) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[737]: 0.743 (+/-0.465) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[738]: 0.743 (+/-0.465) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[739]: 0.743 (+/-0.465) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[740]: 0.724 (+/-0.321) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[741]: 0.724 (+/-0.321) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[742]: 0.724 (+/-0.321) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[743]: 0.724 (+/-0.321) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[744]: 0.733 (+/-0.230) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[745]: 0.733 (+/-0.230) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[746]: 0.733 (+/-0.230) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[747]: 0.733 (+/-0.230) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[748]: 0.638 (+/-0.619) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[749]: 0.638 (+/-0.619) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[750]: 0.638 (+/-0.619) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[751]: 0.638 (+/-0.619) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[752]: 0.838 (+/-0.214) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[753]: 0.838 (+/-0.214) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[754]: 0.838 (+/-0.214) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[755]: 0.838 (+/-0.214) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[756]: 0.762 (+/-0.104) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[757]: 0.762 (+/-0.104) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[758]: 0.762 (+/-0.104) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[759]: 0.762 (+/-0.104) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[760]: 0.743 (+/-0.465) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[761]: 0.743 (+/-0.465) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[762]: 0.743 (+/-0.465) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[763]: 0.743 (+/-0.465) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[764]: 0.724 (+/-0.321) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[765]: 0.724 (+/-0.321) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[766]: 0.724 (+/-0.321) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[767]: 0.724 (+/-0.321) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[768]: 0.733 (+/-0.230) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[769]: 0.733 (+/-0.230) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[770]: 0.733 (+/-0.230) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[771]: 0.733 (+/-0.230) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[772]: 0.638 (+/-0.619) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[773]: 0.638 (+/-0.619) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[774]: 0.638 (+/-0.619) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[775]: 0.638 (+/-0.619) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[776]: 0.838 (+/-0.214) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[777]: 0.838 (+/-0.214) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[778]: 0.838 (+/-0.214) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[779]: 0.838 (+/-0.214) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[780]: 0.762 (+/-0.104) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[781]: 0.762 (+/-0.104) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[782]: 0.762 (+/-0.104) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[783]: 0.762 (+/-0.104) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[784]: 0.743 (+/-0.465) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[785]: 0.743 (+/-0.465) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[786]: 0.743 (+/-0.465) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[787]: 0.743 (+/-0.465) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[788]: 0.724 (+/-0.321) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[789]: 0.724 (+/-0.321) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[790]: 0.724 (+/-0.321) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[791]: 0.724 (+/-0.321) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[792]: 0.781 (+/-0.364) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[793]: 0.781 (+/-0.364) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[794]: 0.781 (+/-0.364) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[795]: 0.781 (+/-0.364) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[796]: 0.933 (+/-0.076) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[797]: 0.933 (+/-0.076) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[798]: 0.933 (+/-0.076) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[799]: 0.933 (+/-0.076) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[800]: 0.790 (+/-0.205) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[801]: 0.790 (+/-0.205) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[802]: 0.790 (+/-0.205) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[803]: 0.790 (+/-0.205) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[804]: 0.667 (+/-0.395) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[805]: 0.667 (+/-0.395) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[806]: 0.667 (+/-0.395) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[807]: 0.667 (+/-0.395) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[808]: 0.686 (+/-0.322) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[809]: 0.686 (+/-0.322) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[810]: 0.686 (+/-0.322) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[811]: 0.686 (+/-0.322) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[812]: 0.733 (+/-0.322) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[813]: 0.733 (+/-0.322) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[814]: 0.733 (+/-0.322) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[815]: 0.733 (+/-0.322) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[816]: 0.781 (+/-0.364) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[817]: 0.781 (+/-0.364) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[818]: 0.781 (+/-0.364) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[819]: 0.781 (+/-0.364) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[820]: 0.933 (+/-0.076) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[821]: 0.933 (+/-0.076) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[822]: 0.933 (+/-0.076) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[823]: 0.933 (+/-0.076) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[824]: 0.790 (+/-0.205) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[825]: 0.790 (+/-0.205) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[826]: 0.790 (+/-0.205) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[827]: 0.790 (+/-0.205) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[828]: 0.667 (+/-0.395) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[829]: 0.667 (+/-0.395) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[830]: 0.667 (+/-0.395) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[831]: 0.667 (+/-0.395) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[832]: 0.686 (+/-0.322) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[833]: 0.686 (+/-0.322) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[834]: 0.686 (+/-0.322) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[835]: 0.686 (+/-0.322) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[836]: 0.733 (+/-0.322) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[837]: 0.733 (+/-0.322) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[838]: 0.733 (+/-0.322) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[839]: 0.733 (+/-0.322) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[840]: 0.781 (+/-0.364) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[841]: 0.781 (+/-0.364) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[842]: 0.781 (+/-0.364) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[843]: 0.781 (+/-0.364) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[844]: 0.933 (+/-0.076) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[845]: 0.933 (+/-0.076) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[846]: 0.933 (+/-0.076) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[847]: 0.933 (+/-0.076) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[848]: 0.790 (+/-0.205) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[849]: 0.790 (+/-0.205) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[850]: 0.790 (+/-0.205) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[851]: 0.790 (+/-0.205) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[852]: 0.667 (+/-0.395) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[853]: 0.667 (+/-0.395) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[854]: 0.667 (+/-0.395) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[855]: 0.667 (+/-0.395) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[856]: 0.686 (+/-0.322) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[857]: 0.686 (+/-0.322) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[858]: 0.686 (+/-0.322) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[859]: 0.686 (+/-0.322) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[860]: 0.733 (+/-0.322) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[861]: 0.733 (+/-0.322) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[862]: 0.733 (+/-0.322) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[863]: 0.733 (+/-0.322) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[864]: 0.819 (+/-0.304) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[865]: 0.819 (+/-0.304) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[866]: 0.819 (+/-0.304) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[867]: 0.819 (+/-0.304) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[868]: 0.895 (+/-0.111) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[869]: 0.895 (+/-0.111) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[870]: 0.895 (+/-0.111) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[871]: 0.895 (+/-0.111) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[872]: 0.895 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[873]: 0.895 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[874]: 0.895 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[875]: 0.895 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[876]: 0.790 (+/-0.230) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[877]: 0.790 (+/-0.230) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[878]: 0.790 (+/-0.230) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[879]: 0.790 (+/-0.230) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[880]: 0.962 (+/-0.038) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[881]: 0.962 (+/-0.038) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[882]: 0.962 (+/-0.038) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[883]: 0.962 (+/-0.038) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[884]: 0.886 (+/-0.177) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[885]: 0.886 (+/-0.177) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[886]: 0.886 (+/-0.177) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[887]: 0.886 (+/-0.177) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[888]: 0.819 (+/-0.304) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[889]: 0.819 (+/-0.304) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[890]: 0.819 (+/-0.304) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[891]: 0.819 (+/-0.304) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[892]: 0.895 (+/-0.111) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[893]: 0.895 (+/-0.111) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[894]: 0.895 (+/-0.111) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[895]: 0.895 (+/-0.111) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[896]: 0.895 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[897]: 0.895 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[898]: 0.895 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[899]: 0.895 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[900]: 0.790 (+/-0.230) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[901]: 0.790 (+/-0.230) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[902]: 0.790 (+/-0.230) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[903]: 0.790 (+/-0.230) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[904]: 0.962 (+/-0.038) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[905]: 0.962 (+/-0.038) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[906]: 0.962 (+/-0.038) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[907]: 0.962 (+/-0.038) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[908]: 0.886 (+/-0.177) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[909]: 0.886 (+/-0.177) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[910]: 0.886 (+/-0.177) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[911]: 0.886 (+/-0.177) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[912]: 0.819 (+/-0.304) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[913]: 0.819 (+/-0.304) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[914]: 0.819 (+/-0.304) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[915]: 0.819 (+/-0.304) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[916]: 0.895 (+/-0.111) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[917]: 0.895 (+/-0.111) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[918]: 0.895 (+/-0.111) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[919]: 0.895 (+/-0.111) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[920]: 0.895 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[921]: 0.895 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[922]: 0.895 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[923]: 0.895 (+/-0.185) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[924]: 0.790 (+/-0.230) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[925]: 0.790 (+/-0.230) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[926]: 0.790 (+/-0.230) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[927]: 0.790 (+/-0.230) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[928]: 0.962 (+/-0.038) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[929]: 0.962 (+/-0.038) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[930]: 0.962 (+/-0.038) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[931]: 0.962 (+/-0.038) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[932]: 0.886 (+/-0.177) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[933]: 0.886 (+/-0.177) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[934]: 0.886 (+/-0.177) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[935]: 0.886 (+/-0.177) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[936]: 0.886 (+/-0.143) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[937]: 0.886 (+/-0.143) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[938]: 0.886 (+/-0.143) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[939]: 0.886 (+/-0.143) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[940]: 0.857 (+/-0.295) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[941]: 0.857 (+/-0.295) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[942]: 0.857 (+/-0.295) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[943]: 0.857 (+/-0.295) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[944]: 0.943 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[945]: 0.943 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[946]: 0.943 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[947]: 0.943 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[948]: 0.838 (+/-0.238) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[949]: 0.838 (+/-0.238) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[950]: 0.838 (+/-0.238) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[951]: 0.838 (+/-0.238) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[952]: 0.962 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[953]: 0.962 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[954]: 0.962 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[955]: 0.962 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[956]: 0.886 (+/-0.114) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[957]: 0.886 (+/-0.114) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[958]: 0.886 (+/-0.114) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[959]: 0.886 (+/-0.114) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[960]: 0.886 (+/-0.143) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[961]: 0.886 (+/-0.143) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[962]: 0.886 (+/-0.143) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[963]: 0.886 (+/-0.143) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[964]: 0.857 (+/-0.295) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[965]: 0.857 (+/-0.295) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[966]: 0.857 (+/-0.295) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[967]: 0.857 (+/-0.295) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[968]: 0.943 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[969]: 0.943 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[970]: 0.943 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[971]: 0.943 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[972]: 0.838 (+/-0.238) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[973]: 0.838 (+/-0.238) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[974]: 0.838 (+/-0.238) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[975]: 0.838 (+/-0.238) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[976]: 0.962 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[977]: 0.962 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[978]: 0.962 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[979]: 0.962 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[980]: 0.886 (+/-0.114) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[981]: 0.886 (+/-0.114) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[982]: 0.886 (+/-0.114) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[983]: 0.886 (+/-0.114) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[984]: 0.886 (+/-0.143) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[985]: 0.886 (+/-0.143) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[986]: 0.886 (+/-0.143) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[987]: 0.886 (+/-0.143) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[988]: 0.857 (+/-0.295) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[989]: 0.857 (+/-0.295) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[990]: 0.857 (+/-0.295) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[991]: 0.857 (+/-0.295) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[992]: 0.943 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[993]: 0.943 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[994]: 0.943 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[995]: 0.943 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[996]: 0.838 (+/-0.238) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[997]: 0.838 (+/-0.238) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[998]: 0.838 (+/-0.238) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[999]: 0.838 (+/-0.238) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1000]: 0.962 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1001]: 0.962 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1002]: 0.962 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1003]: 0.962 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1004]: 0.886 (+/-0.114) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1005]: 0.886 (+/-0.114) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1006]: 0.886 (+/-0.114) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1007]: 0.886 (+/-0.114) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1008]: 0.886 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1009]: 0.886 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1010]: 0.886 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1011]: 0.886 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1012]: 0.762 (+/-0.508) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1013]: 0.762 (+/-0.508) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1014]: 0.762 (+/-0.508) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1015]: 0.762 (+/-0.508) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1016]: 0.895 (+/-0.152) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1017]: 0.895 (+/-0.152) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1018]: 0.895 (+/-0.152) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1019]: 0.895 (+/-0.152) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1020]: 0.800 (+/-0.212) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1021]: 0.800 (+/-0.212) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1022]: 0.800 (+/-0.212) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1023]: 0.800 (+/-0.212) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1024]: 0.952 (+/-0.060) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1025]: 0.952 (+/-0.060) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1026]: 0.952 (+/-0.060) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1027]: 0.952 (+/-0.060) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1028]: 0.876 (+/-0.205) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1029]: 0.876 (+/-0.205) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1030]: 0.876 (+/-0.205) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1031]: 0.876 (+/-0.205) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1032]: 0.886 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1033]: 0.886 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1034]: 0.886 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1035]: 0.886 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1036]: 0.762 (+/-0.508) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1037]: 0.762 (+/-0.508) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1038]: 0.762 (+/-0.508) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1039]: 0.762 (+/-0.508) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1040]: 0.895 (+/-0.152) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1041]: 0.895 (+/-0.152) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1042]: 0.895 (+/-0.152) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1043]: 0.895 (+/-0.152) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1044]: 0.800 (+/-0.212) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1045]: 0.800 (+/-0.212) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1046]: 0.800 (+/-0.212) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1047]: 0.800 (+/-0.212) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1048]: 0.952 (+/-0.060) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1049]: 0.952 (+/-0.060) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1050]: 0.952 (+/-0.060) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1051]: 0.952 (+/-0.060) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1052]: 0.876 (+/-0.205) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1053]: 0.876 (+/-0.205) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1054]: 0.876 (+/-0.205) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1055]: 0.876 (+/-0.205) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1056]: 0.886 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1057]: 0.886 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1058]: 0.886 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1059]: 0.886 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1060]: 0.762 (+/-0.508) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1061]: 0.762 (+/-0.508) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1062]: 0.762 (+/-0.508) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1063]: 0.762 (+/-0.508) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1064]: 0.895 (+/-0.152) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1065]: 0.895 (+/-0.152) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1066]: 0.895 (+/-0.152) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1067]: 0.895 (+/-0.152) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1068]: 0.800 (+/-0.212) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1069]: 0.800 (+/-0.212) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1070]: 0.800 (+/-0.212) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1071]: 0.800 (+/-0.212) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1072]: 0.952 (+/-0.060) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1073]: 0.952 (+/-0.060) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1074]: 0.952 (+/-0.060) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1075]: 0.952 (+/-0.060) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1076]: 0.876 (+/-0.205) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1077]: 0.876 (+/-0.205) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1078]: 0.876 (+/-0.205) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1079]: 0.876 (+/-0.205) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1080]: 0.933 (+/-0.143) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1081]: 0.933 (+/-0.143) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1082]: 0.810 (+/-0.120) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1083]: 0.810 (+/-0.120) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1084]: 0.819 (+/-0.251) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1085]: 0.819 (+/-0.251) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1086]: 0.829 (+/-0.155) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1087]: 0.829 (+/-0.155) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1088]: 0.876 (+/-0.129) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1089]: 0.876 (+/-0.129) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1090]: 0.886 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1091]: 0.886 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1092]: 0.781 (+/-0.143) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1093]: 0.781 (+/-0.143) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1094]: 0.895 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1095]: 0.895 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1096]: 0.905 (+/-0.190) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1097]: 0.905 (+/-0.190) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1098]: 0.886 (+/-0.143) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1099]: 0.886 (+/-0.143) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1100]: 0.781 (+/-0.143) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1101]: 0.781 (+/-0.143) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1102]: 0.876 (+/-0.177) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1103]: 0.876 (+/-0.177) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1104]: 0.933 (+/-0.143) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1105]: 0.933 (+/-0.143) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1106]: 0.810 (+/-0.120) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1107]: 0.810 (+/-0.120) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1108]: 0.819 (+/-0.251) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1109]: 0.819 (+/-0.251) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1110]: 0.829 (+/-0.155) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1111]: 0.829 (+/-0.155) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1112]: 0.876 (+/-0.129) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1113]: 0.876 (+/-0.129) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1114]: 0.886 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1115]: 0.886 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1116]: 0.781 (+/-0.143) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1117]: 0.781 (+/-0.143) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1118]: 0.895 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1119]: 0.895 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1120]: 0.905 (+/-0.190) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1121]: 0.905 (+/-0.190) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1122]: 0.886 (+/-0.143) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1123]: 0.886 (+/-0.143) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1124]: 0.781 (+/-0.143) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1125]: 0.781 (+/-0.143) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1126]: 0.876 (+/-0.177) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1127]: 0.876 (+/-0.177) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1128]: 0.933 (+/-0.143) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1129]: 0.933 (+/-0.143) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1130]: 0.810 (+/-0.120) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1131]: 0.810 (+/-0.120) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1132]: 0.819 (+/-0.251) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1133]: 0.819 (+/-0.251) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1134]: 0.829 (+/-0.155) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1135]: 0.829 (+/-0.155) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1136]: 0.876 (+/-0.129) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1137]: 0.876 (+/-0.129) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1138]: 0.886 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1139]: 0.886 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1140]: 0.781 (+/-0.143) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1141]: 0.781 (+/-0.143) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1142]: 0.895 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1143]: 0.895 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1144]: 0.905 (+/-0.190) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1145]: 0.905 (+/-0.190) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1146]: 0.886 (+/-0.143) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1147]: 0.886 (+/-0.143) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1148]: 0.781 (+/-0.143) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1149]: 0.781 (+/-0.143) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1150]: 0.876 (+/-0.177) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1151]: 0.876 (+/-0.177) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1152]: 0.695 (+/-0.567) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1153]: 0.695 (+/-0.567) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1154]: 0.867 (+/-0.152) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1155]: 0.867 (+/-0.152) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1156]: 0.848 (+/-0.152) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1157]: 0.848 (+/-0.152) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1158]: 0.867 (+/-0.152) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1159]: 0.867 (+/-0.152) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1160]: 0.829 (+/-0.187) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1161]: 0.829 (+/-0.187) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1162]: 0.857 (+/-0.170) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1163]: 0.857 (+/-0.170) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1164]: 0.743 (+/-0.129) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1165]: 0.743 (+/-0.129) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1166]: 0.857 (+/-0.170) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1167]: 0.857 (+/-0.170) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1168]: 0.657 (+/-0.444) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1169]: 0.657 (+/-0.444) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1170]: 0.838 (+/-0.196) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1171]: 0.838 (+/-0.196) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1172]: 0.752 (+/-0.203) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1173]: 0.752 (+/-0.203) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1174]: 0.838 (+/-0.196) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1175]: 0.838 (+/-0.196) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1176]: 0.695 (+/-0.567) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1177]: 0.695 (+/-0.567) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1178]: 0.867 (+/-0.152) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1179]: 0.867 (+/-0.152) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1180]: 0.848 (+/-0.152) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1181]: 0.848 (+/-0.152) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1182]: 0.867 (+/-0.152) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1183]: 0.867 (+/-0.152) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1184]: 0.829 (+/-0.187) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1185]: 0.829 (+/-0.187) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1186]: 0.857 (+/-0.170) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1187]: 0.857 (+/-0.170) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1188]: 0.743 (+/-0.129) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1189]: 0.743 (+/-0.129) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1190]: 0.857 (+/-0.170) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1191]: 0.857 (+/-0.170) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1192]: 0.657 (+/-0.444) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1193]: 0.657 (+/-0.444) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1194]: 0.838 (+/-0.196) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1195]: 0.838 (+/-0.196) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1196]: 0.752 (+/-0.203) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1197]: 0.752 (+/-0.203) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1198]: 0.838 (+/-0.196) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1199]: 0.838 (+/-0.196) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1200]: 0.695 (+/-0.567) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1201]: 0.695 (+/-0.567) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1202]: 0.867 (+/-0.152) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1203]: 0.867 (+/-0.152) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1204]: 0.848 (+/-0.152) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1205]: 0.848 (+/-0.152) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1206]: 0.867 (+/-0.152) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1207]: 0.867 (+/-0.152) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1208]: 0.829 (+/-0.187) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1209]: 0.829 (+/-0.187) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1210]: 0.857 (+/-0.170) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1211]: 0.857 (+/-0.170) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1212]: 0.743 (+/-0.129) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1213]: 0.743 (+/-0.129) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1214]: 0.857 (+/-0.170) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1215]: 0.857 (+/-0.170) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1216]: 0.657 (+/-0.444) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1217]: 0.657 (+/-0.444) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1218]: 0.838 (+/-0.196) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1219]: 0.838 (+/-0.196) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1220]: 0.752 (+/-0.203) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1221]: 0.752 (+/-0.203) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1222]: 0.838 (+/-0.196) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1223]: 0.838 (+/-0.196) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1224]: 0.857 (+/-0.289) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1225]: 0.857 (+/-0.289) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1226]: 0.933 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1227]: 0.933 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1228]: 0.800 (+/-0.265) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1229]: 0.800 (+/-0.265) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1230]: 0.914 (+/-0.111) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1231]: 0.914 (+/-0.111) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1232]: 0.752 (+/-0.472) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1233]: 0.752 (+/-0.472) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1234]: 0.924 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1235]: 0.924 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1236]: 0.857 (+/-0.190) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1237]: 0.857 (+/-0.190) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1238]: 0.943 (+/-0.093) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1239]: 0.943 (+/-0.093) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1240]: 0.800 (+/-0.332) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1241]: 0.800 (+/-0.332) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1242]: 0.962 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1243]: 0.962 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1244]: 0.810 (+/-0.200) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1245]: 0.810 (+/-0.200) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1246]: 0.962 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1247]: 0.962 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1248]: 0.857 (+/-0.289) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1249]: 0.857 (+/-0.289) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1250]: 0.933 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1251]: 0.933 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1252]: 0.800 (+/-0.265) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1253]: 0.800 (+/-0.265) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1254]: 0.914 (+/-0.111) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1255]: 0.914 (+/-0.111) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1256]: 0.752 (+/-0.472) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1257]: 0.752 (+/-0.472) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1258]: 0.924 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1259]: 0.924 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1260]: 0.857 (+/-0.190) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1261]: 0.857 (+/-0.190) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1262]: 0.943 (+/-0.093) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1263]: 0.943 (+/-0.093) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1264]: 0.800 (+/-0.332) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1265]: 0.800 (+/-0.332) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1266]: 0.962 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1267]: 0.962 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1268]: 0.810 (+/-0.200) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1269]: 0.810 (+/-0.200) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1270]: 0.962 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1271]: 0.962 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1272]: 0.857 (+/-0.289) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1273]: 0.857 (+/-0.289) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1274]: 0.933 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1275]: 0.933 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1276]: 0.800 (+/-0.265) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1277]: 0.800 (+/-0.265) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1278]: 0.914 (+/-0.111) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1279]: 0.914 (+/-0.111) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1280]: 0.752 (+/-0.472) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1281]: 0.752 (+/-0.472) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1282]: 0.924 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1283]: 0.924 (+/-0.097) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1284]: 0.857 (+/-0.190) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1285]: 0.857 (+/-0.190) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1286]: 0.943 (+/-0.093) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1287]: 0.943 (+/-0.093) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1288]: 0.800 (+/-0.332) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1289]: 0.800 (+/-0.332) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1290]: 0.962 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1291]: 0.962 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1292]: 0.810 (+/-0.200) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1293]: 0.810 (+/-0.200) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1294]: 0.962 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1295]: 0.962 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1296]: 0.876 (+/-0.222) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1297]: 0.876 (+/-0.222) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1298]: 0.876 (+/-0.222) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1299]: 0.876 (+/-0.222) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1300]: 0.886 (+/-0.143) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1301]: 0.886 (+/-0.143) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1302]: 0.886 (+/-0.143) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1303]: 0.886 (+/-0.143) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1304]: 0.943 (+/-0.093) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1305]: 0.943 (+/-0.093) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1306]: 0.943 (+/-0.093) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1307]: 0.943 (+/-0.093) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1308]: 0.905 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1309]: 0.905 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1310]: 0.905 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1311]: 0.905 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1312]: 0.886 (+/-0.129) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1313]: 0.886 (+/-0.129) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1314]: 0.886 (+/-0.129) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1315]: 0.886 (+/-0.129) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1316]: 0.867 (+/-0.212) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1317]: 0.867 (+/-0.212) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1318]: 0.867 (+/-0.212) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1319]: 0.867 (+/-0.212) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1320]: 0.876 (+/-0.222) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1321]: 0.876 (+/-0.222) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1322]: 0.876 (+/-0.222) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1323]: 0.876 (+/-0.222) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1324]: 0.886 (+/-0.143) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1325]: 0.886 (+/-0.143) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1326]: 0.886 (+/-0.143) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1327]: 0.886 (+/-0.143) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1328]: 0.943 (+/-0.093) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1329]: 0.943 (+/-0.093) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1330]: 0.943 (+/-0.093) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1331]: 0.943 (+/-0.093) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1332]: 0.905 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1333]: 0.905 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1334]: 0.905 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1335]: 0.905 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1336]: 0.886 (+/-0.129) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1337]: 0.886 (+/-0.129) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1338]: 0.886 (+/-0.129) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1339]: 0.886 (+/-0.129) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1340]: 0.867 (+/-0.212) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1341]: 0.867 (+/-0.212) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1342]: 0.867 (+/-0.212) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1343]: 0.867 (+/-0.212) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1344]: 0.876 (+/-0.222) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1345]: 0.876 (+/-0.222) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1346]: 0.876 (+/-0.222) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1347]: 0.876 (+/-0.222) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1348]: 0.886 (+/-0.143) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1349]: 0.886 (+/-0.143) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1350]: 0.886 (+/-0.143) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1351]: 0.886 (+/-0.143) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1352]: 0.943 (+/-0.093) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1353]: 0.943 (+/-0.093) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1354]: 0.943 (+/-0.093) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1355]: 0.943 (+/-0.093) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1356]: 0.905 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1357]: 0.905 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1358]: 0.905 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1359]: 0.905 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1360]: 0.886 (+/-0.129) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1361]: 0.886 (+/-0.129) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1362]: 0.886 (+/-0.129) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1363]: 0.886 (+/-0.129) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1364]: 0.867 (+/-0.212) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1365]: 0.867 (+/-0.212) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1366]: 0.867 (+/-0.212) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1367]: 0.867 (+/-0.212) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1368]: 0.724 (+/-0.304) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1369]: 0.724 (+/-0.304) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1370]: 0.724 (+/-0.304) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1371]: 0.724 (+/-0.304) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1372]: 0.705 (+/-0.327) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1373]: 0.705 (+/-0.327) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1374]: 0.705 (+/-0.327) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1375]: 0.705 (+/-0.327) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1376]: 0.848 (+/-0.185) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1377]: 0.848 (+/-0.185) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1378]: 0.848 (+/-0.185) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1379]: 0.848 (+/-0.185) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1380]: 0.848 (+/-0.185) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1381]: 0.848 (+/-0.185) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1382]: 0.848 (+/-0.185) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1383]: 0.848 (+/-0.185) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1384]: 0.829 (+/-0.273) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1385]: 0.829 (+/-0.273) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1386]: 0.829 (+/-0.273) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1387]: 0.829 (+/-0.273) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1388]: 0.819 (+/-0.304) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1389]: 0.819 (+/-0.304) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1390]: 0.819 (+/-0.304) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1391]: 0.819 (+/-0.304) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1392]: 0.724 (+/-0.304) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1393]: 0.724 (+/-0.304) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1394]: 0.724 (+/-0.304) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1395]: 0.724 (+/-0.304) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1396]: 0.705 (+/-0.327) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1397]: 0.705 (+/-0.327) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1398]: 0.705 (+/-0.327) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1399]: 0.705 (+/-0.327) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1400]: 0.848 (+/-0.185) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1401]: 0.848 (+/-0.185) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1402]: 0.848 (+/-0.185) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1403]: 0.848 (+/-0.185) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1404]: 0.848 (+/-0.185) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1405]: 0.848 (+/-0.185) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1406]: 0.848 (+/-0.185) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1407]: 0.848 (+/-0.185) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1408]: 0.829 (+/-0.273) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1409]: 0.829 (+/-0.273) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1410]: 0.829 (+/-0.273) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1411]: 0.829 (+/-0.273) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1412]: 0.819 (+/-0.304) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1413]: 0.819 (+/-0.304) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1414]: 0.819 (+/-0.304) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1415]: 0.819 (+/-0.304) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1416]: 0.724 (+/-0.304) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1417]: 0.724 (+/-0.304) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1418]: 0.724 (+/-0.304) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1419]: 0.724 (+/-0.304) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1420]: 0.705 (+/-0.327) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1421]: 0.705 (+/-0.327) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1422]: 0.705 (+/-0.327) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1423]: 0.705 (+/-0.327) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1424]: 0.848 (+/-0.185) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1425]: 0.848 (+/-0.185) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1426]: 0.848 (+/-0.185) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1427]: 0.848 (+/-0.185) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1428]: 0.848 (+/-0.185) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1429]: 0.848 (+/-0.185) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1430]: 0.848 (+/-0.185) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1431]: 0.848 (+/-0.185) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1432]: 0.829 (+/-0.273) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1433]: 0.829 (+/-0.273) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1434]: 0.829 (+/-0.273) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1435]: 0.829 (+/-0.273) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1436]: 0.819 (+/-0.304) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1437]: 0.819 (+/-0.304) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1438]: 0.819 (+/-0.304) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1439]: 0.819 (+/-0.304) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1440]: 0.838 (+/-0.230) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1441]: 0.838 (+/-0.230) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1442]: 0.838 (+/-0.230) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1443]: 0.838 (+/-0.230) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1444]: 0.933 (+/-0.076) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1445]: 0.933 (+/-0.076) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1446]: 0.933 (+/-0.076) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1447]: 0.933 (+/-0.076) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1448]: 0.629 (+/-0.251) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1449]: 0.629 (+/-0.251) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1450]: 0.629 (+/-0.251) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1451]: 0.629 (+/-0.251) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1452]: 0.667 (+/-0.395) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1453]: 0.667 (+/-0.395) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1454]: 0.667 (+/-0.395) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1455]: 0.667 (+/-0.395) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1456]: 0.848 (+/-0.236) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1457]: 0.848 (+/-0.236) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1458]: 0.848 (+/-0.236) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1459]: 0.848 (+/-0.236) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1460]: 0.695 (+/-0.155) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1461]: 0.695 (+/-0.155) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1462]: 0.695 (+/-0.155) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1463]: 0.695 (+/-0.155) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1464]: 0.838 (+/-0.230) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1465]: 0.838 (+/-0.230) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1466]: 0.838 (+/-0.230) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1467]: 0.838 (+/-0.230) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1468]: 0.933 (+/-0.076) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1469]: 0.933 (+/-0.076) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1470]: 0.933 (+/-0.076) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1471]: 0.933 (+/-0.076) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1472]: 0.629 (+/-0.251) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1473]: 0.629 (+/-0.251) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1474]: 0.629 (+/-0.251) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1475]: 0.629 (+/-0.251) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1476]: 0.667 (+/-0.395) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1477]: 0.667 (+/-0.395) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1478]: 0.667 (+/-0.395) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1479]: 0.667 (+/-0.395) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1480]: 0.848 (+/-0.236) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1481]: 0.848 (+/-0.236) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1482]: 0.848 (+/-0.236) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1483]: 0.848 (+/-0.236) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1484]: 0.695 (+/-0.155) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1485]: 0.695 (+/-0.155) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1486]: 0.695 (+/-0.155) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1487]: 0.695 (+/-0.155) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1488]: 0.838 (+/-0.230) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1489]: 0.838 (+/-0.230) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1490]: 0.838 (+/-0.230) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1491]: 0.838 (+/-0.230) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1492]: 0.933 (+/-0.076) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1493]: 0.933 (+/-0.076) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1494]: 0.933 (+/-0.076) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1495]: 0.933 (+/-0.076) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1496]: 0.629 (+/-0.251) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1497]: 0.629 (+/-0.251) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1498]: 0.629 (+/-0.251) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1499]: 0.629 (+/-0.251) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1500]: 0.667 (+/-0.395) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1501]: 0.667 (+/-0.395) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1502]: 0.667 (+/-0.395) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1503]: 0.667 (+/-0.395) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1504]: 0.848 (+/-0.236) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1505]: 0.848 (+/-0.236) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1506]: 0.848 (+/-0.236) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1507]: 0.848 (+/-0.236) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1508]: 0.695 (+/-0.155) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1509]: 0.695 (+/-0.155) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1510]: 0.695 (+/-0.155) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1511]: 0.695 (+/-0.155) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1512]: 0.943 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1513]: 0.943 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1514]: 0.943 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1515]: 0.943 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1516]: 0.924 (+/-0.076) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1517]: 0.924 (+/-0.076) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1518]: 0.924 (+/-0.076) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1519]: 0.924 (+/-0.076) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1520]: 0.962 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1521]: 0.962 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1522]: 0.962 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1523]: 0.962 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1524]: 0.857 (+/-0.148) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1525]: 0.857 (+/-0.148) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1526]: 0.857 (+/-0.148) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1527]: 0.857 (+/-0.148) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1528]: 0.981 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1529]: 0.981 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1530]: 0.981 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1531]: 0.981 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1532]: 0.914 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1533]: 0.914 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1534]: 0.914 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1535]: 0.914 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1536]: 0.943 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1537]: 0.943 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1538]: 0.943 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1539]: 0.943 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1540]: 0.924 (+/-0.076) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1541]: 0.924 (+/-0.076) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1542]: 0.924 (+/-0.076) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1543]: 0.924 (+/-0.076) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1544]: 0.962 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1545]: 0.962 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1546]: 0.962 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1547]: 0.962 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1548]: 0.857 (+/-0.148) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1549]: 0.857 (+/-0.148) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1550]: 0.857 (+/-0.148) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1551]: 0.857 (+/-0.148) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1552]: 0.981 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1553]: 0.981 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1554]: 0.981 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1555]: 0.981 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1556]: 0.914 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1557]: 0.914 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1558]: 0.914 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1559]: 0.914 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1560]: 0.943 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1561]: 0.943 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1562]: 0.943 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1563]: 0.943 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1564]: 0.924 (+/-0.076) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1565]: 0.924 (+/-0.076) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1566]: 0.924 (+/-0.076) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1567]: 0.924 (+/-0.076) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1568]: 0.962 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1569]: 0.962 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1570]: 0.962 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1571]: 0.962 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1572]: 0.857 (+/-0.148) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1573]: 0.857 (+/-0.148) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1574]: 0.857 (+/-0.148) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1575]: 0.857 (+/-0.148) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1576]: 0.981 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1577]: 0.981 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1578]: 0.981 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1579]: 0.981 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1580]: 0.914 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1581]: 0.914 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1582]: 0.914 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1583]: 0.914 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1584]: 0.952 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1585]: 0.952 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1586]: 0.952 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1587]: 0.952 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1588]: 0.943 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1589]: 0.943 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1590]: 0.943 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1591]: 0.943 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1592]: 0.952 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1593]: 0.952 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1594]: 0.952 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1595]: 0.952 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1596]: 0.876 (+/-0.205) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1597]: 0.876 (+/-0.205) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1598]: 0.876 (+/-0.205) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1599]: 0.876 (+/-0.205) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1600]: 0.952 (+/-0.000) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1601]: 0.952 (+/-0.000) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1602]: 0.952 (+/-0.000) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1603]: 0.952 (+/-0.000) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1604]: 0.924 (+/-0.114) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1605]: 0.924 (+/-0.114) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1606]: 0.924 (+/-0.114) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1607]: 0.924 (+/-0.114) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1608]: 0.952 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1609]: 0.952 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1610]: 0.952 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1611]: 0.952 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1612]: 0.943 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1613]: 0.943 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1614]: 0.943 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1615]: 0.943 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1616]: 0.952 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1617]: 0.952 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1618]: 0.952 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1619]: 0.952 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1620]: 0.876 (+/-0.205) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1621]: 0.876 (+/-0.205) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1622]: 0.876 (+/-0.205) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1623]: 0.876 (+/-0.205) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1624]: 0.952 (+/-0.000) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1625]: 0.952 (+/-0.000) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1626]: 0.952 (+/-0.000) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1627]: 0.952 (+/-0.000) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1628]: 0.924 (+/-0.114) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1629]: 0.924 (+/-0.114) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1630]: 0.924 (+/-0.114) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1631]: 0.924 (+/-0.114) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1632]: 0.952 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1633]: 0.952 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1634]: 0.952 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1635]: 0.952 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1636]: 0.943 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1637]: 0.943 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1638]: 0.943 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1639]: 0.943 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1640]: 0.952 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1641]: 0.952 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1642]: 0.952 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1643]: 0.952 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1644]: 0.876 (+/-0.205) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1645]: 0.876 (+/-0.205) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1646]: 0.876 (+/-0.205) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1647]: 0.876 (+/-0.205) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1648]: 0.952 (+/-0.000) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1649]: 0.952 (+/-0.000) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1650]: 0.952 (+/-0.000) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1651]: 0.952 (+/-0.000) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1652]: 0.924 (+/-0.114) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1653]: 0.924 (+/-0.114) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1654]: 0.924 (+/-0.114) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1655]: 0.924 (+/-0.114) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1656]: 0.962 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1657]: 0.962 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1658]: 0.962 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1659]: 0.962 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1660]: 0.933 (+/-0.097) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1661]: 0.933 (+/-0.097) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1662]: 0.933 (+/-0.097) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1663]: 0.933 (+/-0.097) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1664]: 0.914 (+/-0.111) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1665]: 0.914 (+/-0.111) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1666]: 0.914 (+/-0.111) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1667]: 0.914 (+/-0.111) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1668]: 0.886 (+/-0.166) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1669]: 0.886 (+/-0.166) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1670]: 0.886 (+/-0.166) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1671]: 0.886 (+/-0.166) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1672]: 0.990 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1673]: 0.990 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1674]: 0.990 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1675]: 0.990 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1676]: 0.905 (+/-0.135) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1677]: 0.905 (+/-0.135) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1678]: 0.905 (+/-0.135) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1679]: 0.905 (+/-0.135) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1680]: 0.962 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1681]: 0.962 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1682]: 0.962 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1683]: 0.962 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1684]: 0.933 (+/-0.097) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1685]: 0.933 (+/-0.097) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1686]: 0.933 (+/-0.097) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1687]: 0.933 (+/-0.097) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1688]: 0.914 (+/-0.111) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1689]: 0.914 (+/-0.111) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1690]: 0.914 (+/-0.111) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1691]: 0.914 (+/-0.111) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1692]: 0.886 (+/-0.166) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1693]: 0.886 (+/-0.166) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1694]: 0.886 (+/-0.166) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1695]: 0.886 (+/-0.166) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1696]: 0.990 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1697]: 0.990 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1698]: 0.990 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1699]: 0.990 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1700]: 0.905 (+/-0.135) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1701]: 0.905 (+/-0.135) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1702]: 0.905 (+/-0.135) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1703]: 0.905 (+/-0.135) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1704]: 0.962 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1705]: 0.962 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1706]: 0.962 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1707]: 0.962 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1708]: 0.933 (+/-0.097) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1709]: 0.933 (+/-0.097) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1710]: 0.933 (+/-0.097) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1711]: 0.933 (+/-0.097) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1712]: 0.914 (+/-0.111) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1713]: 0.914 (+/-0.111) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1714]: 0.914 (+/-0.111) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1715]: 0.914 (+/-0.111) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1716]: 0.886 (+/-0.166) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1717]: 0.886 (+/-0.166) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1718]: 0.886 (+/-0.166) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1719]: 0.886 (+/-0.166) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1720]: 0.990 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1721]: 0.990 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1722]: 0.990 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1723]: 0.990 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1724]: 0.905 (+/-0.135) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1725]: 0.905 (+/-0.135) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1726]: 0.905 (+/-0.135) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1727]: 0.905 (+/-0.135) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1728]: 0.876 (+/-0.143) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1729]: 0.876 (+/-0.143) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1730]: 0.695 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1731]: 0.695 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1732]: 0.886 (+/-0.245) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1733]: 0.886 (+/-0.245) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1734]: 0.695 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1735]: 0.695 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1736]: 0.905 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1737]: 0.905 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1738]: 0.695 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1739]: 0.695 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1740]: 0.838 (+/-0.177) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1741]: 0.838 (+/-0.177) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1742]: 0.695 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1743]: 0.695 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1744]: 0.914 (+/-0.111) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1745]: 0.914 (+/-0.111) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1746]: 0.695 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1747]: 0.695 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1748]: 0.905 (+/-0.104) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1749]: 0.905 (+/-0.104) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1750]: 0.695 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1751]: 0.695 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1752]: 0.876 (+/-0.143) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1753]: 0.876 (+/-0.143) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1754]: 0.695 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1755]: 0.695 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1756]: 0.886 (+/-0.245) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1757]: 0.886 (+/-0.245) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1758]: 0.695 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1759]: 0.695 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1760]: 0.905 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1761]: 0.905 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1762]: 0.695 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1763]: 0.695 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1764]: 0.838 (+/-0.177) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1765]: 0.838 (+/-0.177) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1766]: 0.695 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1767]: 0.695 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1768]: 0.914 (+/-0.111) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1769]: 0.914 (+/-0.111) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1770]: 0.695 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1771]: 0.695 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1772]: 0.905 (+/-0.104) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1773]: 0.905 (+/-0.104) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1774]: 0.695 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1775]: 0.695 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1776]: 0.876 (+/-0.143) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1777]: 0.876 (+/-0.143) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1778]: 0.695 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1779]: 0.695 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1780]: 0.886 (+/-0.245) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1781]: 0.886 (+/-0.245) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1782]: 0.695 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1783]: 0.695 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1784]: 0.905 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1785]: 0.905 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1786]: 0.695 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1787]: 0.695 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1788]: 0.838 (+/-0.177) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1789]: 0.838 (+/-0.177) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1790]: 0.695 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1791]: 0.695 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1792]: 0.914 (+/-0.111) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1793]: 0.914 (+/-0.111) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1794]: 0.695 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1795]: 0.695 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1796]: 0.905 (+/-0.104) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1797]: 0.905 (+/-0.104) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1798]: 0.695 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1799]: 0.695 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1800]: 0.952 (+/-0.104) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1801]: 0.952 (+/-0.104) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1802]: 0.848 (+/-0.152) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1803]: 0.848 (+/-0.152) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1804]: 0.952 (+/-0.104) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1805]: 0.952 (+/-0.104) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1806]: 0.848 (+/-0.152) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1807]: 0.848 (+/-0.152) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1808]: 0.914 (+/-0.093) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1809]: 0.914 (+/-0.093) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1810]: 0.867 (+/-0.126) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1811]: 0.867 (+/-0.126) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1812]: 0.914 (+/-0.093) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1813]: 0.914 (+/-0.093) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1814]: 0.867 (+/-0.126) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1815]: 0.867 (+/-0.126) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1816]: 0.867 (+/-0.185) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1817]: 0.867 (+/-0.185) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1818]: 0.857 (+/-0.104) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1819]: 0.857 (+/-0.104) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1820]: 0.867 (+/-0.185) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1821]: 0.867 (+/-0.185) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1822]: 0.857 (+/-0.104) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1823]: 0.857 (+/-0.104) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1824]: 0.952 (+/-0.104) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1825]: 0.952 (+/-0.104) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1826]: 0.848 (+/-0.152) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1827]: 0.848 (+/-0.152) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1828]: 0.952 (+/-0.104) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1829]: 0.952 (+/-0.104) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1830]: 0.848 (+/-0.152) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1831]: 0.848 (+/-0.152) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1832]: 0.914 (+/-0.093) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1833]: 0.914 (+/-0.093) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1834]: 0.867 (+/-0.126) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1835]: 0.867 (+/-0.126) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1836]: 0.914 (+/-0.093) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1837]: 0.914 (+/-0.093) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1838]: 0.867 (+/-0.126) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1839]: 0.867 (+/-0.126) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1840]: 0.867 (+/-0.185) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1841]: 0.867 (+/-0.185) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1842]: 0.857 (+/-0.104) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1843]: 0.857 (+/-0.104) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1844]: 0.867 (+/-0.185) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1845]: 0.867 (+/-0.185) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1846]: 0.857 (+/-0.104) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1847]: 0.857 (+/-0.104) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1848]: 0.952 (+/-0.104) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1849]: 0.952 (+/-0.104) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1850]: 0.848 (+/-0.152) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1851]: 0.848 (+/-0.152) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1852]: 0.952 (+/-0.104) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1853]: 0.952 (+/-0.104) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1854]: 0.848 (+/-0.152) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1855]: 0.848 (+/-0.152) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1856]: 0.914 (+/-0.093) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1857]: 0.914 (+/-0.093) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1858]: 0.867 (+/-0.126) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1859]: 0.867 (+/-0.126) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1860]: 0.914 (+/-0.093) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1861]: 0.914 (+/-0.093) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1862]: 0.867 (+/-0.126) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1863]: 0.867 (+/-0.126) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1864]: 0.867 (+/-0.185) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1865]: 0.867 (+/-0.185) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1866]: 0.857 (+/-0.104) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1867]: 0.857 (+/-0.104) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1868]: 0.867 (+/-0.185) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1869]: 0.867 (+/-0.185) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1870]: 0.857 (+/-0.104) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1871]: 0.857 (+/-0.104) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1872]: 0.638 (+/-0.524) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1873]: 0.638 (+/-0.524) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1874]: 0.914 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1875]: 0.914 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1876]: 0.829 (+/-0.205) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1877]: 0.829 (+/-0.205) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1878]: 0.895 (+/-0.093) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1879]: 0.895 (+/-0.093) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1880]: 0.914 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1881]: 0.914 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1882]: 0.924 (+/-0.076) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1883]: 0.924 (+/-0.076) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1884]: 0.876 (+/-0.205) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1885]: 0.876 (+/-0.205) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1886]: 0.886 (+/-0.097) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1887]: 0.886 (+/-0.097) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1888]: 0.867 (+/-0.185) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1889]: 0.867 (+/-0.185) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1890]: 0.914 (+/-0.203) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1891]: 0.914 (+/-0.203) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1892]: 0.800 (+/-0.194) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1893]: 0.800 (+/-0.194) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1894]: 0.886 (+/-0.187) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1895]: 0.886 (+/-0.187) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1896]: 0.638 (+/-0.524) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1897]: 0.638 (+/-0.524) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1898]: 0.914 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1899]: 0.914 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1900]: 0.829 (+/-0.205) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1901]: 0.829 (+/-0.205) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1902]: 0.895 (+/-0.093) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1903]: 0.895 (+/-0.093) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1904]: 0.914 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1905]: 0.914 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1906]: 0.924 (+/-0.076) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1907]: 0.924 (+/-0.076) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1908]: 0.876 (+/-0.205) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1909]: 0.876 (+/-0.205) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1910]: 0.886 (+/-0.097) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1911]: 0.886 (+/-0.097) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1912]: 0.867 (+/-0.185) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1913]: 0.867 (+/-0.185) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1914]: 0.914 (+/-0.203) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1915]: 0.914 (+/-0.203) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1916]: 0.800 (+/-0.194) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1917]: 0.800 (+/-0.194) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1918]: 0.886 (+/-0.187) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1919]: 0.886 (+/-0.187) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1920]: 0.638 (+/-0.524) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1921]: 0.638 (+/-0.524) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1922]: 0.914 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1923]: 0.914 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1924]: 0.829 (+/-0.205) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1925]: 0.829 (+/-0.205) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1926]: 0.895 (+/-0.093) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1927]: 0.895 (+/-0.093) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1928]: 0.914 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1929]: 0.914 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1930]: 0.924 (+/-0.076) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1931]: 0.924 (+/-0.076) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1932]: 0.876 (+/-0.205) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1933]: 0.876 (+/-0.205) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1934]: 0.886 (+/-0.097) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1935]: 0.886 (+/-0.097) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1936]: 0.867 (+/-0.185) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1937]: 0.867 (+/-0.185) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1938]: 0.914 (+/-0.203) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1939]: 0.914 (+/-0.203) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1940]: 0.800 (+/-0.194) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1941]: 0.800 (+/-0.194) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1942]: 0.886 (+/-0.187) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1943]: 0.886 (+/-0.187) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1944]: 0.848 (+/-0.373) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1945]: 0.848 (+/-0.373) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1946]: 0.848 (+/-0.373) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1947]: 0.848 (+/-0.373) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1948]: 0.848 (+/-0.383) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1949]: 0.848 (+/-0.383) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1950]: 0.848 (+/-0.383) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1951]: 0.848 (+/-0.383) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1952]: 0.838 (+/-0.214) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1953]: 0.838 (+/-0.214) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1954]: 0.838 (+/-0.214) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1955]: 0.838 (+/-0.214) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1956]: 0.705 (+/-0.164) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1957]: 0.705 (+/-0.164) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1958]: 0.705 (+/-0.164) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1959]: 0.705 (+/-0.164) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1960]: 0.838 (+/-0.322) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1961]: 0.838 (+/-0.322) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1962]: 0.838 (+/-0.322) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1963]: 0.838 (+/-0.322) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1964]: 0.686 (+/-0.129) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1965]: 0.686 (+/-0.129) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1966]: 0.686 (+/-0.129) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1967]: 0.686 (+/-0.129) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1968]: 0.848 (+/-0.373) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1969]: 0.848 (+/-0.373) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1970]: 0.848 (+/-0.373) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1971]: 0.848 (+/-0.373) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1972]: 0.848 (+/-0.383) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1973]: 0.848 (+/-0.383) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1974]: 0.848 (+/-0.383) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1975]: 0.848 (+/-0.383) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1976]: 0.838 (+/-0.214) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1977]: 0.838 (+/-0.214) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1978]: 0.838 (+/-0.214) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1979]: 0.838 (+/-0.214) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1980]: 0.705 (+/-0.164) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1981]: 0.705 (+/-0.164) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1982]: 0.705 (+/-0.164) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1983]: 0.705 (+/-0.164) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1984]: 0.838 (+/-0.322) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1985]: 0.838 (+/-0.322) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1986]: 0.838 (+/-0.322) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1987]: 0.838 (+/-0.322) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1988]: 0.686 (+/-0.129) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1989]: 0.686 (+/-0.129) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1990]: 0.686 (+/-0.129) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1991]: 0.686 (+/-0.129) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1992]: 0.848 (+/-0.373) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1993]: 0.848 (+/-0.373) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1994]: 0.848 (+/-0.373) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1995]: 0.848 (+/-0.373) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[1996]: 0.848 (+/-0.383) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[1997]: 0.848 (+/-0.383) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[1998]: 0.848 (+/-0.383) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[1999]: 0.848 (+/-0.383) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2000]: 0.838 (+/-0.214) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2001]: 0.838 (+/-0.214) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2002]: 0.838 (+/-0.214) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2003]: 0.838 (+/-0.214) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2004]: 0.705 (+/-0.164) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2005]: 0.705 (+/-0.164) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2006]: 0.705 (+/-0.164) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2007]: 0.705 (+/-0.164) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2008]: 0.838 (+/-0.322) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2009]: 0.838 (+/-0.322) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2010]: 0.838 (+/-0.322) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2011]: 0.838 (+/-0.322) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2012]: 0.686 (+/-0.129) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2013]: 0.686 (+/-0.129) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2014]: 0.686 (+/-0.129) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2015]: 0.686 (+/-0.129) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2016]: 0.724 (+/-0.428) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2017]: 0.724 (+/-0.428) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2018]: 0.724 (+/-0.428) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2019]: 0.724 (+/-0.428) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2020]: 0.667 (+/-0.455) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2021]: 0.667 (+/-0.455) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2022]: 0.667 (+/-0.455) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2023]: 0.667 (+/-0.455) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2024]: 0.790 (+/-0.230) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2025]: 0.790 (+/-0.230) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2026]: 0.790 (+/-0.230) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2027]: 0.790 (+/-0.230) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2028]: 0.838 (+/-0.273) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2029]: 0.838 (+/-0.273) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2030]: 0.838 (+/-0.273) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2031]: 0.838 (+/-0.273) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2032]: 0.733 (+/-0.305) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2033]: 0.733 (+/-0.305) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2034]: 0.733 (+/-0.305) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2035]: 0.733 (+/-0.305) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2036]: 0.686 (+/-0.398) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2037]: 0.686 (+/-0.398) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2038]: 0.686 (+/-0.398) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2039]: 0.686 (+/-0.398) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2040]: 0.724 (+/-0.428) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2041]: 0.724 (+/-0.428) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2042]: 0.724 (+/-0.428) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2043]: 0.724 (+/-0.428) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2044]: 0.667 (+/-0.455) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2045]: 0.667 (+/-0.455) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2046]: 0.667 (+/-0.455) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2047]: 0.667 (+/-0.455) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2048]: 0.790 (+/-0.230) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2049]: 0.790 (+/-0.230) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2050]: 0.790 (+/-0.230) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2051]: 0.790 (+/-0.230) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2052]: 0.838 (+/-0.273) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2053]: 0.838 (+/-0.273) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2054]: 0.838 (+/-0.273) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2055]: 0.838 (+/-0.273) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2056]: 0.733 (+/-0.305) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2057]: 0.733 (+/-0.305) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2058]: 0.733 (+/-0.305) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2059]: 0.733 (+/-0.305) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2060]: 0.686 (+/-0.398) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2061]: 0.686 (+/-0.398) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2062]: 0.686 (+/-0.398) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2063]: 0.686 (+/-0.398) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2064]: 0.724 (+/-0.428) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2065]: 0.724 (+/-0.428) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2066]: 0.724 (+/-0.428) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2067]: 0.724 (+/-0.428) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2068]: 0.667 (+/-0.455) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2069]: 0.667 (+/-0.455) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2070]: 0.667 (+/-0.455) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2071]: 0.667 (+/-0.455) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2072]: 0.790 (+/-0.230) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2073]: 0.790 (+/-0.230) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2074]: 0.790 (+/-0.230) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2075]: 0.790 (+/-0.230) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2076]: 0.838 (+/-0.273) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2077]: 0.838 (+/-0.273) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2078]: 0.838 (+/-0.273) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2079]: 0.838 (+/-0.273) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2080]: 0.733 (+/-0.305) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2081]: 0.733 (+/-0.305) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2082]: 0.733 (+/-0.305) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2083]: 0.733 (+/-0.305) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2084]: 0.686 (+/-0.398) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2085]: 0.686 (+/-0.398) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2086]: 0.686 (+/-0.398) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2087]: 0.686 (+/-0.398) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2088]: 0.838 (+/-0.230) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2089]: 0.838 (+/-0.230) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2090]: 0.838 (+/-0.230) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2091]: 0.838 (+/-0.230) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2092]: 0.848 (+/-0.304) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2093]: 0.848 (+/-0.304) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2094]: 0.848 (+/-0.304) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2095]: 0.848 (+/-0.304) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2096]: 0.648 (+/-0.129) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2097]: 0.648 (+/-0.129) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2098]: 0.648 (+/-0.129) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2099]: 0.648 (+/-0.129) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2100]: 0.724 (+/-0.140) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2101]: 0.724 (+/-0.140) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2102]: 0.724 (+/-0.140) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2103]: 0.724 (+/-0.140) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2104]: 0.819 (+/-0.258) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2105]: 0.819 (+/-0.258) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2106]: 0.819 (+/-0.258) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2107]: 0.819 (+/-0.258) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2108]: 0.743 (+/-0.260) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2109]: 0.743 (+/-0.260) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2110]: 0.743 (+/-0.260) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2111]: 0.743 (+/-0.260) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2112]: 0.838 (+/-0.230) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2113]: 0.838 (+/-0.230) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2114]: 0.838 (+/-0.230) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2115]: 0.838 (+/-0.230) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2116]: 0.848 (+/-0.304) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2117]: 0.848 (+/-0.304) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2118]: 0.848 (+/-0.304) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2119]: 0.848 (+/-0.304) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2120]: 0.648 (+/-0.129) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2121]: 0.648 (+/-0.129) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2122]: 0.648 (+/-0.129) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2123]: 0.648 (+/-0.129) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2124]: 0.724 (+/-0.140) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2125]: 0.724 (+/-0.140) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2126]: 0.724 (+/-0.140) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2127]: 0.724 (+/-0.140) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2128]: 0.819 (+/-0.258) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2129]: 0.819 (+/-0.258) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2130]: 0.819 (+/-0.258) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2131]: 0.819 (+/-0.258) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2132]: 0.743 (+/-0.260) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2133]: 0.743 (+/-0.260) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2134]: 0.743 (+/-0.260) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2135]: 0.743 (+/-0.260) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2136]: 0.838 (+/-0.230) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2137]: 0.838 (+/-0.230) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2138]: 0.838 (+/-0.230) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2139]: 0.838 (+/-0.230) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2140]: 0.848 (+/-0.304) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2141]: 0.848 (+/-0.304) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2142]: 0.848 (+/-0.304) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2143]: 0.848 (+/-0.304) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2144]: 0.648 (+/-0.129) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2145]: 0.648 (+/-0.129) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2146]: 0.648 (+/-0.129) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2147]: 0.648 (+/-0.129) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2148]: 0.724 (+/-0.140) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2149]: 0.724 (+/-0.140) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2150]: 0.724 (+/-0.140) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2151]: 0.724 (+/-0.140) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2152]: 0.819 (+/-0.258) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2153]: 0.819 (+/-0.258) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2154]: 0.819 (+/-0.258) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2155]: 0.819 (+/-0.258) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2156]: 0.743 (+/-0.260) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2157]: 0.743 (+/-0.260) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2158]: 0.743 (+/-0.260) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2159]: 0.743 (+/-0.260) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2160]: 0.943 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2161]: 0.943 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2162]: 0.943 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2163]: 0.943 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2164]: 0.924 (+/-0.076) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2165]: 0.924 (+/-0.076) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2166]: 0.924 (+/-0.076) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2167]: 0.924 (+/-0.076) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2168]: 0.962 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2169]: 0.962 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2170]: 0.962 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2171]: 0.962 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2172]: 0.857 (+/-0.148) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2173]: 0.857 (+/-0.148) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2174]: 0.857 (+/-0.148) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2175]: 0.857 (+/-0.148) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2176]: 0.981 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2177]: 0.981 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2178]: 0.981 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2179]: 0.981 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2180]: 0.914 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2181]: 0.914 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2182]: 0.914 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2183]: 0.914 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2184]: 0.943 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2185]: 0.943 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2186]: 0.943 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2187]: 0.943 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2188]: 0.924 (+/-0.076) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2189]: 0.924 (+/-0.076) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2190]: 0.924 (+/-0.076) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2191]: 0.924 (+/-0.076) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2192]: 0.962 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2193]: 0.962 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2194]: 0.962 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2195]: 0.962 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2196]: 0.857 (+/-0.148) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2197]: 0.857 (+/-0.148) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2198]: 0.857 (+/-0.148) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2199]: 0.857 (+/-0.148) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2200]: 0.981 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2201]: 0.981 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2202]: 0.981 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2203]: 0.981 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2204]: 0.914 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2205]: 0.914 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2206]: 0.914 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2207]: 0.914 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2208]: 0.943 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2209]: 0.943 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2210]: 0.943 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2211]: 0.943 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2212]: 0.924 (+/-0.076) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2213]: 0.924 (+/-0.076) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2214]: 0.924 (+/-0.076) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2215]: 0.924 (+/-0.076) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2216]: 0.962 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2217]: 0.962 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2218]: 0.962 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2219]: 0.962 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2220]: 0.857 (+/-0.148) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2221]: 0.857 (+/-0.148) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2222]: 0.857 (+/-0.148) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2223]: 0.857 (+/-0.148) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2224]: 0.981 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2225]: 0.981 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2226]: 0.981 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2227]: 0.981 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2228]: 0.914 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2229]: 0.914 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2230]: 0.914 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2231]: 0.914 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2232]: 0.952 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2233]: 0.952 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2234]: 0.952 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2235]: 0.952 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2236]: 0.943 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2237]: 0.943 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2238]: 0.943 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2239]: 0.943 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2240]: 0.952 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2241]: 0.952 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2242]: 0.952 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2243]: 0.952 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2244]: 0.876 (+/-0.205) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2245]: 0.876 (+/-0.205) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2246]: 0.876 (+/-0.205) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2247]: 0.876 (+/-0.205) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2248]: 0.952 (+/-0.000) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2249]: 0.952 (+/-0.000) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2250]: 0.952 (+/-0.000) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2251]: 0.952 (+/-0.000) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2252]: 0.924 (+/-0.114) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2253]: 0.924 (+/-0.114) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2254]: 0.924 (+/-0.114) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2255]: 0.924 (+/-0.114) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2256]: 0.952 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2257]: 0.952 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2258]: 0.952 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2259]: 0.952 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2260]: 0.943 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2261]: 0.943 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2262]: 0.943 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2263]: 0.943 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2264]: 0.952 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2265]: 0.952 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2266]: 0.952 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2267]: 0.952 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2268]: 0.876 (+/-0.205) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2269]: 0.876 (+/-0.205) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2270]: 0.876 (+/-0.205) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2271]: 0.876 (+/-0.205) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2272]: 0.952 (+/-0.000) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2273]: 0.952 (+/-0.000) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2274]: 0.952 (+/-0.000) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2275]: 0.952 (+/-0.000) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2276]: 0.924 (+/-0.114) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2277]: 0.924 (+/-0.114) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2278]: 0.924 (+/-0.114) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2279]: 0.924 (+/-0.114) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2280]: 0.952 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2281]: 0.952 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2282]: 0.952 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2283]: 0.952 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2284]: 0.943 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2285]: 0.943 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2286]: 0.943 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2287]: 0.943 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2288]: 0.952 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2289]: 0.952 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2290]: 0.952 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2291]: 0.952 (+/-0.085) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2292]: 0.876 (+/-0.205) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2293]: 0.876 (+/-0.205) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2294]: 0.876 (+/-0.205) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2295]: 0.876 (+/-0.205) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2296]: 0.952 (+/-0.000) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2297]: 0.952 (+/-0.000) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2298]: 0.952 (+/-0.000) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2299]: 0.952 (+/-0.000) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2300]: 0.924 (+/-0.114) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2301]: 0.924 (+/-0.114) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2302]: 0.924 (+/-0.114) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2303]: 0.924 (+/-0.114) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2304]: 0.962 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2305]: 0.962 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2306]: 0.962 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2307]: 0.962 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2308]: 0.933 (+/-0.097) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2309]: 0.933 (+/-0.097) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2310]: 0.933 (+/-0.097) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2311]: 0.933 (+/-0.097) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2312]: 0.914 (+/-0.111) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2313]: 0.914 (+/-0.111) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2314]: 0.914 (+/-0.111) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2315]: 0.914 (+/-0.111) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2316]: 0.886 (+/-0.166) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2317]: 0.886 (+/-0.166) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2318]: 0.886 (+/-0.166) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2319]: 0.886 (+/-0.166) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2320]: 0.990 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2321]: 0.990 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2322]: 0.990 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2323]: 0.990 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2324]: 0.905 (+/-0.135) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2325]: 0.905 (+/-0.135) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2326]: 0.905 (+/-0.135) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2327]: 0.905 (+/-0.135) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2328]: 0.962 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2329]: 0.962 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2330]: 0.962 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2331]: 0.962 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2332]: 0.933 (+/-0.097) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2333]: 0.933 (+/-0.097) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2334]: 0.933 (+/-0.097) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2335]: 0.933 (+/-0.097) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2336]: 0.914 (+/-0.111) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2337]: 0.914 (+/-0.111) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2338]: 0.914 (+/-0.111) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2339]: 0.914 (+/-0.111) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2340]: 0.886 (+/-0.166) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2341]: 0.886 (+/-0.166) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2342]: 0.886 (+/-0.166) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2343]: 0.886 (+/-0.166) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2344]: 0.990 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2345]: 0.990 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2346]: 0.990 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2347]: 0.990 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2348]: 0.905 (+/-0.135) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2349]: 0.905 (+/-0.135) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2350]: 0.905 (+/-0.135) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2351]: 0.905 (+/-0.135) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2352]: 0.962 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2353]: 0.962 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2354]: 0.962 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2355]: 0.962 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2356]: 0.933 (+/-0.097) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2357]: 0.933 (+/-0.097) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2358]: 0.933 (+/-0.097) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2359]: 0.933 (+/-0.097) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2360]: 0.914 (+/-0.111) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2361]: 0.914 (+/-0.111) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2362]: 0.914 (+/-0.111) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2363]: 0.914 (+/-0.111) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2364]: 0.886 (+/-0.166) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2365]: 0.886 (+/-0.166) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2366]: 0.886 (+/-0.166) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2367]: 0.886 (+/-0.166) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2368]: 0.990 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2369]: 0.990 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2370]: 0.990 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2371]: 0.990 (+/-0.038) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2372]: 0.905 (+/-0.135) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2373]: 0.905 (+/-0.135) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2374]: 0.905 (+/-0.135) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2375]: 0.905 (+/-0.135) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2376]: 0.886 (+/-0.196) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2377]: 0.886 (+/-0.196) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2378]: 0.790 (+/-0.166) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2379]: 0.790 (+/-0.166) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2380]: 0.857 (+/-0.200) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2381]: 0.857 (+/-0.200) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2382]: 0.781 (+/-0.177) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2383]: 0.781 (+/-0.177) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2384]: 0.829 (+/-0.155) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2385]: 0.829 (+/-0.155) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2386]: 0.886 (+/-0.097) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2387]: 0.886 (+/-0.097) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2388]: 0.838 (+/-0.177) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2389]: 0.838 (+/-0.177) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2390]: 0.895 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2391]: 0.895 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2392]: 0.867 (+/-0.212) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2393]: 0.867 (+/-0.212) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2394]: 0.895 (+/-0.111) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2395]: 0.895 (+/-0.111) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2396]: 0.924 (+/-0.076) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2397]: 0.924 (+/-0.076) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2398]: 0.876 (+/-0.177) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2399]: 0.876 (+/-0.177) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2400]: 0.886 (+/-0.196) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2401]: 0.886 (+/-0.196) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2402]: 0.790 (+/-0.166) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2403]: 0.790 (+/-0.166) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2404]: 0.857 (+/-0.200) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2405]: 0.857 (+/-0.200) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2406]: 0.781 (+/-0.177) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2407]: 0.781 (+/-0.177) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2408]: 0.829 (+/-0.155) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2409]: 0.829 (+/-0.155) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2410]: 0.886 (+/-0.097) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2411]: 0.886 (+/-0.097) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2412]: 0.838 (+/-0.177) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2413]: 0.838 (+/-0.177) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2414]: 0.895 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2415]: 0.895 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2416]: 0.867 (+/-0.212) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2417]: 0.867 (+/-0.212) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2418]: 0.895 (+/-0.111) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2419]: 0.895 (+/-0.111) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2420]: 0.924 (+/-0.076) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2421]: 0.924 (+/-0.076) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2422]: 0.876 (+/-0.177) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2423]: 0.876 (+/-0.177) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2424]: 0.886 (+/-0.196) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2425]: 0.886 (+/-0.196) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2426]: 0.790 (+/-0.166) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2427]: 0.790 (+/-0.166) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2428]: 0.857 (+/-0.200) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2429]: 0.857 (+/-0.200) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2430]: 0.781 (+/-0.177) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2431]: 0.781 (+/-0.177) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2432]: 0.829 (+/-0.155) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2433]: 0.829 (+/-0.155) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2434]: 0.886 (+/-0.097) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2435]: 0.886 (+/-0.097) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2436]: 0.838 (+/-0.177) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2437]: 0.838 (+/-0.177) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2438]: 0.895 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2439]: 0.895 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2440]: 0.867 (+/-0.212) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2441]: 0.867 (+/-0.212) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2442]: 0.895 (+/-0.111) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2443]: 0.895 (+/-0.111) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2444]: 0.924 (+/-0.076) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2445]: 0.924 (+/-0.076) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2446]: 0.876 (+/-0.177) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2447]: 0.876 (+/-0.177) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2448]: 0.771 (+/-0.358) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2449]: 0.771 (+/-0.358) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2450]: 0.867 (+/-0.152) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2451]: 0.867 (+/-0.152) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2452]: 0.676 (+/-0.530) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2453]: 0.676 (+/-0.530) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2454]: 0.867 (+/-0.152) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2455]: 0.867 (+/-0.152) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2456]: 0.819 (+/-0.229) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2457]: 0.819 (+/-0.229) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2458]: 0.857 (+/-0.170) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2459]: 0.857 (+/-0.170) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2460]: 0.876 (+/-0.230) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2461]: 0.876 (+/-0.230) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2462]: 0.857 (+/-0.170) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2463]: 0.857 (+/-0.170) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2464]: 0.581 (+/-0.309) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2465]: 0.581 (+/-0.309) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2466]: 0.838 (+/-0.196) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2467]: 0.838 (+/-0.196) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2468]: 0.762 (+/-0.263) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2469]: 0.762 (+/-0.263) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2470]: 0.848 (+/-0.185) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2471]: 0.848 (+/-0.185) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2472]: 0.771 (+/-0.358) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2473]: 0.771 (+/-0.358) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2474]: 0.867 (+/-0.152) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2475]: 0.867 (+/-0.152) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2476]: 0.676 (+/-0.530) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2477]: 0.676 (+/-0.530) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2478]: 0.867 (+/-0.152) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2479]: 0.867 (+/-0.152) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2480]: 0.819 (+/-0.229) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2481]: 0.819 (+/-0.229) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2482]: 0.857 (+/-0.170) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2483]: 0.857 (+/-0.170) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2484]: 0.876 (+/-0.230) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2485]: 0.876 (+/-0.230) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2486]: 0.857 (+/-0.170) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2487]: 0.857 (+/-0.170) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2488]: 0.581 (+/-0.309) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2489]: 0.581 (+/-0.309) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2490]: 0.838 (+/-0.196) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2491]: 0.838 (+/-0.196) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2492]: 0.762 (+/-0.263) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2493]: 0.762 (+/-0.263) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2494]: 0.848 (+/-0.185) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2495]: 0.848 (+/-0.185) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2496]: 0.771 (+/-0.358) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2497]: 0.771 (+/-0.358) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2498]: 0.867 (+/-0.152) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2499]: 0.867 (+/-0.152) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2500]: 0.676 (+/-0.530) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2501]: 0.676 (+/-0.530) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2502]: 0.867 (+/-0.152) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2503]: 0.867 (+/-0.152) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2504]: 0.819 (+/-0.229) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2505]: 0.819 (+/-0.229) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2506]: 0.857 (+/-0.170) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2507]: 0.857 (+/-0.170) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2508]: 0.876 (+/-0.230) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2509]: 0.876 (+/-0.230) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2510]: 0.857 (+/-0.170) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2511]: 0.857 (+/-0.170) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2512]: 0.581 (+/-0.309) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2513]: 0.581 (+/-0.309) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2514]: 0.838 (+/-0.196) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2515]: 0.838 (+/-0.196) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2516]: 0.762 (+/-0.263) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2517]: 0.762 (+/-0.263) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2518]: 0.848 (+/-0.185) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2519]: 0.848 (+/-0.185) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2520]: 0.657 (+/-0.456) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2521]: 0.657 (+/-0.456) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2522]: 0.943 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2523]: 0.943 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2524]: 0.838 (+/-0.205) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2525]: 0.838 (+/-0.205) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2526]: 0.895 (+/-0.111) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2527]: 0.895 (+/-0.111) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2528]: 0.800 (+/-0.378) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2529]: 0.800 (+/-0.378) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2530]: 0.971 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2531]: 0.971 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2532]: 0.724 (+/-0.093) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2533]: 0.724 (+/-0.093) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2534]: 0.962 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2535]: 0.962 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2536]: 0.848 (+/-0.220) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2537]: 0.848 (+/-0.220) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2538]: 0.952 (+/-0.060) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2539]: 0.952 (+/-0.060) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2540]: 0.848 (+/-0.194) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2541]: 0.848 (+/-0.194) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2542]: 0.962 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2543]: 0.962 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2544]: 0.657 (+/-0.456) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2545]: 0.657 (+/-0.456) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2546]: 0.943 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2547]: 0.943 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2548]: 0.838 (+/-0.205) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2549]: 0.838 (+/-0.205) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2550]: 0.895 (+/-0.111) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2551]: 0.895 (+/-0.111) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2552]: 0.800 (+/-0.378) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2553]: 0.800 (+/-0.378) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2554]: 0.971 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2555]: 0.971 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2556]: 0.724 (+/-0.093) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2557]: 0.724 (+/-0.093) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2558]: 0.962 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2559]: 0.962 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2560]: 0.848 (+/-0.220) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2561]: 0.848 (+/-0.220) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2562]: 0.952 (+/-0.060) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2563]: 0.952 (+/-0.060) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2564]: 0.848 (+/-0.194) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2565]: 0.848 (+/-0.194) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2566]: 0.962 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2567]: 0.962 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2568]: 0.657 (+/-0.456) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2569]: 0.657 (+/-0.456) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2570]: 0.943 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2571]: 0.943 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2572]: 0.838 (+/-0.205) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2573]: 0.838 (+/-0.205) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2574]: 0.895 (+/-0.111) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2575]: 0.895 (+/-0.111) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2576]: 0.800 (+/-0.378) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2577]: 0.800 (+/-0.378) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2578]: 0.971 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2579]: 0.971 (+/-0.047) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2580]: 0.724 (+/-0.093) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2581]: 0.724 (+/-0.093) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2582]: 0.962 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2583]: 0.962 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2584]: 0.848 (+/-0.220) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2585]: 0.848 (+/-0.220) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2586]: 0.952 (+/-0.060) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2587]: 0.952 (+/-0.060) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2588]: 0.848 (+/-0.194) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2589]: 0.848 (+/-0.194) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2590]: 0.962 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2591]: 0.962 (+/-0.071) for {'alpha': 0.001, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2592]: 0.867 (+/-0.212) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2593]: 0.867 (+/-0.212) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2594]: 0.867 (+/-0.212) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2595]: 0.867 (+/-0.212) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2596]: 0.838 (+/-0.286) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2597]: 0.838 (+/-0.286) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2598]: 0.838 (+/-0.286) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2599]: 0.838 (+/-0.286) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2600]: 0.857 (+/-0.104) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2601]: 0.857 (+/-0.104) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2602]: 0.857 (+/-0.104) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2603]: 0.857 (+/-0.104) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2604]: 0.914 (+/-0.093) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2605]: 0.914 (+/-0.093) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2606]: 0.914 (+/-0.093) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2607]: 0.914 (+/-0.093) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2608]: 0.924 (+/-0.129) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2609]: 0.924 (+/-0.129) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2610]: 0.924 (+/-0.129) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2611]: 0.924 (+/-0.129) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2612]: 0.895 (+/-0.111) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2613]: 0.895 (+/-0.111) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2614]: 0.895 (+/-0.111) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2615]: 0.895 (+/-0.111) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2616]: 0.867 (+/-0.212) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2617]: 0.867 (+/-0.212) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2618]: 0.867 (+/-0.212) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2619]: 0.867 (+/-0.212) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2620]: 0.838 (+/-0.286) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2621]: 0.838 (+/-0.286) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2622]: 0.838 (+/-0.286) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2623]: 0.838 (+/-0.286) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2624]: 0.857 (+/-0.104) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2625]: 0.857 (+/-0.104) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2626]: 0.857 (+/-0.104) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2627]: 0.857 (+/-0.104) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2628]: 0.914 (+/-0.093) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2629]: 0.914 (+/-0.093) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2630]: 0.914 (+/-0.093) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2631]: 0.914 (+/-0.093) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2632]: 0.924 (+/-0.129) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2633]: 0.924 (+/-0.129) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2634]: 0.924 (+/-0.129) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2635]: 0.924 (+/-0.129) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2636]: 0.895 (+/-0.111) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2637]: 0.895 (+/-0.111) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2638]: 0.895 (+/-0.111) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2639]: 0.895 (+/-0.111) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2640]: 0.867 (+/-0.212) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2641]: 0.867 (+/-0.212) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2642]: 0.867 (+/-0.212) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2643]: 0.867 (+/-0.212) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2644]: 0.838 (+/-0.286) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2645]: 0.838 (+/-0.286) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2646]: 0.838 (+/-0.286) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2647]: 0.838 (+/-0.286) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2648]: 0.857 (+/-0.104) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2649]: 0.857 (+/-0.104) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2650]: 0.857 (+/-0.104) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2651]: 0.857 (+/-0.104) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2652]: 0.914 (+/-0.093) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2653]: 0.914 (+/-0.093) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2654]: 0.914 (+/-0.093) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2655]: 0.914 (+/-0.093) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2656]: 0.924 (+/-0.129) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2657]: 0.924 (+/-0.129) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2658]: 0.924 (+/-0.129) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2659]: 0.924 (+/-0.129) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2660]: 0.895 (+/-0.111) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2661]: 0.895 (+/-0.111) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2662]: 0.895 (+/-0.111) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2663]: 0.895 (+/-0.111) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2664]: 0.781 (+/-0.328) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2665]: 0.781 (+/-0.328) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2666]: 0.781 (+/-0.328) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2667]: 0.781 (+/-0.328) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2668]: 0.714 (+/-0.335) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2669]: 0.714 (+/-0.335) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2670]: 0.714 (+/-0.335) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2671]: 0.714 (+/-0.335) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2672]: 0.886 (+/-0.245) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2673]: 0.886 (+/-0.245) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2674]: 0.886 (+/-0.245) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2675]: 0.886 (+/-0.245) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2676]: 0.829 (+/-0.260) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2677]: 0.829 (+/-0.260) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2678]: 0.829 (+/-0.260) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2679]: 0.829 (+/-0.260) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2680]: 0.810 (+/-0.295) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2681]: 0.810 (+/-0.295) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2682]: 0.810 (+/-0.295) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2683]: 0.810 (+/-0.295) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2684]: 0.800 (+/-0.279) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2685]: 0.800 (+/-0.279) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2686]: 0.800 (+/-0.279) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2687]: 0.800 (+/-0.279) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2688]: 0.781 (+/-0.328) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2689]: 0.781 (+/-0.328) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2690]: 0.781 (+/-0.328) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2691]: 0.781 (+/-0.328) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2692]: 0.714 (+/-0.335) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2693]: 0.714 (+/-0.335) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2694]: 0.714 (+/-0.335) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2695]: 0.714 (+/-0.335) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2696]: 0.886 (+/-0.245) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2697]: 0.886 (+/-0.245) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2698]: 0.886 (+/-0.245) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2699]: 0.886 (+/-0.245) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2700]: 0.829 (+/-0.260) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2701]: 0.829 (+/-0.260) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2702]: 0.829 (+/-0.260) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2703]: 0.829 (+/-0.260) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2704]: 0.810 (+/-0.295) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2705]: 0.810 (+/-0.295) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2706]: 0.810 (+/-0.295) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2707]: 0.810 (+/-0.295) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2708]: 0.800 (+/-0.279) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2709]: 0.800 (+/-0.279) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2710]: 0.800 (+/-0.279) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2711]: 0.800 (+/-0.279) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2712]: 0.781 (+/-0.328) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2713]: 0.781 (+/-0.328) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2714]: 0.781 (+/-0.328) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2715]: 0.781 (+/-0.328) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2716]: 0.714 (+/-0.335) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2717]: 0.714 (+/-0.335) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2718]: 0.714 (+/-0.335) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2719]: 0.714 (+/-0.335) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2720]: 0.886 (+/-0.245) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2721]: 0.886 (+/-0.245) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2722]: 0.886 (+/-0.245) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2723]: 0.886 (+/-0.245) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2724]: 0.829 (+/-0.260) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2725]: 0.829 (+/-0.260) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2726]: 0.829 (+/-0.260) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2727]: 0.829 (+/-0.260) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2728]: 0.810 (+/-0.295) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2729]: 0.810 (+/-0.295) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2730]: 0.810 (+/-0.295) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2731]: 0.810 (+/-0.295) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2732]: 0.800 (+/-0.279) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2733]: 0.800 (+/-0.279) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2734]: 0.800 (+/-0.279) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2735]: 0.800 (+/-0.279) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2736]: 0.581 (+/-0.480) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2737]: 0.581 (+/-0.480) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2738]: 0.581 (+/-0.480) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2739]: 0.581 (+/-0.480) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2740]: 0.848 (+/-0.304) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2741]: 0.848 (+/-0.304) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2742]: 0.848 (+/-0.304) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2743]: 0.848 (+/-0.304) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2744]: 0.695 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2745]: 0.695 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2746]: 0.695 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2747]: 0.695 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2748]: 0.724 (+/-0.140) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2749]: 0.724 (+/-0.140) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2750]: 0.724 (+/-0.140) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2751]: 0.724 (+/-0.140) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2752]: 0.495 (+/-0.344) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2753]: 0.495 (+/-0.344) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2754]: 0.495 (+/-0.344) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2755]: 0.495 (+/-0.344) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2756]: 0.743 (+/-0.260) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2757]: 0.743 (+/-0.260) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2758]: 0.743 (+/-0.260) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2759]: 0.743 (+/-0.260) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2760]: 0.581 (+/-0.480) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2761]: 0.581 (+/-0.480) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2762]: 0.581 (+/-0.480) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2763]: 0.581 (+/-0.480) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2764]: 0.848 (+/-0.304) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2765]: 0.848 (+/-0.304) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2766]: 0.848 (+/-0.304) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2767]: 0.848 (+/-0.304) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2768]: 0.695 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2769]: 0.695 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2770]: 0.695 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2771]: 0.695 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2772]: 0.724 (+/-0.140) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2773]: 0.724 (+/-0.140) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2774]: 0.724 (+/-0.140) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2775]: 0.724 (+/-0.140) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2776]: 0.495 (+/-0.344) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2777]: 0.495 (+/-0.344) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2778]: 0.495 (+/-0.344) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2779]: 0.495 (+/-0.344) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2780]: 0.743 (+/-0.260) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2781]: 0.743 (+/-0.260) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2782]: 0.743 (+/-0.260) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2783]: 0.743 (+/-0.260) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2784]: 0.581 (+/-0.480) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2785]: 0.581 (+/-0.480) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2786]: 0.581 (+/-0.480) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2787]: 0.581 (+/-0.480) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2788]: 0.848 (+/-0.304) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2789]: 0.848 (+/-0.304) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2790]: 0.848 (+/-0.304) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2791]: 0.848 (+/-0.304) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2792]: 0.695 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2793]: 0.695 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2794]: 0.695 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2795]: 0.695 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2796]: 0.724 (+/-0.140) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2797]: 0.724 (+/-0.140) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2798]: 0.724 (+/-0.140) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2799]: 0.724 (+/-0.140) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2800]: 0.495 (+/-0.344) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2801]: 0.495 (+/-0.344) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2802]: 0.495 (+/-0.344) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2803]: 0.495 (+/-0.344) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2804]: 0.743 (+/-0.260) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2805]: 0.743 (+/-0.260) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2806]: 0.743 (+/-0.260) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2807]: 0.743 (+/-0.260) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2808]: 0.962 (+/-0.038) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2809]: 0.962 (+/-0.038) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2810]: 0.962 (+/-0.038) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2811]: 0.962 (+/-0.038) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2812]: 0.886 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2813]: 0.886 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2814]: 0.886 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2815]: 0.886 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2816]: 0.962 (+/-0.111) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2817]: 0.962 (+/-0.111) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2818]: 0.962 (+/-0.111) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2819]: 0.962 (+/-0.111) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2820]: 0.848 (+/-0.185) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2821]: 0.848 (+/-0.185) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2822]: 0.848 (+/-0.185) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2823]: 0.848 (+/-0.185) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2824]: 0.981 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2825]: 0.981 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2826]: 0.981 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2827]: 0.981 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2828]: 0.933 (+/-0.097) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2829]: 0.933 (+/-0.097) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2830]: 0.933 (+/-0.097) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2831]: 0.933 (+/-0.097) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2832]: 0.962 (+/-0.038) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2833]: 0.962 (+/-0.038) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2834]: 0.962 (+/-0.038) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2835]: 0.962 (+/-0.038) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2836]: 0.886 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2837]: 0.886 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2838]: 0.886 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2839]: 0.886 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2840]: 0.962 (+/-0.111) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2841]: 0.962 (+/-0.111) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2842]: 0.962 (+/-0.111) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2843]: 0.962 (+/-0.111) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2844]: 0.848 (+/-0.185) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2845]: 0.848 (+/-0.185) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2846]: 0.848 (+/-0.185) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2847]: 0.848 (+/-0.185) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2848]: 0.981 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2849]: 0.981 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2850]: 0.981 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2851]: 0.981 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2852]: 0.933 (+/-0.097) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2853]: 0.933 (+/-0.097) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2854]: 0.933 (+/-0.097) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2855]: 0.933 (+/-0.097) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2856]: 0.962 (+/-0.038) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2857]: 0.962 (+/-0.038) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2858]: 0.962 (+/-0.038) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2859]: 0.962 (+/-0.038) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2860]: 0.886 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2861]: 0.886 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2862]: 0.886 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2863]: 0.886 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2864]: 0.962 (+/-0.111) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2865]: 0.962 (+/-0.111) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2866]: 0.962 (+/-0.111) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2867]: 0.962 (+/-0.111) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2868]: 0.848 (+/-0.185) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2869]: 0.848 (+/-0.185) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2870]: 0.848 (+/-0.185) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2871]: 0.848 (+/-0.185) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2872]: 0.981 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2873]: 0.981 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2874]: 0.981 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2875]: 0.981 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2876]: 0.933 (+/-0.097) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2877]: 0.933 (+/-0.097) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2878]: 0.933 (+/-0.097) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2879]: 0.933 (+/-0.097) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2880]: 0.952 (+/-0.104) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2881]: 0.952 (+/-0.104) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2882]: 0.952 (+/-0.104) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2883]: 0.952 (+/-0.104) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2884]: 0.867 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2885]: 0.867 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2886]: 0.867 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2887]: 0.867 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2888]: 0.981 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2889]: 0.981 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2890]: 0.981 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2891]: 0.981 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2892]: 0.962 (+/-0.071) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2893]: 0.962 (+/-0.071) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2894]: 0.962 (+/-0.071) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2895]: 0.962 (+/-0.071) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2896]: 0.971 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2897]: 0.971 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2898]: 0.971 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2899]: 0.971 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2900]: 0.924 (+/-0.114) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2901]: 0.924 (+/-0.114) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2902]: 0.924 (+/-0.114) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2903]: 0.924 (+/-0.114) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2904]: 0.952 (+/-0.104) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2905]: 0.952 (+/-0.104) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2906]: 0.952 (+/-0.104) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2907]: 0.952 (+/-0.104) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2908]: 0.867 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2909]: 0.867 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2910]: 0.867 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2911]: 0.867 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2912]: 0.981 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2913]: 0.981 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2914]: 0.981 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2915]: 0.981 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2916]: 0.962 (+/-0.071) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2917]: 0.962 (+/-0.071) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2918]: 0.962 (+/-0.071) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2919]: 0.962 (+/-0.071) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2920]: 0.971 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2921]: 0.971 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2922]: 0.971 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2923]: 0.971 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2924]: 0.924 (+/-0.114) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2925]: 0.924 (+/-0.114) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2926]: 0.924 (+/-0.114) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2927]: 0.924 (+/-0.114) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2928]: 0.952 (+/-0.104) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2929]: 0.952 (+/-0.104) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2930]: 0.952 (+/-0.104) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2931]: 0.952 (+/-0.104) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2932]: 0.867 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2933]: 0.867 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2934]: 0.867 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2935]: 0.867 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2936]: 0.981 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2937]: 0.981 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2938]: 0.981 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2939]: 0.981 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2940]: 0.962 (+/-0.071) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2941]: 0.962 (+/-0.071) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2942]: 0.962 (+/-0.071) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2943]: 0.962 (+/-0.071) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2944]: 0.971 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2945]: 0.971 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2946]: 0.971 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2947]: 0.971 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2948]: 0.924 (+/-0.114) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2949]: 0.924 (+/-0.114) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2950]: 0.924 (+/-0.114) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2951]: 0.924 (+/-0.114) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2952]: 0.962 (+/-0.038) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2953]: 0.962 (+/-0.038) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2954]: 0.962 (+/-0.038) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2955]: 0.962 (+/-0.038) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2956]: 0.876 (+/-0.230) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2957]: 0.876 (+/-0.230) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2958]: 0.876 (+/-0.230) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2959]: 0.876 (+/-0.230) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2960]: 0.971 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2961]: 0.971 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2962]: 0.971 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2963]: 0.971 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2964]: 0.895 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2965]: 0.895 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2966]: 0.895 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2967]: 0.895 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2968]: 0.971 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2969]: 0.971 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2970]: 0.971 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2971]: 0.971 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2972]: 0.943 (+/-0.140) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2973]: 0.943 (+/-0.140) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2974]: 0.943 (+/-0.140) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2975]: 0.943 (+/-0.140) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2976]: 0.962 (+/-0.038) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2977]: 0.962 (+/-0.038) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2978]: 0.962 (+/-0.038) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2979]: 0.962 (+/-0.038) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2980]: 0.876 (+/-0.230) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2981]: 0.876 (+/-0.230) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2982]: 0.876 (+/-0.230) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2983]: 0.876 (+/-0.230) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2984]: 0.971 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2985]: 0.971 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2986]: 0.971 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2987]: 0.971 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2988]: 0.895 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2989]: 0.895 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2990]: 0.895 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2991]: 0.895 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2992]: 0.971 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2993]: 0.971 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2994]: 0.971 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2995]: 0.971 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[2996]: 0.943 (+/-0.140) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[2997]: 0.943 (+/-0.140) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[2998]: 0.943 (+/-0.140) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[2999]: 0.943 (+/-0.140) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3000]: 0.962 (+/-0.038) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3001]: 0.962 (+/-0.038) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3002]: 0.962 (+/-0.038) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3003]: 0.962 (+/-0.038) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3004]: 0.876 (+/-0.230) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3005]: 0.876 (+/-0.230) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3006]: 0.876 (+/-0.230) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3007]: 0.876 (+/-0.230) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3008]: 0.971 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3009]: 0.971 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3010]: 0.971 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3011]: 0.971 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3012]: 0.895 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3013]: 0.895 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3014]: 0.895 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3015]: 0.895 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3016]: 0.971 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3017]: 0.971 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3018]: 0.971 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3019]: 0.971 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3020]: 0.943 (+/-0.140) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3021]: 0.943 (+/-0.140) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3022]: 0.943 (+/-0.140) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3023]: 0.943 (+/-0.140) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3024]: 0.867 (+/-0.126) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3025]: 0.867 (+/-0.126) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3026]: 0.695 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3027]: 0.695 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3028]: 0.848 (+/-0.194) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3029]: 0.848 (+/-0.194) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3030]: 0.695 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3031]: 0.695 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3032]: 0.905 (+/-0.120) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3033]: 0.905 (+/-0.120) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3034]: 0.695 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3035]: 0.695 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3036]: 0.876 (+/-0.097) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3037]: 0.876 (+/-0.097) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3038]: 0.695 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3039]: 0.695 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3040]: 0.905 (+/-0.135) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3041]: 0.905 (+/-0.135) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3042]: 0.695 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3043]: 0.695 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3044]: 0.829 (+/-0.166) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3045]: 0.829 (+/-0.166) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3046]: 0.695 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3047]: 0.695 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3048]: 0.867 (+/-0.126) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3049]: 0.867 (+/-0.126) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3050]: 0.695 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3051]: 0.695 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3052]: 0.848 (+/-0.194) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3053]: 0.848 (+/-0.194) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3054]: 0.695 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3055]: 0.695 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3056]: 0.905 (+/-0.120) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3057]: 0.905 (+/-0.120) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3058]: 0.695 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3059]: 0.695 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3060]: 0.876 (+/-0.097) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3061]: 0.876 (+/-0.097) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3062]: 0.695 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3063]: 0.695 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3064]: 0.905 (+/-0.135) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3065]: 0.905 (+/-0.135) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3066]: 0.695 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3067]: 0.695 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3068]: 0.829 (+/-0.166) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3069]: 0.829 (+/-0.166) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3070]: 0.695 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3071]: 0.695 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3072]: 0.867 (+/-0.126) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3073]: 0.867 (+/-0.126) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3074]: 0.695 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3075]: 0.695 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3076]: 0.848 (+/-0.194) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3077]: 0.848 (+/-0.194) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3078]: 0.695 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3079]: 0.695 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3080]: 0.905 (+/-0.120) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3081]: 0.905 (+/-0.120) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3082]: 0.695 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3083]: 0.695 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3084]: 0.876 (+/-0.097) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3085]: 0.876 (+/-0.097) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3086]: 0.695 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3087]: 0.695 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3088]: 0.905 (+/-0.135) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3089]: 0.905 (+/-0.135) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3090]: 0.695 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3091]: 0.695 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3092]: 0.829 (+/-0.166) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3093]: 0.829 (+/-0.166) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3094]: 0.695 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3095]: 0.695 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3096]: 0.943 (+/-0.093) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3097]: 0.943 (+/-0.093) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3098]: 0.819 (+/-0.140) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3099]: 0.819 (+/-0.140) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3100]: 0.943 (+/-0.093) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3101]: 0.943 (+/-0.093) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3102]: 0.838 (+/-0.129) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3103]: 0.838 (+/-0.129) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3104]: 0.924 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3105]: 0.924 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3106]: 0.867 (+/-0.126) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3107]: 0.867 (+/-0.126) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3108]: 0.924 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3109]: 0.924 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3110]: 0.867 (+/-0.126) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3111]: 0.867 (+/-0.126) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3112]: 0.867 (+/-0.185) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3113]: 0.867 (+/-0.185) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3114]: 0.848 (+/-0.093) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3115]: 0.848 (+/-0.093) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3116]: 0.857 (+/-0.170) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3117]: 0.857 (+/-0.170) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3118]: 0.857 (+/-0.104) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3119]: 0.857 (+/-0.104) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3120]: 0.943 (+/-0.093) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3121]: 0.943 (+/-0.093) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3122]: 0.819 (+/-0.140) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3123]: 0.819 (+/-0.140) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3124]: 0.943 (+/-0.093) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3125]: 0.943 (+/-0.093) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3126]: 0.838 (+/-0.129) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3127]: 0.838 (+/-0.129) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3128]: 0.924 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3129]: 0.924 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3130]: 0.867 (+/-0.126) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3131]: 0.867 (+/-0.126) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3132]: 0.924 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3133]: 0.924 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3134]: 0.867 (+/-0.126) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3135]: 0.867 (+/-0.126) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3136]: 0.867 (+/-0.185) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3137]: 0.867 (+/-0.185) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3138]: 0.848 (+/-0.093) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3139]: 0.848 (+/-0.093) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3140]: 0.857 (+/-0.170) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3141]: 0.857 (+/-0.170) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3142]: 0.857 (+/-0.104) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3143]: 0.857 (+/-0.104) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3144]: 0.943 (+/-0.093) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3145]: 0.943 (+/-0.093) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3146]: 0.819 (+/-0.140) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3147]: 0.819 (+/-0.140) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3148]: 0.943 (+/-0.093) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3149]: 0.943 (+/-0.093) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3150]: 0.838 (+/-0.129) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3151]: 0.838 (+/-0.129) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3152]: 0.924 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3153]: 0.924 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3154]: 0.867 (+/-0.126) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3155]: 0.867 (+/-0.126) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3156]: 0.924 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3157]: 0.924 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3158]: 0.867 (+/-0.126) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3159]: 0.867 (+/-0.126) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3160]: 0.867 (+/-0.185) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3161]: 0.867 (+/-0.185) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3162]: 0.848 (+/-0.093) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3163]: 0.848 (+/-0.093) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3164]: 0.857 (+/-0.170) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3165]: 0.857 (+/-0.170) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3166]: 0.857 (+/-0.104) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3167]: 0.857 (+/-0.104) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3168]: 0.657 (+/-0.523) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3169]: 0.657 (+/-0.523) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3170]: 0.895 (+/-0.229) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3171]: 0.895 (+/-0.229) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3172]: 0.867 (+/-0.164) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3173]: 0.867 (+/-0.164) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3174]: 0.905 (+/-0.104) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3175]: 0.905 (+/-0.104) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3176]: 0.724 (+/-0.126) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3177]: 0.724 (+/-0.126) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3178]: 0.943 (+/-0.071) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3179]: 0.943 (+/-0.071) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3180]: 0.733 (+/-0.129) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3181]: 0.733 (+/-0.129) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3182]: 0.924 (+/-0.114) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3183]: 0.924 (+/-0.114) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3184]: 0.733 (+/-0.245) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3185]: 0.733 (+/-0.245) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3186]: 0.810 (+/-0.209) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3187]: 0.810 (+/-0.209) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3188]: 0.781 (+/-0.280) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3189]: 0.781 (+/-0.280) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3190]: 0.905 (+/-0.120) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3191]: 0.905 (+/-0.120) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3192]: 0.657 (+/-0.523) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3193]: 0.657 (+/-0.523) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3194]: 0.895 (+/-0.229) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3195]: 0.895 (+/-0.229) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3196]: 0.867 (+/-0.164) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3197]: 0.867 (+/-0.164) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3198]: 0.905 (+/-0.104) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3199]: 0.905 (+/-0.104) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3200]: 0.724 (+/-0.126) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3201]: 0.724 (+/-0.126) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3202]: 0.943 (+/-0.071) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3203]: 0.943 (+/-0.071) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3204]: 0.733 (+/-0.129) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3205]: 0.733 (+/-0.129) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3206]: 0.924 (+/-0.114) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3207]: 0.924 (+/-0.114) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3208]: 0.733 (+/-0.245) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3209]: 0.733 (+/-0.245) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3210]: 0.810 (+/-0.209) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3211]: 0.810 (+/-0.209) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3212]: 0.781 (+/-0.280) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3213]: 0.781 (+/-0.280) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3214]: 0.905 (+/-0.120) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3215]: 0.905 (+/-0.120) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3216]: 0.657 (+/-0.523) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3217]: 0.657 (+/-0.523) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3218]: 0.895 (+/-0.229) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3219]: 0.895 (+/-0.229) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3220]: 0.867 (+/-0.164) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3221]: 0.867 (+/-0.164) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3222]: 0.905 (+/-0.104) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3223]: 0.905 (+/-0.104) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3224]: 0.724 (+/-0.126) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3225]: 0.724 (+/-0.126) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3226]: 0.943 (+/-0.071) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3227]: 0.943 (+/-0.071) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3228]: 0.733 (+/-0.129) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3229]: 0.733 (+/-0.129) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3230]: 0.924 (+/-0.114) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3231]: 0.924 (+/-0.114) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3232]: 0.733 (+/-0.245) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3233]: 0.733 (+/-0.245) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3234]: 0.810 (+/-0.209) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3235]: 0.810 (+/-0.209) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3236]: 0.781 (+/-0.280) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3237]: 0.781 (+/-0.280) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3238]: 0.905 (+/-0.120) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3239]: 0.905 (+/-0.120) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.01, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3240]: 0.838 (+/-0.273) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3241]: 0.838 (+/-0.273) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3242]: 0.838 (+/-0.273) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3243]: 0.838 (+/-0.273) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3244]: 0.743 (+/-0.267) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3245]: 0.743 (+/-0.267) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3246]: 0.743 (+/-0.267) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3247]: 0.743 (+/-0.267) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3248]: 0.695 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3249]: 0.695 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3250]: 0.695 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3251]: 0.695 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3252]: 0.714 (+/-0.060) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3253]: 0.714 (+/-0.060) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3254]: 0.714 (+/-0.060) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3255]: 0.714 (+/-0.060) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3256]: 0.733 (+/-0.311) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3257]: 0.733 (+/-0.311) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3258]: 0.733 (+/-0.311) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3259]: 0.733 (+/-0.311) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3260]: 0.724 (+/-0.236) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3261]: 0.724 (+/-0.236) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3262]: 0.724 (+/-0.236) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3263]: 0.724 (+/-0.236) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3264]: 0.838 (+/-0.273) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3265]: 0.838 (+/-0.273) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3266]: 0.838 (+/-0.273) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3267]: 0.838 (+/-0.273) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3268]: 0.743 (+/-0.267) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3269]: 0.743 (+/-0.267) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3270]: 0.743 (+/-0.267) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3271]: 0.743 (+/-0.267) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3272]: 0.695 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3273]: 0.695 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3274]: 0.695 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3275]: 0.695 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3276]: 0.714 (+/-0.060) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3277]: 0.714 (+/-0.060) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3278]: 0.714 (+/-0.060) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3279]: 0.714 (+/-0.060) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3280]: 0.733 (+/-0.311) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3281]: 0.733 (+/-0.311) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3282]: 0.733 (+/-0.311) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3283]: 0.733 (+/-0.311) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3284]: 0.724 (+/-0.236) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3285]: 0.724 (+/-0.236) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3286]: 0.724 (+/-0.236) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3287]: 0.724 (+/-0.236) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3288]: 0.838 (+/-0.273) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3289]: 0.838 (+/-0.273) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3290]: 0.838 (+/-0.273) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3291]: 0.838 (+/-0.273) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3292]: 0.743 (+/-0.267) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3293]: 0.743 (+/-0.267) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3294]: 0.743 (+/-0.267) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3295]: 0.743 (+/-0.267) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3296]: 0.695 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3297]: 0.695 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3298]: 0.695 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3299]: 0.695 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3300]: 0.714 (+/-0.060) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3301]: 0.714 (+/-0.060) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3302]: 0.714 (+/-0.060) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3303]: 0.714 (+/-0.060) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3304]: 0.733 (+/-0.311) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3305]: 0.733 (+/-0.311) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3306]: 0.733 (+/-0.311) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3307]: 0.733 (+/-0.311) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3308]: 0.724 (+/-0.236) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3309]: 0.724 (+/-0.236) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3310]: 0.724 (+/-0.236) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3311]: 0.724 (+/-0.236) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3312]: 0.638 (+/-0.433) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3313]: 0.638 (+/-0.433) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3314]: 0.638 (+/-0.433) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3315]: 0.638 (+/-0.433) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3316]: 0.571 (+/-0.493) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3317]: 0.571 (+/-0.493) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3318]: 0.571 (+/-0.493) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3319]: 0.571 (+/-0.493) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3320]: 0.848 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3321]: 0.848 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3322]: 0.848 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3323]: 0.848 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3324]: 0.629 (+/-0.304) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3325]: 0.629 (+/-0.304) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3326]: 0.629 (+/-0.304) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3327]: 0.629 (+/-0.304) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3328]: 0.667 (+/-0.225) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3329]: 0.667 (+/-0.225) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3330]: 0.667 (+/-0.225) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3331]: 0.667 (+/-0.225) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3332]: 0.657 (+/-0.140) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3333]: 0.657 (+/-0.140) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3334]: 0.657 (+/-0.140) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3335]: 0.657 (+/-0.140) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3336]: 0.638 (+/-0.433) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3337]: 0.638 (+/-0.433) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3338]: 0.638 (+/-0.433) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3339]: 0.638 (+/-0.433) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3340]: 0.571 (+/-0.493) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3341]: 0.571 (+/-0.493) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3342]: 0.571 (+/-0.493) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3343]: 0.571 (+/-0.493) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3344]: 0.848 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3345]: 0.848 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3346]: 0.848 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3347]: 0.848 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3348]: 0.629 (+/-0.304) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3349]: 0.629 (+/-0.304) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3350]: 0.629 (+/-0.304) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3351]: 0.629 (+/-0.304) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3352]: 0.667 (+/-0.225) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3353]: 0.667 (+/-0.225) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3354]: 0.667 (+/-0.225) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3355]: 0.667 (+/-0.225) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3356]: 0.657 (+/-0.140) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3357]: 0.657 (+/-0.140) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3358]: 0.657 (+/-0.140) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3359]: 0.657 (+/-0.140) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3360]: 0.638 (+/-0.433) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3361]: 0.638 (+/-0.433) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3362]: 0.638 (+/-0.433) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3363]: 0.638 (+/-0.433) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3364]: 0.571 (+/-0.493) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3365]: 0.571 (+/-0.493) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3366]: 0.571 (+/-0.493) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3367]: 0.571 (+/-0.493) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3368]: 0.848 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3369]: 0.848 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3370]: 0.848 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3371]: 0.848 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3372]: 0.629 (+/-0.304) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3373]: 0.629 (+/-0.304) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3374]: 0.629 (+/-0.304) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3375]: 0.629 (+/-0.304) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3376]: 0.667 (+/-0.225) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3377]: 0.667 (+/-0.225) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3378]: 0.667 (+/-0.225) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3379]: 0.667 (+/-0.225) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3380]: 0.657 (+/-0.140) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3381]: 0.657 (+/-0.140) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3382]: 0.657 (+/-0.140) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3383]: 0.657 (+/-0.140) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3384]: 0.581 (+/-0.480) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3385]: 0.581 (+/-0.480) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3386]: 0.581 (+/-0.480) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3387]: 0.581 (+/-0.480) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3388]: 0.733 (+/-0.492) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3389]: 0.733 (+/-0.492) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3390]: 0.733 (+/-0.492) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3391]: 0.733 (+/-0.492) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3392]: 0.752 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3393]: 0.752 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3394]: 0.752 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3395]: 0.752 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3396]: 0.638 (+/-0.267) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3397]: 0.638 (+/-0.267) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3398]: 0.638 (+/-0.267) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3399]: 0.638 (+/-0.267) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3400]: 0.514 (+/-0.406) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3401]: 0.514 (+/-0.406) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3402]: 0.514 (+/-0.406) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3403]: 0.514 (+/-0.406) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3404]: 0.600 (+/-0.492) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3405]: 0.600 (+/-0.492) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3406]: 0.600 (+/-0.492) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3407]: 0.600 (+/-0.492) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3408]: 0.581 (+/-0.480) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3409]: 0.581 (+/-0.480) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3410]: 0.581 (+/-0.480) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3411]: 0.581 (+/-0.480) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3412]: 0.733 (+/-0.492) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3413]: 0.733 (+/-0.492) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3414]: 0.733 (+/-0.492) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3415]: 0.733 (+/-0.492) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3416]: 0.752 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3417]: 0.752 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3418]: 0.752 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3419]: 0.752 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3420]: 0.638 (+/-0.267) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3421]: 0.638 (+/-0.267) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3422]: 0.638 (+/-0.267) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3423]: 0.638 (+/-0.267) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3424]: 0.514 (+/-0.406) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3425]: 0.514 (+/-0.406) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3426]: 0.514 (+/-0.406) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3427]: 0.514 (+/-0.406) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3428]: 0.600 (+/-0.492) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3429]: 0.600 (+/-0.492) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3430]: 0.600 (+/-0.492) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3431]: 0.600 (+/-0.492) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3432]: 0.581 (+/-0.480) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3433]: 0.581 (+/-0.480) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3434]: 0.581 (+/-0.480) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3435]: 0.581 (+/-0.480) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3436]: 0.733 (+/-0.492) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3437]: 0.733 (+/-0.492) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3438]: 0.733 (+/-0.492) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3439]: 0.733 (+/-0.492) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3440]: 0.752 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3441]: 0.752 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3442]: 0.752 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3443]: 0.752 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3444]: 0.638 (+/-0.267) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3445]: 0.638 (+/-0.267) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3446]: 0.638 (+/-0.267) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3447]: 0.638 (+/-0.267) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3448]: 0.514 (+/-0.406) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3449]: 0.514 (+/-0.406) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3450]: 0.514 (+/-0.406) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3451]: 0.514 (+/-0.406) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3452]: 0.600 (+/-0.492) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3453]: 0.600 (+/-0.492) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3454]: 0.600 (+/-0.492) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3455]: 0.600 (+/-0.492) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'constant', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3456]: 0.962 (+/-0.038) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3457]: 0.962 (+/-0.038) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3458]: 0.962 (+/-0.038) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3459]: 0.962 (+/-0.038) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3460]: 0.886 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3461]: 0.886 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3462]: 0.886 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3463]: 0.886 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3464]: 0.962 (+/-0.111) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3465]: 0.962 (+/-0.111) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3466]: 0.962 (+/-0.111) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3467]: 0.962 (+/-0.111) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3468]: 0.848 (+/-0.185) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3469]: 0.848 (+/-0.185) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3470]: 0.848 (+/-0.185) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3471]: 0.848 (+/-0.185) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3472]: 0.981 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3473]: 0.981 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3474]: 0.981 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3475]: 0.981 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3476]: 0.933 (+/-0.097) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3477]: 0.933 (+/-0.097) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3478]: 0.933 (+/-0.097) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3479]: 0.933 (+/-0.097) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3480]: 0.962 (+/-0.038) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3481]: 0.962 (+/-0.038) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3482]: 0.962 (+/-0.038) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3483]: 0.962 (+/-0.038) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3484]: 0.886 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3485]: 0.886 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3486]: 0.886 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3487]: 0.886 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3488]: 0.962 (+/-0.111) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3489]: 0.962 (+/-0.111) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3490]: 0.962 (+/-0.111) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3491]: 0.962 (+/-0.111) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3492]: 0.848 (+/-0.185) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3493]: 0.848 (+/-0.185) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3494]: 0.848 (+/-0.185) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3495]: 0.848 (+/-0.185) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3496]: 0.981 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3497]: 0.981 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3498]: 0.981 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3499]: 0.981 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3500]: 0.933 (+/-0.097) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3501]: 0.933 (+/-0.097) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3502]: 0.933 (+/-0.097) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3503]: 0.933 (+/-0.097) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3504]: 0.962 (+/-0.038) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3505]: 0.962 (+/-0.038) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3506]: 0.962 (+/-0.038) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3507]: 0.962 (+/-0.038) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3508]: 0.886 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3509]: 0.886 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3510]: 0.886 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3511]: 0.886 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3512]: 0.962 (+/-0.111) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3513]: 0.962 (+/-0.111) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3514]: 0.962 (+/-0.111) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3515]: 0.962 (+/-0.111) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3516]: 0.848 (+/-0.185) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3517]: 0.848 (+/-0.185) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3518]: 0.848 (+/-0.185) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3519]: 0.848 (+/-0.185) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3520]: 0.981 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3521]: 0.981 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3522]: 0.981 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3523]: 0.981 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3524]: 0.933 (+/-0.097) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3525]: 0.933 (+/-0.097) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3526]: 0.933 (+/-0.097) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3527]: 0.933 (+/-0.097) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3528]: 0.952 (+/-0.104) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3529]: 0.952 (+/-0.104) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3530]: 0.952 (+/-0.104) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3531]: 0.952 (+/-0.104) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3532]: 0.867 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3533]: 0.867 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3534]: 0.867 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3535]: 0.867 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3536]: 0.981 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3537]: 0.981 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3538]: 0.981 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3539]: 0.981 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3540]: 0.962 (+/-0.071) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3541]: 0.962 (+/-0.071) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3542]: 0.962 (+/-0.071) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3543]: 0.962 (+/-0.071) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3544]: 0.971 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3545]: 0.971 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3546]: 0.971 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3547]: 0.971 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3548]: 0.924 (+/-0.114) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3549]: 0.924 (+/-0.114) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3550]: 0.924 (+/-0.114) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3551]: 0.924 (+/-0.114) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3552]: 0.952 (+/-0.104) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3553]: 0.952 (+/-0.104) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3554]: 0.952 (+/-0.104) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3555]: 0.952 (+/-0.104) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3556]: 0.867 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3557]: 0.867 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3558]: 0.867 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3559]: 0.867 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3560]: 0.981 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3561]: 0.981 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3562]: 0.981 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3563]: 0.981 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3564]: 0.962 (+/-0.071) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3565]: 0.962 (+/-0.071) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3566]: 0.962 (+/-0.071) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3567]: 0.962 (+/-0.071) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3568]: 0.971 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3569]: 0.971 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3570]: 0.971 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3571]: 0.971 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3572]: 0.924 (+/-0.114) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3573]: 0.924 (+/-0.114) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3574]: 0.924 (+/-0.114) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3575]: 0.924 (+/-0.114) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3576]: 0.952 (+/-0.104) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3577]: 0.952 (+/-0.104) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3578]: 0.952 (+/-0.104) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3579]: 0.952 (+/-0.104) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3580]: 0.867 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3581]: 0.867 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3582]: 0.867 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3583]: 0.867 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3584]: 0.981 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3585]: 0.981 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3586]: 0.981 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3587]: 0.981 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3588]: 0.962 (+/-0.071) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3589]: 0.962 (+/-0.071) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3590]: 0.962 (+/-0.071) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3591]: 0.962 (+/-0.071) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3592]: 0.971 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3593]: 0.971 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3594]: 0.971 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3595]: 0.971 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3596]: 0.924 (+/-0.114) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3597]: 0.924 (+/-0.114) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3598]: 0.924 (+/-0.114) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3599]: 0.924 (+/-0.114) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3600]: 0.962 (+/-0.038) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3601]: 0.962 (+/-0.038) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3602]: 0.962 (+/-0.038) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3603]: 0.962 (+/-0.038) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3604]: 0.876 (+/-0.230) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3605]: 0.876 (+/-0.230) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3606]: 0.876 (+/-0.230) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3607]: 0.876 (+/-0.230) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3608]: 0.971 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3609]: 0.971 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3610]: 0.971 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3611]: 0.971 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3612]: 0.895 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3613]: 0.895 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3614]: 0.895 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3615]: 0.895 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3616]: 0.971 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3617]: 0.971 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3618]: 0.971 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3619]: 0.971 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3620]: 0.943 (+/-0.140) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3621]: 0.943 (+/-0.140) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3622]: 0.943 (+/-0.140) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3623]: 0.943 (+/-0.140) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3624]: 0.962 (+/-0.038) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3625]: 0.962 (+/-0.038) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3626]: 0.962 (+/-0.038) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3627]: 0.962 (+/-0.038) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3628]: 0.876 (+/-0.230) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3629]: 0.876 (+/-0.230) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3630]: 0.876 (+/-0.230) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3631]: 0.876 (+/-0.230) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3632]: 0.971 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3633]: 0.971 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3634]: 0.971 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3635]: 0.971 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3636]: 0.895 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3637]: 0.895 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3638]: 0.895 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3639]: 0.895 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3640]: 0.971 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3641]: 0.971 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3642]: 0.971 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3643]: 0.971 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3644]: 0.943 (+/-0.140) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3645]: 0.943 (+/-0.140) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3646]: 0.943 (+/-0.140) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3647]: 0.943 (+/-0.140) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3648]: 0.962 (+/-0.038) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3649]: 0.962 (+/-0.038) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3650]: 0.962 (+/-0.038) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3651]: 0.962 (+/-0.038) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3652]: 0.876 (+/-0.230) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3653]: 0.876 (+/-0.230) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3654]: 0.876 (+/-0.230) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3655]: 0.876 (+/-0.230) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3656]: 0.971 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3657]: 0.971 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3658]: 0.971 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3659]: 0.971 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3660]: 0.895 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3661]: 0.895 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3662]: 0.895 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3663]: 0.895 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3664]: 0.971 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3665]: 0.971 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3666]: 0.971 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3667]: 0.971 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3668]: 0.943 (+/-0.140) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3669]: 0.943 (+/-0.140) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3670]: 0.943 (+/-0.140) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3671]: 0.943 (+/-0.140) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'optimal', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3672]: 0.800 (+/-0.298) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3673]: 0.800 (+/-0.298) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3674]: 0.781 (+/-0.196) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3675]: 0.781 (+/-0.196) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3676]: 0.857 (+/-0.341) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3677]: 0.857 (+/-0.341) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3678]: 0.810 (+/-0.120) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3679]: 0.810 (+/-0.120) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3680]: 0.848 (+/-0.152) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3681]: 0.848 (+/-0.152) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3682]: 0.867 (+/-0.164) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3683]: 0.867 (+/-0.164) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3684]: 0.848 (+/-0.236) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3685]: 0.848 (+/-0.236) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3686]: 0.886 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3687]: 0.886 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3688]: 0.895 (+/-0.140) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3689]: 0.895 (+/-0.140) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3690]: 0.886 (+/-0.143) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3691]: 0.886 (+/-0.143) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3692]: 0.771 (+/-0.251) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3693]: 0.771 (+/-0.251) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3694]: 0.857 (+/-0.159) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3695]: 0.857 (+/-0.159) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3696]: 0.800 (+/-0.298) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3697]: 0.800 (+/-0.298) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3698]: 0.781 (+/-0.196) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3699]: 0.781 (+/-0.196) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3700]: 0.857 (+/-0.341) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3701]: 0.857 (+/-0.341) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3702]: 0.810 (+/-0.120) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3703]: 0.810 (+/-0.120) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3704]: 0.848 (+/-0.152) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3705]: 0.848 (+/-0.152) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3706]: 0.867 (+/-0.164) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3707]: 0.867 (+/-0.164) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3708]: 0.848 (+/-0.236) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3709]: 0.848 (+/-0.236) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3710]: 0.886 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3711]: 0.886 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3712]: 0.895 (+/-0.140) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3713]: 0.895 (+/-0.140) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3714]: 0.886 (+/-0.143) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3715]: 0.886 (+/-0.143) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3716]: 0.771 (+/-0.251) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3717]: 0.771 (+/-0.251) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3718]: 0.857 (+/-0.159) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3719]: 0.857 (+/-0.159) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3720]: 0.800 (+/-0.298) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3721]: 0.800 (+/-0.298) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3722]: 0.781 (+/-0.196) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3723]: 0.781 (+/-0.196) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3724]: 0.857 (+/-0.341) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3725]: 0.857 (+/-0.341) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3726]: 0.810 (+/-0.120) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3727]: 0.810 (+/-0.120) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3728]: 0.848 (+/-0.152) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3729]: 0.848 (+/-0.152) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3730]: 0.867 (+/-0.164) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3731]: 0.867 (+/-0.164) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3732]: 0.848 (+/-0.236) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3733]: 0.848 (+/-0.236) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3734]: 0.886 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3735]: 0.886 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3736]: 0.895 (+/-0.140) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3737]: 0.895 (+/-0.140) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3738]: 0.886 (+/-0.143) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3739]: 0.886 (+/-0.143) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3740]: 0.771 (+/-0.251) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3741]: 0.771 (+/-0.251) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3742]: 0.857 (+/-0.159) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3743]: 0.857 (+/-0.159) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3744]: 0.629 (+/-0.464) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3745]: 0.629 (+/-0.464) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3746]: 0.867 (+/-0.152) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3747]: 0.867 (+/-0.152) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3748]: 0.590 (+/-0.453) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3749]: 0.590 (+/-0.453) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3750]: 0.867 (+/-0.152) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3751]: 0.867 (+/-0.152) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3752]: 0.752 (+/-0.368) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3753]: 0.752 (+/-0.368) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3754]: 0.857 (+/-0.170) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3755]: 0.857 (+/-0.170) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3756]: 0.743 (+/-0.166) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3757]: 0.743 (+/-0.166) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3758]: 0.857 (+/-0.170) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3759]: 0.857 (+/-0.170) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3760]: 0.752 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3761]: 0.752 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3762]: 0.838 (+/-0.196) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3763]: 0.838 (+/-0.196) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3764]: 0.648 (+/-0.369) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3765]: 0.648 (+/-0.369) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3766]: 0.838 (+/-0.196) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3767]: 0.838 (+/-0.196) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3768]: 0.629 (+/-0.464) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3769]: 0.629 (+/-0.464) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3770]: 0.867 (+/-0.152) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3771]: 0.867 (+/-0.152) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3772]: 0.590 (+/-0.453) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3773]: 0.590 (+/-0.453) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3774]: 0.867 (+/-0.152) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3775]: 0.867 (+/-0.152) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3776]: 0.752 (+/-0.368) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3777]: 0.752 (+/-0.368) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3778]: 0.857 (+/-0.170) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3779]: 0.857 (+/-0.170) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3780]: 0.743 (+/-0.166) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3781]: 0.743 (+/-0.166) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3782]: 0.857 (+/-0.170) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3783]: 0.857 (+/-0.170) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3784]: 0.752 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3785]: 0.752 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3786]: 0.838 (+/-0.196) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3787]: 0.838 (+/-0.196) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3788]: 0.648 (+/-0.369) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3789]: 0.648 (+/-0.369) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3790]: 0.829 (+/-0.222) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3791]: 0.829 (+/-0.222) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3792]: 0.629 (+/-0.464) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3793]: 0.629 (+/-0.464) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3794]: 0.867 (+/-0.152) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3795]: 0.867 (+/-0.152) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3796]: 0.590 (+/-0.453) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3797]: 0.590 (+/-0.453) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3798]: 0.867 (+/-0.152) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3799]: 0.867 (+/-0.152) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3800]: 0.752 (+/-0.368) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3801]: 0.752 (+/-0.368) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3802]: 0.857 (+/-0.170) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3803]: 0.857 (+/-0.170) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3804]: 0.743 (+/-0.166) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3805]: 0.743 (+/-0.166) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3806]: 0.857 (+/-0.170) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3807]: 0.857 (+/-0.170) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3808]: 0.752 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3809]: 0.752 (+/-0.203) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3810]: 0.838 (+/-0.196) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3811]: 0.838 (+/-0.196) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3812]: 0.648 (+/-0.369) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3813]: 0.648 (+/-0.369) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3814]: 0.848 (+/-0.229) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3815]: 0.848 (+/-0.229) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'squared_hinge', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3816]: 0.733 (+/-0.364) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3817]: 0.733 (+/-0.364) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3818]: 0.876 (+/-0.205) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3819]: 0.876 (+/-0.205) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3820]: 0.667 (+/-0.439) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3821]: 0.667 (+/-0.439) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3822]: 0.914 (+/-0.126) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3823]: 0.914 (+/-0.126) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3824]: 0.781 (+/-0.222) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3825]: 0.781 (+/-0.222) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3826]: 0.886 (+/-0.129) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3827]: 0.886 (+/-0.129) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3828]: 0.714 (+/-0.159) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3829]: 0.714 (+/-0.159) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3830]: 0.952 (+/-0.104) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3831]: 0.952 (+/-0.104) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3832]: 0.724 (+/-0.298) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3833]: 0.724 (+/-0.298) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3834]: 0.971 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3835]: 0.971 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3836]: 0.552 (+/-0.299) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3837]: 0.552 (+/-0.299) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3838]: 0.933 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3839]: 0.933 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 300, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3840]: 0.733 (+/-0.364) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3841]: 0.733 (+/-0.364) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3842]: 0.876 (+/-0.205) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3843]: 0.876 (+/-0.205) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3844]: 0.667 (+/-0.439) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3845]: 0.667 (+/-0.439) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3846]: 0.914 (+/-0.126) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3847]: 0.914 (+/-0.126) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3848]: 0.781 (+/-0.222) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3849]: 0.781 (+/-0.222) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3850]: 0.886 (+/-0.129) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3851]: 0.886 (+/-0.129) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3852]: 0.714 (+/-0.159) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3853]: 0.714 (+/-0.159) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3854]: 0.952 (+/-0.104) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3855]: 0.952 (+/-0.104) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3856]: 0.724 (+/-0.298) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3857]: 0.724 (+/-0.298) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3858]: 0.971 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3859]: 0.971 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3860]: 0.552 (+/-0.299) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3861]: 0.552 (+/-0.299) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3862]: 0.933 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3863]: 0.933 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 900, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3864]: 0.733 (+/-0.364) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3865]: 0.733 (+/-0.364) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3866]: 0.876 (+/-0.205) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3867]: 0.876 (+/-0.205) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3868]: 0.667 (+/-0.439) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3869]: 0.667 (+/-0.439) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3870]: 0.914 (+/-0.126) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3871]: 0.914 (+/-0.126) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 5, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3872]: 0.781 (+/-0.222) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3873]: 0.781 (+/-0.222) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3874]: 0.886 (+/-0.129) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3875]: 0.886 (+/-0.129) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3876]: 0.714 (+/-0.159) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3877]: 0.714 (+/-0.159) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3878]: 0.952 (+/-0.104) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3879]: 0.952 (+/-0.104) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 10, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3880]: 0.724 (+/-0.298) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3881]: 0.724 (+/-0.298) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3882]: 0.971 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3883]: 0.971 (+/-0.076) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l1', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\t[3884]: 0.552 (+/-0.299) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.1}\n",
      "\t[3885]: 0.552 (+/-0.299) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.1, 'validation_fraction': 0.2}\n",
      "\t[3886]: 0.933 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.1}\n",
      "\t[3887]: 0.933 (+/-0.047) for {'alpha': 0.01, 'early_stopping': False, 'eta0': 0.1, 'learning_rate': 'invscaling', 'loss': 'perceptron', 'max_iter': 1400, 'n_iter_no_change': 20, 'penalty': 'l2', 'power_t': 0.5, 'validation_fraction': 0.2}\n",
      "\n",
      "Detailed classification report:\n",
      "\tThe model is trained on the full development set.\n",
      "\tThe scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        16\n",
      "           1       1.00      0.89      0.94        18\n",
      "           2       0.85      1.00      0.92        11\n",
      "\n",
      "    accuracy                           0.96        45\n",
      "   macro avg       0.95      0.96      0.95        45\n",
      "weighted avg       0.96      0.96      0.96        45\n",
      "\n",
      "\n",
      "CTOR for best model: SGDClassifier(alpha=0.001, eta0=0.01, loss='perceptron', max_iter=300,\n",
      "              n_iter_no_change=20, penalty='l1', power_t=0.1, random_state=42)\n",
      "\n",
      "best: dat=iris, score=0.99048, model=SGDClassifier(alpha=0.001,early_stopping=False,eta0=0.01,learning_rate='optimal',loss='perceptron',max_iter=300,n_iter_no_change=20,penalty='l1',power_t=0.1,validation_fraction=0.1)\n",
      "\n",
      "OK(grid-search)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html\n",
    "\n",
    "# Setup data\n",
    "X_train, X_test, y_train, y_test = LoadAndSetupData(\n",
    "    'iris')  # 'iris', 'moon', or 'mnist'\n",
    "\n",
    "# Setup search parameters\n",
    "model = SGDClassifier(\n",
    "    loss='hinge',\n",
    "    random_state=42\n",
    ")  \n",
    "\n",
    "tuning_parameters = {\n",
    "    'loss': ['hinge', 'squared_hinge', 'perceptron'],\n",
    "    'max_iter': [300, 900, 1400],\n",
    "    'alpha': [0.0001, 0.001, 0.01],\n",
    "    'eta0': [0.01, 0.1],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'learning_rate': ['constant', 'optimal', 'invscaling'],\n",
    "    'power_t': [0.1, 0.5],\n",
    "    'early_stopping': [False],\n",
    "    'validation_fraction': [0.1, 0.2],\n",
    "    'n_iter_no_change': [5, 10, 20],\n",
    "}\n",
    "\n",
    "\n",
    "CV = 5\n",
    "VERBOSE = 0\n",
    "\n",
    "# Run GridSearchCV for the model\n",
    "grid_tuned = GridSearchCV(model,\n",
    "                          tuning_parameters,\n",
    "                          cv=CV,\n",
    "                          scoring='f1_micro',\n",
    "                          verbose=VERBOSE,\n",
    "                          n_jobs=-1)\n",
    "\n",
    "start = time()\n",
    "grid_tuned.fit(X_train, y_train)\n",
    "t = time() - start\n",
    "\n",
    "# Report result\n",
    "b0, m0 = FullReport(grid_tuned, X_test, y_test, t)\n",
    "print('OK(grid-search)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qc Hyperparameter Random  Search using an SDG classifier\n",
    "\n",
    "\n",
    "The default parameters for the random search were given and put in to the code for the RandomizedSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T09:34:57.082189Z",
     "start_time": "2023-11-30T09:34:56.960851Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA: iris..\n",
      "  org. data:  X.shape      =(  150;    4), y.shape      =(  150)\n",
      "  train data: X_train.shape=(  105;    4), y_train.shape=(  105)\n",
      "  test data:  X_test.shape =(   45;    4), y_test.shape =(   45)\n",
      "\n",
      "SEARCH TIME: 0.05 sec\n",
      "\n",
      "Best model set found on train set:\n",
      "\n",
      "\tbest parameters={'validation_fraction': 0.3, 'power_t': 0.5, 'penalty': 'l1', 'n_iter_no_change': 5, 'max_iter': 2000, 'loss': 'hinge', 'learning_rate': 'optimal', 'eta0': 0.1, 'early_stopping': False, 'alpha': 0.01}\n",
      "\tbest 'f1_micro' score=0.9619047619047618\n",
      "\tbest index=11\n",
      "\n",
      "Best estimator CTOR:\n",
      "\tSGDClassifier(alpha=0.01, eta0=0.1, max_iter=2000, penalty='l1',\n",
      "              random_state=42, validation_fraction=0.3)\n",
      "\n",
      "Grid scores ('f1_micro') on development set:\n",
      "\t[ 0]: 0.619 (+/-0.301) for {'validation_fraction': 0.1, 'power_t': 0.1, 'penalty': 'l2', 'n_iter_no_change': 10, 'max_iter': 300, 'loss': 'squared_hinge', 'learning_rate': 'constant', 'eta0': 0.2, 'early_stopping': False, 'alpha': 0.01}\n",
      "\t[ 1]: 0.886 (+/-0.177) for {'validation_fraction': 0.3, 'power_t': 0.5, 'penalty': 'l2', 'n_iter_no_change': 20, 'max_iter': 2000, 'loss': 'hinge', 'learning_rate': 'optimal', 'eta0': 0.01, 'early_stopping': False, 'alpha': 0.0001}\n",
      "\t[ 2]: 0.705 (+/-0.071) for {'validation_fraction': 0.3, 'power_t': 0.8, 'penalty': 'l1', 'n_iter_no_change': 20, 'max_iter': 2000, 'loss': 'hinge', 'learning_rate': 'invscaling', 'eta0': 0.2, 'early_stopping': False, 'alpha': 0.0001}\n",
      "\t[ 3]: 0.581 (+/-0.304) for {'validation_fraction': 0.3, 'power_t': 0.1, 'penalty': 'l2', 'n_iter_no_change': 10, 'max_iter': 2000, 'loss': 'hinge', 'learning_rate': 'constant', 'eta0': 0.2, 'early_stopping': False, 'alpha': 0.1}\n",
      "\t[ 4]: 0.829 (+/-0.260) for {'validation_fraction': 0.1, 'power_t': 0.5, 'penalty': 'l2', 'n_iter_no_change': 10, 'max_iter': 900, 'loss': 'squared_hinge', 'learning_rate': 'constant', 'eta0': 0.01, 'early_stopping': False, 'alpha': 0.01}\n",
      "\t[ 5]: 0.914 (+/-0.164) for {'validation_fraction': 0.2, 'power_t': 0.8, 'penalty': 'l2', 'n_iter_no_change': 20, 'max_iter': 300, 'loss': 'squared_hinge', 'learning_rate': 'invscaling', 'eta0': 0.2, 'early_stopping': False, 'alpha': 0.001}\n",
      "\t[ 6]: 0.829 (+/-0.177) for {'validation_fraction': 0.3, 'power_t': 0.5, 'penalty': 'l2', 'n_iter_no_change': 10, 'max_iter': 900, 'loss': 'hinge', 'learning_rate': 'optimal', 'eta0': 0.2, 'early_stopping': False, 'alpha': 0.1}\n",
      "\t[ 7]: 0.838 (+/-0.230) for {'validation_fraction': 0.2, 'power_t': 0.1, 'penalty': 'l1', 'n_iter_no_change': 5, 'max_iter': 300, 'loss': 'perceptron', 'learning_rate': 'constant', 'eta0': 0.01, 'early_stopping': False, 'alpha': 0.001}\n",
      "\t[ 8]: 0.829 (+/-0.196) for {'validation_fraction': 0.3, 'power_t': 0.1, 'penalty': 'l1', 'n_iter_no_change': 5, 'max_iter': 300, 'loss': 'hinge', 'learning_rate': 'invscaling', 'eta0': 0.2, 'early_stopping': False, 'alpha': 0.01}\n",
      "\t[ 9]: 0.562 (+/-0.383) for {'validation_fraction': 0.2, 'power_t': 0.8, 'penalty': 'l2', 'n_iter_no_change': 20, 'max_iter': 900, 'loss': 'perceptron', 'learning_rate': 'constant', 'eta0': 0.2, 'early_stopping': False, 'alpha': 0.0001}\n",
      "\t[10]: 0.705 (+/-0.236) for {'validation_fraction': 0.3, 'power_t': 0.1, 'penalty': 'l1', 'n_iter_no_change': 20, 'max_iter': 1400, 'loss': 'perceptron', 'learning_rate': 'constant', 'eta0': 0.2, 'early_stopping': False, 'alpha': 0.1}\n",
      "\t[11]: 0.962 (+/-0.038) for {'validation_fraction': 0.3, 'power_t': 0.5, 'penalty': 'l1', 'n_iter_no_change': 5, 'max_iter': 2000, 'loss': 'hinge', 'learning_rate': 'optimal', 'eta0': 0.1, 'early_stopping': False, 'alpha': 0.01}\n",
      "\t[12]: 0.933 (+/-0.129) for {'validation_fraction': 0.3, 'power_t': 0.5, 'penalty': 'l1', 'n_iter_no_change': 10, 'max_iter': 1400, 'loss': 'squared_hinge', 'learning_rate': 'invscaling', 'eta0': 0.2, 'early_stopping': False, 'alpha': 0.001}\n",
      "\t[13]: 0.514 (+/-0.406) for {'validation_fraction': 0.1, 'power_t': 0.5, 'penalty': 'l1', 'n_iter_no_change': 20, 'max_iter': 300, 'loss': 'perceptron', 'learning_rate': 'constant', 'eta0': 0.2, 'early_stopping': False, 'alpha': 0.01}\n",
      "\t[14]: 0.838 (+/-0.230) for {'validation_fraction': 0.1, 'power_t': 0.8, 'penalty': 'l1', 'n_iter_no_change': 5, 'max_iter': 1400, 'loss': 'perceptron', 'learning_rate': 'constant', 'eta0': 0.1, 'early_stopping': False, 'alpha': 0.001}\n",
      "\t[15]: 0.952 (+/-0.104) for {'validation_fraction': 0.3, 'power_t': 0.1, 'penalty': 'l2', 'n_iter_no_change': 5, 'max_iter': 2000, 'loss': 'squared_hinge', 'learning_rate': 'invscaling', 'eta0': 0.01, 'early_stopping': False, 'alpha': 0.0001}\n",
      "\t[16]: 0.895 (+/-0.111) for {'validation_fraction': 0.2, 'power_t': 0.5, 'penalty': 'l2', 'n_iter_no_change': 5, 'max_iter': 1400, 'loss': 'hinge', 'learning_rate': 'optimal', 'eta0': 0.01, 'early_stopping': False, 'alpha': 0.0001}\n",
      "\t[17]: 0.781 (+/-0.364) for {'validation_fraction': 0.1, 'power_t': 0.5, 'penalty': 'l1', 'n_iter_no_change': 5, 'max_iter': 900, 'loss': 'perceptron', 'learning_rate': 'constant', 'eta0': 0.1, 'early_stopping': False, 'alpha': 0.0001}\n",
      "\t[18]: 0.867 (+/-0.194) for {'validation_fraction': 0.2, 'power_t': 0.1, 'penalty': 'l1', 'n_iter_no_change': 10, 'max_iter': 1400, 'loss': 'hinge', 'learning_rate': 'invscaling', 'eta0': 0.2, 'early_stopping': False, 'alpha': 0.0001}\n",
      "\t[19]: 0.800 (+/-0.212) for {'validation_fraction': 0.3, 'power_t': 0.1, 'penalty': 'l2', 'n_iter_no_change': 10, 'max_iter': 900, 'loss': 'perceptron', 'learning_rate': 'optimal', 'eta0': 0.2, 'early_stopping': False, 'alpha': 0.0001}\n",
      "\n",
      "Detailed classification report:\n",
      "\tThe model is trained on the full development set.\n",
      "\tThe scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        16\n",
      "           1       1.00      0.83      0.91        18\n",
      "           2       0.79      1.00      0.88        11\n",
      "\n",
      "    accuracy                           0.93        45\n",
      "   macro avg       0.93      0.94      0.93        45\n",
      "weighted avg       0.95      0.93      0.93        45\n",
      "\n",
      "\n",
      "CTOR for best model: SGDClassifier(alpha=0.01, eta0=0.1, max_iter=2000, penalty='l1',\n",
      "              random_state=42, validation_fraction=0.3)\n",
      "\n",
      "best: dat=iris, score=0.96190, model=SGDClassifier(alpha=0.01,early_stopping=False,eta0=0.1,learning_rate='optimal',loss='hinge',max_iter=2000,n_iter_no_change=5,penalty='l1',power_t=0.5,validation_fraction=0.3)\n",
      "\n",
      "OK(randomized-search)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Setup data\n",
    "X_train, X_test, y_train, y_test = LoadAndSetupData('iris')\n",
    "\n",
    "# Setup search parameters for RandomizedSearchCV\n",
    "model = SGDClassifier(loss='hinge', random_state=42)\n",
    "\n",
    "random_tuning_parameters = {\n",
    "    'loss': ['hinge', 'squared_hinge', 'perceptron'],\n",
    "    'max_iter': [300, 900, 1400, 2000],\n",
    "    'alpha': [0.0001, 0.001, 0.01, 0.1],\n",
    "    'eta0': [0.01, 0.1, 0.2],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'learning_rate': ['constant', 'optimal', 'invscaling'],\n",
    "    'power_t': [0.1, 0.5, 0.8],\n",
    "    'early_stopping': [False],\n",
    "    'validation_fraction': [0.1, 0.2, 0.3],\n",
    "    'n_iter_no_change': [5, 10, 20],\n",
    "}\n",
    "\n",
    "CV = 5\n",
    "VERBOSE = 0\n",
    "\n",
    "# Run RandomizedSearchCV for the model\n",
    "random_tuned = RandomizedSearchCV(\n",
    "    model,\n",
    "    random_tuning_parameters,\n",
    "    n_iter=20,\n",
    "    random_state=42,\n",
    "    cv=CV,\n",
    "    scoring='f1_micro',\n",
    "    verbose=VERBOSE,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "start_random = time()\n",
    "random_tuned.fit(X_train, y_train)\n",
    "t_random = time() - start_random\n",
    "\n",
    "# Report result for RandomizedSearchCV\n",
    "b_random, m_random = FullReport(random_tuned, X_test, y_test, t_random)\n",
    "print('OK(randomized-search)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid search is systematic and ensures to explore all combinations and making it exhaustive but potentially computationally expensive.\n",
    "Random search is more flexible, exploring a random subset of combinations, which can be advantageous when the hyperparameter space is vast.\n",
    "Grid search may be computationally expensive, especially with large hyperparameter spaces.\n",
    "Random search might be more time-efficient in such cases but may not guarantee finding the absolute best set of hyperparameters.\n",
    "\n",
    "Both grid search (GridSearchCV) and random search (RandomizedSearchCV) are used with the same set of initial hyperparameter values. This allows for a direct comparison of their results, demonstrating the trade-offs between an exhaustive search and a more flexible, randomized approach.\n",
    "\n",
    "__Result of GridSearchCV__\n",
    "best: dat=iris, score=0.99048, model=SGDClassifier(alpha=0.001,early_stopping=False,eta0=0.01,learning_rate='optimal',loss='perceptron',max_iter=300,n_iter_no_change=20,penalty='l1',power_t=0.1,validation_fraction=0.1)\n",
    "\n",
    "__Result of RandomizedSearchCV__\n",
    "best: dat=iris, score=0.96190, model=SGDClassifier(alpha=0.01,early_stopping=False,eta0=0.1,learning_rate='optimal',loss='hinge',max_iter=2000,n_iter_no_change=5,penalty='l1',power_t=0.5,validation_fraction=0.3)\n",
    "\n",
    "As the results show the GridSearchCV has the highest score of 0.99048 compared to 0.96190 thereby showing that the combination of hyperparameters found by GridSearchCV resulted in a better-performing model on th f1_micro scoring metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Qd MNIST Search Quest II\n",
    "\n",
    "For the MNIST dataset, we chose the RandomForestClassifier, which is a versatile learning model known for its effectiveness in classification tasks. We think it would be good for the complexity of the MNIST dataset by combining multiple decision trees, thereby improving overall predictive accuracy and mitigating overfitting.\n",
    "\n",
    "The RandomForestClassifier was configured with a set of hyperparameters defined in the tuning_parameters. These parameters cover various aspects such as the number of trees (n_estimators), tree depth (max_depth), minimum samples required to split an internal node (min_samples_split), and other crucial settings.\n",
    "\n",
    "To efficiently search through this hyperparameter space, we employed RandomizedSearchCV.\n",
    "\n",
    "To ensure reproducibility, we set the random_state parameter, and a higher number of iterations (n_iter=100) in RandomizedSearchCV allows for an extensive exploration of hyperparameter combinations, increasing the likelihood of finding optimal settings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T09:41:04.897215Z",
     "start_time": "2023-11-30T09:34:57.003102Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA: mnist..\n",
      "  org. data:  X.shape      =(70000;  784), y.shape      =(70000)\n",
      "  train data: X_train.shape=(49000;  784), y_train.shape=(49000)\n",
      "  test data:  X_test.shape =(21000;  784), y_test.shape =(21000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:578: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:578: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:578: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:578: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:578: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/joblib/externals/loky/process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:578: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:578: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:578: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:578: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:578: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:578: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:578: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:578: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:578: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:578: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:578: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:578: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:578: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:578: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:578: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:578: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:578: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:578: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:578: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:578: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:578: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:578: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:578: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:578: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:578: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:578: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:578: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:578: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:578: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:578: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:578: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:578: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:578: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:578: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:578: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:578: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:578: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:578: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:578: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:578: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:578: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:578: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:578: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:578: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:578: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:578: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:578: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:578: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:578: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:578: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:578: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:578: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:578: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:578: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:578: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Users/christianduwekonnerup/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:780: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEARCH TIME: 366.93 sec\n",
      "\n",
      "Best model set found on train set:\n",
      "\n",
      "\tbest parameters={'warm_start': False, 'oob_score': True, 'n_estimators': 200, 'min_samples_split': 10, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.0, 'max_leaf_nodes': None, 'max_features': 'sqrt', 'max_depth': 30, 'criterion': 'entropy', 'class_weight': 'balanced', 'ccp_alpha': 0.0, 'bootstrap': True}\n",
      "\tbest 'f1_micro' score=0.9628163265306122\n",
      "\tbest index=80\n",
      "\n",
      "Best estimator CTOR:\n",
      "\tRandomForestClassifier(class_weight='balanced', criterion='entropy',\n",
      "                       max_depth=30, min_samples_leaf=2, min_samples_split=10,\n",
      "                       n_estimators=200, oob_score=True, random_state=83)\n",
      "\n",
      "Grid scores ('f1_micro') on development set:\n",
      "\t[ 0]: 0.568 (+/-0.020) for {'warm_start': False, 'oob_score': False, 'n_estimators': 100, 'min_samples_split': 5, 'min_samples_leaf': 1, 'min_impurity_decrease': 0.2, 'max_leaf_nodes': None, 'max_features': 'sqrt', 'max_depth': 30, 'criterion': 'entropy', 'class_weight': 'balanced_subsample', 'ccp_alpha': 0.1, 'bootstrap': True}\n",
      "\t[ 1]: 0.550 (+/-0.007) for {'warm_start': True, 'oob_score': False, 'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.2, 'max_leaf_nodes': 10, 'max_features': 'sqrt', 'max_depth': 20, 'criterion': 'entropy', 'class_weight': None, 'ccp_alpha': 0.2, 'bootstrap': True}\n",
      "\t[ 2]: 0.765 (+/-0.010) for {'warm_start': False, 'oob_score': False, 'n_estimators': 100, 'min_samples_split': 10, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.0, 'max_leaf_nodes': 5, 'max_features': 'log2', 'max_depth': 10, 'criterion': 'gini', 'class_weight': 'balanced', 'ccp_alpha': 0.0, 'bootstrap': True}\n",
      "\t[ 3]: 0.655 (+/-0.018) for {'warm_start': True, 'oob_score': True, 'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.0, 'max_leaf_nodes': 20, 'max_features': 'log2', 'max_depth': None, 'criterion': 'entropy', 'class_weight': 'balanced_subsample', 'ccp_alpha': 0.2, 'bootstrap': True}\n",
      "\t[ 4]: 0.475 (+/-0.051) for {'warm_start': False, 'oob_score': True, 'n_estimators': 10, 'min_samples_split': 5, 'min_samples_leaf': 1, 'min_impurity_decrease': 0.0, 'max_leaf_nodes': 5, 'max_features': 'sqrt', 'max_depth': 30, 'criterion': 'entropy', 'class_weight': None, 'ccp_alpha': 0.2, 'bootstrap': True}\n",
      "\t[ 5]: 0.620 (+/-0.024) for {'warm_start': True, 'oob_score': False, 'n_estimators': 10, 'min_samples_split': 10, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.1, 'max_leaf_nodes': 10, 'max_features': 'sqrt', 'max_depth': 20, 'criterion': 'entropy', 'class_weight': 'balanced', 'ccp_alpha': 0.0, 'bootstrap': True}\n",
      "\t[ 6]: 0.764 (+/-0.012) for {'warm_start': False, 'oob_score': True, 'n_estimators': 100, 'min_samples_split': 2, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.0, 'max_leaf_nodes': 5, 'max_features': 'log2', 'max_depth': 20, 'criterion': 'gini', 'class_weight': 'balanced_subsample', 'ccp_alpha': 0.0, 'bootstrap': True}\n",
      "\t[ 7]: 0.099 (+/-0.010) for {'warm_start': True, 'oob_score': True, 'n_estimators': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_impurity_decrease': 0.0, 'max_leaf_nodes': None, 'max_features': 'sqrt', 'max_depth': 30, 'criterion': 'gini', 'class_weight': 'balanced', 'ccp_alpha': 0.2, 'bootstrap': True}\n",
      "\t[ 8]: 0.682 (+/-0.009) for {'warm_start': True, 'oob_score': True, 'n_estimators': 200, 'min_samples_split': 10, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.0, 'max_leaf_nodes': 5, 'max_features': 'sqrt', 'max_depth': 30, 'criterion': 'entropy', 'class_weight': 'balanced_subsample', 'ccp_alpha': 0.1, 'bootstrap': True}\n",
      "\t[ 9]: 0.568 (+/-0.020) for {'warm_start': False, 'oob_score': True, 'n_estimators': 100, 'min_samples_split': 10, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.2, 'max_leaf_nodes': 20, 'max_features': 'sqrt', 'max_depth': 20, 'criterion': 'entropy', 'class_weight': 'balanced_subsample', 'ccp_alpha': 0.0, 'bootstrap': True}\n",
      "\t[10]: 0.112 (+/-0.000) for {'warm_start': True, 'oob_score': True, 'n_estimators': 100, 'min_samples_split': 2, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.0, 'max_leaf_nodes': 20, 'max_features': 'sqrt', 'max_depth': None, 'criterion': 'gini', 'class_weight': None, 'ccp_alpha': 0.1, 'bootstrap': True}\n",
      "\t[11]: 0.102 (+/-0.005) for {'warm_start': False, 'oob_score': False, 'n_estimators': 10, 'min_samples_split': 5, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.1, 'max_leaf_nodes': 10, 'max_features': 'sqrt', 'max_depth': None, 'criterion': 'gini', 'class_weight': 'balanced_subsample', 'ccp_alpha': 0.2, 'bootstrap': True}\n",
      "\t[12]: 0.097 (+/-0.007) for {'warm_start': False, 'oob_score': False, 'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.2, 'max_leaf_nodes': 20, 'max_features': 'sqrt', 'max_depth': None, 'criterion': 'gini', 'class_weight': 'balanced_subsample', 'ccp_alpha': 0.2, 'bootstrap': True}\n",
      "\t[13]: 0.475 (+/-0.051) for {'warm_start': True, 'oob_score': True, 'n_estimators': 10, 'min_samples_split': 5, 'min_samples_leaf': 1, 'min_impurity_decrease': 0.2, 'max_leaf_nodes': 20, 'max_features': 'sqrt', 'max_depth': 10, 'criterion': 'entropy', 'class_weight': None, 'ccp_alpha': 0.2, 'bootstrap': True}\n",
      "\t[14]: 0.404 (+/-0.099) for {'warm_start': False, 'oob_score': False, 'n_estimators': 10, 'min_samples_split': 2, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.0, 'max_leaf_nodes': 20, 'max_features': 'log2', 'max_depth': None, 'criterion': 'entropy', 'class_weight': 'balanced', 'ccp_alpha': 0.2, 'bootstrap': True}\n",
      "\t[15]: 0.098 (+/-0.002) for {'warm_start': True, 'oob_score': True, 'n_estimators': 100, 'min_samples_split': 5, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.2, 'max_leaf_nodes': 10, 'max_features': 'sqrt', 'max_depth': 30, 'criterion': 'gini', 'class_weight': 'balanced', 'ccp_alpha': 0.1, 'bootstrap': True}\n",
      "\t[16]: 0.112 (+/-0.000) for {'warm_start': True, 'oob_score': False, 'n_estimators': 100, 'min_samples_split': 2, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.2, 'max_leaf_nodes': None, 'max_features': 'sqrt', 'max_depth': None, 'criterion': 'gini', 'class_weight': None, 'ccp_alpha': 0.0, 'bootstrap': True}\n",
      "\t[17]: 0.620 (+/-0.024) for {'warm_start': True, 'oob_score': True, 'n_estimators': 10, 'min_samples_split': 2, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.1, 'max_leaf_nodes': 10, 'max_features': 'sqrt', 'max_depth': 30, 'criterion': 'entropy', 'class_weight': 'balanced', 'ccp_alpha': 0.0, 'bootstrap': True}\n",
      "\t[18]: 0.928 (+/-0.005) for {'warm_start': False, 'oob_score': False, 'n_estimators': 10, 'min_samples_split': 5, 'min_samples_leaf': 1, 'min_impurity_decrease': 0.0, 'max_leaf_nodes': None, 'max_features': 'sqrt', 'max_depth': 10, 'criterion': 'entropy', 'class_weight': None, 'ccp_alpha': 0.0, 'bootstrap': True}\n",
      "\t[19]: 0.101 (+/-0.006) for {'warm_start': False, 'oob_score': True, 'n_estimators': 200, 'min_samples_split': 10, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.0, 'max_leaf_nodes': None, 'max_features': 'log2', 'max_depth': None, 'criterion': 'gini', 'class_weight': 'balanced', 'ccp_alpha': 0.2, 'bootstrap': True}\n",
      "\t[20]: 0.705 (+/-0.007) for {'warm_start': False, 'oob_score': False, 'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.1, 'max_leaf_nodes': 20, 'max_features': 'log2', 'max_depth': 10, 'criterion': 'entropy', 'class_weight': None, 'ccp_alpha': 0.1, 'bootstrap': True}\n",
      "\t[21]: 0.102 (+/-0.005) for {'warm_start': False, 'oob_score': False, 'n_estimators': 10, 'min_samples_split': 10, 'min_samples_leaf': 1, 'min_impurity_decrease': 0.2, 'max_leaf_nodes': 10, 'max_features': 'log2', 'max_depth': 10, 'criterion': 'gini', 'class_weight': 'balanced_subsample', 'ccp_alpha': 0.2, 'bootstrap': True}\n",
      "\t[22]: 0.097 (+/-0.007) for {'warm_start': True, 'oob_score': False, 'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.1, 'max_leaf_nodes': 20, 'max_features': 'sqrt', 'max_depth': 20, 'criterion': 'gini', 'class_weight': 'balanced_subsample', 'ccp_alpha': 0.0, 'bootstrap': True}\n",
      "\t[23]: 0.097 (+/-0.007) for {'warm_start': True, 'oob_score': False, 'n_estimators': 100, 'min_samples_split': 5, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.1, 'max_leaf_nodes': 20, 'max_features': 'sqrt', 'max_depth': 10, 'criterion': 'gini', 'class_weight': 'balanced_subsample', 'ccp_alpha': 0.0, 'bootstrap': True}\n",
      "\t[24]: 0.663 (+/-0.014) for {'warm_start': False, 'oob_score': True, 'n_estimators': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_impurity_decrease': 0.1, 'max_leaf_nodes': 5, 'max_features': 'sqrt', 'max_depth': 30, 'criterion': 'entropy', 'class_weight': 'balanced_subsample', 'ccp_alpha': 0.1, 'bootstrap': True}\n",
      "\t[25]: 0.617 (+/-0.019) for {'warm_start': False, 'oob_score': True, 'n_estimators': 10, 'min_samples_split': 10, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.1, 'max_leaf_nodes': 5, 'max_features': 'sqrt', 'max_depth': 10, 'criterion': 'entropy', 'class_weight': 'balanced', 'ccp_alpha': 0.1, 'bootstrap': True}\n",
      "\t[26]: 0.772 (+/-0.008) for {'warm_start': True, 'oob_score': False, 'n_estimators': 100, 'min_samples_split': 10, 'min_samples_leaf': 1, 'min_impurity_decrease': 0.0, 'max_leaf_nodes': 10, 'max_features': 'sqrt', 'max_depth': 10, 'criterion': 'gini', 'class_weight': None, 'ccp_alpha': 0.0, 'bootstrap': True}\n",
      "\t[27]: 0.636 (+/-0.014) for {'warm_start': True, 'oob_score': True, 'n_estimators': 100, 'min_samples_split': 10, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.2, 'max_leaf_nodes': 5, 'max_features': 'log2', 'max_depth': 30, 'criterion': 'entropy', 'class_weight': 'balanced_subsample', 'ccp_alpha': 0.1, 'bootstrap': True}\n",
      "\t[28]: 0.837 (+/-0.008) for {'warm_start': False, 'oob_score': True, 'n_estimators': 100, 'min_samples_split': 5, 'min_samples_leaf': 1, 'min_impurity_decrease': 0.0, 'max_leaf_nodes': 20, 'max_features': 'sqrt', 'max_depth': 30, 'criterion': 'entropy', 'class_weight': 'balanced', 'ccp_alpha': 0.0, 'bootstrap': True}\n",
      "\t[29]: 0.098 (+/-0.002) for {'warm_start': False, 'oob_score': False, 'n_estimators': 100, 'min_samples_split': 10, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.0, 'max_leaf_nodes': None, 'max_features': 'log2', 'max_depth': None, 'criterion': 'gini', 'class_weight': 'balanced', 'ccp_alpha': 0.2, 'bootstrap': True}\n",
      "\t[30]: 0.099 (+/-0.010) for {'warm_start': True, 'oob_score': True, 'n_estimators': 10, 'min_samples_split': 2, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.1, 'max_leaf_nodes': 20, 'max_features': 'log2', 'max_depth': 10, 'criterion': 'gini', 'class_weight': 'balanced', 'ccp_alpha': 0.1, 'bootstrap': True}\n",
      "\t[31]: 0.101 (+/-0.006) for {'warm_start': False, 'oob_score': True, 'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.2, 'max_leaf_nodes': 10, 'max_features': 'sqrt', 'max_depth': 10, 'criterion': 'gini', 'class_weight': 'balanced', 'ccp_alpha': 0.1, 'bootstrap': True}\n",
      "\t[32]: 0.549 (+/-0.011) for {'warm_start': True, 'oob_score': True, 'n_estimators': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_impurity_decrease': 0.1, 'max_leaf_nodes': None, 'max_features': 'sqrt', 'max_depth': 10, 'criterion': 'entropy', 'class_weight': None, 'ccp_alpha': 0.2, 'bootstrap': True}\n",
      "\t[33]: 0.396 (+/-0.076) for {'warm_start': True, 'oob_score': False, 'n_estimators': 10, 'min_samples_split': 10, 'min_samples_leaf': 1, 'min_impurity_decrease': 0.2, 'max_leaf_nodes': 10, 'max_features': 'log2', 'max_depth': 30, 'criterion': 'entropy', 'class_weight': 'balanced', 'ccp_alpha': 0.2, 'bootstrap': True}\n",
      "\t[34]: 0.102 (+/-0.005) for {'warm_start': False, 'oob_score': False, 'n_estimators': 10, 'min_samples_split': 5, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.1, 'max_leaf_nodes': None, 'max_features': 'log2', 'max_depth': None, 'criterion': 'gini', 'class_weight': 'balanced_subsample', 'ccp_alpha': 0.2, 'bootstrap': True}\n",
      "\t[35]: 0.099 (+/-0.010) for {'warm_start': False, 'oob_score': False, 'n_estimators': 10, 'min_samples_split': 5, 'min_samples_leaf': 1, 'min_impurity_decrease': 0.0, 'max_leaf_nodes': None, 'max_features': 'log2', 'max_depth': 10, 'criterion': 'gini', 'class_weight': 'balanced', 'ccp_alpha': 0.1, 'bootstrap': True}\n",
      "\t[36]: 0.722 (+/-0.020) for {'warm_start': True, 'oob_score': False, 'n_estimators': 10, 'min_samples_split': 2, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.0, 'max_leaf_nodes': 10, 'max_features': 'sqrt', 'max_depth': 10, 'criterion': 'entropy', 'class_weight': 'balanced', 'ccp_alpha': 0.0, 'bootstrap': True}\n",
      "\t[37]: 0.112 (+/-0.000) for {'warm_start': False, 'oob_score': False, 'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_impurity_decrease': 0.1, 'max_leaf_nodes': 5, 'max_features': 'log2', 'max_depth': 20, 'criterion': 'gini', 'class_weight': None, 'ccp_alpha': 0.2, 'bootstrap': True}\n",
      "\t[38]: 0.578 (+/-0.011) for {'warm_start': True, 'oob_score': False, 'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 1, 'min_impurity_decrease': 0.2, 'max_leaf_nodes': None, 'max_features': 'sqrt', 'max_depth': 30, 'criterion': 'entropy', 'class_weight': 'balanced', 'ccp_alpha': 0.2, 'bootstrap': True}\n",
      "\t[39]: 0.112 (+/-0.000) for {'warm_start': False, 'oob_score': True, 'n_estimators': 10, 'min_samples_split': 5, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.0, 'max_leaf_nodes': 20, 'max_features': 'log2', 'max_depth': 20, 'criterion': 'gini', 'class_weight': None, 'ccp_alpha': 0.1, 'bootstrap': True}\n",
      "\t[40]: 0.596 (+/-0.005) for {'warm_start': True, 'oob_score': False, 'n_estimators': 10, 'min_samples_split': 5, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.0, 'max_leaf_nodes': 20, 'max_features': 'log2', 'max_depth': 30, 'criterion': 'entropy', 'class_weight': None, 'ccp_alpha': 0.1, 'bootstrap': True}\n",
      "\t[41]: 0.101 (+/-0.006) for {'warm_start': False, 'oob_score': True, 'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_impurity_decrease': 0.1, 'max_leaf_nodes': None, 'max_features': 'log2', 'max_depth': 30, 'criterion': 'gini', 'class_weight': 'balanced', 'ccp_alpha': 0.1, 'bootstrap': True}\n",
      "\t[42]: 0.701 (+/-0.016) for {'warm_start': True, 'oob_score': True, 'n_estimators': 200, 'min_samples_split': 10, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.0, 'max_leaf_nodes': 5, 'max_features': 'sqrt', 'max_depth': None, 'criterion': 'entropy', 'class_weight': 'balanced', 'ccp_alpha': 0.0, 'bootstrap': True}\n",
      "\t[43]: 0.097 (+/-0.007) for {'warm_start': False, 'oob_score': False, 'n_estimators': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_impurity_decrease': 0.1, 'max_leaf_nodes': 20, 'max_features': 'sqrt', 'max_depth': 20, 'criterion': 'gini', 'class_weight': 'balanced_subsample', 'ccp_alpha': 0.2, 'bootstrap': True}\n",
      "\t[44]: 0.097 (+/-0.007) for {'warm_start': True, 'oob_score': False, 'n_estimators': 100, 'min_samples_split': 10, 'min_samples_leaf': 1, 'min_impurity_decrease': 0.2, 'max_leaf_nodes': 10, 'max_features': 'log2', 'max_depth': 20, 'criterion': 'gini', 'class_weight': 'balanced_subsample', 'ccp_alpha': 0.0, 'bootstrap': True}\n",
      "\t[45]: 0.576 (+/-0.012) for {'warm_start': True, 'oob_score': True, 'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 1, 'min_impurity_decrease': 0.0, 'max_leaf_nodes': 20, 'max_features': 'sqrt', 'max_depth': 10, 'criterion': 'entropy', 'class_weight': 'balanced_subsample', 'ccp_alpha': 0.2, 'bootstrap': True}\n",
      "\t[46]: 0.097 (+/-0.007) for {'warm_start': True, 'oob_score': False, 'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 1, 'min_impurity_decrease': 0.0, 'max_leaf_nodes': 10, 'max_features': 'sqrt', 'max_depth': 10, 'criterion': 'gini', 'class_weight': 'balanced_subsample', 'ccp_alpha': 0.2, 'bootstrap': True}\n",
      "\t[47]: 0.653 (+/-0.016) for {'warm_start': True, 'oob_score': False, 'n_estimators': 200, 'min_samples_split': 10, 'min_samples_leaf': 1, 'min_impurity_decrease': 0.2, 'max_leaf_nodes': 10, 'max_features': 'log2', 'max_depth': 30, 'criterion': 'entropy', 'class_weight': 'balanced_subsample', 'ccp_alpha': 0.2, 'bootstrap': True}\n",
      "\t[48]: 0.097 (+/-0.007) for {'warm_start': False, 'oob_score': True, 'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 1, 'min_impurity_decrease': 0.1, 'max_leaf_nodes': None, 'max_features': 'log2', 'max_depth': 30, 'criterion': 'gini', 'class_weight': 'balanced_subsample', 'ccp_alpha': 0.1, 'bootstrap': True}\n",
      "\t[49]: 0.097 (+/-0.007) for {'warm_start': False, 'oob_score': False, 'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.1, 'max_leaf_nodes': 5, 'max_features': 'log2', 'max_depth': 20, 'criterion': 'gini', 'class_weight': 'balanced_subsample', 'ccp_alpha': 0.0, 'bootstrap': True}\n",
      "\t[50]: 0.690 (+/-0.009) for {'warm_start': False, 'oob_score': False, 'n_estimators': 200, 'min_samples_split': 10, 'min_samples_leaf': 1, 'min_impurity_decrease': 0.1, 'max_leaf_nodes': 10, 'max_features': 'sqrt', 'max_depth': 30, 'criterion': 'entropy', 'class_weight': 'balanced_subsample', 'ccp_alpha': 0.0, 'bootstrap': True}\n",
      "\t[51]: 0.101 (+/-0.006) for {'warm_start': False, 'oob_score': True, 'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.2, 'max_leaf_nodes': 5, 'max_features': 'sqrt', 'max_depth': 30, 'criterion': 'gini', 'class_weight': 'balanced', 'ccp_alpha': 0.0, 'bootstrap': True}\n",
      "\t[52]: 0.651 (+/-0.017) for {'warm_start': True, 'oob_score': True, 'n_estimators': 200, 'min_samples_split': 10, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.2, 'max_leaf_nodes': 5, 'max_features': 'log2', 'max_depth': 20, 'criterion': 'entropy', 'class_weight': 'balanced', 'ccp_alpha': 0.0, 'bootstrap': True}\n",
      "\t[53]: 0.608 (+/-0.053) for {'warm_start': True, 'oob_score': True, 'n_estimators': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_impurity_decrease': 0.0, 'max_leaf_nodes': None, 'max_features': 'sqrt', 'max_depth': 20, 'criterion': 'entropy', 'class_weight': 'balanced_subsample', 'ccp_alpha': 0.1, 'bootstrap': True}\n",
      "\t[54]: 0.097 (+/-0.007) for {'warm_start': False, 'oob_score': True, 'n_estimators': 200, 'min_samples_split': 10, 'min_samples_leaf': 1, 'min_impurity_decrease': 0.0, 'max_leaf_nodes': None, 'max_features': 'log2', 'max_depth': None, 'criterion': 'gini', 'class_weight': 'balanced_subsample', 'ccp_alpha': 0.1, 'bootstrap': True}\n",
      "\t[55]: 0.112 (+/-0.000) for {'warm_start': True, 'oob_score': True, 'n_estimators': 10, 'min_samples_split': 10, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.1, 'max_leaf_nodes': 5, 'max_features': 'log2', 'max_depth': 20, 'criterion': 'gini', 'class_weight': None, 'ccp_alpha': 0.0, 'bootstrap': True}\n",
      "\t[56]: 0.710 (+/-0.007) for {'warm_start': True, 'oob_score': True, 'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.0, 'max_leaf_nodes': 20, 'max_features': 'log2', 'max_depth': 10, 'criterion': 'entropy', 'class_weight': None, 'ccp_alpha': 0.1, 'bootstrap': True}\n",
      "\t[57]: 0.347 (+/-0.024) for {'warm_start': True, 'oob_score': False, 'n_estimators': 10, 'min_samples_split': 2, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.2, 'max_leaf_nodes': None, 'max_features': 'log2', 'max_depth': 10, 'criterion': 'entropy', 'class_weight': None, 'ccp_alpha': 0.0, 'bootstrap': True}\n",
      "\t[58]: 0.112 (+/-0.000) for {'warm_start': False, 'oob_score': False, 'n_estimators': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_impurity_decrease': 0.1, 'max_leaf_nodes': 10, 'max_features': 'log2', 'max_depth': None, 'criterion': 'gini', 'class_weight': None, 'ccp_alpha': 0.1, 'bootstrap': True}\n",
      "\t[59]: 0.825 (+/-0.009) for {'warm_start': True, 'oob_score': True, 'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.0, 'max_leaf_nodes': 10, 'max_features': 'log2', 'max_depth': None, 'criterion': 'gini', 'class_weight': 'balanced', 'ccp_alpha': 0.0, 'bootstrap': True}\n",
      "\t[60]: 0.636 (+/-0.014) for {'warm_start': False, 'oob_score': True, 'n_estimators': 100, 'min_samples_split': 10, 'min_samples_leaf': 1, 'min_impurity_decrease': 0.2, 'max_leaf_nodes': 5, 'max_features': 'log2', 'max_depth': 20, 'criterion': 'entropy', 'class_weight': 'balanced_subsample', 'ccp_alpha': 0.0, 'bootstrap': True}\n",
      "\t[61]: 0.660 (+/-0.007) for {'warm_start': False, 'oob_score': True, 'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.1, 'max_leaf_nodes': 5, 'max_features': 'sqrt', 'max_depth': 10, 'criterion': 'entropy', 'class_weight': None, 'ccp_alpha': 0.1, 'bootstrap': True}\n",
      "\t[62]: 0.817 (+/-0.015) for {'warm_start': True, 'oob_score': False, 'n_estimators': 100, 'min_samples_split': 5, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.0, 'max_leaf_nodes': 10, 'max_features': 'log2', 'max_depth': 30, 'criterion': 'gini', 'class_weight': 'balanced_subsample', 'ccp_alpha': 0.0, 'bootstrap': True}\n",
      "\t[63]: 0.590 (+/-0.032) for {'warm_start': False, 'oob_score': False, 'n_estimators': 10, 'min_samples_split': 10, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.1, 'max_leaf_nodes': 10, 'max_features': 'sqrt', 'max_depth': 30, 'criterion': 'entropy', 'class_weight': None, 'ccp_alpha': 0.0, 'bootstrap': True}\n",
      "\t[64]: 0.404 (+/-0.099) for {'warm_start': False, 'oob_score': True, 'n_estimators': 10, 'min_samples_split': 5, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.1, 'max_leaf_nodes': 5, 'max_features': 'log2', 'max_depth': 20, 'criterion': 'entropy', 'class_weight': 'balanced', 'ccp_alpha': 0.2, 'bootstrap': True}\n",
      "\t[65]: 0.773 (+/-0.008) for {'warm_start': False, 'oob_score': True, 'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.0, 'max_leaf_nodes': 10, 'max_features': 'sqrt', 'max_depth': 30, 'criterion': 'entropy', 'class_weight': None, 'ccp_alpha': 0.0, 'bootstrap': True}\n",
      "\t[66]: 0.102 (+/-0.005) for {'warm_start': False, 'oob_score': True, 'n_estimators': 10, 'min_samples_split': 2, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.2, 'max_leaf_nodes': 10, 'max_features': 'log2', 'max_depth': 10, 'criterion': 'gini', 'class_weight': 'balanced_subsample', 'ccp_alpha': 0.1, 'bootstrap': True}\n",
      "\t[67]: 0.633 (+/-0.017) for {'warm_start': True, 'oob_score': True, 'n_estimators': 100, 'min_samples_split': 5, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.1, 'max_leaf_nodes': None, 'max_features': 'log2', 'max_depth': 10, 'criterion': 'entropy', 'class_weight': 'balanced', 'ccp_alpha': 0.2, 'bootstrap': True}\n",
      "\t[68]: 0.962 (+/-0.003) for {'warm_start': False, 'oob_score': True, 'n_estimators': 100, 'min_samples_split': 10, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.0, 'max_leaf_nodes': None, 'max_features': 'sqrt', 'max_depth': 20, 'criterion': 'gini', 'class_weight': 'balanced_subsample', 'ccp_alpha': 0.0, 'bootstrap': True}\n",
      "\t[69]: 0.653 (+/-0.019) for {'warm_start': False, 'oob_score': True, 'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.1, 'max_leaf_nodes': 10, 'max_features': 'log2', 'max_depth': 30, 'criterion': 'entropy', 'class_weight': 'balanced', 'ccp_alpha': 0.2, 'bootstrap': True}\n",
      "\t[70]: 0.112 (+/-0.000) for {'warm_start': False, 'oob_score': True, 'n_estimators': 10, 'min_samples_split': 2, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.2, 'max_leaf_nodes': 10, 'max_features': 'log2', 'max_depth': 20, 'criterion': 'gini', 'class_weight': None, 'ccp_alpha': 0.2, 'bootstrap': True}\n",
      "\t[71]: 0.097 (+/-0.007) for {'warm_start': True, 'oob_score': True, 'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_impurity_decrease': 0.0, 'max_leaf_nodes': 5, 'max_features': 'sqrt', 'max_depth': 20, 'criterion': 'gini', 'class_weight': 'balanced_subsample', 'ccp_alpha': 0.2, 'bootstrap': True}\n",
      "\t[72]: 0.480 (+/-0.056) for {'warm_start': False, 'oob_score': False, 'n_estimators': 10, 'min_samples_split': 10, 'min_samples_leaf': 1, 'min_impurity_decrease': 0.2, 'max_leaf_nodes': None, 'max_features': 'sqrt', 'max_depth': None, 'criterion': 'entropy', 'class_weight': 'balanced', 'ccp_alpha': 0.0, 'bootstrap': True}\n",
      "\t[73]: 0.097 (+/-0.007) for {'warm_start': False, 'oob_score': False, 'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.2, 'max_leaf_nodes': 20, 'max_features': 'log2', 'max_depth': 20, 'criterion': 'gini', 'class_weight': 'balanced_subsample', 'ccp_alpha': 0.1, 'bootstrap': True}\n",
      "\t[74]: 0.609 (+/-0.011) for {'warm_start': False, 'oob_score': False, 'n_estimators': 10, 'min_samples_split': 2, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.1, 'max_leaf_nodes': 20, 'max_features': 'log2', 'max_depth': 30, 'criterion': 'entropy', 'class_weight': 'balanced', 'ccp_alpha': 0.1, 'bootstrap': True}\n",
      "\t[75]: 0.112 (+/-0.000) for {'warm_start': False, 'oob_score': True, 'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.0, 'max_leaf_nodes': 10, 'max_features': 'log2', 'max_depth': 20, 'criterion': 'gini', 'class_weight': None, 'ccp_alpha': 0.1, 'bootstrap': True}\n",
      "\t[76]: 0.765 (+/-0.010) for {'warm_start': False, 'oob_score': True, 'n_estimators': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_impurity_decrease': 0.0, 'max_leaf_nodes': 5, 'max_features': 'log2', 'max_depth': 20, 'criterion': 'gini', 'class_weight': 'balanced', 'ccp_alpha': 0.0, 'bootstrap': True}\n",
      "\t[77]: 0.097 (+/-0.007) for {'warm_start': False, 'oob_score': True, 'n_estimators': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_impurity_decrease': 0.2, 'max_leaf_nodes': 20, 'max_features': 'sqrt', 'max_depth': 30, 'criterion': 'gini', 'class_weight': 'balanced_subsample', 'ccp_alpha': 0.1, 'bootstrap': True}\n",
      "\t[78]: 0.652 (+/-0.018) for {'warm_start': True, 'oob_score': True, 'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.1, 'max_leaf_nodes': None, 'max_features': 'log2', 'max_depth': 20, 'criterion': 'entropy', 'class_weight': 'balanced_subsample', 'ccp_alpha': 0.2, 'bootstrap': True}\n",
      "\t[79]: 0.112 (+/-0.000) for {'warm_start': True, 'oob_score': True, 'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 1, 'min_impurity_decrease': 0.2, 'max_leaf_nodes': 5, 'max_features': 'log2', 'max_depth': None, 'criterion': 'gini', 'class_weight': None, 'ccp_alpha': 0.1, 'bootstrap': True}\n",
      "\t[80]: 0.963 (+/-0.002) for {'warm_start': False, 'oob_score': True, 'n_estimators': 200, 'min_samples_split': 10, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.0, 'max_leaf_nodes': None, 'max_features': 'sqrt', 'max_depth': 30, 'criterion': 'entropy', 'class_weight': 'balanced', 'ccp_alpha': 0.0, 'bootstrap': True}\n",
      "\t[81]: 0.112 (+/-0.000) for {'warm_start': True, 'oob_score': True, 'n_estimators': 200, 'min_samples_split': 10, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.1, 'max_leaf_nodes': None, 'max_features': 'sqrt', 'max_depth': 10, 'criterion': 'gini', 'class_weight': None, 'ccp_alpha': 0.1, 'bootstrap': True}\n",
      "\t[82]: 0.720 (+/-0.016) for {'warm_start': False, 'oob_score': False, 'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.0, 'max_leaf_nodes': 5, 'max_features': 'sqrt', 'max_depth': 20, 'criterion': 'gini', 'class_weight': 'balanced', 'ccp_alpha': 0.0, 'bootstrap': True}\n",
      "\t[83]: 0.585 (+/-0.012) for {'warm_start': True, 'oob_score': True, 'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_impurity_decrease': 0.2, 'max_leaf_nodes': 20, 'max_features': 'log2', 'max_depth': 30, 'criterion': 'entropy', 'class_weight': None, 'ccp_alpha': 0.0, 'bootstrap': True}\n",
      "\t[84]: 0.577 (+/-0.011) for {'warm_start': True, 'oob_score': True, 'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.2, 'max_leaf_nodes': 5, 'max_features': 'sqrt', 'max_depth': None, 'criterion': 'entropy', 'class_weight': 'balanced', 'ccp_alpha': 0.0, 'bootstrap': True}\n",
      "\t[85]: 0.099 (+/-0.010) for {'warm_start': False, 'oob_score': False, 'n_estimators': 10, 'min_samples_split': 5, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.1, 'max_leaf_nodes': 5, 'max_features': 'sqrt', 'max_depth': 30, 'criterion': 'gini', 'class_weight': 'balanced', 'ccp_alpha': 0.1, 'bootstrap': True}\n",
      "\t[86]: 0.102 (+/-0.005) for {'warm_start': False, 'oob_score': False, 'n_estimators': 10, 'min_samples_split': 5, 'min_samples_leaf': 1, 'min_impurity_decrease': 0.2, 'max_leaf_nodes': 5, 'max_features': 'log2', 'max_depth': 10, 'criterion': 'gini', 'class_weight': 'balanced_subsample', 'ccp_alpha': 0.2, 'bootstrap': True}\n",
      "\t[87]: 0.547 (+/-0.013) for {'warm_start': False, 'oob_score': False, 'n_estimators': 100, 'min_samples_split': 10, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.0, 'max_leaf_nodes': 5, 'max_features': 'sqrt', 'max_depth': 30, 'criterion': 'entropy', 'class_weight': None, 'ccp_alpha': 0.2, 'bootstrap': True}\n",
      "\t[88]: 0.637 (+/-0.017) for {'warm_start': True, 'oob_score': False, 'n_estimators': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_impurity_decrease': 0.0, 'max_leaf_nodes': 5, 'max_features': 'log2', 'max_depth': None, 'criterion': 'entropy', 'class_weight': 'balanced_subsample', 'ccp_alpha': 0.2, 'bootstrap': True}\n",
      "\t[89]: 0.112 (+/-0.000) for {'warm_start': False, 'oob_score': False, 'n_estimators': 10, 'min_samples_split': 2, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.2, 'max_leaf_nodes': 10, 'max_features': 'log2', 'max_depth': 30, 'criterion': 'gini', 'class_weight': None, 'ccp_alpha': 0.0, 'bootstrap': True}\n",
      "\t[90]: 0.097 (+/-0.007) for {'warm_start': False, 'oob_score': True, 'n_estimators': 100, 'min_samples_split': 10, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.2, 'max_leaf_nodes': 5, 'max_features': 'sqrt', 'max_depth': 30, 'criterion': 'gini', 'class_weight': 'balanced_subsample', 'ccp_alpha': 0.1, 'bootstrap': True}\n",
      "\t[91]: 0.739 (+/-0.009) for {'warm_start': False, 'oob_score': True, 'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.0, 'max_leaf_nodes': 5, 'max_features': 'log2', 'max_depth': 20, 'criterion': 'entropy', 'class_weight': 'balanced_subsample', 'ccp_alpha': 0.1, 'bootstrap': True}\n",
      "\t[92]: 0.655 (+/-0.018) for {'warm_start': True, 'oob_score': True, 'n_estimators': 200, 'min_samples_split': 10, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.0, 'max_leaf_nodes': 5, 'max_features': 'log2', 'max_depth': 30, 'criterion': 'entropy', 'class_weight': 'balanced_subsample', 'ccp_alpha': 0.2, 'bootstrap': True}\n",
      "\t[93]: 0.112 (+/-0.000) for {'warm_start': False, 'oob_score': False, 'n_estimators': 10, 'min_samples_split': 5, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.1, 'max_leaf_nodes': 5, 'max_features': 'sqrt', 'max_depth': 10, 'criterion': 'gini', 'class_weight': None, 'ccp_alpha': 0.0, 'bootstrap': True}\n",
      "\t[94]: 0.112 (+/-0.000) for {'warm_start': True, 'oob_score': False, 'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_impurity_decrease': 0.0, 'max_leaf_nodes': 5, 'max_features': 'log2', 'max_depth': None, 'criterion': 'gini', 'class_weight': None, 'ccp_alpha': 0.2, 'bootstrap': True}\n",
      "\t[95]: 0.112 (+/-0.000) for {'warm_start': False, 'oob_score': True, 'n_estimators': 100, 'min_samples_split': 10, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.0, 'max_leaf_nodes': 20, 'max_features': 'sqrt', 'max_depth': 10, 'criterion': 'gini', 'class_weight': None, 'ccp_alpha': 0.1, 'bootstrap': True}\n",
      "\t[96]: 0.740 (+/-0.008) for {'warm_start': True, 'oob_score': False, 'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.1, 'max_leaf_nodes': None, 'max_features': 'log2', 'max_depth': 10, 'criterion': 'entropy', 'class_weight': 'balanced', 'ccp_alpha': 0.1, 'bootstrap': True}\n",
      "\t[97]: 0.097 (+/-0.007) for {'warm_start': True, 'oob_score': False, 'n_estimators': 100, 'min_samples_split': 2, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.0, 'max_leaf_nodes': 5, 'max_features': 'sqrt', 'max_depth': 10, 'criterion': 'gini', 'class_weight': 'balanced_subsample', 'ccp_alpha': 0.1, 'bootstrap': True}\n",
      "\t[98]: 0.577 (+/-0.013) for {'warm_start': False, 'oob_score': False, 'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.2, 'max_leaf_nodes': None, 'max_features': 'sqrt', 'max_depth': 20, 'criterion': 'entropy', 'class_weight': 'balanced_subsample', 'ccp_alpha': 0.1, 'bootstrap': True}\n",
      "\t[99]: 0.631 (+/-0.036) for {'warm_start': False, 'oob_score': False, 'n_estimators': 10, 'min_samples_split': 2, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.1, 'max_leaf_nodes': None, 'max_features': 'sqrt', 'max_depth': 30, 'criterion': 'entropy', 'class_weight': 'balanced_subsample', 'ccp_alpha': 0.1, 'bootstrap': True}\n",
      "\n",
      "Detailed classification report:\n",
      "\tThe model is trained on the full development set.\n",
      "\tThe scores are computed on the full evaluation set.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98      2077\n",
      "           1       0.99      0.98      0.99      2385\n",
      "           2       0.95      0.97      0.96      2115\n",
      "           3       0.97      0.94      0.95      2117\n",
      "           4       0.96      0.97      0.96      2004\n",
      "           5       0.96      0.96      0.96      1900\n",
      "           6       0.97      0.98      0.97      2045\n",
      "           7       0.97      0.96      0.96      2189\n",
      "           8       0.95      0.95      0.95      2042\n",
      "           9       0.95      0.94      0.94      2126\n",
      "\n",
      "    accuracy                           0.96     21000\n",
      "   macro avg       0.96      0.96      0.96     21000\n",
      "weighted avg       0.96      0.96      0.96     21000\n",
      "\n",
      "\n",
      "CTOR for best model: RandomForestClassifier(class_weight='balanced', criterion='entropy',\n",
      "                       max_depth=30, min_samples_leaf=2, min_samples_split=10,\n",
      "                       n_estimators=200, oob_score=True, random_state=83)\n",
      "\n",
      "best: dat=mnist, score=0.96282, model=RandomForestClassifier(bootstrap=True,ccp_alpha=0.0,class_weight='balanced',criterion='entropy',max_depth=30,max_features='sqrt',max_leaf_nodes=None,min_impurity_decrease=0.0,min_samples_leaf=2,min_samples_split=10,n_estimators=200,oob_score=True,warm_start=False)\n",
      "\n",
      "OK(grid-search)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Setup data\n",
    "X_train, X_test, y_train, y_test = LoadAndSetupData(\n",
    "    'mnist')  # 'iris', 'moon', or 'mnist'\n",
    "\n",
    "# Setup search parameters\n",
    "model = RandomForestClassifier(\n",
    "    random_state=83\n",
    ")  \n",
    "\n",
    "tuning_parameters = {\n",
    "    'n_estimators': [10, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'class_weight': [None, 'balanced', 'balanced_subsample'],\n",
    "    'max_leaf_nodes': [None, 5, 10, 20],\n",
    "    'min_impurity_decrease': [0.0, 0.1, 0.2],\n",
    "    'oob_score': [True, False],\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "    'bootstrap': [True],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'warm_start': [True, False],\n",
    "    'ccp_alpha': [0.0, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "CV = 5\n",
    "VERBOSE = 0\n",
    "\n",
    "# Run GridSearchCV for the model\n",
    "grid_tuned = RandomizedSearchCV(model, \n",
    "                                tuning_parameters, \n",
    "                                n_iter=100, \n",
    "                                random_state=69, \n",
    "                                cv=CV, \n",
    "                                scoring='f1_micro', \n",
    "                                verbose=VERBOSE, \n",
    "                                n_jobs=-1)\n",
    "\n",
    "start = time()\n",
    "grid_tuned.fit(X_train, y_train)\n",
    "t = time() - start\n",
    "\n",
    "# Report result\n",
    "b0, m0 = FullReport(grid_tuned, X_test, y_test, t)\n",
    "print('OK(grid-search)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Conclusion__\n",
    "\n",
    "We made various adjustments, tweaking parameters like the number of iterations (n_iter), max-depth, min sample split, and others. Despite these changes, the accuracy score stayed close to an average of 0.96, with only a slight 0.001 difference after tuning. This hints that the dataset might not contain enough information to achieve a significantly higher accuracy score. The best result is as follows:\n",
    "\n",
    "Best Result: Dataset=MNIST, Score=0.96553, Model=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced_subsample', criterion='entropy', max_depth=20, max_features='sqrt', max_leaf_nodes=None, min_impurity_decrease=0.0, min_samples_leaf=1, min_samples_split=5, n_estimators=200, oob_score=False, warm_start=True)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T09:41:04.899707Z",
     "start_time": "2023-11-30T09:41:04.896610Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SWMAL Exercise\n",
    "\n",
    "## Advanced CNN using Roboflow\n",
    "\n",
    "### Finding a dataset\n",
    "We went to roboflow and found the face detection dataset which was already labeled, then we downloaded it and created a project with YOLOv8 as the model. After that we uploaded to roboflow project.\n",
    "\n",
    "![\"Dataset.png\"](Dataset.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating the model\n",
    "In roboflow we followed the step by step guide to generate the model. We used the default settings. \n",
    "\n",
    "![\"GenerateModel.png\"](GenerateModel.png)\n",
    "\n",
    "\n",
    "### Training the model\n",
    "After having generated the model we then trained it. This again was done following the roboflow steps. We press train with roboflow and select fast option, then the Train from previous checkpoint option. We then wait for the model to train this took around two hours.\n",
    "\n",
    "### Training graphs\n",
    "\n",
    "Below are pictures of the result of training. \n",
    "There is the mAP, Box loss, Class loss and object loss:\n",
    "![\"graphs.png\"](graphs.png)\n",
    "\n",
    "<img src=\"graphs.png\" style=\"height:500px\">\n",
    "\n",
    "![\"Numbers.png\"](Numbers.png)\n",
    "\n",
    "<img src=\"Numbers.png\" style=\"height:500px\">\n",
    "\n",
    "### Conclussion\n",
    "\n",
    "Precision: 92.1% \n",
    "\n",
    "mAP (Average of average precision metric): 87,5%\n",
    "\n",
    "Recall (percentage of relevant labels that were correctly classified): 72.1%\n",
    "\n",
    "Overall the precision is good in the low 90s, but the recall is not as good. This means that the model is good at finding faces, but it is not as good at finding all the faces. In terms of the train, validate and test split the dataset is not equally split in desired ratio.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T09:41:04.902172Z",
     "start_time": "2023-11-30T09:41:04.899598Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
