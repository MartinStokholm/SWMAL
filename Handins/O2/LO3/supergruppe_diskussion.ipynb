{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SWMAL Exercise\n",
    "\n",
    "\n",
    "## Supergruppe diskussion\n",
    "\n",
    "\n",
    "## ยง 2 \"End-to-End Machine Learning Project\" [HOML]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resume: Look at the Big Picture\n",
    "\n",
    "The first chapter explains what machine learning is in general through an example on how to predict the median of housing prices in California based on population data. It explains that you need to frame the problem correctly, so you are able to select the correct algorithms, which performance measure is used to evalute the model and how much effort is needed to tweak it. What kind of learning is needed - Supervised, unsupervised or Reinforcement? What kind of task is it a classification, a regression or other? And which learning technice is used batch og online. Example in this chapter is a typical supervised learning task, that has a typical regression task that is a mulivariation regression problem and is plain batch learning.\n",
    "\n",
    "The chapter also introduces the concept of a data pipeline which are a sequence of data processing components and are very common in Machine Learning systems to process and transform data asynchronously. The District Pricing is an example of a component. A pipeline makes for a good arcitecture but a broken component can be hard to detect if monitoring isn't done.\n",
    "\n",
    "After framing the problem you need to select a performance measure. Root Mean Square Error (RMSE) is typically a suitable option when working with a regression model as it measures the standard deviation of the errors of predictions. Mean absolute error (MAE) can also be used but is more commonly used in situations where there are numerous outliers.\n",
    "\n",
    "The chapter also highlights the importance of validating assumptions about the project since errors in these assumptions can lead to incorrect decisions later in the process. For instance, the author investigates whether the downstream machine learning system that receives housing price predictions actually uses the prices as they are or converts them into categories. This critical thinking and problem clarification are essential to avoid wasting resources and time in the project.\n",
    "\n",
    "\n",
    "#### Resume: Get the Data\n",
    "\n",
    "The section concludes by describing how to create a test set for machine learning, including various methods for splitting data into a training set and a test set. It also explains how stratified sampling can be used to create a test set that is representative of different categories in the dataset.\n",
    "\n",
    "There are many different ways to gather data from which might be available in an online database, or might have to be collected by one self. It really depends on what you are making a machine learning model for. \n",
    "When you have the needed data, writing a function that handles the data automatically instead of doing the manual labor of decompressing all the data. \n",
    "\n",
    "In summary, this section is about preparing data and establishing a test set to ensure that the machine learning system is trained and evaluated correctly.\n",
    "\n",
    "\n",
    "#### Resume: Explore and Visualize the Data to Gain Insights,\n",
    "\n",
    "In this phase of the project, the focus is on exploring and visualizing the dataset. The training set is isolated, and a copy is created for exploration. Geographical data is visualized using scatterplots to identify patterns in the dataset, and correlation analysis is conducted to assess relationships between attributes and median house prices. Additionally, experiments are carried out with combinations of attributes to uncover new associations. This step is crucial for gaining insights into the data before utilizing it in machine learning algorithms, and it contributes to making informed decisions regarding data cleaning and feature engineering.   \n",
    "\n",
    "#### Resume: Prepare the Data for Machine Learning Algorithms\n",
    "\n",
    "In this step, the data is prepared for machine learning algorithms. Features are created to perform data cleaning, transformations, and scaling processes. First, the training data is separated concerning the target variable (median house price), and data cleaning is performed to address missing values. Techniques such as standardization and min-max scaling are also employed to ensure that the data is on the same scale. Additionally, a transformation pipeline is created to automate these steps and make them reusable. Finally, ColumnTransformer is used to apply the necessary transformations to both numerical and categorical attributes simultaneously. This process is crucial for preparing the data for training machine learning models. \n",
    "\n",
    "#### Resume: Select and Train a Model\n",
    "\n",
    "Selectiong a model is a crucial phase in the machine learning workflow. During this step, you choose a machine learning algorithm, train it on your prepared data, and assess its performance. This typically involves starting with a basic model, such as Linear Regression, and then experimenting with more complex models like Decision Trees or Random Forests. You evaluate these models for issues like underfitting or overfitting, aiming for the right balance to achieve optimal predictive accuracy. Cross-validation is often used to ensure robust performance assessment. The ultimate goal is to find the best model for your specific problem and dataset before proceeding with the training process.\n",
    "\n",
    "#### Resume: Fine-Tune Your Model\n",
    "In this section, the process of refining machine learning models is discussed. After shortlisting promising models, the focus turns to optimizing them. The two primary methods for this are Grid Search and Randomized Search.\n",
    "\n",
    "Grid Search involves systematically trying out combinations of hyperparameter values to find the best configuration. This can be a time-consuming process but is made easier by tools like Scikit-Learn's GridSearchCV, which evaluates various combinations of hyperparameters using cross-validation.\n",
    "\n",
    "Randomized Search, on the other hand, selects random values for hyperparameters in each iteration, making it more efficient when dealing with a large hyperparameter search space.\n",
    "\n",
    "Once the best model is determined, it can be further improved by combining it with other models, creating an ensemble. This ensemble approach is particularly effective when individual models make different types of errors.\n",
    "\n",
    "To gain insights into a model's performance, examining feature importances can help identify which attributes are crucial for predictions. This information can guide decisions on feature selection and cleaning. Additionally, analyzing the specific errors your model makes can provide valuable insights into how to further enhance its performance.\n",
    "\n",
    "After fine-tuning a model, it's time to test it on the test set. Consider a confidence interval for the generalization error. While test set performance may be slightly worse than during cross-validation due to fine-tuning, avoid tweaking hyperparameters for test set improvement. In the project pre-launch phase, summarize your work, present key findings, and acknowledge system limitations. Clear documentation and visual presentations are crucial. Even if the model doesn't outperform experts, it can be valuable and free up their time for more interesting tasks.\n",
    "\n",
    "#### Resume: Launch, Monitor, and Maintain Your System\n",
    "\n",
    "In this phase, you prepare your solution for production by integrating data sources, writing tests, and implementing continuous monitoring to detect issues and performance degradation. Human analysis, data quality checks, and regular model updates are crucial. Automated training and snapshots of the system's state ensure stability and performance over time, particularly for online learning systems. This phase ensures your system is production-ready and maintained effectively.\n",
    "\n",
    "#### Resume: Try It Out!.\n",
    "\n",
    "The last chapter is about trying out all the different things we already read about earlier in the chapter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
